@INPROCEEDINGS{8332632,
author={Liu, He and Huang, Fupeng and Li, Han and Liu, Weiwei and Wang, Tongxun},
booktitle={2017 14th Web Information Systems and Applications Conference (WISA)},
title={A Big Data Framework for Electric Power Data Quality Assessment},
year={2017},
volume={},
number={},
pages={289-292},
abstract={Since a low-quality data may influence the effectiveness and reliability of applications, data quality is required to be guaranteed. Data quality assessment is considered as the foundation of the promotion of data quality, so it is essential to access the data quality before any other data related activities. In the electric power industry, more and more electric power data is continuously accumulated, and many electric power applications have been developed based on these data. In China, the power grid has many special characteristic, traditional big data assessment frameworks cannot be directly applied. Therefore, a big data framework for electric power data quality assessment is proposed. Based on big data techniques, the framework can accumulate both the real-time data and the history data, provide an integrated computation environment for electric power big data assessment, and support the storage of different types of data.},
keywords={Big Data;Data integrity;Power grids;History;Real-time systems;Sensors;data quality;electric power data;data quality assessment;big data;framework},
doi={10.1109/WISA.2017.29},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8029366,
author={Taleb, Ikbal and Serhani, Mohamed Adel},
booktitle={2017 IEEE International Congress on Big Data (BigData Congress)},
title={Big Data Pre-Processing: Closing the Data Quality Enforcement Loop},
year={2017},
volume={},
number={},
pages={498-501},
abstract={In the Big Data Era, data is the core for any governmental, institutional, and private organization. Efforts were geared towards extracting highly valuable insights that cannot happen if data is of poor quality. Therefore, data quality (DQ) is considered as a key element in Big data processing phase. In this stage, low quality data is not penetrated to the Big Data value chain. This paper, addresses the data quality rules discovery (DQR) after the evaluation of quality and prior to Big Data pre-processing. We propose a DQR discovery model to enhance and accurately target the pre-processing activities based on quality requirements. We defined, a set of pre-processing activities associated with data quality dimensions (DQD's) to automatize the DQR generation process. Rules optimization are applied on validated rules to avoid multi-passes pre-processing activities and eliminates duplicate rules. Conducted experiments showed an increased quality scores after applying the discovered and optimized DQR's on data.},
keywords={Big Data;Optimization;Data models;Quality assessment;Big Data;Data Quality Evaluation;Data Quality Rules Discovery;Big Data Pre-Processing},
doi={10.1109/BigDataCongress.2017.73},
ISSN={},
month={June},}
@INPROCEEDINGS{9245455,
author={Loetpipatwanich, Sakda and Vichitthamaros, Preecha},
booktitle={2020 1st International Conference on Big Data Analytics and Practices (IBDAP)},
title={Sakdas: A Python Package for Data Profiling and Data Quality Auditing},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Data Profiling and data quality management become a more significant part of data engineering, which an essential part of ensuring that the system delivers quality information to users. In the last decade, data quality was considered to need more managing. Especially in the big data era that the data comes from many sources, many data types, and an enormous amount. Thus it makes the managing of data quality is more difficult and complicated. The traditional system was unable to respond as needed. The data quality managing software for big data was developed but often found in a high-priced, difficult to customize as needed, and mostly provide as GUI, which is challenging to integrate with other systems. From this problem, we have developed an opensource package for data quality managing. By using Python programming language, Which is a programming language that is widely used in the scientific and engineering field today. Because it is a programming language that is easy to read syntax, small, and has many additional packages to integrate. The software developed here is called “Sakdas” this package has been divided into three parts. The first part deals with data profiling provide a set of data analyses to generate a data profile, and this profile will help to define the data quality rules. The second part deals with data quality auditing that users can set their own data quality rules for data quality measurement. The final part deals with data visualizing that provides data profiling and data auditing report to improve the data quality. The results of the profiling and auditing services, the user can specify both the form of a report for self-review. Or in the form of JSON for use in post-process automation.},
keywords={Data integrity;Pipelines;Data visualization;Big Data;Syntactics;Software;Python;Data Quality Management;Data Profiling;Data Quality Auditing;Python Package;Data Pipeline},
doi={10.1109/IBDAP50342.2020.9245455},
ISSN={},
month={Sep.},}
