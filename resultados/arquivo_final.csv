,sourceid,title_csv,type,issn,sjr,sjr best quartile,h index,total docs. (2020),total docs. (3years),total refs.,total cites (3years),citable docs. (3years),cites / doc. (2years),ref. / doc.,country,region,publisher,coverage,categories,total cites,journal impact factor,eigenfactor score,abstract,doi,year,author,title_bib,type_publication
0,22401,JOURNAL OF THE AMERICAN COLLEGE OF CARDIOLOGY,journal,07351097,"10,315",Q1,431,935,2960,22363,23475,1191,"7,44","23,92",United States,Northern America,Elsevier USA,1983-2020,Cardiology and Cardiovascular Medicine (Q1),"125,873",24.094,0.177,"Data science is likely to lead to major changes in cardiovascular imaging. Problems with timing, efficiency, and missed diagnoses occur at all stages of the imaging chain. The application of artificial intelligence (AI) is dependent on robust data; the application of appropriate computational approaches and tools; and validation of its clinical application to image segmentation, automated measurements, and eventually, automated diagnosis. AI may reduce cost and improve value at the stages of image acquisition, interpretation, and decision-making. Moreover, the precision now possible with cardiovascular imaging, combined with “big data” from the electronic health record and pathology, is likely to better characterize disease and personalize therapy. This review summarizes recent promising applications of AI in cardiology and cardiac imaging, which potentially add value to patient care.",https://doi.org/10.1016/j.jacc.2018.12.054,2019,Damini Dey and Piotr J. Slomka and Paul Leeson and Dorin Comaniciu and Sirish Shrestha and Partho P. Sengupta and Thomas H. Marwick,ARTIFICIAL INTELLIGENCE IN CARDIOVASCULAR IMAGING: JACC STATE-OF-THE-ART REVIEW,article
1,21149,LEADERSHIP QUARTERLY,journal,10489843,"4,989",Q1,151,78,150,9416,1576,142,"9,94","120,72",United States,Northern America,Elsevier Inc.,1990-2020,Applied Psychology (Q1); Business and International Management (Q1); Organizational Behavior and Human Resource Management (Q1); Sociology and Political Science (Q1),"14,059",10.517,0.00895,"Machine Learning (ML) techniques offer exciting new avenues for leadership research. In this paper we discuss how ML techniques can be used to inform predictive and causal models of leadership effects and clarify why both types of model are important for leadership research. We propose combining ML and experimental designs to draw causal inferences by introducing a recently developed technique to isolate “heterogeneous treatment effects.” We provide a step-by-step guide on how to design studies that combine field experiments with the application of ML to establish causal relationships with maximal predictive power. Drawing on examples in the leadership literature, we illustrate how the suggested approach can be applied to examine the impact of, for example, leadership behavior on follower outcomes. We also discuss how ML can be used to advance leadership research from theoretical, methodological and practical perspectives and consider limitations.",https://doi.org/10.1016/j.leaqua.2020.101426,2020,Allan Lee and Ilke Inceoglu and Oliver Hauser and Michael Greene,DETERMINING CAUSAL RELATIONSHIPS IN LEADERSHIP RESEARCH USING MACHINE LEARNING: THE POWERFUL SYNERGY OF EXPERIMENTS AND DATA SCIENCE,article
2,17600155011,MOLECULAR PLANT,journal,16742052,"4,588",Q1,115,153,474,8872,4792,380,"9,60","57,99",United States,Northern America,Cell Press,2008-2020,Molecular Biology (Q1); Plant Science (Q1),"15,778",13.164,0.02686,"The first paradigm of plant breeding involves direct selection based phenotypic observation, followed by predictive breeding using statistical models constructed for quantitative traits based on genetic experimental design and more recently by incorporating molecular marker genotypes. However, plant performance or phenotype (P) is determined by the combining effects of genotype (G), envirotype (E) and genotype by environment interaction (GEI). Phenotypes can be predicted more precisely by training a model using data collected from multiple sources, including spatiotemporal omics (genomics, phenomics and enviromics across time and space). Integration of 3D information profiles (G-P-E), each with multidimensionality, provides predictive breeding with both tremendous opportunities and great challenges. Here, we first review innovative technologies for predictive breeding. We then evaluate multidimensional information profiles that can be integrated with a predictive breeding strategy, particularly envirotypic data, which have largely been neglected in data collection and nearly untouched in model construction. We propose a smart breeding scheme, integrated genomic-enviromic prediction (iGEP), as an extension of genomic prediction, using integrated multiomics information, big data technology and artificial intelligence (mainly focus on machine and deep learning). How to implement iGEP was discussed, including spatiotemporal models, environmental indices, factorial and spatiotemporal structure of plant breeding data, and cross-species prediction. A strategy is then proposed for prediction-based crop redesign at both the macro (individual, population and species) and micro (gene, metabolism and network) scales. Finally, we provide perspectives on translating the smart breeding into genetic gain through integrative breeding platforms and open-source breeding initiatives. We call for coordinated efforts in smart breeding through iGEP, institutional partnerships, and innovative technological support.",https://doi.org/10.1016/j.molp.2022.09.001,2022,Yunbi Xu and Xingping Zhang and Huihui Li and Hongjian Zheng and Jianan Zhang and Michael S. Olsen and Rajeev K. Varshney and Boddupalli M. Prasanna and Qian Qian,"SMART BREEDING DRIVEN BY BIG DATA, ARTIFICIAL INTELLIGENCE AND INTEGRATED GENOMIC-ENVIROMIC PREDICTION",article
3,17600155011,MOLECULAR PLANT,journal,16742052,"4,588",Q1,115,153,474,8872,4792,380,"9,60","57,99",United States,Northern America,Cell Press,2008-2020,Molecular Biology (Q1); Plant Science (Q1),"15,778",13.164,0.02686,,https://doi.org/10.1016/j.molp.2019.01.008,2019,Yoshiaki Ueda and Shuichi Yanagisawa,DELINEATION OF NITROGEN SIGNALING NETWORKS: COMPUTATIONAL APPROACHES IN THE BIG DATA ERA,article
4,17809,TRENDS IN PLANT SCIENCE,journal,13601385,"4,587",Q1,263,162,386,9428,4844,377,"11,39","58,20",United Kingdom,Western Europe,Elsevier Ltd.,1996-2020,Plant Science (Q1),"29,531",18.313,0.02277,"Optical sensors and sensing-based phenotyping techniques have become mainstream approaches in high-throughput phenotyping for improving trait selection and genetic gains in crops. We review recent progress and contemporary applications of optical sensing-based phenotyping (OSP) techniques in cereal crops and highlight optical sensing principles for spectral response and sensor specifications. Further, we group phenotypic traits determined by OSP into four categories – morphological, biochemical, physiological, and performance traits – and illustrate appropriate sensors for each extraction. In addition to the current status, we discuss the challenges of OSP and provide possible solutions. We propose that optical sensing-based traits need to be explored further, and that standardization of the language of phenotyping and worldwide collaboration between phenotyping researchers and other fields need to be established.",https://doi.org/10.1016/j.tplants.2021.07.015,2022,Dawei Sun and Kelly Robbins and Nicolas Morales and Qingyao Shu and Haiyan Cen,ADVANCES IN OPTICAL PHENOTYPING OF CEREAL CROPS,article
5,6400153137,JOURNAL OF THORACIC ONCOLOGY,journal,15560864,"4,539",Q1,133,316,1028,6973,6688,581,"6,04","22,07",United States,Northern America,International Association for the Study of Lung Cancer,2006-2020,Medicine (miscellaneous) (Q1); Oncology (Q1); Pulmonary and Respiratory Medicine (Q1),"24,405",15.609,0.04278,,https://doi.org/10.1016/j.jtho.2022.02.010,2022,Ahmed Salem and Kevin Franks and Alastair Greystoke and Gerard G. Hanna and Stephen Harrow and Matthew Hatton and Crispin Hiley and Fiona McDonald and Corinne Faivre-Finn,UNACCOUNTED CONFOUNDERS LIMIT THE ABILITY TO DRAW CONCLUSIONS FROM BIG DATA ANALYSIS COMPARING RADIOTHERAPY FRACTIONATION REGIMENS IN NSCLC,article
6,21100943502,MATTER,journal,25902385,"4,138",Q1,22,322,156,15168,1414,133,"9,06","47,11",United States,Northern America,Cell Press,2019-2020,Materials Science (miscellaneous) (Q1),"2,357",15.589,0.00396,"With thousands of publications per year, the volume of data published on perovskite solar cells since the spark of the “perovskite fever” in 2013 is enormous and far exceeds the amount that any individual researcher could digest. To tackle this issue, Jacobsson et al.1 have created The Perovskite Database, which is part of a larger trend to harness the power of big data and artificial intelligence to accelerate the commercialization of perovskite solar cells.",https://doi.org/10.1016/j.matt.2022.06.001,2022,Kameron R. Hansen and Luisa Whittaker-Brooks,FINDING THE FAIRNESS IN PEROVSKITE PHOTOVOLTAICS RESEARCH,article
7,24046,SEMINARS IN CANCER BIOLOGY,journal,1044579X,"3,908",Q1,148,287,310,47920,3555,286,"11,39","166,97",United States,Northern America,Academic Press Inc.,1990-2020,Cancer Research (Q1),"11,552",15.707,0.01211,"Radiotherapy is a discipline closely integrated with computer science. Artificial intelligence (AI) has developed rapidly over the past few years. With the explosive growth of medical big data, AI promises to revolutionize the field of radiotherapy through highly automated workflow, enhanced quality assurance, improved regional balances of expert experiences, and individualized treatment guided by multi-omics. In addition to independent researchers, the increasing number of large databases, biobanks, and open challenges significantly facilitated AI studies on radiation oncology. This article reviews the latest research, clinical applications, and challenges of AI in each part of radiotherapy including image processing, contouring, planning, quality assurance, motion management, and outcome prediction. By summarizing cutting-edge findings and challenges, we aim to inspire researchers to explore more future possibilities and accelerate the arrival of AI radiotherapy.",https://doi.org/10.1016/j.semcancer.2022.08.005,2022,Guangqi Li and Xin Wu and Xuelei Ma,ARTIFICIAL INTELLIGENCE IN RADIOTHERAPY,article
8,15537,CURRENT BIOLOGY,journal,09609822,"3,822",Q1,316,929,2432,38487,15523,2265,"5,99","41,43",United States,Northern America,Cell Press,1991-2020,"Agricultural and Biological Sciences (miscellaneous) (Q1); Biochemistry, Genetics and Molecular Biology (miscellaneous) (Q1); Neuroscience (miscellaneous) (Q1)","78,289",10.834,0.1161,"Summary
Fungi have successfully established themselves across seemingly every possible niche, substrate, and biome. They are fundamental to biogeochemical cycling, interspecies interactions, food production, and drug bioprocessing, as well as playing less heroic roles as difficult to treat human infections and devastating plant pathogens. Despite community efforts to estimate and catalog fungal diversity, we have only named and described a minute fraction of the fungal world. The identification, characterization, and conservation of fungal diversity is paramount to preserving fungal bioresources, and to understanding and predicting ecosystem cycling and the evolution and epidemiology of fungal disease. Although species and ecosystem conservation are necessarily the foundation of preserving this diversity, there is value in expanding our definition of conservation to include the protection of biological collections, ecological metadata, genetic and genomic data, and the methods and code used for our analyses. These definitions of conservation are interdependent. For example, we need metadata on host specificity and biogeography to understand rarity and set priorities for conservation. To aid in these efforts, we need to draw expertise from diverse fields to tie traditional taxonomic knowledge to data obtained from modern -omics-based approaches, and support the advancement of diverse research perspectives. We also need new tools, including an updated framework for describing and tracking species known only from DNA, and the continued integration of functional predictions to link genetic diversity to functional and ecological diversity. Here, we review the state of fungal diversity research as shaped by recent technological advancements, and how changing viewpoints in taxonomy, -omics, and systematics can be integrated to advance mycological research and preserve fungal biodiversity.",https://doi.org/10.1016/j.cub.2021.06.083,2021,Lotus A. Lofgren and Jason E. Stajich,"FUNGAL BIODIVERSITY AND CONSERVATION MYCOLOGY IN LIGHT OF NEW TECHNOLOGY, BIG DATA, AND CHANGING ATTITUDES",article
9,28973,JOURNAL OF ECONOMETRICS,journal,03044076,"3,769",Q1,159,241,418,11045,1497,408,"3,38","45,83",Netherlands,Western Europe,Elsevier BV,1973-2020,Applied Mathematics (Q1); Economics and Econometrics (Q1); History and Philosophy of Science (Q1),"25,569",2.388,0.02085,"Nearly all studies that analyze the term structure of interest rates take a two-step approach. First, actual bond prices are summarized by interpolated synthetic zero-coupon yields, and second, some of these yields are used as the source data for further empirical examination. In contrast, we consider the advantages of a one-step approach that directly analyzes the universe of bond prices. To illustrate the feasibility and desirability of the one-step approach, we compare arbitrage-free dynamic term structure models estimated using both approaches. We also provide a simulation study showing that a one-step approach can extract the information in large panels of bond prices and avoid any arbitrary noise introduced from a first-stage interpolation of yields.",https://doi.org/10.1016/j.jeconom.2019.04.019,2019,Martin M. Andreasen and Jens H.E. Christensen and Glenn D. Rudebusch,TERM STRUCTURE ANALYSIS WITH BIG DATA: ONE-STEP ESTIMATION USING BOND PRICES,article
10,130050,OCULAR SURFACE,journal,15420124,"3,505",Q1,65,120,234,5895,1932,204,"3,81","49,13",United States,Northern America,Elsevier Inc.,2003-2020,Ophthalmology (Q1),"4,145",5.033,0.00623,,https://doi.org/10.1016/j.jtos.2019.07.010,2019,C.J. Puranik and Sreenivasa Rao and S. Chennamaneni,THE PERILS AND PITFALLS OF BIG DATA ANALYSIS IN MEDICINE,article
11,16547,TOURISM MANAGEMENT,journal,02615177,"3,328",Q1,199,159,690,11910,8354,687,"11,06","74,91",United Kingdom,Western Europe,Elsevier Ltd.,1982-2021,"Development (Q1); Strategy and Management (Q1); Tourism, Leisure and Hospitality Management (Q1); Transportation (Q1)","37,117",10.967,0.02226,"Even at an early stage, diverse big data have been applied to tourism research and made an amazing improvement. This paper might be the first attempt to present a comprehensive literature review on different types of big data in tourism research. By data sources, the tourism-related big data fall into three primary categories: UGC data (generated by users), including online textual data and online photo data; device data (by devices), including GPS data, mobile roaming data, Bluetooth data, etc.; transaction data (by operations), including web search data, webpage visiting data, online booking data, etc. Carrying different information, different data types address different tourism issues. For each type, a systematical analysis is conducted from the perspectives of research focuses, data characteristics, analytic techniques, major challenges and further directions. This survey facilitates a thorough understanding of this sunrise research and offers valuable insights into its future prospects.",https://doi.org/10.1016/j.tourman.2018.03.009,2018,Jingjing Li and Lizhi Xu and Ling Tang and Shouyang Wang and Ling Li,BIG DATA IN TOURISM RESEARCH: A LITERATURE REVIEW,article
12,17495,NEUROIMAGE,journal,10538119,"3,259",Q1,364,981,2802,73619,20526,2767,"6,82","75,04",United States,Northern America,Academic Press Inc.,"1970, 1992-2020",Cognitive Neuroscience (Q1); Neurology (Q1),"119,618",6.556,0.10582,"We analyzed factors that may hamper the advancement of computational cognitive neuroscience (CCN). These factors include a particular statistical mindset, which paves the way for the dominance of statistical power theory and a preoccupation with statistical replicability in the behavioral and neural sciences. Exclusive statistical concerns about sampling error occur at the cost of an inadequate representation of the problem of measurement error. We contrasted the manipulation of data quantity (sampling error, by varying the number of subjects) against the manipulation of data quality (measurement error, by varying the number of data per subject) in a simulated Bayesian model identifiability study. The results were clear-cut in showing that - across all levels of signal-to-noise ratios - varying the number of subjects was completely inconsequential, whereas the number of data per subject exerted massive effects on model identifiability. These results emphasize data quality over data quantity, and they call for the integration of statistics and measurement theory.",https://doi.org/10.1016/j.neuroimage.2018.01.005,2018,Antonio Kolossa and Bruno Kopp,DATA QUALITY OVER DATA QUANTITY IN COMPUTATIONAL COGNITIVE NEUROSCIENCE,article
13,17495,NEUROIMAGE,journal,10538119,"3,259",Q1,364,981,2802,73619,20526,2767,"6,82","75,04",United States,Northern America,Academic Press Inc.,"1970, 1992-2020",Cognitive Neuroscience (Q1); Neurology (Q1),"119,618",6.556,0.10582,"Brain activity is a dynamic combination of the responses to sensory inputs and its own spontaneous processing. Consequently, such brain activity is continuously changing whether or not one is focusing on an externally imposed task. Previously, we have introduced an analysis method that allows us, using Hidden Markov Models (HMM), to model task or rest brain activity as a dynamic sequence of distinct brain networks, overcoming many of the limitations posed by sliding window approaches. Here, we present an advance that enables the HMM to handle very large amounts of data, making possible the inference of very reproducible and interpretable dynamic brain networks in a range of different datasets, including task, rest, MEG and fMRI, with potentially thousands of subjects. We anticipate that the generation of large and publicly available datasets from initiatives such as the Human Connectome Project and UK Biobank, in combination with computational methods that can work at this scale, will bring a breakthrough in our understanding of brain function in both health and disease.",https://doi.org/10.1016/j.neuroimage.2017.06.077,2018,Diego Vidaurre and Romesh Abeysuriya and Robert Becker and Andrew J. Quinn and Fidel Alfaro-Almagro and Stephen M. Smith and Mark W. Woolrich,DISCOVERING DYNAMIC BRAIN NETWORKS FROM BIG DATA IN REST AND TASK,article
14,16146,TRENDS IN BIOTECHNOLOGY,journal,01677799,"3,192",Q1,219,167,397,11206,4561,346,"11,86","67,10",United Kingdom,Western Europe,Elsevier Ltd.,1983-2020,Bioengineering (Q1); Biotechnology (Q1),"20,693",19.536,0.01817,"Batch effects (BEs) are technical biases that may confound analysis of high-throughput biotechnological data. BEs are complex and effective mitigation is highly context-dependent. In particular, the advent of high-resolution technologies such as single-cell RNA sequencing presents new challenges. We first cover how BE modeling differs between traditional datasets and the new data landscape. We also discuss new approaches for measuring and mitigating BEs, including whether a BE is significant enough to warrant correction. Even with the advent of machine learning and artificial intelligence, the increased complexity of next-generation biotechnological data means increased complexities in BE management. We forecast that BEs will not only remain relevant in the age of big data but will become even more important.",https://doi.org/10.1016/j.tibtech.2022.02.005,2022,Wilson Wen Bin Goh and Chern Han Yong and Limsoon Wong,ARE BATCH EFFECTS STILL RELEVANT IN THE AGE OF BIG DATA?,article
15,22990,JOURNAL OF RETAILING,journal,00224359,"3,184",Q1,136,66,98,4311,839,87,"4,51","65,32",United Kingdom,Western Europe,Elsevier BV,1993-2020,Marketing (Q1),"10,594",5.245,0.00458,"The paper examines the opportunities in and possibilities arising from big data in retailing, particularly along five major data dimensions—data pertaining to customers, products, time, (geo-spatial) location and channel. Much of the increase in data quality and application possibilities comes from a mix of new data sources, a smart application of statistical tools and domain knowledge combined with theoretical insights. The importance of theory in guiding any systematic search for answers to retailing questions, as well as for streamlining analysis remains undiminished, even as the role of big data and predictive analytics in retailing is set to rise in importance, aided by newer sources of data and large-scale correlational techniques. The Statistical issues discussed include a particular focus on the relevance and uses of Bayesian analysis techniques (data borrowing, updating, augmentation and hierarchical modeling), predictive analytics using big data and a field experiment, all in a retailing context. Finally, the ethical and privacy issues that may arise from the use of big data in retailing are also highlighted.",https://doi.org/10.1016/j.jretai.2016.12.004,2017,Eric T. Bradlow and Manish Gangwar and Praveen Kopalle and Sudhir Voleti,THE ROLE OF BIG DATA AND PREDICTIVE ANALYTICS IN RETAILING,article
16,12396,JOURNAL OF STRATEGIC INFORMATION SYSTEMS,journal,09638687,"3,133",Q1,88,24,75,2111,965,61,"12,45","87,96",Netherlands,Western Europe,Elsevier,1991-2020,Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"2,945",11.022,0.00233,"Big data has been considered to be a breakthrough technological development over recent years. Notwithstanding, we have as yet limited understanding of how organizations translate its potential into actual social and economic value. We conduct an in-depth systematic review of IS literature on the topic and identify six debates central to how organizations realize value from big data, at different levels of analysis. Based on this review, we identify two socio-technical features of big data that influence value realization: portability and interconnectivity. We argue that, in practice, organizations need to continuously realign work practices, organizational models, and stakeholder interests in order to reap the benefits from big data. We synthesize the findings by means of an integrated model.",https://doi.org/10.1016/j.jsis.2017.07.003,2017,Wendy Arianne Günther and Mohammad H. {Rezazade Mehrizi} and Marleen Huysman and Frans Feldberg,DEBATING BIG DATA: A LITERATURE REVIEW ON REALIZING VALUE FROM BIG DATA,article
17,12396,JOURNAL OF STRATEGIC INFORMATION SYSTEMS,journal,09638687,"3,133",Q1,88,24,75,2111,965,61,"12,45","87,96",Netherlands,Western Europe,Elsevier,1991-2020,Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"2,945",11.022,0.00233,"In common with much contemporary discourse around big data, recent discussion of datafication in the Journal of Strategic Information Systems has focused on its effects on individuals, organisations and society. Generally missing from such analysis, however, is any consideration of data themselves. What is it that is having these effects? In this Viewpoint article I therefore present a critical analysis of a number of widely-held assumptions about data in general and big data in particular. Rather than being a referential, natural, foundational, objective and equal representation of the world, it will be argued, data are partial and contingent and are brought into being through situated practices of conceptualization, recording and use. Big data are also not as revolutionary voluminous, universal or exhaustive as they are often presented. Some initial implications of this reconceptualization of data are explored. A distinction is made between “data in principle” as they are recorded, and the “data in practice” as they are used. It is only the latter, typically a small and not necessarily representative subset of the former, that will contribute directly to the effects of datafication.",https://doi.org/10.1016/j.jsis.2018.10.005,2019,Matthew Jones,WHAT WE TALK ABOUT WHEN WE TALK ABOUT (BIG) DATA,article
18,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Data visualization is a key tool in data mining for understanding big datasets. Many visualization methods have been proposed, including the well-regarded state-of-the-art method t-distributed stochastic neighbor embedding. However, the most powerful visualization methods have a significant limitation: the manner in which they create their visualization from the original features of the dataset is completely opaque. Many domains require an understanding of the data in terms of the original features; there is hence a need for powerful visualization methods which use understandable models. In this article, we propose a genetic programming (GP) approach called GP-tSNE for evolving interpretable mappings from the dataset to high-quality visualizations. A multiobjective approach is designed that produces a variety of visualizations in a single run which gives different tradeoffs between visual quality and model complexity. Testing against baseline methods on a variety of datasets shows the clear potential of GP-tSNE to allow deeper insight into data than that provided by existing visualization methods. We further highlight the benefits of a multiobjective approach through an in-depth analysis of a candidate front, which shows how multiple models can be analyzed jointly to give increased insight into the dataset.",10.1109/TCYB.2020.2970198,2021,,GENETIC PROGRAMMING FOR EVOLVING A FRONT OF INTERPRETABLE MODELS FOR DATA VISUALIZATION,
19,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Generating highly accurate predictions for missing quality-of-service (QoS) data is an important issue. Latent factor (LF)-based QoS-predictors have proven to be effective in dealing with it. However, they are based on first-order solvers that cannot well address their target problem that is inherently bilinear and nonconvex, thereby leaving a significant opportunity for accuracy improvement. This paper proposes to incorporate an efficient second-order solver into them to raise their accuracy. To do so, we adopt the principle of Hessian-free optimization and successfully avoid the direct manipulation of a Hessian matrix, by employing the efficiently obtainable product between its Gauss-Newton approximation and an arbitrary vector. Thus, the second-order information is innovatively integrated into them. Experimental results on two industrial QoS datasets indicate that compared with the state-of-the-art predictors, the newly proposed one achieves significantly higher prediction accuracy at the expense of affordable computational burden. Hence, it is especially suitable for industrial applications requiring high prediction accuracy of unknown QoS data.",10.1109/TCYB.2017.2685521,2018,,INCORPORATION OF EFFICIENT SECOND-ORDER SOLVERS INTO LATENT FACTOR MODELS FOR ACCURATE PREDICTION OF MISSING QOS DATA,
20,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Dunn's internal cluster validity index is used to assess partition quality and subsequently identify a “best” crisp partition of n objects. Computing Dunn's index (DI) for partitions of n p-dimensional feature vector data has quadratic time complexity O(pn2), so its computation is impractical for very large values of n. This note presents six methods for approximating DI. Four methods are based on Maximin sampling, which identifies a skeleton of the full partition that contains some boundary points in each cluster. Two additional methods are presented that estimate boundary points associated with unsupervised training of one class support vector machines. Numerical examples compare approximations to DI based on all six methods. Four experiments on seven real and synthetic data sets support our assertion that computing approximations to DI with an incremental, neighborhood-based Maximin skeleton is both tractable and reliably accurate.",10.1109/TCYB.2018.2806886,2019,,APPROXIMATING DUNN’S CLUSTER VALIDITY INDICES FOR PARTITIONS OF BIG DATA,
21,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Quality-of-service (QoS) data vary over time, making it vital to capture the temporal patterns hidden in such dynamic data for predicting missing ones with high accuracy. However, currently latent factor (LF) analysis-based QoS-predictors are mostly defined on static QoS data without the consideration of such temporal dynamics. To address this issue, this paper presents a biased non-negative latent factorization of tensors (BNLFTs) model for temporal pattern-aware QoS prediction. Its main idea is fourfold: 1) incorporating linear biases into the model for describing QoS fluctuations; 2) constraining the model to be non-negative for describing QoS non-negativity; 3) deducing a single LF-dependent, non-negative, and multiplicative update scheme for training the model; and 4) incorporating an alternating direction method into the model for faster convergence. The empirical studies on two dynamic QoS datasets from real applications show that compared with the state-of-the-art QoS-predictors, BNLFT represents temporal patterns more precisely with high computational efficiency, thereby achieving the most accurate predictions for missing QoS data.",10.1109/TCYB.2019.2903736,2020,,TEMPORAL PATTERN-AWARE QOS PREDICTION VIA BIASED NON-NEGATIVE LATENT FACTORIZATION OF TENSORS,
22,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"With the rapid development of services computing in the past decade, Quality-of-Service (QoS)-aware selection of Web services has become a hot yet thorny issue. Conducting warming-up tests on a large set of candidate services for QoS evaluation is time consuming and expensive, making it vital to implement accurate QoS-estimators. Existing QoS-estimators barely consider the temporal patterns hidden in QoS data. However, such data are naturally time dependent. For addressing this critical issue, this study presents a Kalman-filter-incorporated latent factor analysis (KLFA)-based QoS-estimator for accurate representation to temporally dynamic QoS data. Its main idea is to make the user latent features (LFs) time dependent, while the service ones time consistent. A novel iterative training scheme is designed, where the user LFs are learned through a Kalman filter for precisely modeling the temporal patterns, and the service ones are alternatively trained via an alternating least squares algorithm for precisely representing the historical QoS data. Empirical studies on large-scale and real Web service QoS datasets demonstrate that the proposed KLFA model significantly outperforms state-of-the-art QoS-estimators in estimation accuracy for dynamic QoS data.",10.1109/TCYB.2022.3185117,2022,,A KALMAN-FILTER-INCORPORATED LATENT FACTOR ANALYSIS MODEL FOR TEMPORALLY DYNAMIC SPARSE DATA,
23,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Numerous detection problems in computer vision, including road crack detection, suffer from exceedingly foreground-background imbalance. Fortunately, modification of loss function appears to solve this puzzle once and for all. In this article, we propose a pixel-based adaptive weighted cross-entropy (WCE) loss in conjunction with Jaccard distance to facilitate high-quality pixel-level road crack detection. Our work profoundly demonstrates the influence of loss functions on detection outcomes and sheds light on the sophisticated consecutive improvements in the realm of crack detection. Specifically, to verify the effectiveness of the proposed loss, we conduct extensive experiments on four public databases, that is, CrackForest, AigleRN, Crack360, and BJN260. Compared to the vanilla WCE, the proposed loss significantly speeds up the training process while retaining the performance.",10.1109/TCYB.2021.3103885,2021,,FAST AND ACCURATE ROAD CRACK DETECTION BASED ON ADAPTIVE COST-SENSITIVE LOSS FUNCTION,
24,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Deep learning approaches have significantly contributed to recent progress in stereo matching. These deep stereo matching methods are usually based on supervised training, which requires a large amount of high-quality ground-truth depth map annotations that are expensive to collect. Furthermore, only a limited quantity of stereo vision training data are currently available, obtained either by active sensors (Lidar and ToF cameras) or through computer graphics simulations and not meeting requirements for deep supervised training. Here, we propose a novel deep stereo approach called the “self-supervised multiscale adversarial regression network (SMAR-Net),” which relaxes the need for ground-truth depth maps for training. Specifically, we design a two-stage network. The first stage is a disparity regressor, in which a regression network estimates disparity values from stacked stereo image pairs. Stereo image stacking method is a novel contribution as it not only contains the spatial appearances of stereo images but also implies matching correspondences with different disparity values. In the second stage, a synthetic left image is generated based on the left–right consistency assumption. Our network is trained by minimizing a hybrid loss function composed of a content loss and an adversarial loss. The content loss minimizes the average warping error between the synthetic images and the real ones. In contrast to the generative adversarial loss, our proposed adversarial loss penalizes mismatches using multiscale features. This constrains the synthetic image and real image as being pixelwise identical instead of just belonging to the same distribution. Furthermore, the combined utilization of multiscale feature extraction in both the content loss and adversarial loss further improves the adaptability of SMAR-Net in ill-posed regions. Experiments on multiple benchmark datasets show that SMAR-Net outperforms the current state-of-the-art self-supervised methods and achieves comparable outcomes to supervised methods. The source code can be accessed at: https://github.com/Dawnstar8411/SMAR-Net.",10.1109/TCYB.2020.2999492,2021,,SELF-SUPERVISED MULTISCALE ADVERSARIAL REGRESSION NETWORK FOR STEREO DISPARITY ESTIMATION,
25,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"The performance of many robust model fitting techniques is largely dependent on the quality of the generated hypotheses. In this paper, we propose a novel guided sampling method, called accelerated guided sampling (AGS), to efficiently generate the accurate hypotheses for multistructure model fitting. Based on the observations that residual sorting can effectively reveal the data relationship (i.e., determine whether two data points belong to the same structure), and keypoint matching scores can be used to distinguish inliers from gross outliers, AGS effectively combines the benefits of residual sorting and keypoint matching scores to efficiently generate accurate hypotheses via information theoretic principles. Moreover, we reduce the computational cost of residual sorting in AGS by designing a new residual sorting strategy, which only sorts the top-ranked residuals of input data, rather than all input data. Experimental results demonstrate the effectiveness of the proposed method in computer vision tasks, such as homography matrix and fundamental matrix estimation.",10.1109/TCYB.2018.2889908,2020,,ACCELERATED GUIDED SAMPLING FOR MULTISTRUCTURE MODEL FITTING,
26,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"To automatically determine the number of clusters and generate more quality clusters while clustering data samples, we propose a harmonious genetic clustering algorithm, named HGCA, which is based on harmonious mating in eugenic theory. Different from extant genetic clustering methods that only use fitness, HGCA aims to select the most suitable mate for each chromosome and takes into account chromosomes gender, age, and fitness when computing mating attractiveness. To avoid illegal mating, we design three mating prohibition schemes, i.e., no mating prohibition, mating prohibition based on lineal relativeness, and mating prohibition based on collateral relativeness, and three mating strategies, i.e., greedy eugenics-based mating strategy, eugenics-based mating strategy based on weighted bipartite matching, and eugenics-based mating strategy based on unweighted bipartite matching, for harmonious mating. In particular, a novel single-point crossover operator called variable-length-and-gender-balance crossover is devised to probabilistically guarantee the balance between population gender ratio and dynamics of chromosome lengths. We evaluate the proposed approach on real-life and artificial datasets, and the results show that our algorithm outperforms existing genetic clustering methods in terms of robustness, efficiency, and effectiveness.",10.1109/TCYB.2016.2628722,2018,,HARMONIOUS GENETIC CLUSTERING,
27,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"In today's digital world, we are faced with an explosion of data and models produced and manipulated by numerous large-scale cloud-based applications. Under such settings, existing transfer evolutionary optimization (TrEO) frameworks grapple with simultaneously satisfying two important quality attributes, namely: 1) scalability against a growing number of source tasks and 2) online learning agility against sparsity of relevant sources to the target task of interest. Satisfying these attributes shall facilitate practical deployment of transfer optimization to scenarios with big task instances, while curbing the threat of negative transfer. While applications of existing algorithms are limited to tens of source tasks, in this article, we take a quantum leap forward in enabling more than two orders of magnitude scale-up in the number of tasks; that is, we efficiently handle scenarios beyond 1000 source task instances. We devise a novel TrEO framework comprising two co-evolving species for joint evolutions in the space of source knowledge and in the search space of solutions to the target problem. In particular, co-evolution enables the learned knowledge to be orchestrated on the fly, expediting convergence in the target optimization task. We have conducted an extensive series of experiments across a set of practically motivated discrete and continuous optimization examples comprising a large number of source task instances, of which only a small fraction indicate source-target relatedness. The experimental results show that not only does our proposed framework scale efficiently with a growing number of source tasks but is also effective in capturing relevant knowledge against sparsity of related sources, fulfilling the two salient features of scalability and online learning agility.",10.1109/TCYB.2022.3164399,2022,,SCALABLE TRANSFER EVOLUTIONARY OPTIMIZATION: COPING WITH BIG TASK INSTANCES,
28,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Despite that convolutional neural networks (CNNs) have shown high-quality reconstruction for single image dehazing, recovering natural and realistic dehazed results remains a challenging problem due to semantic confusion in the hazy scene. In this article, we show that it is possible to recover textures faithfully by incorporating semantic prior into dehazing network since objects in haze-free images tend to show certain shapes, textures, and colors. We propose a semantic-aware dehazing network (SDNet) in which the semantic prior is taken as a color constraint for dehazing, benefiting the acquisition of a reasonable scene configuration. In addition, we design a densely connected block to capture global and local information for dehazing and semantic prior estimation. To eliminate the unnatural appearance of some objects, we propose to fuse the features from shallow and deep layers adaptively. Experimental results demonstrate that our proposed model performs favorably against the state-of-the-art single image dehazing approaches.",10.1109/TCYB.2021.3124231,2021,,SEMANTIC-AWARE DEHAZING NETWORK WITH ADAPTIVE FEATURE FUSION,
29,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Constructing information granules (IGs) has been of significant interest to the discipline of granular computing. The principle of justifiable granularity has been proposed to guide the design of IGs, opening an avenue of pursuits of building IGs carried out on a basis of well-defined and intuitively appealing principles. However, how to improve the efficiency and accuracy of the resulting constructs is an open issue. In this paper, we present a local-density-based optimal granulation model (LoDOG), exhibiting evident advantages: 1) it can detect arbitrarily-shaped IGs and 2) it finds the optimal granulation solutions with O(N) complexity, once the leading tree structure has been constructed. We describe IGs of arbitrary shapes using a small collection of landmark points positioned on the skeleton of the underlying manifold, which contribute to approximate reconstruction capabilities of the original dataset. A dissimilarity metric is developed to evaluate the quality of the obtained reconstruction. The interpretability of LoDOG IGs is discussed. Theoretical analysis and empirical evaluations are covered to demonstrate the effectiveness of LoDOG and the manifold description.",10.1109/TCYB.2017.2750481,2018,,LOCAL-DENSITY-BASED OPTIMAL GRANULATION AND MANIFOLD INFORMATION GRANULE DESCRIPTION,
30,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Topic models have achieved big success in recent years. To detect topics in a text stream, various online topic models have been proposed in the literature. The limitations of these works include that: 1) most of them run with fixed topic numbers and 2) the overlaps between the topics may enlarge in the evolving process. Hierarchical topic model is a candidate solution to these problems since it can reveal many useful relationships between the topics. These relationships can help to find high quality topics and reduce topic overlaps. In this paper, a knowledge-based semisupervised hierarchical online topic detection framework is proposed. The proposed framework can detect topics in an online hierarchical way. In addition, it has been proven that introducing external knowledge can improve the performance of text mining. Therefore, the knowledge from external knowledge sources and human experts are also integrated in the proposed framework. Experiments are conducted to evaluate the proposed framework with different metrics. The results show that compared with the baseline methods, our framework can achieve better performance with competitive time efficiency.",10.1109/TCYB.2018.2841504,2019,,A KNOWLEDGE-BASED SEMISUPERVISED HIERARCHICAL ONLINE TOPIC DETECTION FRAMEWORK,
31,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Cloud workflow scheduling is significantly challenging due to not only the large scale of workflow but also the elasticity and heterogeneity of cloud resources. Moreover, the pricing model of clouds makes the execution time and execution cost two critical issues in the scheduling. This paper models the cloud workflow scheduling as a multiobjective optimization problem that optimizes both execution time and execution cost. A novel multiobjective ant colony system based on a co-evolutionary multiple populations for multiple objectives framework is proposed, which adopts two colonies to deal with these two objectives, respectively. Moreover, the proposed approach incorporates with the following three novel designs to efficiently deal with the multiobjective challenges: 1) a new pheromone update rule based on a set of nondominated solutions from a global archive to guide each colony to search its optimization objective sufficiently; 2) a complementary heuristic strategy to avoid a colony only focusing on its corresponding single optimization objective, cooperating with the pheromone update rule to balance the search of both objectives; and 3) an elite study strategy to improve the solution quality of the global archive to help further approach the global Pareto front. Experimental simulations are conducted on five types of real-world scientific workflows and consider the properties of Amazon EC2 cloud platform. The experimental results show that the proposed algorithm performs better than both some state-of-the-art multiobjective optimization approaches and the constrained optimization approaches.",10.1109/TCYB.2018.2832640,2019,,MULTIOBJECTIVE CLOUD WORKFLOW SCHEDULING: A MULTIPLE POPULATIONS ANT COLONY SYSTEM APPROACH,
32,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"High-dimensional problems are ubiquitous in many fields, yet still remain challenging to be solved. To tackle such problems with high effectiveness and efficiency, this article proposes a simple yet efficient stochastic dominant learning swarm optimizer. Particularly, this optimizer not only compromises swarm diversity and convergence speed properly, but also consumes as little computing time and space as possible to locate the optima. In this optimizer, a particle is updated only when its two exemplars randomly selected from the current swarm are its dominators. In this way, each particle has an implicit probability to directly enter the next generation, making it possible to maintain high swarm diversity. Since each updated particle only learns from its dominators, good convergence is likely to be achieved. To alleviate the sensitivity of this optimizer to newly introduced parameters, an adaptive parameter adjustment strategy is further designed based on the evolutionary information of particles at the individual level. Finally, extensive experiments on two high dimensional benchmark sets substantiate that the devised optimizer achieves competitive or even better performance in terms of solution quality, convergence speed, scalability, and computational cost, compared to several state-of-the-art methods. In particular, experimental results show that the proposed optimizer performs excellently on partially separable problems, especially partially separable multimodal problems, which are very common in real-world applications. In addition, the application to feature selection problems further demonstrates the effectiveness of this optimizer in tackling real-world problems.",10.1109/TCYB.2020.3034427,2022,,AN ADAPTIVE STOCHASTIC DOMINANT LEARNING SWARM OPTIMIZER FOR HIGH-DIMENSIONAL OPTIMIZATION,
33,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"In the context of customization and personalization, the multistage fine-manufacturing system has become emerging in modern manufacturing industries. In this study, the scheduling problem of such a system called distributed hybrid differentiation flowshop scheduling problem is addressed for the first time to minimize makespan. The manufacturing process has three dedicated stages, including distributed fabrication for jobs, assembly from jobs to products, and further differentiation for products to meet customized requirements. Due to the scheduling complexity of the problem, the evolutionary algorithm is designed. First, the population is initialized heuristically and divided into three subpopulations with different identities based on the quality. The identity will be transited dynamically along with evolution. Second, a distributed heterogeneous global exploration strategy is designed to coevolve three subpopulations. According to identity differences, different subpopulations will choose their suitable learning operators and learning strengths to make full use of superior search knowledge. Third, to enhance search intensification, a problem-specific local exploitation strategy consisting of a variable neighborhood local search and a random block local search is devised and carried out adaptively. Fourth, by organizing the global exploration and local exploitation, a novel distributed heterogeneous co-evolutionary algorithm (DHCA) is proposed. The effect of parameter setting on DHCA is investigated by design-of-experiment and computational experiments are carried out to evaluate the algorithm. The results validate the effectiveness of special designs and show that DHCA are more effective and efficient than the compared state-of-the-art algorithms in solving the considered problem.",10.1109/TCYB.2022.3217074,2022,,DISTRIBUTED HETEROGENEOUS CO-EVOLUTIONARY ALGORITHM FOR SCHEDULING A MULTISTAGE FINE-MANUFACTURING SYSTEM WITH SETUP CONSTRAINTS,
34,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Generating action proposals in untrimmed videos is a challenging task, since video sequences usually contain lots of irrelevant contents and the duration of an action instance is arbitrary. The quality of action proposals is key to action detection performance. The previous methods mainly rely on sliding windows or anchor boxes to cover all ground-truth actions, but this is infeasible and computationally inefficient. To this end, this article proposes a RecapNet—a novel framework for generating action proposal, by mimicking the human cognitive process of understanding video content. Specifically, this RecapNet includes a residual causal convolution module to build a short memory of the past events, based on which the joint probability actionness density ranking mechanism is designed to retrieve the action proposals. The RecapNet can handle videos with arbitrary length and more important, a video sequence will need to be processed only in one single pass in order to generate all action proposals. The experiments show that the proposed RecapNet outperforms the state of the art under all metrics on the benchmark THUMOS14 and ActivityNet-1.3 datasets. The code is available publicly at https://github.com/tianwangbuaa/RecapNet.",10.1109/TCYB.2020.2965196,2021,,RECAPNET: ACTION PROPOSAL GENERATION MIMICKING HUMAN COGNITIVE PROCESS,
35,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"The control of virus spreading over complex networks with a limited budget has attracted much attention but remains challenging. This article aims at addressing the combinatorial, discrete resource allocation problems (RAPs) in virus spreading control. To meet the challenges of increasing network scales and improve the solving efficiency, an evolutionary divide-and-conquer algorithm is proposed, namely, a coevolutionary algorithm with network-community-based decomposition (NCD-CEA). It is characterized by the community-based dividing technique and cooperative coevolution conquering thought. First, to reduce the time complexity, NCD-CEA divides a network into multiple communities by a modified community detection method such that the most relevant variables in the solution space are clustered together. The problem and the global swarm are subsequently decomposed into subproblems and subswarms with low-dimensional embeddings. Second, to obtain high-quality solutions, an alternative evolutionary approach is designed by promoting the evolution of subswarms and the global swarm, in turn, with subsolutions evaluated by local fitness functions and global solutions evaluated by a global fitness function. Extensive experiments on different networks show that NCD-CEA has a competitive performance in solving RAPs. This article advances toward controlling virus spreading over large-scale networks.",10.1109/TCYB.2020.2975530,2021,,EVOLUTIONARY DIVIDE-AND-CONQUER ALGORITHM FOR VIRUS SPREADING CONTROL OVER NETWORKS,
36,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Automatically generating an accurate and meaningful description of an image is very challenging. However, the recent scheme of generating an image caption by maximizing the likelihood of target sentences lacks the capacity of recognizing the human–object interaction (HOI) and semantic relationship between HOIs and scenes, which are the essential parts of an image caption. This article proposes a novel two-phase framework to generate an image caption by addressing the above challenges: 1) a hybrid deep learning and 2) an image description generation. In the hybrid deep-learning phase, a novel factored three-way interaction machine was proposed to learn the relational features of the human–object pairs hierarchically. In this way, the image recognition problem is transformed into a latent structured labeling task. In the image description generation phase, a lexicalized probabilistic context-free tree growing scheme is innovatively integrated with a description generator to transform the descriptions generation task into a syntactic-tree generation process. Extensively comparing state-of-the-art image captioning methods on benchmark datasets, we demonstrated that our proposed framework outperformed the existing captioning methods in different ways, such as significantly improving the performance of the HOI and relationships between HOIs and scenes (RHIS) predictions, and quality of generated image captions in a semantically and structurally coherent manner.",10.1109/TCYB.2020.3041595,2022,,AUTOMATICALLY GENERATING NATURAL LANGUAGE DESCRIPTIONS OF IMAGES BY A DEEP HIERARCHICAL FRAMEWORK,
37,21100274221,IEEE TRANSACTIONS ON CYBERNETICS,journal,21682275,"3,109",Q1,124,542,1065,18740,13312,997,"11,19","34,58",United States,Northern America,IEEE Advancing Technology for Humanity,2013-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Human-Computer Interaction (Q1); Information Systems (Q1); Software (Q1),"24,753",11.448,0.05214,"Recommender systems are important approaches for dealing with the information overload problem in the big data era, and various kinds of auxiliary information, including time and sequential information, can help improve the performance of retrieval and recommendation tasks. However, it is still a challenging problem how to fully exploit such information to achieve high-quality recommendation results and improve users’ experience. In this work, we present a novel sequential recommendation model, called multivariate Hawkes process embedding with attention (MHPE-a), which combines a temporal point process with the attention mechanism to predict the items that the target user may interact with according to her/his historical records. Specifically, the proposed approach MHPE-a can model users’ sequential patterns in their temporal interaction sequences accurately with a multivariate Hawkes process. Then, we perform an accurate sequential recommendation to satisfy target users’ real-time requirements based on their preferences obtained with MHPE-a from their historical records. Especially, an attention mechanism is used to leverage users’ long/short-term preferences adaptively to achieve an accurate sequential recommendation. Extensive experiments are conducted on two real-world datasets (lastfm and gowalla), and the results show that MHPE-a achieves better performance than state-of-the-art baselines.",10.1109/TCYB.2021.3077361,2022,,SEQUENTIAL RECOMMENDATION BASED ON MULTIVARIATE HAWKES PROCESS EMBEDDING WITH ATTENTION,
38,18795,WATER RESEARCH,journal,00431354,"3,099",Q1,303,1142,2603,70129,29848,2588,"11,32","61,41",United Kingdom,Western Europe,Elsevier Ltd.,1967-2020,Civil and Structural Engineering (Q1); Ecological Modeling (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1); Water Science and Technology (Q1),"120,695",11.236,0.07878,"Recent advancements in data-driven process control and performance analysis could provide the wastewater treatment industry with an opportunity to reduce costs and improve operations. However, big data in wastewater treatment plants (WWTP) is widely underutilized, due in part to a workforce that lacks background knowledge of data science required to fully analyze the unique characteristics of WWTP. Wastewater treatment processes exhibit nonlinear, nonstationary, autocorrelated, and co-correlated behavior that (i) is very difficult to model using first principals and (ii) must be considered when implementing data-driven methods. This review provides an overview of data-driven methods of achieving fault detection, variable prediction, and advanced control of WWTP. We present how big data has been used in the context of WWTP, and much of the discussion can also be applied to water treatment. Due to the assumptions inherent in different data-driven modeling approaches (e.g., control charts, statistical process control, model predictive control, neural networks, transfer functions, fuzzy logic), not all methods are appropriate for every goal or every dataset. Practical guidance is given for matching a desired goal with a particular methodology along with considerations regarding the assumed data structure. References for further reading are provided, and an overall analysis framework is presented.",https://doi.org/10.1016/j.watres.2019.03.030,2019,Kathryn B. Newhart and Ryan W. Holloway and Amanda S. Hering and Tzahi Y. Cath,DATA-DRIVEN PERFORMANCE ANALYSES OF WASTEWATER TREATMENT PLANTS: A REVIEW,article
39,98982,TRANSPORT REVIEWS,journal,01441647,"3,046",Q1,82,52,124,3838,1233,106,"9,34","73,81",United Kingdom,Western Europe,Routledge,1981-2020,Transportation (Q1),"4,598",9.643,0.00476,"ABSTRACT
The information-rich vessel movement data provided by the Automatic Identification System (AIS) has gained much popularity over the past decade, during which the employment of satellite-based receivers has enabled wide coverage and improved data quality. The application of AIS data has developed from simply navigation-oriented research to now include trade flow estimation, emission accounting, and vessel performance monitoring. The AIS now provides high frequency, real-time positioning and sailing patterns for almost the whole world's commercial fleet, and therefore, in combination with supplementary databases and analyses, AIS data has arguably kickstarted the era of digitisation in the shipping industry. In this study, we conduct a comprehensive review of the literature regarding AIS applications by dividing it into three development stages, namely, basic application, extended application, and advanced application. Each stage contains two to three application fields, and in total we identified seven application fields, including (1) AIS data mining, (2) navigation safety, (3) ship behaviour analysis, (4) environmental evaluation, (5) trade analysis, (6) ship and port performance, and (7) Arctic shipping. We found that the original application of AIS data to navigation safety has, with the improvement of data accessibility, evolved into diverse applications in various directions. Moreover, we summarised the major methodologies in the literature into four categories, these being (1) data processing and mining, (2) index measurement, (3) causality analysis, and (4) operational research. Undoubtedly, the applications of AIS data will be further expanded in the foreseeable future. This will not only provide a more comprehensive understanding of voyage performance and allow researchers to examine shipping market dynamics from the micro level, but also the abundance of AIS data may also open up the rather opaque aspect of how shipping companies release information to external authorities, including the International Maritime Organization, port states, scientists and researchers. It is expected that more multi-disciplinary AIS studies will emerge in the coming years. We believe that this study will shed further light on the future development of AIS studies.",https://doi.org/10.1080/01441647.2019.1649315,2019,Dong Yang and Lingxiao Wu and Shuaian Wang and Haiying Jia and Kevin X. Li,HOW BIG DATA ENRICHES MARITIME RESEARCH – A CRITICAL REVIEW OF AUTOMATIC IDENTIFICATION SYSTEM (AIS) DATA APPLICATIONS,article
40,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"Building heat demand is responsible for a significant share of the total global final energy consumption. Building stock models with a high spatio-temporal resolution are a powerful tool to investigate the effects of new building policies aimed at increasing energy efficiency, the introduction of new heating technologies or the integration of buildings within an energy system based on renewable energy sources. Therefore, building stock models have to be able to model the improvements and variation of used materials in buildings. In this paper, we propose a method based on generalized large-scale geographic information system (GIS) to model building heat demand of large regions with a high temporal resolution. In contrast to existing building stock models, our approach allows to derive the envelope of all buildings from digital elevation models and to model location dependent effects such as shadowing due to the topography and climate conditions. We integrate spatio-temporal climate data for temperature and solar radiation to model climate effects of complex terrain. The model is validated against a database containing the measured energy demand of 1845 buildings of the city of St. Gallen, Switzerland and 120 buildings of the Alpine village of Zernez, Switzerland. The proposed model is able to assess and investigate large regions by using spatial data describing natural and anthropogenic land features. The validation resulted in an average goodness of fit (R2) of 0.6.",https://doi.org/10.1016/j.apenergy.2017.10.041,2017,René Buffat and Andreas Froemelt and Niko Heeren and Martin Raubal and Stefanie Hellweg,BIG DATA GIS ANALYSIS FOR NOVEL APPROACHES IN BUILDING STOCK MODELLING,article
41,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"Building energy data has been used for decades to understand energy flows in buildings and plan for future energy demand. Recent market, technology and policy drivers have resulted in widespread data collection by stakeholders across the buildings industry. Consolidation of independently collected and maintained datasets presents a cost-effective opportunity to build a database of unprecedented size. Applications of the data include peer group analysis to evaluate building performance, and data-driven algorithms that use empirical data to estimate energy savings associated with building retrofits. This paper discusses technical considerations in compiling such a database using the DOE Buildings Performance Database (BPD) as a case study. We gathered data on over 750,000 residential and commercial buildings. We describe the process and challenges of mapping and cleansing data from disparate sources. We analyze the distributions of buildings in the BPD relative to the Commercial Building Energy Consumption Survey (CBECS) and Residential Energy Consumption Survey (RECS), evaluating peer groups of buildings that are well or poorly represented, and discussing how differences in the distributions of the three datasets impact use-cases of the data. Finally, we discuss the usefulness and limitations of the current dataset and the outlook for increasing its size and applications.",https://doi.org/10.1016/j.apenergy.2014.11.042,2015,Paul A. Mathew and Laurel N. Dunn and Michael D. Sohn and Andrea Mercado and Claudine Custudio and Travis Walter,BIG-DATA FOR BUILDING ENERGY PERFORMANCE: LESSONS FROM ASSEMBLING A VERY LARGE NATIONAL DATABASE OF BUILDING ENERGY USE,article
42,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"Battery is one of the most important and costly devices in electric vehicles (EVs). Developing an efficient battery management method is of great significance to enhancing vehicle safety and economy. Recently developed big-data and cloud platform computing technologies bring a bright perspective for efficient utilization and protection of vehicle batteries. However, a reliable data transmission network and a high-quality cloud battery dataset are indispensable to enable this benefit. This paper makes the first effort to systematically solve data quality problems in cloud-based vehicle battery monitoring and management by developing a novel integrated battery data cleaning framework. In the first stage, the outlier samples are detected by analyzing the temporal features in the battery data time series. The outlier data in the dataset can be accurately detected to avoid their impacts on battery monitoring and management. Then, the abnormal samples, including the noise polluted data and missing value, are restored by a novel future fusion data restoring model. The real electric bus operation data collected by a cloud-based battery monitoring and management platform are used to verify the performance of the developed data cleaning method. More than 93.3% of outlier samples can be detected, and the data restoring error can be limited to 2.11%, which validates the effectiveness of the developed methods. The proposed data cleaning method provides an effective data quality assessment tool in cloud-based vehicle battery management, which can further boost the practical application of the vehicle big data platform and Internet of vehicle.",https://doi.org/10.1016/j.apenergy.2022.119292,2022,Shuangqi Li and Hongwen He and Pengfei Zhao and Shuang Cheng,DATA CLEANING AND RESTORING METHOD FOR VEHICLE BATTERY BIG DATA PLATFORM,article
43,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"As one of the bottleneck technologies of electric vehicles (EVs), the battery hosts complex and hardly observable internal chemical reactions. Therefore, a precise mathematical model is crucial for the battery management system (BMS) to ensure the secure and stable operation of the battery in a multi-variable environment. First, a Cloud-based BMS (C-BMS) is established based on a database containing complete battery status information. Next, a data cleaning method based on machine learning is applied to the big data of batteries. Meanwhile, to improve the model stability under dynamic conditions, an F-divergence-based data distribution quality assessment method and a sampling-based data preprocess method is designed. Then, a lithium-ion battery temperature-dependent model is built based on Stacked Denoising Autoencoders- Extreme Learning Machine (SDAE-ELM) algorithm, and a new training method combined with data preprocessing is also proposed to improve the model accuracy. Finally, to improve reliability, a conjunction working mode between the C-BMS and the BMS in vehicles (V-BMS) is also proposed, providing as an applied case of the model. Using the battery data extracted from electric buses, the effectiveness and accuracy of the model are validated. The error of the estimated battery terminal voltage is within 2%, and the error of the estimated State of Charge (SoC) is within 3%.",https://doi.org/10.1016/j.apenergy.2019.03.154,2019,Shuangqi Li and Hongwen He and Jianwei Li,BIG DATA DRIVEN LITHIUM-ION BATTERY MODELING METHOD BASED ON SDAE-ELM ALGORITHM AND DATA PRE-PROCESSING TECHNOLOGY,article
44,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"Energy economy models are central to decision making on energy and climate issues in the 21st century, such as informing the design of deep decarbonisation strategies under the Paris Agreement. Designing policies that are aimed at achieving such radical transitions in the energy system will require ever more in-depth modelling of end-use demand, efficiency and fuel switching, as well as an increasing need for regional, sectoral, and agent disaggregation to capture technological, jurisdictional and policy detail. Building and using these models entails complex trade-offs between the level of detail, the size of the system boundary, and the available computing resources. The availability of data to characterise key energy system sectors and interactions is also a key driver of model structure and parameterisation, and there are many blind spots and design compromises that are caused by data scarcity. We may soon, however, live in a world of data abundance, potentially enabling previously impossible levels of resolution and coverage in energy economy models. But while big data concepts and platforms have already begun to be used in a number of selected energy research applications, their potential to improve or even completely revolutionise energy economy modelling has been almost completely overlooked in the existing literature. In this paper, we explore the challenges and possibilities of this emerging frontier. We identify critical gaps and opportunities for the field, as well as developing foundational concepts for guiding the future application of big data to energy economy modelling, with reference to the existing literature on decision making under uncertainty, scenario analysis and the philosophy of science.",https://doi.org/10.1016/j.apenergy.2019.02.002,2019,Francis G.N. Li and Chris Bataille and Steve Pye and Aidan O'Sullivan,"PROSPECTS FOR ENERGY ECONOMY MODELLING WITH BIG DATA: HYPE, ELIMINATING BLIND SPOTS, OR REVOLUTIONISING THE STATE OF THE ART?",article
45,28801,APPLIED ENERGY,journal,03062619,"3,035",Q1,212,1729,5329,100144,56804,5304,"10,59","57,92",United Kingdom,Western Europe,Elsevier BV,1975-2020,"Building and Construction (Q1); Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1)","122,712",9.746,0.15329,"Data play an essential role in asset management decisions. The amount of data is increasing through accumulating historical data records, new measuring devices, and communication technology, notably with the evolution toward smart grids. Consequently, the management of data quantity and quality is becoming even more relevant for asset managers to meet efficiency and reliability requirements for power grids. In this work, we propose an innovative data quality management framework enabling asset managers (i) to quantify the impact of poor data quality, and (ii) to determine the conditions under which an investment in data quality improvement is required. To this end, an algorithm is used to determine the optimal year for component replacement based on three scenarios, a Reference scenario, an Imperfect information scenario, and an Investment in higher data quality scenario. Our results indicate that (i) the impact on the optimal year of replacement is the highest for middle-aged components; (ii) the profitability of investments in data quality improvement depends on various factors, including data quality, and the cost of investment in data quality improvement. Finally, we discuss the implementation of the proposed models to control data quality in practice, while taking into account real-world technological and economic limitations.",https://doi.org/10.1016/j.apenergy.2020.116057,2021,Sylvie Koziel and Patrik Hilber and Per Westerlund and Ebrahim Shayesteh,INVESTMENTS IN DATA QUALITY: EVALUATING IMPACTS OF FAULTY DATA ON ASSET MANAGEMENT IN POWER SYSTEMS,article
46,15857,JOURNAL OF CLINICAL EPIDEMIOLOGY,journal,08954356,"2,993",Q1,212,314,726,8870,3242,528,"4,25","28,25",United States,Northern America,Elsevier USA,1988-2020,Epidemiology (Q1),"36,224",6.437,0.02836,"Background and Objectives
To highlight the potential of multiple file record linkage. Linkage increases the value of existing information by supplying missing data or correcting errors in existing data, through generating important covariates, and by using family information to control for unmeasured variables and expand research opportunities.
Methods
Recent Manitoba papers highlight the use of linkage to produce better studies. Specific ways in which linkage helps deal with different substantive issues are described.
Results
Wide data files—files containing considerable amounts of information on each individual—generated by linkage improve research by facilitating better design. Nonexperimental work in particular benefits from such linkages. Population registries are especially valuable in supplying family data to facilitate work across different substantive fields.
Conclusion
Several examples show how record linkage magnifies the value of information from individual projects. The results of observational studies become more defensible through the better designs facilitated by such linkage.",https://doi.org/10.1016/j.jclinepi.2022.06.006,2022,Leslie L. Roos and Elizabeth Wall-Wieler and Charles Burchill and Naomi C. Hamm and Amani F. Hamad and Lisa M. Lix,RECORD LINKAGE AND BIG DATA—ENHANCING INFORMATION AND IMPROVING DESIGN,article
47,29161,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,journal,09242716,"2,960",Q1,138,264,677,16114,7306,668,"10,56","61,04",Netherlands,Western Europe,Elsevier,1989-2020,"Atomic and Molecular Physics, and Optics (Q1); Computer Science Applications (Q1); Computers in Earth Sciences (Q1); Engineering (miscellaneous) (Q1); Geography, Planning and Development (Q1)","18,026",8.979,0.02145,"Spatially contiguous aerosol type grids were rarely available for air quality management in the past. To bridge the gap, we developed an integrated remote sensing and big data analytics framework to generate spatially gap-free aerosol type grids between 2000 and 2020 in China. The effect of emission control via environmental management on haze reduction was fully realized for the first time with the aid of satellite-based gap-free aerosol type data. Daily gap-free aerosol fine mode fraction (FMF) data were first derived via a data-driven regression model based on remote sensing big data. According to empirically determined FMF probability distributions over regions with typical emission sources, aerosols in China were classified into eight major types, including typical/atypical/mixed anthropogenic aerosols, typical/atypical/mixed dust, and typical mixed and multiple modes. The results indicated that the gridded FMF estimates derived in this study agreed well with FMF retrievals from AERONET, with correlation coefficient of 0.81 and root mean square error of 0.13. The long-term variations in major aerosol types showed that in China the territory covered by typical anthropogenic aerosols was reduced from 21.38% to 11.76% over the past two decades, while dust aerosols decreased from 6.99% to 2.15%. The declining trend in anthropogenic aerosols could be attributed to reduced coal consumption and/or favorable dispersion conditions, whereas decreasing dust aerosols were largely associated with increased vegetation cover and/or weakened wind speed in the west. Overall, such advancements provide fresh evidence to improve our understanding of the emission control effect on haze pollution variations in China.",https://doi.org/10.1016/j.isprsjprs.2022.09.001,2022,Ke Li and Kaixu Bai and Mingliang Ma and Jianping Guo and Zhengqiang Li and Gehui Wang and Ni-Bin Chang,SPATIALLY GAP FREE ANALYSIS OF AEROSOL TYPE GRIDS IN CHINA: FIRST RETRIEVAL VIA SATELLITE REMOTE SENSING AND BIG DATA ANALYTICS,article
48,29161,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,journal,09242716,"2,960",Q1,138,264,677,16114,7306,668,"10,56","61,04",Netherlands,Western Europe,Elsevier,1989-2020,"Atomic and Molecular Physics, and Optics (Q1); Computer Science Applications (Q1); Computers in Earth Sciences (Q1); Engineering (miscellaneous) (Q1); Geography, Planning and Development (Q1)","18,026",8.979,0.02145,"The recent explosive publications of big data studies have well documented the rise of big data and its ongoing prevalence. Different types of “big data” have emerged and have greatly enriched spatial information sciences and related fields in terms of breadth and granularity. Studies that were difficult to conduct in the past time due to data availability can now be carried out. However, big data brings lots of “big errors” in data quality and data usage, which cannot be used as a substitute for sound research design and solid theories. We indicated and summarized the problems faced by current big data studies with regard to data collection, processing and analysis: inauthentic data collection, information incompleteness and noise of big data, unrepresentativeness, consistency and reliability, and ethical issues. Cases of empirical studies are provided as evidences for each problem. We propose that big data research should closely follow good scientific practice to provide reliable and scientific “stories”, as well as explore and develop techniques and methods to mitigate or rectify those ‘big-errors’ brought by big data.",https://doi.org/10.1016/j.isprsjprs.2015.11.006,2016,Jianzheng Liu and Jie Li and Weifeng Li and Jiansheng Wu,RETHINKING BIG DATA: A REVIEW ON THE DATA QUALITY AND USAGE ISSUES,article
49,29161,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,journal,09242716,"2,960",Q1,138,264,677,16114,7306,668,"10,56","61,04",Netherlands,Western Europe,Elsevier,1989-2020,"Atomic and Molecular Physics, and Optics (Q1); Computer Science Applications (Q1); Computers in Earth Sciences (Q1); Engineering (miscellaneous) (Q1); Geography, Planning and Development (Q1)","18,026",8.979,0.02145,"Accurate information about the location, extent, and type of Land Cover (LC) is essential for various applications. The only recent available country-wide LC map of Iran was generated in 2016 by the Iranian Space Agency (ISA) using Moderate Resolution Imaging Spectroradiometer (MODIS) images with a considerably low accuracy. Therefore, the production of an up-to-date and accurate Iran-wide LC map using the most recent remote sensing, machine learning, and big data processing algorithms is required. Moreover, it is important to develop an efficient method for automatic LC generation for various time periods without the need to collect additional ground truth data from this immense country. Therefore, this study was conducted to fulfill two objectives. First, an improved Iranian LC map with 13 LC classes and a spatial resolution of 10 m was produced using multi-temporal synergy of Sentinel-1 and Sentinel-2 satellite datasets applied to an object-based Random forest (RF) algorithm. For this purpose, 2,869 Sentinel-1 and 11,994 Sentinel-2 scenes acquired in 2017 were processed and classified within the Google Earth Engine (GEE) cloud computing platform allowing big geospatial data analysis. The Overall Accuracy (OA) and Kappa Coefficient (KC) of the final Iran-wide LC map for 2017 was 95.6% and 0.95, respectively, indicating the considerable potential of the proposed big data processing method. Second, an efficient automatic method was developed based on Sentinel-2 images to migrate ground truth samples from a reference year to automatically generate an LC map for any target year. The OA and KC for the LC map produced for the target year 2019 were 91.35% and 0.91, respectively, demonstrating the efficiency of the proposed method for automatic LC mapping. Based on the obtained accuracies, this method can potentially be applied to other regions of interest for LC mapping without the need for ground truth data from the target year.",https://doi.org/10.1016/j.isprsjprs.2020.07.013,2020,Arsalan Ghorbanian and Mohammad Kakooei and Meisam Amani and Sahel Mahdavi and Ali Mohammadzadeh and Mahdi Hasanlou,IMPROVED LAND COVER MAP OF IRAN USING SENTINEL IMAGERY WITHIN GOOGLE EARTH ENGINE AND A NOVEL AUTOMATIC WORKFLOW FOR LAND COVER CLASSIFICATION USING MIGRATED TRAINING SAMPLES,article
50,29161,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,journal,09242716,"2,960",Q1,138,264,677,16114,7306,668,"10,56","61,04",Netherlands,Western Europe,Elsevier,1989-2020,"Atomic and Molecular Physics, and Optics (Q1); Computer Science Applications (Q1); Computers in Earth Sciences (Q1); Engineering (miscellaneous) (Q1); Geography, Planning and Development (Q1)","18,026",8.979,0.02145,"Discrete global grid systems (DGGS) have been proposed as a data model for a digital earth framework. We introduce a new data model and analytics system called IDEAS – integrated discrete environmental analysis system to create an operational DGGS-based GIS which is suitable for large scale environmental modelling and analysis. Our analysis demonstrates that DGGS-based GIS is feasible within a relational database environment incorporating common data analytics tools. Common GIS operations implemented in our DGGS data model outperformed the same operations computed using traditional geospatial data types. A case study into wildfire modelling demonstrates the capability for data integration and supporting big data geospatial analytics. These results indicate that DGGS data models have significant capability to solve some of the key outstanding problems related to geospatial data analytics, providing a common representation upon which fast and scalable algorithms can be built.",https://doi.org/10.1016/j.isprsjprs.2020.02.009,2020,Colin Robertson and Chiranjib Chaudhuri and Majid Hojati and Steven A. Roberts,AN INTEGRATED ENVIRONMENTAL ANALYTICS SYSTEM (IDEAS) BASED ON A DGGS,article
51,29161,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,journal,09242716,"2,960",Q1,138,264,677,16114,7306,668,"10,56","61,04",Netherlands,Western Europe,Elsevier,1989-2020,"Atomic and Molecular Physics, and Optics (Q1); Computer Science Applications (Q1); Computers in Earth Sciences (Q1); Engineering (miscellaneous) (Q1); Geography, Planning and Development (Q1)","18,026",8.979,0.02145,"Big data has now become a strong focus of global interest that is increasingly attracting the attention of academia, industry, government and other organizations. Big data can be situated in the disciplinary area of traditional geospatial data handling theory and methods. The increasing volume and varying format of collected geospatial big data presents challenges in storing, managing, processing, analyzing, visualizing and verifying the quality of data. This has implications for the quality of decisions made with big data. Consequently, this position paper of the International Society for Photogrammetry and Remote Sensing (ISPRS) Technical Commission II (TC II) revisits the existing geospatial data handling methods and theories to determine if they are still capable of handling emerging geospatial big data. Further, the paper synthesises problems, major issues and challenges with current developments as well as recommending what needs to be developed further in the near future.",https://doi.org/10.1016/j.isprsjprs.2015.10.012,2016,Songnian Li and Suzana Dragicevic and Francesc Antón Castro and Monika Sester and Stephan Winter and Arzu Coltekin and Christopher Pettit and Bin Jiang and James Haworth and Alfred Stein and Tao Cheng,GEOSPATIAL BIG DATA HANDLING THEORY AND METHODS: A REVIEW AND RESEARCH CHALLENGES,article
52,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"For large-scale industrial plants, quality-related process monitoring is challenging because of the complex features of multiunit, multimode, high-dimension data. Hence, a hierarchical quality monitoring (HQM) algorithm based on the distributed parallel semisupervised Gaussian mixture model (dp-S2GMM) is proposed in this article. In HQM, a large-scale process is first decomposed into a group of unit blocks according to the process structure. Subsequently, in each block, a quality regression model with multimode big process data is built using the dp-S2GMM, which is derived from a scalable stochastic variational inference semisupervised GMM (SVI-S2GMM). With the regression model, a hierarchical fault detection and diagnosis scheme in both quality-related and quality-unrelated subspaces is proposed from the variable level, block level to plant-wide level. Finally, an industrial case study on the Tennessee Eastman process demonstrates the feasibility and effectiveness of the proposed HQM algorithm.",10.1109/TNNLS.2019.2958184,2021,,HIERARCHICAL QUALITY MONITORING FOR LARGE-SCALE INDUSTRIAL PLANTS WITH BIG PROCESS DATA,
53,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Product quality prediction, as an important issue of industrial intelligence, is a typical task of industrial process analysis, in which product quality will be evaluated and improved as feedback for industrial process adjustment. Data-driven methods, with predictive model to analyze various industrial data, have been received considerable attention in recent years. However, to get an accurate prediction, it is an essential issue to extract quality features from industrial data, including several variables generated from supply chain and time-variant machining process. In this article, a data-driven method based on wide-deep-sequence (WDS) model is proposed to provide a reliable quality prediction for industrial process with different types of industrial data. To process industrial data of high redundancy, in this article, data reduction is first conducted on different variables by different techniques. Also, an improved wide-deep (WD) model is proposed to extract quality features from key time-invariant variables. Meanwhile, an long short-term memory (LSTM)-based sequence model is presented for exploring quality information from time-domain features. Under the joint training strategy, these models will be combined and optimized by a designed penalty mechanism for unreliable predictions, especially on reduction of defective products. Finally, experiments on a real-world manufacturing process data set are carried out to present the effectiveness of the proposed method in product quality prediction.",10.1109/TNNLS.2020.3001602,2020,,A WIDE-DEEP-SEQUENCE MODEL-BASED QUALITY PREDICTION METHOD IN INDUSTRIAL PROCESS ANALYSIS,
54,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"In this paper, we investigate into the problem of image quality assessment (IQA) and enhancement via machine learning. This issue has long attracted a wide range of attention in computational intelligence and image processing communities, since, for many practical applications, e.g., object detection and recognition, raw images are usually needed to be appropriately enhanced to raise the visual quality (e.g., visibility and contrast). In fact, proper enhancement can noticeably improve the quality of input images, even better than originally captured images, which are generally thought to be of the best quality. In this paper, we present two most important contributions. The first contribution is to develop a new no-reference (NR) IQA model. Given an image, our quality measure first extracts 17 features through analysis of contrast, sharpness, brightness and more, and then yields a measure of visual quality using a regression module, which is learned with big-data training samples that are much bigger than the size of relevant image data sets. The results of experiments on nine data sets validate the superiority and efficiency of our blind metric compared with typical state-of-the-art full-reference, reduced-reference and NA IQA methods. The second contribution is that a robust image enhancement framework is established based on quality optimization. For an input image, by the guidance of the proposed NR-IQA measure, we conduct histogram modification to successively rectify image brightness and contrast to a proper level. Thorough tests demonstrate that our framework can well enhance natural images, low-contrast images, low-light images, and dehazed images. The source code will be released at https://sites.google.com/site/guke198701/publications.",10.1109/TNNLS.2017.2649101,2018,,LEARNING A NO-REFERENCE QUALITY ASSESSMENT MODEL OF ENHANCED IMAGES WITH BIG DATA,
55,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process regression (GPR), a well-known nonparametric, and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. However, they have not yet been comprehensively reviewed and analyzed to be well understood by both academia and industry. The review of scalable GPs in the GP community is timely and important due to the explosion of data size. To this end, this article is devoted to reviewing state-of-the-art scalable GPs involving two main categories: global approximations that distillate the entire data and local approximations that divide the data for subspace learning. Particularly, for global approximations, we mainly focus on sparse approximations comprising prior approximations that modify the prior but perform exact inference, posterior approximations that retain exact prior but perform approximate inference, and structured sparse approximations that exploit specific structures in kernel matrix; for local approximations, we highlight the mixture/product of experts that conducts model averaging from multiple local experts to boost predictions. To present a complete review, recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues.",10.1109/TNNLS.2019.2957109,2020,,WHEN GAUSSIAN PROCESS MEETS BIG DATA: A REVIEW OF SCALABLE GPS,
56,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Most existing multiview clustering methods are based on the original feature space. However, the feature redundancy and noise in the original feature space limit their clustering performance. Aiming at addressing this problem, some multiview clustering methods learn the latent data representation linearly, while performance may decline if the relation between the latent data representation and the original data is nonlinear. The other methods which nonlinearly learn the latent data representation usually conduct the latent representation learning and clustering separately, resulting in that the latent data representation might be not well adapted to clustering. Furthermore, none of them model the intercluster relation and intracluster correlation of data points, which limits the quality of the learned latent data representation and therefore influences the clustering performance. To solve these problems, this article proposes a novel multiview clustering method via proximity learning in latent representation space, named multiview latent proximity learning (MLPL). For one thing, MLPL learns the latent data representation in a nonlinear manner which takes the intercluster relation and intracluster correlation into consideration simultaneously. For another, through conducting the latent representation learning and consensus proximity learning simultaneously, MLPL learns a consensus proximity matrix with k connected components to output the clustering result directly. Extensive experiments are conducted on seven real-world datasets to demonstrate the effectiveness and superiority of the MLPL method compared with the state-of-the-art multiview clustering methods.",10.1109/TNNLS.2021.3104846,2021,,MULTIVIEW CLUSTERING VIA PROXIMITY LEARNING IN LATENT REPRESENTATION SPACE,
57,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"As a fundamental problem in social network analysis, community detection has recently attracted wide attention, accompanied by the output of numerous community detection methods. However, most existing methods are developed by only exploiting link topology, without taking node homophily (i.e., node similarity) into consideration. Thus, much useful information that can be utilized to improve the quality of detected communities is ignored. To overcome this limitation, we propose a new community detection approach based on nonnegative matrix factorization (NMF), namely, homophily preserving NMF (HPNMF), which models not only link topology but also node homophily of networks. As such, HPNMF is able to better reflect the inherent properties of community structure. In order to capture node homophily from scratch, we provide three similarity measurements that naturally reveal the association relationships between nodes. We further present an efficient learning algorithm with convergence guarantee to solve the proposed model. Finally, extensive experiments are conducted, and the results demonstrate that HPNMF has strong ability to outperform the state-of-the-art baseline methods.",10.1109/TNNLS.2019.2933850,2020,,HOMOPHILY PRESERVING COMMUNITY DETECTION,
58,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Video anomaly detection (VAD) refers to the discrimination of unexpected events in videos. The deep generative model (DGM)-based method learns the regular patterns on normal videos and expects the learned model to yield larger generative errors for abnormal frames. However, DGM cannot always do so, since it usually captures the shared patterns between normal and abnormal events, which results in similar generative errors for them. In this article, we propose a novel self-supervised framework for unsupervised VAD to tackle the above-mentioned problem. To this end, we design a novel self-supervised attentive generative adversarial network (SSAGAN), which is composed of the self-attentive predictor, the vanilla discriminator, and the self-supervised discriminator. On the one hand, the self-attentive predictor can capture the long-term dependences for improving the prediction qualities of normal frames. On the other hand, the predicted frames are fed to the vanilla discriminator and self-supervised discriminator for performing true-false discrimination and self-supervised rotation detection, respectively. Essentially, the role of the self-supervised task is to enable the predictor to encode semantic information into the predicted normal frames via adversarial training, in order for the angles of rotated normal frames can be detected. As a result, our self-supervised framework lessens the generalization ability of the model to abnormal frames, resulting in larger detection errors for abnormal frames. Extensive experimental results indicate that SSAGAN outperforms other state-of-the-art methods, which demonstrates the validity and advancement of SSAGAN.",10.1109/TNNLS.2022.3159538,2022,,SELF-SUPERVISED ATTENTIVE GENERATIVE ADVERSARIAL NETWORKS FOR VIDEO ANOMALY DETECTION,
59,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"A start–end frame pair and a motion pattern-based motion synthesis scheme can provide more control to the synthesis process and produce content-various motion sequences. However, the data preparation for the motion training is intractable, and concatenating feature spaces of the start–end frame pair and the motion pattern lacks theoretical rationality in previous works. In this article, we propose a deep learning framework that completes automatic data preparation and learns the nonlinear mapping from start–end frame pairs to motion patterns. The proposed model consists of three modules: action detection, motion extraction, and motion synthesis networks. The action detection network extends the deep subspace learning framework to a supervised version, i.e., uses the local self-expression (LSE) of the motion data to supervise feature learning and complement the classification error. A long short-term memory (LSTM)-based network is used to efficiently extract the motion patterns to address the speed deficiency reflected in the previous optimization-based method. A motion synthesis network consists of a group of LSTM-based blocks, where each of them is to learn the nonlinear relation between the start–end frame pairs and the motion patterns of a certain joint. The superior performances in action detection accuracy, motion pattern extraction efficiency, and motion synthesis quality show the effectiveness of each module in the proposed framework.",10.1109/TNNLS.2022.3213596,2022,,A DEEP LEARNING FRAMEWORK FOR START–END FRAME PAIR-DRIVEN MOTION SYNTHESIS,
60,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Session-based recommendation tries to make use of anonymous session data to deliver high-quality recommendations under the condition that user profiles and the complete historical behavioral data of a target user are unavailable. Previous works consider each session individually and try to capture user interests within a session. Despite their encouraging results, these models can only perceive intra-session items and cannot draw upon the massive historical relational information. To solve this problem, we propose a novel method named global graph guided session-based recommendation (G^3SR). G^3SR decomposes the session-based recommendation workflow into two steps. First, a global graph is built upon all session data, from which the global item representations are learned in an unsupervised manner. Then, these representations are refined on session graphs under the graph networks, and a readout function is used to generate session representations for each session. Extensive experiments on two real-world benchmark datasets show remarkable and consistent improvements of the G^3SR method over the state-of-the-art methods, especially for cold items.",10.1109/TNNLS.2022.3159592,2022,,G^3SR: GLOBAL GRAPH GUIDED SESSION-BASED RECOMMENDATION,
61,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Deep reinforcement learning (DRL) has recently shown its success in tackling complex combinatorial optimization problems. When these problems are extended to multiobjective ones, it becomes difficult for the existing DRL approaches to flexibly and efficiently deal with multiple subproblems determined by the weight decomposition of objectives. This article proposes a concise meta-learning-based DRL approach. It first trains a meta-model by meta-learning. The meta-model is fine-tuned with a few update steps to derive submodels for the corresponding subproblems. The Pareto front is then built accordingly. Compared with other learning-based methods, our method can greatly shorten the training time of multiple submodels. Due to the rapid and excellent adaptability of the meta-model, more submodels can be derived so as to increase the quality and diversity of the found solutions. The computational experiments on multiobjective traveling salesman problems and multiobjective vehicle routing problems with time windows demonstrate the superiority of our method over most of the learning-based and iteration-based approaches.",10.1109/TNNLS.2022.3148435,2022,,META-LEARNING-BASED DEEP REINFORCEMENT LEARNING FOR MULTIOBJECTIVE OPTIMIZATION PROBLEMS,
62,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"The tracking performance of discriminative correlation filters (DCFs) is often subject to unwanted boundary effects. Many attempts have already been made to address the above issue by enlarging searching regions over the last years. However, introducing excessive background information makes the discriminative filter prone to learn from the surrounding context rather than the target. In this article, we propose a novel context restrained correlation tracking filter (CRCTF) that can effectively suppress background interference via incorporating high-quality adversarial generative negative instances. Concretely, we first construct an adversarial context generation network to simulate the central target area with surrounding background information at the initial frame. Then, we suggest a coarse background estimation network to accelerate the background generation in subsequent frames. By introducing a suppression convolution term, we utilize generative background patches to reformulate the original ridge regression objective through circulant property of correlation and a cropping operator. Finally, our tracking filter is efficiently solved by the alternating direction method of multipliers (ADMM). CRCTF demonstrates the accuracy performance on par with several well-established and highly optimized baselines on multiple challenging tracking datasets, verifying the effectiveness of our proposed approach.",10.1109/TNNLS.2021.3133441,2021,,LEARNING CONTEXT RESTRAINED CORRELATION TRACKING FILTERS VIA ADVERSARIAL NEGATIVE INSTANCE GENERATION,
63,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Dimension reduction (DR) computes faithful low-dimensional (LD) representations of high-dimensional (HD) data. Outstanding performances are achieved by recent neighbor embedding (NE) algorithms such as  $t$ -SNE, which mitigate the curse of dimensionality. The single-scale or multiscale nature of NE schemes drives the HD neighborhood preservation in the LD space (LDS). While single-scale methods focus on single-sized neighborhoods through the concept of perplexity, multiscale ones preserve neighborhoods in a broader range of sizes and account for the global HD organization to define the LDS. For both single-scale and multiscale methods, however, their time complexity in the number of samples is unaffordable for big data sets. Single-scale methods can be accelerated by relying on the inherent sparsity of the HD similarities they involve. On the other hand, the dense structure of the multiscale HD similarities prevents developing fast multiscale schemes in a similar way. This article addresses this difficulty by designing randomized accelerations of the multiscale methods. To account for all levels of interactions, the HD data are first subsampled at different scales, enabling to identify small and relevant neighbor sets for each data point thanks to vantage-point trees. Afterward, these sets are employed with a Barnes–Hut algorithm to cheaply evaluate the considered cost function and its gradient, enabling large-scale use of multiscale NE schemes. Extensive experiments demonstrate that the proposed accelerations are, statistically significantly, both faster than the original multiscale methods by orders of magnitude, and better preserving the HD neighborhoods than state-of-the-art single-scale schemes, leading to high-quality LD embeddings. Public codes are freely available at https://github.com/cdebodt.",10.1109/TNNLS.2020.3042807,2022,,FAST MULTISCALE NEIGHBOR EMBEDDING,
64,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"A new global nonlinear predictor with a particle swarm-optimized interval support vector regression (PSO-ISVR) is proposed to address three issues (viz., kernel selection, model optimization, kernel method speed) encountered when applying SVR in the presence of large data sets. The novel prediction model can reduce the SVR computing overhead by dividing input space and adaptively selecting the optimized kernel functions to obtain optimal SVR parameter by PSO. To quantify the quality of the predictor, its generalization performance and execution speed are investigated based on statistical learning theory. In addition, experiments using synthetic data as well as the stock volume weighted average price are reported to demonstrate the effectiveness of the developed models. The experimental results show that the proposed PSO-ISVR predictor can improve the computational efficiency and the overall prediction accuracy compared with the results produced by the SVR and other regression methods. The proposed PSO-ISVR provides an important tool for nonlinear regression analysis of big data.",10.1109/TNNLS.2015.2426182,2015,,GLOBAL NONLINEAR KERNEL PREDICTION FOR LARGE DATA SET WITH A PARTICLE SWARM-OPTIMIZED INTERVAL SUPPORT VECTOR REGRESSION,
65,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Recently, large volumes of false or unverified information (e.g., fake news and rumors) appear frequently in emerging social media, which are often discussed on a large scale and widely disseminated, causing bad consequences. Many studies on rumor detection indicate that the stance distribution of posts is closely related to the rumor veracity. However, these two tasks are generally considered separately or just using a shared encoder/layer via multitask learning, without exploring the more profound correlation between them. In particular, the performance of existing methods relies heavily on the quality of hand-crafted features and the quantity of labeled data, which is not conducive to early rumor detection and few-shot detection. In this article, we construct a hierarchical heterogeneous graph by associating posts containing the same high-frequency words to facilitate the feature cross-topic propagation and jointly formulate stance and rumor detection as multistage classification tasks. To realize the updating of node embeddings jointly driven by stance and rumor detection, we propose a multigraph neural network framework, which can more flexibly capture the attribute and structure information of the context. Experiments on real datasets collected from Twitter and Reddit show that our method outperforms state-of-the-art by a large margin on both stance and rumor detection. And the experimental results also show that our method has better interpretability and requires less labeled data.",10.1109/TNNLS.2021.3114027,2022,,JOINT STANCE AND RUMOR DETECTION IN HIERARCHICAL HETEROGENEOUS GRAPH,
66,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"The rapid rise of IoT and Big Data has facilitated copious data-driven applications to enhance our quality of life. However, the omnipresent and all-encompassing nature of the data collection can generate privacy concerns. Hence, there is a strong need to develop techniques that ensure the data serve only the intended purposes, giving users control over the information they share. To this end, this article studies new variants of supervised and adversarial learning methods, which remove the sensitive information in the data before they are sent out for a particular application. The explored methods optimize privacy-preserving feature mappings and predictive models simultaneously in an end-to-end fashion. Additionally, the models are built with an emphasis on placing little computational burden on the user side so that the data can be desensitized on device in a cheap manner. Experimental results on mobile sensing and face datasets demonstrate that our models can successfully maintain the utility performances of predictive models while causing sensitive predictions to perform poorly.",10.1109/TNNLS.2021.3110831,2021,,PRIVACY ENHANCING MACHINE LEARNING VIA REMOVAL OF UNWANTED DEPENDENCIES,
67,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a “black box,” which generalizes and learns the transmitted data, into a “glass box” that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.",10.1109/TNNLS.2021.3111745,2021,,NEW INSIGHTS INTO DRUG REPURPOSING FOR COVID-19 USING DEEP LEARNING,
68,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Convolutional neural networks (CNNs) have obtained remarkable performance via deep architectures. However, these CNNs often achieve poor robustness for image super-resolution (SR) under complex scenes. In this article, we present a heterogeneous group SR CNN (HGSRCNN) via leveraging structure information of different types to obtain a high-quality image. Specifically, each heterogeneous group block (HGB) of HGSRCNN uses a heterogeneous architecture containing a symmetric group convolutional block and a complementary convolutional block in a parallel way to enhance the internal and external relations of different channels for facilitating richer low-frequency structure information of different types. To prevent the appearance of obtained redundant features, a refinement block (RB) with signal enhancements in a serial way is designed to filter useless information. To prevent the loss of original information, a multilevel enhancement mechanism guides a CNN to achieve a symmetric architecture for promoting expressive ability of HGSRCNN. Besides, a parallel upsampling mechanism is developed to train a blind SR model. Extensive experiments illustrate that the proposed HGSRCNN has obtained excellent SR performance in terms of both quantitative and qualitative analysis. Codes can be accessed at https://github.com/hellloxiaotian/HGSRCNN.",10.1109/TNNLS.2022.3210433,2022,,A HETEROGENEOUS GROUP CNN FOR IMAGE SUPER-RESOLUTION,
69,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Community detection aims at partitioning a network into several densely connected subgraphs. Recently, nonnegative matrix factorization (NMF) has been widely adopted in many successful community detection applications. However, most existing NMF-based community detection algorithms neglect the multihop network topology and the extreme sparsity of adjacency matrices. To resolve them, we propose a novel conception of adjacency tensor, which extends adjacency matrix to multihop cases. Then, we develop a novel tensor Tucker decomposition-based community detection method—autoencoder-like nonnegative tensor decomposition (ANTD), leveraging the constructed adjacency tensor. Distinct from simply applying tensor decomposition on the constructed adjacency tensor, which only works as a decoder, ANTD also introduces an encoder component to constitute an autoencoder-like architecture, which can further enhance the quality of the detected communities. We also develop an efficient alternative updating algorithm with convergence guarantee to optimize ANTD, and theoretically analyze the algorithm complexity. Moreover, we also study a graph regularized variant of ANTD. Extensive experiments on real-world benchmark networks by comparing 27 state-of-the-art methods, validate the effectiveness, efficiency, and robustness of our proposed methods.",10.1109/TNNLS.2022.3201906,2022,,COMMUNITY DETECTION VIA AUTOENCODER-LIKE NONNEGATIVE TENSOR DECOMPOSITION,
70,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.",10.1109/TNNLS.2016.2599820,2017,,EVALUATING THE VISUALIZATION OF WHAT A DEEP NEURAL NETWORK HAS LEARNED,
71,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.",10.1109/TNNLS.2022.3152527,2022,,LEARNING FROM NOISY LABELS WITH DEEP NEURAL NETWORKS: A SURVEY,
72,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Current learning-based 3-D object detection accuracy is heavily impacted by the annotation quality. It is still a challenge to expect an overall high detection accuracy for all classes under different scenarios given the dataset sparsity. To mitigate this challenge, this article proposes a novel method called semi-supervised learning and progressive distillation (SPD), which uses semi-supervised learning (SSL) and knowledge distillation to improve label efficiency. The SPD uses two big backbones to hand the unlabeled/labeled input data augmented by the periodic IO augmentation (PA). Then the backbones are compressed using progressive distillation (PD). Precisely, PA periodically shifts the data augmentation operations between the input and output of the big backbone, aiming to improve the network&#x2019;s generalization of the unseen and unlabeled data. Using the big backbone can benefit from large-scale augmented data better than the small one. And two backbones are trained by the data scale and ratio-sensitive loss (data-loss). It solves the over-flat caused by the large-scale unlabeled data from PA and helps the big backbone prevent overfitting on the limited-scale labeled data. Hence, using the PA and data loss during SSL training dramatically improves the label efficiency. Next, the trained big backbone set as the teacher CNN is progressively distilled to obtain a small student model, referenced as PD. PD mitigates the problem that student CNN performance degrades when the gap between the student and the teacher is oversized. Extensive experiments are conducted on the indoor datasets SUN RGB-D and ScanNetV2 and outdoor dataset KITTI. Using only 50% labeled data and a 27% smaller model size, SPD performs 0.32 higher than the fully supervised VoteNetqi2019deep which is adopted as our backbone. Besides, using only 2% labeled data, compared to the other fully supervised backbone PV-RCNNshi2020pv, SPD accomplishes a similar accuracy (84.1 and 84.83) and 30% less inference time.",10.1109/TNNLS.2022.3193614,2022,,SPD: SEMI-SUPERVISED LEARNING AND PROGRESSIVE DISTILLATION FOR 3-D DETECTION,
73,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Image style transfer aims at synthesizing an image with the content from one image and the style from another. User studies have revealed that the semantic correspondence between style and content greatly affects subjective perception of style transfer results. While current studies have made great progress in improving the visual quality of stylized images, most methods directly transfer global style statistics without considering semantic alignment. Current semantic style transfer approaches still work in an iterative optimization fashion, which is impractically computationally expensive. Addressing these issues, we introduce a novel dual-affinity style embedding network (DaseNet) to synthesize images with style aligned at semantic region granularity. In the dual-affinity module, feature correlation and semantic correspondence between content and style images are modeled jointly for embedding local style patterns according to semantic distribution. Furthermore, the semantic-weighted style loss and the region-consistency loss are introduced to ensure semantic alignment and content preservation. With the end-to-end network architecture, DaseNet can well balance visual quality and inference efficiency for semantic style transfer. Experimental results on different scene categories have demonstrated the effectiveness of the proposed method.",10.1109/TNNLS.2022.3143356,2022,,DUAL-AFFINITY STYLE EMBEDDING NETWORK FOR SEMANTIC-ALIGNED IMAGE STYLE TRANSFER,
74,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"To alleviate the sparsity issue, many recommender systems have been proposed to consider the review text as the auxiliary information to improve the recommendation quality. Despite success, they only use the ratings as the ground truth for error backpropagation. However, the rating information can only indicate the users’ overall preference for the items, while the review text contains rich information about the users’ preferences and the attributes of the items. In real life, reviews with the same rating may have completely opposite semantic information. If only the ratings are used for error backpropagation, the latent factors of these reviews will tend to be consistent, resulting in the loss of a large amount of review information. In this article, we propose a novel deep model termed deep rating and review neural network (DRRNN) for recommendation. Specifically, compared with the existing models that adopt the review text as the auxiliary information, DRRNN additionally considers both the target rating and target review of the given user–item pair as ground truth for error backpropagation in the training stage. Therefore, we can keep more semantic information of the reviews while making rating predictions. Extensive experiments on four publicly available datasets demonstrate the effectiveness of the proposed DRRNN model in terms of rating prediction.",10.1109/TNNLS.2021.3083264,2022,,DEEP RATING AND REVIEW NEURAL NETWORK FOR ITEM RECOMMENDATION,
75,21100235616,IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS,journal,21622388,"2,882",Q1,212,609,1117,22815,14914,1107,"12,51","37,46",United States,Northern America,IEEE Computational Intelligence Society,2012-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Computer Science Applications (Q1); Software (Q1),"36,361",10.451,0.04868,"Multilabel annotation is a critical step to generate training sets when learning classification models in various application domains, but asking domain experts to provide labels is usually time-consuming and expensive, which cannot meet the current requirement of the fast evolution of the models in the big data era. Although crowdsourcing provides a fast solution to acquire labels for multilabel learning, it faces the risk of high data acquisition cost and low label quality. This article proposes a novel one-coin label-dependent active crowdsourcing (OCLDAC) method to iteratively query noisy labels from crowd workers and learn multilabel classification models. In each iteration of active learning, integrated labels of instances are first inferred by a novel one-coin label-dependent model, which utilizes a mixture of multiple independent Bernoulli distributions to explore and exploit correlations among the labels to increase the accuracy of truth inference. Then, instances, labels, and workers are selected according to the novel strategies that incorporate the distribution of noisy labels, the prediction probability of learning models, label correlations, and the reliability of crowd workers. Simulations on eight multilabel datasets and evaluation on one real-world crowdsourcing dataset consistently show that the proposed OCLDAC significantly outperforms the state-of-the-art methods and their variants.",10.1109/TNNLS.2022.3194022,2022,,ACTIVE CROWDSOURCING FOR MULTILABEL ANNOTATION,
76,22647,GONDWANA RESEARCH,journal,1342937X,"2,859",Q1,135,243,535,31951,3698,517,"5,81","131,49",United States,Northern America,Elsevier Inc.,1997-2020,Geology (Q1),"18,040",6.051,0.01984,"The so-called Fourth Paradigm has witnessed a boom during the past two decades, with large volumes of observational data becoming available to scientists and engineers. Big data is characterized by the rule of the five Vs: Volume, Variety, Value, Velocity and Veracity. The concept of big data naturally matches well with the features of geoengineering and geoscience. Large-scale, comprehensive, multidirectional and multifield geotechnical data analysis is becoming a trend. On the other hand, Machine learning (ML), Deep Learning (DL) and Optimization Algorithm (OA) provide the ability to learn from data and deliver in-depth insight into geotechnical problems. Researchers use different ML, DL and OA models to solve various problems associated with geoengineering and geoscience. Consequently, there is a need to extend its research with big data research through integrating the use of ML, DL and OA techniques. This work focuses on a systematic review on the state-of-the-art application of ML, DL and OA algorithms in geoengineering and geoscience. Various ML, DL, and OA approaches are firstly concisely introduced, concerning mainly the supervised learning, unsupervised learning, deep learning and optimization algorithms. Then their representative applications in the geoengineering and geoscience are summarized via VOSviewer demonstration. The authors also provided their own thoughts learnt from these applications as well as work ongoing and future recommendations. This review paper aims to make a comprehensive summary and provide fundamental guidelines for researchers and engineers in the discipline of geoengineering and geoscience or similar research areas on how to integrate and apply ML, DL and OA methods.",https://doi.org/10.1016/j.gr.2022.03.015,2022,Wengang Zhang and Xin Gu and Libin Tang and Yueping Yin and Dongsheng Liu and Yanmei Zhang,"APPLICATION OF MACHINE LEARNING, DEEP LEARNING AND OPTIMIZATION ALGORITHMS IN GEOENGINEERING AND GEOSCIENCE: COMPREHENSIVE REVIEW AND FUTURE CHALLENGE",article
77,15579,CURRENT OPINION IN BIOTECHNOLOGY,journal,09581669,"2,843",Q1,202,193,475,11888,4236,444,"9,14","61,60",United Kingdom,Western Europe,Elsevier Ltd.,1990-2020,Bioengineering (Q1); Biomedical Engineering (Q1); Biotechnology (Q1),"18,835",9.740,0.0197,"Modern agriculture and food production systems are facing increasing pressures from climate change, land and water availability, and, more recently, a pandemic. These factors are threatening the environmental and economic sustainability of current and future food supply systems. Scientific and technological innovations are needed more than ever to secure enough food for a fast-growing global population. Scientific advances have led to a better understanding of how various components of the agricultural system interact, from the cell to the field level. Despite incredible advances in genetic tools over the past few decades, our ability to accurately assess crop status in the field, at scale, has been severely lacking until recently. Thanks to recent advances in remote sensing and Artificial Intelligence (AI), we can now quantify field scale phenotypic information accurately and integrate the big data into predictive and prescriptive management tools. This review focuses on the use of recent technological advances in remote sensing and AI to improve the resilience of agricultural systems, and we will present a unique opportunity for the development of prescriptive tools needed to address the next decade’s agricultural and human nutrition challenges.",https://doi.org/10.1016/j.copbio.2020.09.003,2021,Jinha Jung and Murilo Maeda and Anjin Chang and Mahendra Bhandari and Akash Ashapure and Juan Landivar-Bowles,THE POTENTIAL OF REMOTE SENSING AND ARTIFICIAL INTELLIGENCE AS TOOLS TO IMPROVE THE RESILIENCE OF AGRICULTURE PRODUCTION SYSTEMS,article
78,26099,INFORMATION FUSION,journal,15662535,"2,776",Q1,107,168,318,13659,5599,312,"15,73","81,30",Netherlands,Western Europe,Elsevier,2000-2021,Hardware and Architecture (Q1); Information Systems (Q1); Signal Processing (Q1); Software (Q1),"9,059",12.975,0.0126,"Urban big data fusion creates huge values for urban computing in solving urban problems. In recent years, various models and algorithms based on deep learning have been proposed to unlock the power of knowledge from urban big data. To clarify the methodologies of urban big data fusion based on deep learning (DL), this paper classifies them into three categories: DL-output-based fusion, DL-input-based fusion and DL-double-stage-based fusion. These methods use deep learning to learn feature representation from multi-source big data. Then each category of fusion methods is introduced and some examples are shown. The difficulties and ideas of dealing with urban big data will also be discussed.",https://doi.org/10.1016/j.inffus.2019.06.016,2020,Jia Liu and Tianrui Li and Peng Xie and Shengdong Du and Fei Teng and Xin Yang,URBAN BIG DATA FUSION BASED ON DEEP LEARNING: AN OVERVIEW,article
79,26099,INFORMATION FUSION,journal,15662535,"2,776",Q1,107,168,318,13659,5599,312,"15,73","81,30",Netherlands,Western Europe,Elsevier,2000-2021,Hardware and Architecture (Q1); Information Systems (Q1); Signal Processing (Q1); Software (Q1),"9,059",12.975,0.0126,"The advancement of various research sectors such as Internet of Things (IoT), Machine Learning, Data Mining, Big Data, and Communication Technology has shed some light in transforming an urban city integrating the aforementioned techniques to a commonly known term - Smart City. With the emergence of smart city, plethora of data sources have been made available for wide variety of applications. The common technique for handling multiple data sources is data fusion, where it improves data output quality or extracts knowledge from the raw data. In order to cater evergrowing highly complicated applications, studies in smart city have to utilize data from various sources and evaluate their performance based on multiple aspects. To this end, we introduce a multi-perspectives classification of the data fusion to evaluate the smart city applications. Moreover, we applied the proposed multi-perspectives classification to evaluate selected applications in each domain of the smart city. We conclude the paper by discussing potential future direction and challenges of data fusion integration.",https://doi.org/10.1016/j.inffus.2019.05.004,2019,Billy Pik Lik Lau and Sumudu Hasala Marakkalage and Yuren Zhou and Naveed Ul Hassan and Chau Yuen and Meng Zhang and U-Xuan Tan,A SURVEY OF DATA FUSION IN SMART CITY APPLICATIONS,article
80,26099,INFORMATION FUSION,journal,15662535,"2,776",Q1,107,168,318,13659,5599,312,"15,73","81,30",Netherlands,Western Europe,Elsevier,2000-2021,Hardware and Architecture (Q1); Information Systems (Q1); Signal Processing (Q1); Software (Q1),"9,059",12.975,0.0126,"Deep learning, as one of the most currently remarkable machine learning techniques, has achieved great success in many applications such as image analysis, speech recognition and text understanding. It uses supervised and unsupervised strategies to learn multi-level representations and features in hierarchical architectures for the tasks of classification and pattern recognition. Recent development in sensor networks and communication technologies has enabled the collection of big data. Although big data provides great opportunities for a broad of areas including e-commerce, industrial control and smart medical, it poses many challenging issues on data mining and information processing due to its characteristics of large volume, large variety, large velocity and large veracity. In the past few years, deep learning has played an important role in big data analytic solutions. In this paper, we review the emerging researches of deep learning models for big data feature learning. Furthermore, we point out the remaining challenges of big data deep learning and discuss the future topics.",https://doi.org/10.1016/j.inffus.2017.10.006,2018,Qingchen Zhang and Laurence T. Yang and Zhikui Chen and Peng Li,A SURVEY ON DEEP LEARNING FOR BIG DATA,article
81,26099,INFORMATION FUSION,journal,15662535,"2,776",Q1,107,168,318,13659,5599,312,"15,73","81,30",Netherlands,Western Europe,Elsevier,2000-2021,Hardware and Architecture (Q1); Information Systems (Q1); Signal Processing (Q1); Software (Q1),"9,059",12.975,0.0126,"The landscape of mental health has undergone tremendous changes within the last two decades, but the research on mental health is still at the initial stage with substantial knowledge gaps and the lack of precise diagnosis. Nowadays, big data and artificial intelligence offer new opportunities for the screening and prediction of mental problems. In this review paper, we outline the vision of digital phenotyping of mental health (DPMH) by fusing the enriched data from ubiquitous sensors, social media and healthcare systems, and present a broad overview of DPMH from sensing and computing perspectives. We first conduct a systematical literature review and propose the research framework, which highlights the key aspects related with mental health, and discuss the challenges elicited by the enriched data for digital phenotyping. Next, five key research strands including affect recognition, cognitive analytics, behavioral anomaly detection, social analytics, and biomarker analytics are unfolded in the psychiatric context. Finally, we discuss various open issues and the corresponding solutions to underpin the digital phenotyping of mental health.",https://doi.org/10.1016/j.inffus.2019.04.001,2019,Yunji Liang and Xiaolong Zheng and Daniel D. Zeng,A SURVEY ON BIG DATA-DRIVEN DIGITAL PHENOTYPING OF MENTAL HEALTH,article
82,26099,INFORMATION FUSION,journal,15662535,"2,776",Q1,107,168,318,13659,5599,312,"15,73","81,30",Netherlands,Western Europe,Elsevier,2000-2021,Hardware and Architecture (Q1); Information Systems (Q1); Signal Processing (Q1); Software (Q1),"9,059",12.975,0.0126,"Big data has become an important issue for a large number of research areas such as data mining, machine learning, computational intelligence, information fusion, the semantic Web, and social networks. The rise of different big data frameworks such as Apache Hadoop and, more recently, Spark, for massive data processing based on the MapReduce paradigm has allowed for the efficient utilisation of data mining methods and machine learning algorithms in different domains. A number of libraries such as Mahout and SparkMLib have been designed to develop new efficient applications based on machine learning algorithms. The combination of big data technologies and traditional machine learning algorithms has generated new and interesting challenges in other areas as social media and social networks. These new challenges are focused mainly on problems such as data processing, data storage, data representation, and how data can be used for pattern mining, analysing user behaviours, and visualizing and tracking data, among others. In this paper, we present a revision of the new methodologies that is designed to allow for efficient data mining and information fusion from social media and of the new applications and frameworks that are currently appearing under the “umbrella” of the social networks, social media and big data paradigms.",https://doi.org/10.1016/j.inffus.2015.08.005,2016,Gema Bello-Orgaz and Jason J. Jung and David Camacho,SOCIAL BIG DATA: RECENT ACHIEVEMENTS AND NEW CHALLENGES,article
83,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Open data aims to unlock the innovation potential of businesses, governments, and entrepreneurs, yet it also harbours significant challenges for its effective use. While numerous innovation successes exist that are based on the open data paradigm, there is uncertainty over the data quality of such datasets. This data quality uncertainty is a threat to the value that can be generated from such data. Data quality has been studied extensively over many decades and many approaches to data quality management have been proposed. However, these approaches are typically based on datasets internal to organizations, with known metadata, and domain knowledge of the data semantics. Open data, on the other hand, are often unfamiliar to the user and may lack metadata. The aim of this research note is to outline the challenges in dealing with data quality of open datasets, and to set an agenda for future research to address this risk to deriving value from open data investments.",https://doi.org/10.1016/j.ijinfomgt.2017.01.003,2017,Shazia Sadiq and Marta Indulska,OPEN DATA: QUALITY OVER QUANTITY,article
84,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The social housing sector has yet to realise the potential of high data quality. While other businesses, mainly in the private sector, reap the benefits of data quality, the social housing sector seems paralysed, as it is still struggling with recent government regulations and steep revenue reduction. This paper offers a succinct review of relevant literature on data quality and how it relates to social housing. The Housing and Development Board in Singapore offers a great example on how to integrate data quality initiatives in the social housing sector. Taking this example, the research presented in this paper is extrapolating cross-disciplinarily recommendations on how to implement data quality initiatives in social housing providers in the UK.",https://doi.org/10.1016/j.ijinfomgt.2017.09.008,2018,Caroline Duvier and Daniel Neagu and Crina Oltean-Dumbrava and Dave Dickens,DATA QUALITY CHALLENGES IN THE UK SOCIAL HOUSING SECTOR,article
85,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The success or failure of a RIS in a scientific institution is largely related to the quality of the data available as a basis for the RIS applications. The most beautiful Business Intelligence (BI) tools (reporting, etc.) are worthless when displaying incorrect, incomplete, or inconsistent data. An integral part of every RIS is thus the integration of data from the operative systems. Before starting the integration process (ETL) of a source system, a rich analysis of source data is required. With the support of a data quality check, causes of quality problems can usually be detected. Corresponding analyzes are performed with data profiling to provide a good picture of the state of the data. In this paper, methods of data profiling are presented in order to gain an overview of the quality of the data in the source systems before their integration into the RIS. With the help of data profiling, the scientific institutions can not only evaluate their research information and provide information about their quality, but also examine the dependencies and redundancies between data fields and better correct them within their RIS.",https://doi.org/10.1016/j.ijinfomgt.2018.02.007,2018,Otmane Azeroual and Gunter Saake and Eike Schallehn,ANALYZING DATA QUALITY ISSUES IN RESEARCH INFORMATION SYSTEMS VIA DATA PROFILING,article
86,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"This is the first systematic literature review concerning the interconnections between big data (BD) and co-innovation. It uses BD as a common perspective of analysis as well as a concept aggregating different research streams (open innovation, co-creation and collaborative innovation). The review is based on the results of a bibliographic coupling analysis performed with 51 peer-reviewed papers published before the end of 2019. Three thematic clusters were discovered, which respectively focused on BD as a knowledge creation enabler within co-innovation contexts, BD as a driver of co-innovation processes based on customer engagement, and the impact of BD on co-innovation within service ecosystems. The paper theoretically argues that the use of BD, in addition to enhancing intentional and direct collaborative innovation processes, allows the development of passive and unintentional co-innovation that can be implemented through indirect relationships between the collaborative actors. This study also makes eleven unique research propositions concerning further theoretical developments and managerial implementations in the field of BD-driven co-innovation.",https://doi.org/10.1016/j.ijinfomgt.2021.102347,2021,Stefano Bresciani and Francesco Ciampi and Francesco Meli and Alberto Ferraris,"USING BIG DATA FOR CO-INNOVATION PROCESSES: MAPPING THE FIELD OF DATA-DRIVEN INNOVATION, PROPOSING THEORETICAL DEVELOPMENTS AND PROVIDING A RESEARCH AGENDA",article
87,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Big data analytics associated with database searching, mining, and analysis can be seen as an innovative IT capability that can improve firm performance. Even though some leading companies are actively adopting big data analytics to strengthen market competition and to open up new business opportunities, many firms are still in the early stage of the adoption curve due to lack of understanding of and experience with big data. Hence, it is interesting and timely to understand issues relevant to big data adoption. In this study, a research model is proposed to explain the acquisition intention of big data analytics mainly from the theoretical perspectives of data quality management and data usage experience. Our empirical investigation reveals that a firm's intention for big data analytics can be positively affected by its competence in maintaining the quality of corporate data. Moreover, a firm's favorable experience (i.e., benefit perceptions) in utilizing external source data could encourage future acquisition of big data analytics. Surprisingly, a firm's favorable experience (i.e., benefit perceptions) in utilizing internal source data could hamper its adoption intention for big data analytics.",https://doi.org/10.1016/j.ijinfomgt.2014.02.002,2014,Ohbyung Kwon and Namyeon Lee and Bongsik Shin,"DATA QUALITY MANAGEMENT, DATA USAGE EXPERIENCE AND ACQUISITION INTENTION OF BIG DATA ANALYTICS",article
88,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Data governance refers to the exercise of authority and control over the management of data. The purpose of data governance is to increase the value of data and minimize data-related cost and risk. Despite data governance gaining in importance in recent years, a holistic view on data governance, which could guide both practitioners and researchers, is missing. In this review paper, we aim to close this gap and develop a conceptual framework for data governance, synthesize the literature, and provide a research agenda. We base our work on a structured literature review including 145 research papers and practitioner publications published during 2001-2019. We identify the major building blocks of data governance and decompose them along six dimensions. The paper supports future research on data governance by identifying five research areas and displaying a total of 15 research questions. Furthermore, the conceptual framework provides an overview of antecedents, scoping parameters, and governance mechanisms to assist practitioners in approaching data governance in a structured manner.",https://doi.org/10.1016/j.ijinfomgt.2019.07.008,2019,Rene Abraham and Johannes Schneider and Jan {vom Brocke},"DATA GOVERNANCE: A CONCEPTUAL FRAMEWORK, STRUCTURED REVIEW, AND RESEARCH AGENDA",article
89,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The critical factors in the big data era are collection, analysis, and dissemination of information to improve an organization’s competitive position and enhance its products and services. In this scenario, it is imperative that organizations use Intelligence, which is understood as a process of gathering, analyzing, interpreting, and disseminating high-value data and information at the right time for use in the decision-making process. Earlier, the concept of Intelligence was associated with the military and national security sector; however, in present times, and as organizations evolve, Intelligence has been defined in several ways for the purposes of different applications. Given that the purpose of Intelligence is to obtain real value from data, information, and the dynamism of the organizations, the study of this discipline provides an opportunity to analyze the core trends related to data collection and processing, information management, decision-making process, and organizational capabilities. Therefore, the present study makes a conceptual analysis of the existing definitions of intelligence in the literature by quantifying the main bibliometric performance indicators, identifying the main authors and research areas, and evaluating the development of the field using SciMAT as a bibliometric analysis software.",https://doi.org/10.1016/j.ijinfomgt.2019.01.013,2019,J.R. López-Robles and J.R. Otegi-Olaso and I. {Porto Gómez} and M.J. Cobo,30 YEARS OF INTELLIGENCE MODELS IN MANAGEMENT AND BUSINESS: A BIBLIOMETRIC REVIEW,article
90,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Agile methodologies were introduced in 2001. Since this time, practitioners have applied Agile methodologies to many delivery disciplines. This article explores the application of Agile methodologies and principles to business intelligence delivery and how Agile has changed with the evolution of business intelligence. Business intelligence has evolved because the amount of data generated through the internet and smart devices has grown exponentially altering how organizations and individuals use information. The practice of business intelligence delivery with an Agile methodology has matured; however, business intelligence has evolved altering the use of Agile principles and practices. The Big Data phenomenon, the volume, variety, and velocity of data, has impacted business intelligence and the use of information. New trends such as fast analytics and data science have emerged as part of business intelligence. This paper addresses how Agile principles and practices have evolved with business intelligence, as well as its challenges and future directions.",https://doi.org/10.1016/j.ijinfomgt.2016.04.013,2016,Deanne Larson and Victor Chang,"A REVIEW AND FUTURE DIRECTION OF AGILE, BUSINESS INTELLIGENCE, ANALYTICS AND DATA SCIENCE",article
91,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Analysis of data by humans can be a time-consuming activity and thus use of sophisticated cognitive systems can be utilized to crunch this enormous amount of data. Cognitive computing can be utilized to reduce the shortcomings of the concerns faced during big data analytics. The aim of the study is to provide readers a complete understanding of past, present and future directions in the domain big data and cognitive computing. A systematic literature review has been adopted for this study by using the Scopus, DBLP and Web of Science databases. The work done in the field of big data and cognitive computing is currently at the nascent stage and this is evident from the publication record. The characteristics of cognitive computing, namely observation, interpretation, evaluation and decision were mapped to the five V’s of big data namely volume, variety, veracity, velocity and value. Perspectives which touch all these parameters are yet to be widely explored in existing literature.",https://doi.org/10.1016/j.ijinfomgt.2018.06.005,2018,Shivam Gupta and Arpan Kumar Kar and Abdullah Baabdullah and Wassan A.A. Al-Khowaiter,BIG DATA WITH COGNITIVE COMPUTING: A REVIEW FOR THE FUTURE,article
92,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"People, devices, infrastructures and sensors can constantly communicate exchanging data and generating new data that trace many of these exchanges. This leads to vast volumes of data collected at ever increasing velocities and of different variety, a phenomenon currently known as Big Data. In particular, recent developments in Information and Communications Technologies are pushing the fourth industrial revolution, Industry 4.0, being data generated by several sources like machine controllers, sensors, manufacturing systems, among others. Joining volume, variety and velocity of data, with Industry 4.0, makes the opportunity to enhance sustainable innovation in the Factories of the Future. In this, the collection, integration, storage, processing and analysis of data is a key challenge, being Big Data systems needed to link all the entities and data needs of the factory. Thereby, this paper addresses this key challenge, proposing and implementing a Big Data Analytics architecture, using a multinational organisation (Bosch Car Multimedia – Braga) as a case study. In this work, all the data lifecycle, from collection to analysis, is handled, taking into consideration the different data processing speeds that can exist in the real environment of a factory (batch or stream).",https://doi.org/10.1016/j.ijinfomgt.2017.07.012,2017,Maribel Yasmina Santos and Jorge {Oliveira e Sá} and Carina Andrade and Francisca {Vale Lima} and Eduarda Costa and Carlos Costa and Bruno Martinho and João Galvão,A BIG DATA SYSTEM SUPPORTING BOSCH BRAGA INDUSTRY 4.0 STRATEGY,article
93,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Big data is a potential research area receiving considerable attention from academia and IT communities. In the digital world, the amounts of data generated and stored have expanded within a short period of time. Consequently, this fast growing rate of data has created many challenges. In this paper, we use structuralism and functionalism paradigms to analyze the origins of big data applications and its current trends. This paper presents a comprehensive discussion on state-of-the-art big data technologies based on batch and stream data processing. Moreover, strengths and weaknesses of these technologies are analyzed. This study also discusses big data analytics techniques, processing methods, some reported case studies from different vendors, several open research challenges, and the opportunities brought about by big data. The similarities and differences of these techniques and technologies based on important parameters are also investigated. Emerging technologies are recommended as a solution for big data problems.",https://doi.org/10.1016/j.ijinfomgt.2016.07.009,2016,Ibrar Yaqoob and Ibrahim Abaker Targio Hashem and Abdullah Gani and Salimah Mokhtar and Ejaz Ahmed and Nor Badrul Anuar and Athanasios V. Vasilakos,BIG DATA: FROM BEGINNING TO FUTURE,article
94,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The purpose of this study is to enrich the existing state-of-the-art literature on the impact of big data on business growth by examining how dozens of organizational theories can be applied to enhance the understanding of the effects of big data on organizational performance. While the majority of management disciplines have had research dedicated to the conceptual discussion of how to link a variety of organizational theories to empirically quantified research topics, the body of research into big data so far lacks an academic work capable of systematising the organizational theories supporting big data domain. The three main contributions of this work are: (a) it addresses the application of dozens of organizational theories to big data research; (b) it offers a research agenda on how to link organizational theories to empirical research in big data; and (c) it foresees promising linkages between organizational theories and the effects of big data on organizational performance, with the aim of contributing to further research in this field. This work concludes by presenting implications for researchers and managers, and by highlighting intrinsic limitations of the research.",https://doi.org/10.1016/j.ijinfomgt.2018.07.005,2018,Paula {de Camargo Fiorini} and Bruno Michel {Roman Pais Seles} and Charbel Jose {Chiappetta Jabbour} and Enzo {Barberio Mariano} and Ana Beatriz Lopes {de Sousa Jabbour},MANAGEMENT THEORY AND BIG DATA LITERATURE: FROM A REVIEW TO A RESEARCH AGENDA,article
95,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Recently, patient safety and healthcare have gained high attention in professional and health policy-makers. This rapid growth causes generating a high amount of data, which is known as big data. Therefore, handling and processing of this data are attracted great attention. Cloud computing is one of the main choices for handling and processing of this type of data. But, as far as we know, the detailed review and deep discussion in this filed are very rare. Therefore, this paper reviews and discusses the recently introduced mechanisms in this field as well as providing a deep analysis of their applied mechanisms. Moreover, the drawbacks and benefits of the reviewed mechanisms have been discussed and the main challenges of these mechanisms are highlighted for developing more efficient healthcare big data processing techniques over cloud computing in the future.",https://doi.org/10.1016/j.ijinfomgt.2019.05.017,2019,Lila Rajabion and Abdusalam Abdulla Shaltooki and Masoud Taghikhah and Amirhossein Ghasemi and Arshad Badfar,HEALTHCARE BIG DATA PROCESSING MECHANISMS: THE ROLE OF CLOUD COMPUTING,article
96,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The advent of connected devices and omnipresence of Internet have paved way for intruders to attack networks, which leads to cyber-attack, financial loss, information theft in healthcare, and cyber war. Hence, network security analytics has become an important area of concern and has gained intensive attention among researchers, off late, specifically in the domain of anomaly detection in network, which is considered crucial for network security. However, preliminary investigations have revealed that the existing approaches to detect anomalies in network are not effective enough, particularly to detect them in real time. The reason for the inefficacy of current approaches is mainly due the amassment of massive volumes of data though the connected devices. Therefore, it is crucial to propose a framework that effectively handles real time big data processing and detect anomalies in networks. In this regard, this paper attempts to address the issue of detecting anomalies in real time. Respectively, this paper has surveyed the state-of-the-art real-time big data processing technologies related to anomaly detection and the vital characteristics of associated machine learning algorithms. This paper begins with the explanation of essential contexts and taxonomy of real-time big data processing, anomalous detection, and machine learning algorithms, followed by the review of big data processing technologies. Finally, the identified research challenges of real-time big data processing in anomaly detection are discussed.",https://doi.org/10.1016/j.ijinfomgt.2018.08.006,2019,Riyaz Ahamed {Ariyaluran Habeeb} and Fariza Nasaruddin and Abdullah Gani and Ibrahim Abaker {Targio Hashem} and Ejaz Ahmed and Muhammad Imran,REAL-TIME BIG DATA PROCESSING FOR ANOMALY DETECTION: A SURVEY,article
97,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Patients face difficulties identifying appropriate doctors owing to the sizeable quantity and uneven quality of information in online healthcare communities. In studying physician searches, researchers often focus on expertise similarity matches and sentiment analyses of reviews. However, the quality is often ignored. To address patients' information needs holistically, we propose a four-dimensional IT framework based on signaling theory. The model takes expertise knowledge, online reviews, profile descriptions (e.g., hospital reputation, number of patients, city) and service quality (e.g., response speed, interaction frequency, cost) as signals that distinguish high-quality physicians. It uses machine learning approaches to derive similarity matches and sentiment analysis. It also measures the relative importance of the signals by multi-criterion analysis and derives the physician rankings through the aggregated scores. Our study revealed that the proposed approach performs better compared with the other two recommend techniques. This research expands the boundary of signaling theory to healthcare management and enriches the literature on IT use and inter-organizational systems. The proposed IT model may improve patient care, alleviate the physician-patient relationship and reduce lawsuits against hospitals; it also has practical implications for healthcare management.",https://doi.org/10.1016/j.ijinfomgt.2019.01.005,2019,Yan Ye and Yang Zhao and Jennifer Shang and Liyi Zhang,A HYBRID IT FRAMEWORK FOR IDENTIFYING HIGH-QUALITY PHYSICIANS USING BIG DATA ANALYTICS,article
98,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"Value creation is a major sustainability factor for enterprises, in addition to profit maximization and revenue generation. Modern enterprises collect big data from various inbound and outbound data sources. The inbound data sources handle data generated from the results of business operations, such as manufacturing, supply chain management, marketing, and human resource management, among others. Outbound data sources handle customer-generated data which are acquired directly or indirectly from customers, market analysis, surveys, product reviews, and transactional histories. However, cloud service utilization costs increase because of big data analytics and value creation activities for enterprises and customers. This article presents a novel concept of big data reduction at the customer end in which early data reduction operations are performed to achieve multiple objectives, such as (a) lowering the service utilization cost, (b) enhancing the trust between customers and enterprises, (c) preserving privacy of customers, (d) enabling secure data sharing, and (e) delegating data sharing control to customers. We also propose a framework for early data reduction at customer end and present a business model for end-to-end data reduction in enterprise applications. The article further presents a business model canvas and maps the future application areas with its nine components. Finally, the article discusses the technology adoption challenges for value creation through big data reduction in enterprise applications.",https://doi.org/10.1016/j.ijinfomgt.2016.05.013,2016,Muhammad Habib ur Rehman and Victor Chang and Aisha Batool and Teh Ying Wah,BIG DATA REDUCTION FRAMEWORK FOR VALUE CREATION IN SUSTAINABLE ENTERPRISES,article
99,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The expansion of big data and the evolution of Internet of Things (IoT) technologies have played an important role in the feasibility of smart city initiatives. Big data offer the potential for cities to obtain valuable insights from a large amount of data collected through various sources, and the IoT allows the integration of sensors, radio-frequency identification, and Bluetooth in the real-world environment using highly networked services. The combination of the IoT and big data is an unexplored research area that has brought new and interesting challenges for achieving the goal of future smart cities. These new challenges focus primarily on problems related to business and technology that enable cities to actualize the vision, principles, and requirements of the applications of smart cities by realizing the main smart environment characteristics. In this paper, we describe the state-of-the-art communication technologies and smart-based applications used within the context of smart cities. The visions of big data analytics to support smart cities are discussed by focusing on how big data can fundamentally change urban populations at different levels. Moreover, a future business model of big data for smart cities is proposed, and the business and technological research challenges are identified. This study can serve as a benchmark for researchers and industries for the future progress and development of smart cities in the context of big data.",https://doi.org/10.1016/j.ijinfomgt.2016.05.002,2016,Ibrahim Abaker Targio Hashem and Victor Chang and Nor Badrul Anuar and Kayode Adewole and Ibrar Yaqoob and Abdullah Gani and Ejaz Ahmed and Haruna Chiroma,THE ROLE OF BIG DATA IN SMART CITY,article
100,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"The increased availability of social media big data has created a unique challenge for marketing decision-makers; turning this data into useful information. One of the significant areas of opportunity in digital marketing is influencer marketing, but identifying these influencers from big data sets is a continual challenge. This research illustrates how one type of influencer, the market maven, can be identified using big data. Using a mixed-method combination of both self-report survey data and publicly accessible big data, we gathered 556,150 tweets from 370 active Twitter users. We then proposed and tested a range of social-media-based metrics to identify market mavens. Findings show that market mavens (when compared to non-mavens) have more followers, post more often, have less readable posts, use more uppercase letters, use less distinct words, and use hashtags more often. These metrics are openly available from public Twitter accounts and could integrate into a broad-scale decision support system for marketing and information systems managers. These findings have the potential to improve influencer identification effectiveness and efficiency, and thus improve influencer marketing.",https://doi.org/10.1016/j.ijinfomgt.2020.102246,2021,Paul Harrigan and Timothy M. Daly and Kristof Coussement and Julie A. Lee and Geoffrey N. Soutar and Uwana Evers,IDENTIFYING INFLUENCERS ON SOCIAL MEDIA,article
101,15631,INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT,journal,02684012,"2,770",Q1,114,224,382,20318,5853,373,"16,16","90,71",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1986-2021",Artificial Intelligence (Q1); Computer Networks and Communications (Q1); Information Systems (Q1); Information Systems and Management (Q1); Library and Information Sciences (Q1); Management Information Systems (Q1); Marketing (Q1),"12,245",14.098,0.01167,"While the use of big data tends to add value for business throughout the entire value chain, the integration of big data analytics (BDA) to the decision-making process remains a challenge. This study, based on a systematic literature review, thematic analysis and qualitative interview findings, proposes a set of six-steps to establish both rigor and relevance in the process of analytics-driven decision-making. Our findings illuminate the key steps in this decision process including problem definition, review of past findings, model development, data collection, data analysis as well as actions on insights in the context of service systems. Although findings have been discussed in a sequence of steps, the study identifies them as interdependent and iterative. The proposed six-step analytics-driven decision-making process, practical evidence from service systems, and future research agenda, provide altogether the foundation for future scholarly research and can serve as a step-wise guide for industry practitioners.",https://doi.org/10.1016/j.ijinfomgt.2019.01.020,2019,Shahriar Akter and Ruwan Bandara and Umme Hani and Samuel {Fosso Wamba} and Cyril Foropon and Thanos Papadopoulos,ANALYTICS-BASED DECISION-MAKING FOR SERVICE SYSTEMS: A QUALITATIVE STUDY AND AGENDA FOR FUTURE RESEARCH,article
102,13266,AMERICAN JOURNAL OF OPHTHALMOLOGY,journal,00029394,"2,704",Q1,186,428,1146,11979,4453,848,"3,73","27,99",United States,Northern America,Elsevier USA,1918-2020,Ophthalmology (Q1),"32,566",5.258,0.0263,"Purpose
To characterize the role of Big Data in evaluating quality of care in ophthalmology, to highlight opportunities for studying quality improvement using data available in the American Academy of Ophthalmology Intelligent Research in Sight (IRIS) Registry, and to show how Big Data informs us about rare events such as endophthalmitis after cataract surgery.
Design
Review of published studies, analysis of public-use Medicare claims files from 2010 to 2013, and analysis of IRIS Registry from 2013 to 2014.
Methods
Statistical analysis of observational data.
Results
The overall rate of endophthalmitis after cataract surgery was 0.14% in 216 703 individuals in the Medicare database. In the IRIS Registry the endophthalmitis rate after cataract surgery was 0.08% among 511 182 individuals. Endophthalmitis rates tended to be higher in eyes with combined cataract surgery and anterior vitrectomy (P = .051), although only 0.08% of eyes had this combined procedure. Visual acuity (VA) in the IRIS Registry in eyes with and without postoperative endophthalmitis measured 1–7 days postoperatively were logMAR 0.58 (standard deviation [SD]: 0.84) (approximately Snellen acuity of 20/80) and logMAR 0.31 (SD: 0.34) (approximately Snellen acuity of 20/40), respectively. In 33 547 eyes with postoperative VA after cataract surgery, 18.3% had 1-month-postoperative VA worse than 20/40.
Conclusions
Big Data drawing on Medicare claims and IRIS Registry records can help identify additional areas for quality improvement, such as in the 18.3% of eyes in the IRIS Registry having 1-month-postoperative VA worse than 20/40. The ability to track patient outcomes in Big Data sets provides opportunities for further research on rare complications such as postoperative endophthalmitis and outcomes from uncommon procedures such as cataract surgery combined with anterior vitrectomy. But privacy and data-security concerns associated with Big Data should not be taken lightly.",https://doi.org/10.1016/j.ajo.2015.09.028,2015,Anne Louise Coleman,HOW BIG DATA INFORMS US ABOUT CATARACT SURGERY: THE LXXII EDWARD JACKSON MEMORIAL LECTURE,article
103,26371,NATURAL PRODUCT REPORTS,journal,02650568,"2,703",Q1,177,92,246,12696,2233,239,"8,45","138,00",United Kingdom,Western Europe,Royal Society of Chemistry,1984-2020,Biochemistry (Q1); Drug Discovery (Q1); Organic Chemistry (Q1),"13,293",13.423,0.01116,"ABSTRACT
Systematic, large-scale, studies at the genomic, metabolomic, and functional level have transformed the natural product sciences. Improvements in technology and reduction in cost for obtaining spectroscopic, chromatographic, and genomic data coupled with the creation of readily accessible curated and functionally annotated data sets have altered the practices of virtually all natural product research laboratories. Gone are the days when the natural products researchers were expected to devote themselves exclusively to the isolation, purification, and structure elucidation of small molecules. We now also engage with big data in taxonomic, genomic, proteomic, and/or metabolomic collections, and use these data to generate and test hypotheses. While the oft stated aim for the use of large-scale -omics data in the natural products sciences is to achieve a rapid increase in the rate of discovery of new drugs, this has not yet come to pass. At the same time, new technologies have provided unexpected opportunities for natural products chemists to ask and answer new and different questions. With this viewpoint, we discuss the evolution of big data as a part of natural products research and provide a few examples of how discoveries have been enabled by access to big data. We also draw attention to some of the limitations in our existing engagement with large datasets and consider what would be necessary to overcome them.",https://doi.org/10.1039/d1np00061f,2021,Nadja B. Cech and Marnix H. Medema and Jon Clardy,BENEFITING FROM BIG DATA IN NATURAL PRODUCTS: IMPORTANCE OF PRESERVING FOUNDATIONAL SKILLS AND PRIORITIZING DATA QUALITY,article
104,19366,AMERICAN JOURNAL OF KIDNEY DISEASES,journal,02726386,"2,677",Q1,214,264,857,7570,3775,538,"4,45","28,67",United Kingdom,Western Europe,W.B. Saunders Ltd,1981-2020,Nephrology (Q1),"27,640",8.860,0.0271,,https://doi.org/10.1053/j.ajkd.2017.04.008,2017,Rajiv Saran and Diane Steffick and Jennifer Bragg-Gresham,THE CHINA KIDNEY DISEASE NETWORK (CK-NET): “BIG DATA—BIG DREAMS”,article
105,20689,AUTOIMMUNITY REVIEWS,journal,15689972,"2,621",Q1,122,177,465,12128,3509,408,"7,66","68,52",Netherlands,Western Europe,Elsevier,2002-2020,Immunology (Q1); Immunology and Allergy (Q1),"13,493",9.754,0.01481,"The past decade has seen tremendous development in digital health, including in innovative new technologies such as Electronic Health Records, telemedicine, virtual visits, wearable technology and sophisticated analytical tools such as artificial intelligence (AI) and machine learning for the deep-integration of big data. In the field of rare connective tissue diseases (rCTDs), these opportunities include increased access to scarce and remote expertise, improved patient monitoring, increased participation and therapeutic adherence, better patient outcomes and patient empowerment. In this review, we discuss opportunities and key-barriers to improve application of digital health technologies in the field of autoimmune diseases. We also describe what could be the fully digital pathway of rCTD patients. Smart technologies can be used to provide real-world evidence about the natural history of rCTDs, to determine real-life drug utilization, advanced efficacy and safety data for rare diseases and highlight significant unmet needs. Yet, digitalization remains one of the most challenging issues faced by rCTD patients, their physicians and healthcare systems. Digital health technologies offer enormous potential to improve autoimmune rCTD care but this potential has so far been largely unrealized due to those significant obstacles. The need for robust assessments of the efficacy, affordability and scalability of AI in the context of digital health is crucial to improve the care of patients with rare autoimmune diseases.",https://doi.org/10.1016/j.autrev.2021.102864,2021,Hugo Bergier and Loïc Duron and Christelle Sordet and Lou Kawka and Aurélien Schlencker and François Chasset and Laurent Arnaud,"DIGITAL HEALTH, BIG DATA AND SMART TECHNOLOGIES FOR THE CARE OF PATIENTS WITH SYSTEMIC AUTOIMMUNE DISEASES: WHERE DO WE STAND?",article
106,21858,BRITISH JOURNAL OF ANAESTHESIA,journal,00070912,"2,589",Q1,181,486,1260,12638,5321,684,"4,33","26,00",United Kingdom,Western Europe,Elsevier Ltd.,1923-2020,Anesthesiology and Pain Medicine (Q1),"27,510",9.166,0.02901,,https://doi.org/10.1016/j.bja.2020.01.012,2020,Daniel I. McIsaac,REAL-WORLD EVALUATION OF ENHANCED RECOVERY AFTER SURGERY: BIG DATA UNDER THE MICROSCOPE,article
107,21858,BRITISH JOURNAL OF ANAESTHESIA,journal,00070912,"2,589",Q1,181,486,1260,12638,5321,684,"4,33","26,00",United Kingdom,Western Europe,Elsevier Ltd.,1923-2020,Anesthesiology and Pain Medicine (Q1),"27,510",9.166,0.02901,"Advances in computer technology, patient monitoring systems, and electronic health record systems have enabled rapid accumulation of patient data in electronic form (i.e. big data). Organizations such as the Anesthesia Quality Institute and Multicenter Perioperative Outcomes Group have spearheaded large-scale efforts to collect anaesthesia big data for outcomes research and quality improvement. Analytics—the systematic use of data combined with quantitative and qualitative analysis to make decisions—can be applied to big data for quality and performance improvements, such as predictive risk assessment, clinical decision support, and resource management. Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces, and it can facilitate performance of cognitive activities involving big data. Ongoing integration of big data and analytics within anaesthesia and health care will increase demand for anaesthesia professionals who are well versed in both the medical and the information sciences.",https://doi.org/10.1093/bja/aeu552,2015,A.F. Simpao and L.M. Ahumada and M.A. Rehman,BIG DATA AND VISUAL ANALYTICS IN ANAESTHESIA AND HEALTH CARE†,article
108,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"In mobile edge networks (MENs), big data caching services are expected to provide mobile users with better quality of experience (QoE) than normal scenarios. However, the increasing types of sensors and devices are producing an explosion of big data. Extracting valuable contents for caching is becoming a vital issue for the satisfaction of QoE. Therefore, it is urgent to propose some rational strategies to improve QoE, which is the major challenge for content-centric caching. This article introduces a novel big data architecture consisting of data management units for content extraction and caching decision, improving quality of service and ensuring QoE. Then a caching strategy is proposed to improve QoE, including three parts: (1) the caching location decision, which means the method of deploying caching nodes to make them closer to users; (2) caching capacity assessment, which aims to seek suitable contents to match the capacity of caching nodes; and (3) caching priority choice, which leads to contents being cached according to their priority to meet user demands. With this architecture and strategy, we particularly use a caching algorithm based on deep reinforcement learning to achieve lower cost for intelligent caching. Experimental results indicate that our schemes achieve higher QoE than existing algorithms.",10.1109/MNET.011.1900393,2020,,EDGE QOE: INTELLIGENT BIG DATA CACHING VIA DEEP REINFORCEMENT LEARNING,
109,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Big data and 3D technologies have been successfully leveraged in a variety of industries to improve their efficiency and quality. The healthcare sector has lagged in the uptake of these new technologies. In this article, we propose a novel light field (LF)-based 3D telemedicine system. The proposed system is able to provide a life-like tele-consultation experience that provides a quality of experience far beyond conventional 2D telemedicine systems. In addition, its embedded 3D data in light field video (LFV) format can also facilitate a higher level of big data analysis, so-called big LFV data analysis. To solve the challenges in storage and analysis of LFV, we extend the standard multi-view video coding (MVC) approach to LF-MVC, which is able to achieve up to a 23 percent higher compression rate when compared to standard MVC. Furthermore, a big data analysis framework is proposed to integrate LFV into conventional telemedicine analysis, which can achieve improved classification, statistics gathering, prediction, and cognitive analysis for healthcare applications.",10.1109/MNET.2016.7474341,2016,,BIG VIDEO DATA FOR LIGHT-FIELD-BASED 3D TELEMEDICINE,
110,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Big data stream mobile computing is proposed as a paradigm that relies on the convergence of broadband Internet mobile networking and real-time mobile cloud computing. It aims at fostering the rise of novel self-configuring integrated computing-communication platforms for enabling in real time the offloading and processing of big data streams acquired by resource-limited mobile/wireless devices. This position article formalizes this paradigm, discusses its most significant application opportunities, and outlines the major challenges in performing real-time energy-efficient management of the distributed resources available at both mobile devices and Internet-connected data centers. The performance analysis of a small-scale prototype is also included in order to provide insight into the energy vs. performance tradeoff that is achievable through the optimized design of the resource management modules. Performance comparisons with some state-of-the-art resource managers corroborate the discussion. Hints for future research directions conclude the article.",10.1109/MNET.2016.7437025,2016,,"ENERGY-EFFICIENT DYNAMIC TRAFFIC OFFLOADING AND RECONFIGURATION OF NETWORKED DATA CENTERS FOR BIG DATA STREAM MOBILE COMPUTING: REVIEW, CHALLENGES, AND A CASE STUDY",
111,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Big data offers a plethora of opportunities to mobile network operators for improving quality of service. This article explores various means of integrating big data analytics with network optimization toward the objective of improving the user quality of experience. We first propose a framework of Big Data-Driven (BDD) mobile network optimization. We then present the characteristics of big data that are collected not only from user equipment but also from mobile networks. Moreover, several techniques in data collection and analytics are discussed from the viewpoint of network optimization. Certain user cases on the application of the proposed framework for improving network performance are also given in order to demonstrate the feasibility of the framework. With the integration of the emerging fifth generation (5G) mobile networks with big data analytics, the quality of our daily mobile life is expected to be tremendously enhanced.",10.1109/MNET.2016.7389830,2016,,BIG DATA-DRIVEN OPTIMIZATION FOR MOBILE NETWORKS TOWARD 5G,
112,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"VANETs enable information exchange among vehicles, other end devices and public networks, which plays a key role in road safety/infotainment, intelligent transportation systems, and self-driving systems. As vehicular connectivity soars, and new on-road mobile applications and technologies emerge, VANETs are generating an ever-increasing amount of data, requiring fast and reliable transmissions through VANETs. On the other hand, a variety of VANETs related data can be analyzed and utilized to improve the performance of VANETs. In this article, we first review VANETs technologies to efficiently and reliably transmit big data. Then, the methods employing big data for studying VANETs characteristics and improving VANETs performance are discussed. Furthermore, we present a case study where machine learning schemes are applied to analyze VANETs measurement data for efficiently detecting negative communication conditions.",10.1109/MNET.2018.1700460,2018,,BIG DATA DRIVEN VEHICULAR NETWORKS,
113,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"The growing volume of network traffic and gradual deployment of SDN devices initiate a new era in which one distinguished feature is the application of big data technology to SDNs for construction of flexible, scalable, and self-managing networks. The primary purpose of this article is to develop a novel tensor-based model for efficient provisioning of QoS in software defined networks. First, a forwarding tensor model is proposed to formalize the networking functions in the data plane; then a controlling tensor model is presented for routing path recommendation in the control plane. Finally, the article introduces a transition tensor model for network traffic prediction and QoS provisioning. The three models can automatically monitor the network state, recommend routing paths and predict network traffic, respectively. A case study to recommend routing paths is investigated in the article.",10.1109/MNET.2016.7389828,2016,,A TENSOR-BASED BIG DATA MODEL FOR QOS IMPROVEMENT IN SOFTWARE DEFINED NETWORKS,
114,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Through time, we have seen mobile phones transform into multifaceted devices, adapted to meet and exceed our everyday needs. These needs range from something as personal as a health care manager to something as purely analytical as an environment monitor. In effect, mobile phones have come into our lives, making life easier, smarter, and more efficient. In this article we discuss mobile sensing and cloud computing separately and in detail, then combine the two concepts to form the singular idea of mobile cloud sensing. We will also give an intuitive architectural description of mobile cloud sensing, along with discussions about each of its individual building blocks. There are limitations to mobile cloud sensing today, but with the emergence of 5G coupled with the analysis of big data, we can address the current issues at hand. We believe that with the advent of mobile cloud sensing, 5G, and big data analysis, our lives will continue to see an increase in overall quality.",10.1109/MNET.2015.7064901,2015,,"MOBILE CLOUD SENSING, BIG DATA, AND 5G NETWORKS MAKE AN INTELLIGENT AND SMART WORLD",
115,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"While an al dente character of 5G is yet to emerge, network densification, miscellany of node types, split of control and data plane, network virtualization, heavy and localized cache, infrastructure sharing, concurrent operation at multiple frequency bands, simultaneous use of different medium access control and physical layers, and flexible spectrum allocations can be envisioned as some of the potential ingredients of 5G. It is not difficult to prognosticate that with such a conglomeration of technologies, the complexity of operation and OPEX can become the biggest challenge in 5G. To cope with similar challenges in the context of 3G and 4G networks, recently, self-organizing networks, or SONs, have been researched extensively. However, the ambitious quality of experience requirements and emerging multifarious vision of 5G, and the associated scale of complexity and cost, demand a significantly different, if not totally new, approach toward SONs in order to make 5G technically as well as financially feasible. In this article we first identify what challenges hinder the current self-optimizing networking paradigm from meeting the requirements of 5G. We then propose a comprehensive framework for empowering SONs with big data to address the requirements of 5G. Under this framework we first characterize big data in the context of future mobile networks, identifying its sources and future utilities. We then explicate the specific machine learning and data analytics tools that can be exploited to transform big data into the right data that provides a readily useable knowledge base to create end-to-end intelligence of the network. We then explain how a SON engine can build on the dynamic models extractable from the right data. The resultant dynamicity of a big data empowered SON (BSON) makes it more agile and can essentially transform the SON from being a reactive to proactive paradigm and hence act as a key enabler for 5G's extremely low latency requirements. Finally, we demonstrate the key concepts of our proposed BSON framework through a case study of a problem that the classic 3G/4G SON fails to solve.",10.1109/MNET.2014.6963801,2014,,CHALLENGES IN 5G: HOW TO EMPOWER SON WITH BIG DATA FOR ENABLING 5G,
116,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Due to the rapid development of mobile social networks, mobile big data play an important role in providing mobile social users with various mobile services. However, as mobile big data have inherent properties, current MSNs face a challenge to provide mobile social user with a satisfactory quality of experience. Therefore, in this article, we propose a novel framework to deliver mobile big data over content- centric mobile social networks. At first, the characteristics and challenges of mobile big data are studied. Then the content-centric network architecture to deliver mobile big data in MSNs is presented, where each datum consists of interest packets and data packets, respectively. Next, how to select the agent node to forward interest packets and the relay node to transmit data packets are given by defining priorities of interest packets and data packets. Finally, simulation results show the performance of our framework with varied parameters.",10.1109/MNET.2016.7389831,2016,,BIG DATA IN MOBILE SOCIAL NETWORKS: A QOE-ORIENTED FRAMEWORK,
117,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Rapid development in Information and Communications Technologies (ICT), Internet of Things (IoT), and Big Data (BD) analytics has revolutionized the manufacturing industry, which introduces the Industrial Internet of Things (IIoT) in Industry 4.0. IIoT includes machinery, manufacturing processes, and automation mechanisms. The existing IIoT system uses a centralized architecture, where the trusted third party (TTP) performs transactions, which raises security and privacy concerns and may have a single point of failure. The emerging technology Blockchain is a prominent solution to address the aforementioned issues. Motivated by these facts, in this article we highlight the issues of data dissemination in the IIoT environment and present a blockchain-based decentralized model for IIoT (DMIIoT). The proposed model uses a secure Peer-to-Peer (P2P) network, where each node interacts with other nodes. Then we highlight the potential of the DMIIoT to improve various services in IIoT, such as better production visibility and Quality of Service (QoS). Finally, we present a case study on a Smart Grid (SG) system to evaluate the efficacy of the proposed model with data load balance, energy management costs, and transmission delay parameters.",10.1109/MNET.011.2000355,2021,,BLOCKCHAIN-BASED MASSIVE DATA DISSEMINATION HANDLING IN IIOT ENVIRONMENT,
118,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"The heterogeneous network is the foundation of next-generation networks. It aims to explore the existing network resources effectively, and providing better QoS for every kind of traffic flow as far as possible. However, the diversity and dynamic nature of heterogeneous networks will bring a huge burden and big data to the network traffic control. Therefore, how to achieve efficient and intelligent network traffic control becomes the key problem of heterogeneous networks. In this article, an AI-inspired traffic control scheme is proposed. In order to realize fine-grained traffic control in heterogeneous networks, multi-dimensional (i.e., inter-layer, intra-layer, and caching and pushing) network traffic control is introduced. It is worth noting that backpropagation in deep recurrent neural networks is applied in the intra-layer such that an intelligent traffic control scheme can be derived efficiently when facing the huge traffic load in heterogeneous networks. Moreover, DBSCAN is adopted in the inter-layer, which supports efficient classification in the inter-layer. In addition, caching and pushing is adopted to make full use of network resources and provide better QoS. Simulation results demonstrate the effectiveness and practicability of the proposed scheme.",10.1109/MNET.2018.1800120,2018,,ARTIFICIAL INTELLIGENCE INSPIRED MULTI-DIMENSIONAL TRAFFIC CONTROL FOR HETEROGENEOUS NETWORKS,
119,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Energy Internet (also referred to as Smart Grid 2.0) is another promising application of the Industrial Internet of Things (IIoT), for example, in the way energy is being produced, traded, distributed, and consumed. This is partly due to the lowering of barriers (e.g., costs and Internet connectivity) and advances in the underlying technologies, such as smart meters, electric vehicles, and actuators. This has also resulted in significant growth in the volume, velocity, variety, veracity, and value of data (i.e., the 5 Vs of big data). However, efficiently and effectively handling such big data remains challenging. One solution currently being explored in the literature (including industry) to cope with the increasing network traffic is to use conventional cloud infrastructure, but the key limitations of such an approach include long response time and high bandwidth consumption. Therefore, there have been attempts to introduce next-generation Internet of Things networks to satisfy (real-time) network service demands and guarantee quality of service, for example, by pushing computing capabilities closer to the users (e.g., edge of the network). However, computation-intensive energy analytics can be challenging to perform at the network edge by edge or fog computing devices. Hence, there have also been attempts to utilize software defined networking (SDN) and network function virtualization (NFV) in order to improve network functionality while adding programmability and flexibility features to the network infrastructure. Specifically, NFV facilitates virtual network function (VNF) deployment and orchestration, while SDN controls them for specific use cases. However, with the rise of next-generation mobile networks (i.e., 5G), applications and services require fast and smooth operations with greater flexibility, efficiency, and scalability. In order to align with 5G and leverage potential benefits of edge computing, VNFs should possess critical processing requirements (e.g., high throughput, low latency, and minimal computation overheads). In other words, virtualization plays an important role. To date, several techniques have been introduced in order to achieve the desired objective using virtual machines (VMs) and containers in isolation. However, a hybrid approach using VMs and containers is likely to bring potential benefits for the large-scale deployment of VNFs across the heterogeneous edge and cloud platform. Thus, in this article, a novel architecture for SDN integrated with NFV, specifically for the Energy Internet ecosystem, is presented by leveraging the advantagesof edge computing. In the considered setup, the deployment of VNFs is achieved using a mix of both virtualization and containerization. Findings from our evaluation demonstrate the potential for VNF placement across a hybrid execution setup powered by VMs, as well as the benefits of using containers.",10.1109/MNET.011.1900602,2021,,SDN-NFV-AIDED EDGE-CLOUD INTERPLAY FOR 5G-ENVISIONED ENERGY INTERNET ECOSYSTEM,
120,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"The Industrial Internet of Things (IIoT) can improve manufacturing efficiency, enhance product quality, and reduce cost and pollution in industrial production, realizing intelligent industrialization. With the rise of big data, generated by intelligent terminals and then sent to the cloud platform in IIoT, some problems like high latency are emerging. Edge intelligence is a promising technology to address these problems by offering computing and storage resources at the edge of the network. However, IIoT with edge intelligence is still confronted by several significant challenges in data security and energy consumption. In this article, we state these challenges and also pro",10.1109/MNET.001.1800478,2019,,SERIOUS CHALLENGES AND POTENTIAL SOLUTIONS FOR THE INDUSTRIAL INTERNET OF THINGS WITH EDGE INTELLIGENCE,
121,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"The fifth generation (5G) mobile communication technology brings people a higher perceived rate experience, the high-quality service of high-density user connection, and other commercial applications. As an important means of data processing in 5G heterogeneous networks (HetNets), data fusion technology is faced with a large number of malicious code attacks. Thus, it is particularly important to find an efficient malicious code detection method. However, in the traditional research, due to dataset imbalance, the complexity of the deep learning network model, the use of a single-objective algorithm, and other factors, it brings greater loss and lower detection accuracy. Therefore, how to choose a suitable network model and improve the data classification accuracy in HetNets is a big challenge. To enhance the model's robustness, a multi-objective restricted Boltzmann machine (RBM) model is designed for training. In this article, evaluation indices are used to comprehensively measure the effect of data classification, introducing a strategy pool to improve the effect of data fusion and using non-dominated sorting genetic algorithms (NSGA-II) to deal with the imbalanced malware family. Experimental results demonstrate that the proposed multi-objective RBM model combined with NSGA-II can effectively enhance the data classification accuracy of HetNets and reduce the loss in the process of data fusion.",10.1109/MNET.011.2000331,2021,,MALICIOUS CODE DETECTION UNDER 5G HETNETS BASED ON A MULTI-OBJECTIVE RBM MODEL,
122,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Crowd sensing networks play a critical role in big data generation where a large number of mobile devices collect various kinds of data with large-volume features. Although which information should be collected is essential for the success of crowd-sensing applications, few research efforts have been made so far. On the other hand, an efficient incentive mechanism is required to encourage all crowd-sensing participants, including data collectors, service providers, and service consumers, to join the networks. In this article, we propose a new incentive mechanism called QUOIN, which simultaneously ensures Quality and Usability Of INformation for crowd-sensing application requirements. We apply a Stackelberg game model to the proposed mechanism to guarantee each participant achieves a satisfactory level of profits. Performance of QUOIN is evaluated with a case study, and experimental results demonstrate that it is efficient and effective in collecting valuable information for crowd-sensing applications.",10.1109/MNET.2017.1500151,2018,,QUOIN: INCENTIVE MECHANISMS FOR CROWD SENSING NETWORKS,
123,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"With the development of 5G, the wireless world will be interconnected without barriers. This new technology will enable many challenging applications, and more personalized and interactive services are expected to be available with resource-limited mobile terminals. Fortunately, mobile cloud computing (MCC) emerging in the context of 5G has the potential to overcome this bottleneck, which enables many resource-intensive services for mobile users with the support of mobile big data delivery and cloud-assisted computing. In this article we propose a novel framework named EMC in the context of 5G, which offers personalized emotion-aware services by MCC and affective computing. With the proposed framework, the traditional MCC architecture is modified to achieve the required Quality of Experience in emotion-aware applications. Furthermore, we design a partitioning solution corresponding to the fundamental trade-off between the communication and computation in EMC. The framework would be helpful to provide personalized, human-centric, intelligent emotion-aware services in 5G.",10.1109/MNET.2015.7064900,2015,,EMC: EMOTION-AWARE MOBILE CLOUD COMPUTING IN 5G,
124,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"In this article, we propose a hybrid computing model, UAV-Edge-Cloud, bringing edge/cloud computing and UAV swarm together to achieve high quality of service (QoS) guarantees. First, we design this novel hybrid computing framework to provide powerful resources to support resource-intensive applications and real-time tasks at edge networks. Next, we discuss some potential applications for smart cities and raise open research issues of the proposed hybrid framework. We then study a joint task placement and routing problem for latency-critical applications as a case study. Finally, the simulation results show that our approach can improve the QoS of UAV swarms effectively.",10.1109/MNET.2019.1800222,2019,,WHEN UAV SWARM MEETS EDGE-CLOUD COMPUTING: THE QOS PERSPECTIVE,
125,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"In this article we propose a new paradigm of resource-efficient edge computing for the emerging intelligent IoT applications such as flying ad hoc networks for precision agriculture, e-health, and smart homes. We devise a resource-efficient edge computing scheme such that an intelligent IoT device user can well support its computationally intensive task by proper task offloading across the local device, nearby helper device, and the edge cloud in proximity. Different from existing studies for mobile computation offloading, we explore the novel perspective of resource efficiency and devise an efficient computation offloading mechanism consisting of a delay-aware task graph partition algorithm and an optimal virtual machine selection method in order to minimize an intelligent IoT device's edge resource occupancy and meanwhile satisfy its QoS requirement. Performance evaluation corroborates the effectiveness and superior performance of the proposed resource-efficient edge computing scheme.",10.1109/MNET.2018.1700145,2018,,THRIFTYEDGE: RESOURCE-EFFICIENT EDGE COMPUTING FOR INTELLIGENT IOT APPLICATIONS,
126,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"As network data keeps getting bigger, deep learning is coming to play a key role in network design and management. Meanwhile, accurate network traffic prediction is of critical importance for network management that is implemented to improve the quality of service (QoS) for users. However, the performance of existing network traffic prediction methods is still poor due to three challenges: complicated characteristics of network traffic, dynamics of traffic patterns caused by different network applications, and a complex set of variations like burstiness. In this article, we propose a long short-term memory (LSTM) based network traffic prediction (LNTP) model, which aims to forecast network traffic timely and accurately. The model can be divided into two parts, namely, wavelet transform and LSTM. The working process of LNTP falls into three stages, i.e., data acquisition, model training, and online learning and prediction. In addition, to avoid the negative incentives to models caused by the burstiness and adapt to the changing trend of the network traffic, a weight optimization algorithm of the neural network named sliding window gradient descent (SWGD), is also proposed. Extensive experiments based on two real-world network traffic datasets demonstrate that our model outperforms the state-of-the-art network traffic prediction models by more than 29 percent.",10.1109/MNET.011.1900647,2021,,LNTP: AN END-TO-END ONLINE PREDICTION MODEL FOR NETWORK TRAFFIC,
127,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"The rapid growth in the transportation sector has led to the emergence of smart vehicles that are equipped with ICT. These modern smart vehicles are connected to the Internet to access various services such as road condition information, infotainment, and energy management. This kind of scenario can be viewed as a vehicular cyber-physical system (VCPS) where the vehicles are at the physical layer and services are at the cyber layer. However, network traffic management is the biggest issue in the modern VCPS scenario as the mismanagement of network resources can degrade the quality of service (QoS) for end users. To deal with this issue, we propose a software defined networking (SDN)-enabled approach, named SeDaTiVe, which uses deep learning architecture to control the incoming traffic in the network in the VCPS environment. The advantage of using deep learning in network traffic control is that it learns the hidden patterns in data packets and creates an optimal route based on the learned features. Moreover, a virtual-controller-based scheme for flow management using SDN in VCPS is designed for effective resource utilization. The simulation scenario comprising 1000 vehicles seeking various services in the network is considered to generate the dataset using SUMO. The data obtained from the simulation study is evaluated using NS-2, and proves that the proposed scheme effectively handles real-time incoming requests in VCPS. The results also depict the improvement in performance on various evaluation metrics like delay, throughput, packet delivery ratio, and network load by using the proposed scheme over the traditional SDN and TCP/IP protocol suite.",10.1109/MNET.2018.1800101,2018,,SEDATIVE: SDN-ENABLED DEEP LEARNING ARCHITECTURE FOR NETWORK TRAFFIC CONTROL IN VEHICULAR CYBER-PHYSICAL SYSTEMS,
128,27239,IEEE NETWORK,journal,1558156X,"2,546",Q1,129,263,401,3525,4922,375,"13,58","13,40",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1986-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1),"6,526",10.693,0.01189,"Big data analytics has shown great potential in optimizing operations, making decisions, spotting business trends, preventing threats, and capitalizing on new sources of revenues in various fields such as manufacturing, healthcare, finance, insurance, and retail. The management of various networks has become inefficient and difficult because of their high complexities and interdependencies. Big data, in forms of device logs, software logs, media content, and sensed data, provide rich information and facilitate a fundamentally different and novel approach to explore, design, and develop reliable and scalable networks. This Special Issue covers the most recent research results that address challenges of big data for networking. We received 45 submissions, and ultimately nine high quality papers, organized into two groups, have been selected for inclusion in this Special Issue.",10.1109/MNET.2016.7389823,2016,,BIG DATA FOR NETWORKING [GUEST EDITORIAL],
129,29374,ENERGY ECONOMICS,journal,01409883,"2,500",Q1,152,378,1081,21992,8195,1072,"7,10","58,18",Netherlands,Western Europe,Elsevier,1979-2019,Economics and Econometrics (Q1); Energy (miscellaneous) (Q1),"26,186",7.042,0.02456,"The authenticity and quality of industrial statistical data directly affects all types of systematic research based on it. Considering the limitations of extant data quality evaluation literature on research objects and evaluation methods, we constructed a new data quality comprehensive inspection and evaluation model based on Benford's Law (BL) and the technique for order of preference by similarity to ideal solution (TOPSIS), selected coal-related industries as the research object, and conducted an empirical test along the research path of “Industry→Province→Indicator”. The results showed that, at industry level, the quality of statistical data for China's coal-related industries from 2001 to 2016 was generally poor. Among the eight sample industries selected, the data quality for five industries (including coal, electricity, and steel) was assessed as poor or slightly poor. Furthermore, at the provincial level, there is significant spatial heterogeneity in the quality of statistical data for various industries affected by factors such as economic structure, marketization level, and industrial diversity. Compared with other types of statistical indicators, industry financial indicators are more prone to data quality problems at the indicator level, and the suspicious indicators of different industries show certain common characteristics and some industry differences. To improve the quality of industrial statistical data and reduce the possible adverse impacts of data quality problems, based on the research findings, we propose targeted countermeasures and suggestions on how to prevent data fraud and effectively identify and rationally use suspicious data.",https://doi.org/10.1016/j.eneco.2022.106310,2022,Delu Wang and Fan Chen and Jingqi Mao and Nannan Liu and Fangyu Rong,ARE THE OFFICIAL NATIONAL DATA CREDIBLE? EMPIRICAL EVIDENCE FROM STATISTICS QUALITY EVALUATION OF CHINA'S COAL AND ITS DOWNSTREAM INDUSTRIES,article
130,29160,CANCER LETTERS,journal,03043835,"2,470",Q1,182,430,1423,27650,11608,1409,"7,85","64,30",Ireland,Western Europe,Elsevier Ireland Ltd,1975-2020,Cancer Research (Q1); Oncology (Q1),"42,174",8.679,0.04013,"Precision medicine relies on an increasing amount of heterogeneous data. Advances in radiation oncology, through the use of CT Scan, dosimetry and imaging performed before each fraction, have generated a considerable flow of data that needs to be integrated. In the same time, Electronic Health Records now provide phenotypic profiles of large cohorts of patients that could be correlated to this information. In this review, we describe methods that could be used to create integrative predictive models in radiation oncology. Potential uses of machine learning methods such as support vector machine, artificial neural networks, and deep learning are also discussed.",https://doi.org/10.1016/j.canlet.2016.05.033,2016,Jean-Emmanuel Bibault and Philippe Giraud and Anita Burgun,BIG DATA AND MACHINE LEARNING IN RADIATION ONCOLOGY: STATE OF THE ART AND FUTURE PROSPECTS,article
131,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"Today׳s supply chain professionals are inundated with data, motivating new ways of thinking about how data are produced, organized, and analyzed. This has provided an impetus for organizations to adopt and perfect data analytic functions (e.g. data science, predictive analytics, and big data) in order to enhance supply chain processes and, ultimately, performance. However, management decisions informed by the use of these data analytic methods are only as good as the data on which they are based. In this paper, we introduce the data quality problem in the context of supply chain management (SCM) and propose methods for monitoring and controlling data quality. In addition to advocating for the importance of addressing data quality in supply chain research and practice, we also highlight interdisciplinary research topics based on complementary theory.",https://doi.org/10.1016/j.ijpe.2014.04.018,2014,Benjamin T. Hazen and Christopher A. Boone and Jeremy D. Ezell and L. Allison Jones-Farmer,"DATA QUALITY FOR DATA SCIENCE, PREDICTIVE ANALYTICS, AND BIG DATA IN SUPPLY CHAIN MANAGEMENT: AN INTRODUCTION TO THE PROBLEM AND SUGGESTIONS FOR RESEARCH AND APPLICATIONS",article
132,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"This study adopts the diffusion of innovation theory as to develop the smart product service system model in banking industry due to prior studies are lacking in identifying the attributes. The smart product service system functions are bearing high uncertainty and system complexity; hence, the hybrid method of fuzzy Delphi method and fuzzy decision-making trial and evaluation laboratory to construct a valid hierarchical model and identified the causal interrelationships among the attributes. The smart product service system hierarchical model with eight aspects and 41 criteria are proposed enriching the existing literature and that identify appropriate strategies to achieve operational performance. The results show that seven aspects and 22 criteria are determined as the valid hierarchical model. The institutional compression, digital platform operation, and e-knowledge management are the causing aspects helps to form smart product service system operational performance in high uncertainty. For practices, the banking decision-makers should develop innovative actions relied on the forcible compression, cyber-physical systems, industrial big data, cloud service allocation and sharing, and transparency improvement as they are most importance criteria playing a decisive role in a successful SPSS. This provides guidelines for banking industry practice in Taiwan encouraging the miscellany of digital technology accomplishment for sustainable target.",https://doi.org/10.1016/j.ijpe.2021.108244,2021,Ming-Lang Tseng and Tat-Dat Bui and Shulin Lan and Ming K. Lim and Abu Hashan Md Mashud,SMART PRODUCT SERVICE SYSTEM HIERARCHICAL MODEL IN BANKING INDUSTRY UNDER UNCERTAINTIES,article
133,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"In recent years, big data has emerged as one of the prominent buzzwords in business and management. In spite of the mounting body of research on big data across the social science disciplines, scholars have offered little synthesis on the current state of knowledge. To take stock of academic research that contributes to the big data revolution, this paper tracks scholarly work's perspectives on big data in the management domain over the past decade. We identify key themes emerging in management studies and develop an integrated framework to link the multiple streams of research in fields of organisation, operations, marketing, information management and other relevant areas. Our analysis uncovers a growing awareness of big data's business values and managerial changes led by data-driven approach. Stemming from the review is the suggestion for research that both structured and unstructured big data should be harnessed to advance understanding of big data value in informing organisational decisions and enhancing firm competitiveness. To discover the full value, firms need to formulate and implement a data-driven strategy. In light of these, the study identifies and outlines the implications and directions for future research.",https://doi.org/10.1016/j.ijpe.2017.06.006,2017,Jie Sheng and Joseph Amankwah-Amoah and Xiaojun Wang,A MULTIDISCIPLINARY PERSPECTIVE OF BIG DATA IN MANAGEMENT RESEARCH,article
134,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"Big data has the potential to revolutionize the art of management. Despite the high operational and strategic impacts, there is a paucity of empirical research to assess the business value of big data. Drawing on a systematic review and case study findings, this paper presents an interpretive framework that analyzes the definitional perspectives and the applications of big data. The paper also provides a general taxonomy that helps broaden the understanding of big data and its role in capturing business value. The synthesis of the diverse concepts within the literature on big data provides deeper insights into achieving value through big data strategy and implementation.",https://doi.org/10.1016/j.ijpe.2014.12.031,2015,Samuel {Fosso Wamba} and Shahriar Akter and Andrew Edwards and Geoffrey Chopin and Denis Gnanzou,HOW ‘BIG DATA’ CAN MAKE BIG IMPACT: FINDINGS FROM A SYSTEMATIC REVIEW AND A LONGITUDINAL CASE STUDY,article
135,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"Servitization has become a pervasive business strategy among manufacturers, enabling them to undergird their competitive advantage. However, it has at least one weakness. While it is used worldwide also in economies with lower production costs, services in manufacturing are slowly becoming commoditized and will become a necessary, though not sufficient, condition for reaching an above average competitive advantage. Consequently, in this article we propose a new basis for competitive advantage for manufacturing enterprises called a Big Data Strategy in servitization. We scrutinize how manufacturers can exploit the opportunity arising from combined Big Data and servitization. Therefore, the concept of a Big Data Strategy framework in servitization is proposed. The findings are benchmarked against established frameworks in the Big Data and servitization literature. Its impact on competitive advantage is assessed through three theoretical perspectives that increase the validity of the results. The main finding is that, through the proposed strategy, new revenue streams can be created, while opening the possibility to decrease prices for product–services. Through the proposed strategy manufacturers can differentiate themselves from the ones that are already servitizing. This article introduces the possibility of influencing the most important of the five “Vs” in Big Data–Value, in addition to the other four “Vs”—Volume, Variety, Velocity and Verification. As in regards to servitization, the article adds a third layer of added value— “information”, beside the two existing ones: product and service. The results have strategic implications for managers.",https://doi.org/10.1016/j.ijpe.2014.12.036,2015,David Opresnik and Marco Taisch,THE VALUE OF BIG DATA IN SERVITIZATION,article
136,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"Today, firms can access to big data (tweets, videos, click streams, and other unstructured sources) to extract new ideas or understanding about their products, customers, and markets. Thus, managers increasingly view data as an important driver of innovation and a significant source of value creation and competitive advantage. To get the most out of the big data (in combination with a firm׳s existing data), a more sophisticated way of handling, managing, analysing and interpreting data is necessary. However, there is a lack of data analytics techniques to assist firms to capture the potential of innovation afforded by data and to gain competitive advantage. This research aims to address this gap by developing and testing an analytic infrastructure based on the deduction graph technique. The proposed approach provides an analytic infrastructure for firms to incorporate their own competence sets with other firms. Case studies results indicate that the proposed data analytic approach enable firms to utilise big data to gain competitive advantage by enhancing their supply chain innovation capabilities.",https://doi.org/10.1016/j.ijpe.2014.12.034,2015,Kim Hua Tan and YuanZhu Zhan and Guojun Ji and Fei Ye and Chingter Chang,HARVESTING BIG DATA TO ENHANCE SUPPLY CHAIN INNOVATION CAPABILITIES: AN ANALYTIC INFRASTRUCTURE BASED ON DEDUCTION GRAPH,article
137,19165,INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS,journal,09255273,"2,406",Q1,185,327,891,21712,8124,881,"8,31","66,40",Netherlands,Western Europe,Elsevier,1991-2021,"Business, Management and Accounting (miscellaneous) (Q1); Economics and Econometrics (Q1); Industrial and Manufacturing Engineering (Q1); Management Science and Operations Research (Q1)","32,606",7.885,0.0228,"The recent interest in big data has led many companies to develop big data analytics capability (BDAC) in order to enhance firm performance (FPER). However, BDAC pays off for some companies but not for others. It appears that very few have achieved a big impact through big data. To address this challenge, this study proposes a BDAC model drawing on the resource-based theory (RBT) and the entanglement view of sociomaterialism. The findings show BDAC as a hierarchical model, which consists of three primary dimensions (i.e., management, technology, and talent capability) and 11 subdimensions (i.e., planning, investment, coordination, control, connectivity, compatibility, modularity, technology management knowledge, technical knowledge, business knowledge and relational knowledge). The findings from two Delphi studies and 152 online surveys of business analysts in the U.S. confirm the value of the entanglement conceptualization of the higher-order BDAC model and its impact on FPER. The results also illuminate the significant moderating impact of analytics capability–business strategy alignment on the BDAC–FPER relationship.",https://doi.org/10.1016/j.ijpe.2016.08.018,2016,Shahriar Akter and Samuel Fosso Wamba and Angappa Gunasekaran and Rameshwar Dubey and Stephen J. Childe,HOW TO IMPROVE FIRM PERFORMANCE USING BIG DATA ANALYTICS CAPABILITY AND BUSINESS STRATEGY ALIGNMENT?,article
138,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"With the rapid development of the internet and popularization of intelligent mobile devices, social media is evolving fast and contains rich spatial information, such as geolocated posts, tweets, photos, video, and audio. Those location-based social media data have offered new opportunities for hazards and disaster identification or tracking, recommendations for locations, friends or tags, pay-per-click advertising, etc. Meanwhile, a massive amount of remote sensing (RS) data can be easily acquired in both high temporal and spatial resolution with a multiple satellite system, if RS maps can be provided, to possibly enable the monitoring of our location-based living environments with some devices like charge-coupled device (CCD) cameras but on a much larger scale. To generate the classification maps, usually, labeled RS image pixels should be provided by RS experts to train a classification system. Traditionally, labeled samples are obtained according to ground surveys, image photo interpretation or a combination of the aforementioned strategies. All the strategies should be taken care of by domain experts, in a means which is costly, time consuming, and sometimes of a low quality due to reasons such as photo interpretation based on RS images only. These practices and constraints make it more challenging to classify land-cover RS images using big RS data. In this paper, a new methodology is proposed to classify urban RS images by exploiting the semantics of location-based social media photos (SMPs). To validate the effectiveness of this methodology, an automatic classification system is developed based on RS images as well as SMPs via big data analysis techniques including active learning, crowdsourcing, shallow machine learning, and deep learning. As the labels of RS training data are given by ordinary people with a crowdsourcing technique, the developed system is named Crowd4RS. The quantitative and qualitative experiments confirm the effectiveness of the proposed Crowd4RS system as well as the proposed methodology for automatically generating RS image maps in terms of classification results based on big RS data made up of multispectral RS images in a high spatial resolution and a large amount of photos from social media sites, such as Flickr and Panoramio.",10.1109/JPROC.2017.2730585,2017,,A NOVEL METHODOLOGY TO LABEL URBAN REMOTE SENSING IMAGES BASED ON LOCATION-BASED SOCIAL MEDIA PHOTOS,
139,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"A typical high-end film production generates several terabytes of data per day, either as footage from multiple cameras or as background information regarding the set (laser scans, spherical captures, etc). This paper presents solutions to improve the integration of the multiple data sources, and understand their quality and content, which are useful both to support creative decisions on-set (or near it) and enhance the postproduction process. The main cinema specific contributions, tested on a multisource production dataset made publicly available for research purposes, are the monitoring and quality assurance of multicamera set-ups, multisource registration and acceleration of 3-D reconstruction, anthropocentric visual analysis techniques for semantic content annotation, and integrated 2-D–3-D web visualization tools. We discuss as well improvements carried out in basic techniques for acceleration, clustering and visualization, which were necessary to deal with the very large multisource data, and can be applied to other big data problems in diverse application fields.",10.1109/JPROC.2015.2496111,2016,,BIG DATA ANALYSIS FOR MEDIA PRODUCTION,
140,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"As a newly emerging technology, deep learning (DL) is a very promising field in big data applications. Remote sensing often involves huge data volumes obtained daily by numerous in-orbit satellites. This makes it a perfect target area for data-driven applications. Nowadays, technological advances in terms of software and hardware have a noticeable impact on Earth observation applications, more specifically in remote sensing techniques and procedures, allowing for the acquisition of data sets with greater quality at higher acquisition ratios. This results in the collection of huge amounts of remotely sensed data, characterized by their large spatial resolution (in terms of the number of pixels per scene), and very high spectral dimensionality, with hundreds or even thousands of spectral bands. As a result, remote sensing instruments on spaceborne and airborne platforms are now generating data cubes with extremely high dimensionality, imposing several restrictions in terms of both processing runtimes and storage capacity. In this article, we provide a comprehensive review of the state of the art in DL for remote sensing data interpretation, analyzing the strengths and weaknesses of the most widely used techniques in the literature, as well as an exhaustive description of their parallel and distributed implementations (with a particular focus on those conducted using cloud computing systems). We also provide quantitative results, offering an assessment of a DL technique in a specific case study (source code available: https://github.com/mhaut/cloud-dnn-HSI). This article concludes with some remarks and hints about future challenges in the application of DL techniques to distributed remote sensing data interpretation problems. We emphasize the role of the cloud in providing a powerful architecture that is now able to manage vast amounts of remotely sensed data due to its implementation simplicity, low cost, and high efficiency compared to other parallel and distributed architectures, such as grid computing or dedicated clusters.",10.1109/JPROC.2021.3063258,2021,,DISTRIBUTED DEEP LEARNING FOR REMOTE SENSING DATA INTERPRETATION,
141,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"Statistical estimation in many contemporary settings involves the acquisition, analysis, and aggregation of data sets from multiple sources, which can have significant differences in character and in value. Due to these variations, the effectiveness of employing a given resource, e.g., a sensing device or computing power, for gathering or processing data from a particular source depends on the nature of that source. As a result, the appropriate division and assignment of a collection of resources to a set of data sources can substantially impact the overall performance of an inferential strategy. In this expository article, we adopt a general view of the notion of a resource and its effect on the quality of a data source, and we describe a framework for the allocation of a given set of resources to a collection of sources in order to optimize a specified metric of statistical efficiency. We discuss several stylized examples involving inferential tasks such as parameter estimation and hypothesis testing based on heterogeneous data sources, in which optimal allocations can be computed either in closed form or via efficient numerical procedures based on convex optimization. This work is an inferential analog of the literature in information theory on allocating power across communications channels of variable quality in order to optimize for total throughput.",10.1109/JPROC.2015.2494098,2016,,RESOURCE ALLOCATION FOR STATISTICAL ESTIMATION,
142,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"The explosive growth in Big Data has attracted much attention in designing efficient indexing and search methods recently. In many critical applications such as large-scale search and pattern matching, finding the nearest neighbors to a query is a fundamental research problem. However, the straightforward solution using exhaustive comparison is infeasible due to the prohibitive computational complexity and memory requirement. In response, approximate nearest neighbor (ANN) search based on hashing techniques has become popular due to its promising performance in both efficiency and accuracy. Prior randomized hashing methods, e.g., locality-sensitive hashing (LSH), explore data-independent hash functions with random projections or permutations. Although having elegant theoretic guarantees on the search quality in certain metric spaces, performance of randomized hashing has been shown insufficient in many real-world applications. As a remedy, new approaches incorporating data-driven learning methods in development of advanced hash functions have emerged. Such learning-to-hash methods exploit information such as data distributions or class labels when optimizing the hash codes or functions. Importantly, the learned hash codes are able to preserve the proximity of neighboring data in the original feature spaces in the hash code spaces. The goal of this paper is to provide readers with systematic understanding of insights, pros, and cons of the emerging techniques. We provide a comprehensive survey of the learning-to-hash framework and representative techniques of various types, including unsupervised, semisupervised, and supervised. In addition, we also summarize recent hashing approaches utilizing the deep learning models. Finally, we discuss the future direction and trends of research in this area.",10.1109/JPROC.2015.2487976,2016,,LEARNING TO HASH FOR INDEXING BIG DATA—A SURVEY,
143,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"Modern computer vision research consumes labelled data in quantity, and building datasets has become an important activity. The Internet has become a tremendous resource for computer vision researchers. By seeing the Internet as a vast, slightly disorganized collection of visual data, we can build datasets. The key point is that visual data are surrounded by contextual information like text and HTML tags, which is a strong, if noisy, cue to what the visual data means. In a series of case studies, we illustrate how useful this contextual information is. It can be used to build a large and challenging labelled face dataset with no manual intervention. With very small amounts of manual labor, contextual data can be used together with image data to identify pictures of animals. In fact, these contextual data are sufficiently reliable that a very large pool of noisily tagged images can be used as a resource to build image features, which reliably improve on conventional visual features. By seeing the Internet as a marketplace that can connect sellers of annotation services to researchers, we can obtain accurately annotated datasets quickly and cheaply. We describe methods to prepare data, check quality, and set prices for work for this annotation process. The problems posed by attempting to collect very big research datasets are fertile for researchers because collecting datasets requires us to focus on two important questions: What makes a good picture? What is the meaning of a picture?",10.1109/JPROC.2009.2032355,2010,,IT'S ALL ABOUT THE DATA,
144,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.",10.1109/JPROC.2015.2494218,2016,,TAKING THE HUMAN OUT OF THE LOOP: A REVIEW OF BAYESIAN OPTIMIZATION,
145,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"We are living in a world where massive end devices perform computing everywhere and everyday. However, these devices are constrained by the battery and computational resources. With the increasing number of intelligent applications (e.g., augmented reality and face recognition) that require much more computational power, they shift to perform computation offloading to the cloud, known as mobile cloud computing (MCC). Unfortunately, the cloud is usually far away from end devices, leading to a high latency as well as the bad quality of experience (QoE) for latency-sensitive applications. In this context, the emergence of edge computing is no coincidence. Edge computing extends the cloud to the edge of the network, close to end users, bringing ultra-low latency and high bandwidth. Consequently, there is a trend of computation offloading toward edge computing. In this paper, we provide a comprehensive perspective on this trend. First, we give an insight into the architecture refactoring in edge computing. Based on that insight, this paper reviews the state-of-the-art research on computation offloading in terms of application partitioning, task allocation, resource management, and distributed execution, with highlighting features for edge computing. Then, we illustrate some disruptive application scenarios that we envision as critical drivers for the flourish of edge computing, such as real-time video analytics, smart “things” (e.g., smart city and smart home), vehicle applications, and cloud gaming. Finally, we discuss the opportunities and future research directions.",10.1109/JPROC.2019.2922285,2019,,COMPUTATION OFFLOADING TOWARD EDGE COMPUTING,
146,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"The Industry 4.0 concept promotes a digital manufacturing (DM) paradigm that can enhance quality and productivity, which reduces inventory and the lead time for delivering custom, batch-of-one products based on achieving convergence of additive, subtractive, and hybrid manufacturing machines, automation and robotic systems, sensors, computing, and communication networks, artificial intelligence, and big data. A DM system consists of embedded electronics, sensors, actuators, control software, and interconnectivity to enable the machines and the components within them to exchange data with other machines, components therein, the plant operators, the inventory managers, and customers. This article presents the cybersecurity risks in the emerging DM context, assesses the impact on manufacturing, and identifies approaches to secure DM.",10.1109/JPROC.2020.3032074,2021,,A SURVEY OF CYBERSECURITY OF DIGITAL MANUFACTURING,
147,17915,PROCEEDINGS OF THE IEEE,journal,15582256,"2,383",Q1,287,128,422,13575,6686,411,"15,15","106,05",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1927, 1963-2020",Computer Science (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"36,371",10.961,0.02642,"Chronic diseases like diabetes mellitus often require a permanent monitoring of vital signs. Especially the use of telemedicine will increase the quality of life for affected patients. Therefore, novel systems are necessary which are able to permanently detect and provide health status information. But these systems must not control patient's life and should work autonomously. For this purpose, intelligent medical implants are well qualified. This work describes a system for wireless power supply and communication with medical implant applications. Monitoring vital signs will create a big amount of data. Therefore, high data rates are necessary provided by high operating frequencies which in turn lead to electromagnetic far-field conditions. In this case, high attenuation losses due to the permittivity of the human body εr have to be considered. Hence, high frequencies are not suitable for the transfer of energy into the human body. The presented concept is based on two different frequencies for power supply and data transmission. An independent development of both blocks is thereby possible. The power supply operates at a frequency of 13.56 MHz, using inductive coupling. Consequently, the human body does not affect the energy transfer. In contrast, the data transmission is operated at a frequency of the medical implant communication service (MICS) band. The elaborated system consists of a power supply unit, a data transmission unit, and a control unit. The implementation of the power supply and data transmission as well as associated theoretical basics are presented. Performed measurements demonstrate that the realized system is qualified for the use on human beings.",10.1109/JPROC.2014.2359517,2014,,REMOTE POWERED MEDICAL IMPLANTS FOR TELEMONITORING,
148,28686,INTERNATIONAL JOURNAL OF HOSPITALITY MANAGEMENT,journal,02784319,"2,321",Q1,122,321,509,25314,4796,490,"8,98","78,86",United Kingdom,Western Europe,Elsevier Ltd.,1982-2020,"Strategy and Management (Q1); Tourism, Leisure and Hospitality Management (Q1)","17,219",9.237,0.01134,"The main purpose of this study is based on qualitative and quantitative research procedures, and integrates the key service factors for the online food delivery (OFD) industry extracted by Internet Big Data Analytics (IBDA) to construct a OFD service quality scale (OFD-SERV). This study takes OFD customers in Taipei City as the objects. The results show that 20 key service factors for the OFD industry are extracted through IBDA. The OFD-SERV scale contains six dimensions including reliability, maintenance of meal quality and hygiene, assurance, security, system operation and traceability, a total of 28 items. The results from the structural equation modeling showed that the reliability, assurance and system operation have a positive impact on customer satisfaction. Finally, the findings provide knowledge and inspiration for the current OFD, and enable OFD operators and future researchers to more accurately identify the deficiency of service quality.",https://doi.org/10.1016/j.ijhm.2021.102938,2021,Ching-Chan Cheng and Ya-Yuan Chang and Cheng-Ta Chen,CONSTRUCTION OF A SERVICE QUALITY SCALE FOR THE ONLINE FOOD DELIVERY INDUSTRY,article
149,14966,JOURNAL OF MANUFACTURING SYSTEMS,journal,02786125,"2,310",Q1,70,155,294,8906,2949,288,"10,88","57,46",Netherlands,Western Europe,Elsevier,1982-2020,Control and Systems Engineering (Q1); Hardware and Architecture (Q1); Industrial and Manufacturing Engineering (Q1); Software (Q1),"5,413",8.633,0.00561,"Digital twin takes Industrial Internet as a carrier deeply coordinating and integrating virtual spaces with physical spaces, which effectively promotes smart factory development. Digital twin-based big data learning and analysis (BDLA) deepens virtual and real fusion, interaction and closed-loop iterative optimization in smart factories. This paper proposes a digital twin-based big data virtual and real fusion (DT-BDVRL) reference framework supported by Industrial Internet towards smart manufacturing. The reference framework is synthetically designed from three perspectives. The first one is an overall framework of DT-BDVRL supported by Industrial Internet. The second one is the establishment method and flow of BDLA models based on digital twin. The final one is digital thread of DT-BDVRL in virtual and real fusion analysis, iteration and closed-loop feedback in product full life cycle processes. For different virtual scenes, iterative optimization and verification methods and processes of BDLA models in virtual spaces are established. Moreover, the BDLA results can drive digital twin running in virtual spaces. By this, the BDLA results can be validated iteratively multiple times in virtual spaces. At same time, the BDLA results that run in virtual spaces are synchronized and executed in physical spaces through Industrial Internet platforms, effectively improving the physical execution effect of BDLA models. Finally, the above contents were applied and verified in the actual production case study of power switchgear equipment.",https://doi.org/10.1016/j.jmsy.2020.11.012,2021,Pei Wang and Ming Luo,A DIGITAL TWIN-BASED BIG DATA VIRTUAL AND REAL FUSION LEARNING REFERENCE FRAMEWORK SUPPORTED BY INDUSTRIAL INTERNET TOWARDS SMART MANUFACTURING,article
150,14966,JOURNAL OF MANUFACTURING SYSTEMS,journal,02786125,"2,310",Q1,70,155,294,8906,2949,288,"10,88","57,46",Netherlands,Western Europe,Elsevier,1982-2020,Control and Systems Engineering (Q1); Hardware and Architecture (Q1); Industrial and Manufacturing Engineering (Q1); Software (Q1),"5,413",8.633,0.00561,"Industrial big data technology has become one of the important driving forces to intelligent manufacturing in the steel industry. In this study, the characteristics of data in steel production are analyzed and an industrial big data platform for steeling process is developed to extract the quality-related parameters. A data-driven approach to construct prediction intervals (PIs) of mechanical performances for hot-rolling strips is proposed to represent the uncertainty and reliability of the prediction results. The proposed method employs a new manifold visualization method, SLISEMAP, to reduce the feature dimensions with interpretability, utilizes lower upper bound estimation (LUBE) method to obtain the PIs, in which the broad learning system (BLS) is used as the basic training network model and the artificial bee colony (ABC) algorithm is applied to optimize the weighting parameters of BLS under the LUBE framework. A hot-rolling steel coil dataset consisting of 39 variables and 1335 coil samples is used to validate the proposed method. Two Delta-based approaches, namely back propagation neural network (BPNN) and extreme learning machine (ELM); and three LUBE-based approaches, namely ABC-BPNN, ABC-ELM, and ABC-support vector regression (SVR) are compared with the proposed method. Results show that the proposed ABC-BLS in LUBE is effective and efficient in constructing the PIs with a higher coverage probability and a narrower interval width.",https://doi.org/10.1016/j.jmsy.2022.08.014,2022,Gongzhuang Peng and Yinliang Cheng and Yufei Zhang and Jian Shao and Hongwei Wang and Weiming Shen,INDUSTRIAL BIG DATA-DRIVEN MECHANICAL PERFORMANCE PREDICTION FOR HOT-ROLLING STEEL USING LOWER UPPER BOUND ESTIMATION METHOD,article
151,14966,JOURNAL OF MANUFACTURING SYSTEMS,journal,02786125,"2,310",Q1,70,155,294,8906,2949,288,"10,88","57,46",Netherlands,Western Europe,Elsevier,1982-2020,Control and Systems Engineering (Q1); Hardware and Architecture (Q1); Industrial and Manufacturing Engineering (Q1); Software (Q1),"5,413",8.633,0.00561,"The fourth industrial revolution is derived from advances in digitization and prognostic and health management (PHM) disciplines to make plants smarter and more efficient. However, an adapted approach for data-driven PHM process implementation in small and medium-sized enterprises (SMEs) has not been yet discussed. This research gap is due to the specificities of SMEs and the lack of documentation. In this paper, we examine existing standards for implementing PHM in the industrial field and discuss the limitations within SMEs. Based on that, a novel strategy to implement a data-driven PHM approach in SMEs is proposed. Accordingly, the data management process and the impact of data quality are reviewed to address some critical data problems in SMEs (e.g., data volume and data accuracy). A first set of simulations was carried out to study the impact of the data volume and percentage of missing data on classification problems in PHM. A general model of the evolution of the results accuracy in function of data volume and missing data is then generated, and an economic data volume notion is proposed for data infrastructure resizing. The proposed strategy and the developed models are then applied to the Scoder enterprise, which is a French SME. The feedback on the first results of this application is reported and discussed.",https://doi.org/10.1016/j.jmsy.2020.04.002,2020,N. Omri and Z. {Al Masry} and N. Mairot and S. Giampiccolo and N. Zerhouni,INDUSTRIAL DATA MANAGEMENT STRATEGY TOWARDS AN SME-ORIENTED PHM,article
152,14966,JOURNAL OF MANUFACTURING SYSTEMS,journal,02786125,"2,310",Q1,70,155,294,8906,2949,288,"10,88","57,46",Netherlands,Western Europe,Elsevier,1982-2020,Control and Systems Engineering (Q1); Hardware and Architecture (Q1); Industrial and Manufacturing Engineering (Q1); Software (Q1),"5,413",8.633,0.00561,"Manufacturing companies struggle to be efficient and effective when conducting root cause analyses of production disturbances; a fact which hinders them from creating and developing resilient production systems. This article aims to describe the challenges and enablers identified in current research relating to the different phases of root cause analysis. A systematic literature review was conducted, in which a total of 14 challenges and 17 enablers are identified and described. These correlate to the different phases of root cause analysis. Examples of challenges are “need for expertise”, “employee bias”, “poor data quality” and “lack of data integration”, among others. Examples of enablers are “visualisation tools”, “collaborative platforms”, “thesaurus” and “machine learning techniques”. Based on these findings, the authors also propose potential areas for further research and then design inputs for new solutions to improve root cause analysis. This article provides a theoretical contribution in that it describes the challenges and enablers of root cause analysis and their correlation to the creation of resilient production systems. The article also provides practical contributions, with an overview of current research to support practitioners in gaining insights into potential solutions to be implemented and further developed, with the aim of improving root cause analysis in production systems.",https://doi.org/10.1016/j.jmsy.2022.07.015,2022,Adriana Ito and Malin Hagström and Jon Bokrantz and Anders Skoogh and Mario Nawcki and Kanika Gandhi and Dag Bergsjö and Maja Bärring,IMPROVED ROOT CAUSE ANALYSIS SUPPORTING RESILIENT PRODUCTION SYSTEMS,article
153,14966,JOURNAL OF MANUFACTURING SYSTEMS,journal,02786125,"2,310",Q1,70,155,294,8906,2949,288,"10,88","57,46",Netherlands,Western Europe,Elsevier,1982-2020,Control and Systems Engineering (Q1); Hardware and Architecture (Q1); Industrial and Manufacturing Engineering (Q1); Software (Q1),"5,413",8.633,0.00561,"The current task scheduling mainly concerns the availability of machining resources, rather than the potential errors after scheduling. To minimise such errors in advance, this paper presents a big data analytics based fault prediction approach for shop floor scheduling. Within the context, machining tasks, machining resources, and machining processes are represented by data attributes. Based on the available data on the shop floor, the potential fault/error patterns, referring to machining errors, machine faults and maintenance states, are mined for unsuitable scheduling arrangements before machining as well as upcoming errors during machining. Comparing the data-represented tasks with the mined error patterns, their similarities or differences are calculated. Based on the calculated similarities, the fault probabilities of the scheduled tasks or the current machining tasks can be obtained, and they provide a reference of decision making for scheduling and rescheduling the tasks. By rescheduling high-risk tasks carefully, the potential errors can be avoided. In this paper, the architecture of the approach consisting of three steps in three levels is proposed. Furthermore, big data are considered in three levels, i.e. local data, local network data and cloud data. In order to implement this idea, several key techniques are illustrated in detail, e.g. data attribute, data cleansing, data integration of databases in different levels, and big data analytic algorithms. Finally, a simplified case study is described to show the prediction process of the proposed method.",https://doi.org/10.1016/j.jmsy.2017.03.008,2017,Wei Ji and Lihui Wang,BIG DATA ANALYTICS BASED FAULT PREDICTION FOR SHOP FLOOR SCHEDULING,article
154,14726,TECHNOVATION,journal,01664972,"2,300",Q1,130,53,102,5179,837,93,"6,66","97,72",United Kingdom,Western Europe,Elsevier Ltd.,1981-2020,Engineering (miscellaneous) (Q1); Management of Technology and Innovation (Q1),"8,486",6.606,0.00351,"The recent development and diffusion of next-generation digital technologies (NGDTs) such as artificial intelligence, the Internet of Things, big data, 3D printing, and so on are expected to have an immense impact on businesses, innovation, and society. While we know from extant research that a firm's R&D investment, intangible assets, and productivity are factors that influence technology use more generally, to date there is little known about the factors that determine how these emerging tools are used, and by who. Using Probit and OLS modeling on a survey of 12,579 South Korean firms in 2017, we conduct one of the first comprehensive examinations highlighting various firm characteristics that drive NGDT implementation. While much of the literature assesses the use of individual technologies, our research attempts to unveil the extent to which firms implement NGDTs in bundles. Our investigation shows that more than half of the firms that use NGDTs deployed multiple technologies simultaneously. One of the insightful complementarities identified in this research exists amongst technologies that generate, facilitate and demand large sums of data, including big data, IoT, cloud computing and AI. Such technologies also appear important for innovative tools such as 3D printing and robotics.",https://doi.org/10.1016/j.technovation.2022.102477,2022,Jaehan Cho and Timothy DeStefano and Hanhin Kim and Inchul Kim and Jin Hyun Paik,WHAT'S DRIVING THE DIFFUSION OF NEXT-GENERATION DIGITAL TECHNOLOGIES?,article
155,21080,MECHANICAL SYSTEMS AND SIGNAL PROCESSING,journal,08883270,"2,275",Q1,167,538,2031,23327,16068,2017,"7,95","43,36",United States,Northern America,Elsevier,1987-2021,Aerospace Engineering (Q1); Civil and Structural Engineering (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Mechanical Engineering (Q1); Signal Processing (Q1),"30,686",6.823,0.03775,"The onset of the Internet of Things enables machines to be outfitted with always-on sensors that can provide health information to cloud-based monitoring systems for prognostics and health management (PHM), which greatly improves reliability and avoids downtime of machines and processes on the shop floor. On the other hand, real-time monitoring produces large amounts of data, leading to significant challenges for efficient and effective data transmission (from the shop floor to the cloud) and analysis (in the cloud). Restricted by industrial hardware capability, especially Internet bandwidth, most solutions approach data transmission from the perspective of data compression (before transmission, at local computing devices) coupled with data reconstruction (after transmission, in the cloud). However, existing data compression techniques may not adapt to domain-specific characteristics of data, and hence have limitations in addressing high compression ratios where full restoration of signal details is important for revealing machine conditions. This study integrates Deep Convolutional Autoencoders (DCAE) with local structure and physics-informed loss terms that incorporate PHM domain knowledge such as the importance of frequency content for machine fault diagnosis. Furthermore, Fault Division Autoencoder Multiplexing (FDAM) is proposed to mitigate the negative effects of multiple disjoint operating conditions on reconstruction fidelity. The proposed methods are evaluated on two case studies, and autocorrelation-based noise analysis provides insight into the relative performance across machine health and operating conditions. Results indicate that physically-informed DCAE compression outperforms prevalent data compression approaches, such as compressed sensing, Principal Component Analysis (PCA), Discrete Cosine Transform (DCT), and DCAE with a standard loss function. FDAM can further improve the data reconstruction quality for certain machine conditions.",https://doi.org/10.1016/j.ymssp.2021.108709,2022,Matthew Russell and Peng Wang,PHYSICS-INFORMED DEEP LEARNING FOR SIGNAL COMPRESSION AND RECONSTRUCTION OF BIG DATA IN INDUSTRIAL CONDITION MONITORING,article
156,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Economic, social and environmental requirements make planning for a sustainable electricity generation mix a demanding endeavour. Technological innovation offers a range of renewable generation and energy management options which require fine tuning and accurate control to be successful, which calls for the use of large-scale, detailed datasets. In this paper, we focus on the UK and use Multi-Criteria Decision Making (MCDM) to evaluate electricity generation options against technical, environmental and social criteria. Data incompleteness and redundancy, usual in large-scale datasets, as well as expert opinion ambiguity are dealt with using a comprehensive grey TOPSIS model. We used evaluation scores to develop a multi-objective optimization model to maximize the technical, environmental and social utility of the electricity generation mix and to enable a larger role for innovative technologies. Demand uncertainty was handled with an interval range and we developed our problem with multi-objective grey linear programming (MOGLP). Solving the mathematical model provided us with the electricity generation mix for every 5 min of the period under study. Our results indicate that nuclear and renewable energy options, specifically wind, solar, and hydro, but not biomass energy, perform better against all criteria indicating that interindustry architectural innovation in the power generation mix is key to sustainable UK electricity production and supply.",https://doi.org/10.1016/j.techfore.2018.04.031,2019,Konstantinos J. Chalvatzis and Hanif Malekpoor and Nishikant Mishra and Fiona Lettice and Sonal Choudhary,SUSTAINABLE RESOURCE ALLOCATION FOR POWER GENERATION: THE ROLE OF BIG DATA IN ENABLING INTERINDUSTRY ARCHITECTURAL INNOVATION,article
157,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Faced with internal and external pressure to adapt and implement environmental friendly business activities, it is becoming crucial for firms to identify practices that enhance their competitive advantage, economic, and environmental performance. Green innovation, green technologies, and the implementation of green supply chain management are examples of such practices. Green innovation and the adoption of the combination of green product innovation and green process innovation involve reduction in consumption of energy and pollution emission, recycling of wastes, sustainable utilization of resources, and green product designs. Although the extent research in this area is substantial, research on the importance of considering corporate environmental ethics, stakeholders view of green product, and demand for green products as drivers of green innovation must be conducted. Moreover, the role of large scale data, management commitment, and human resource practices play to overcome the technological challenges, achieve competitive advantage, and enhance the economic and environmental performance have yet to be addressed. This paper develops and tests a holistic model that depicts and examines the relationships among green innovation, its drivers, as well as factors that help overcome the technological challenges and influence the performance and competitive advantage of the firm. This paper is among the first works to deal with such a complex framework which considers the interrelationships among numerous constructs and their effects on competitive advantage as well as overall organizational performance. A questionnaire was designed to measure the influence of green innovation adoption/implementation and its drivers on performance and competitive advantage while taking into consideration the impact of management commitment and HR practices, as well as the use of large data on these relationships. Data collected from a sample of 215 respondents working in Middle East and North Africa (MENA) region and Golf-Cooperation Countries (GCC) were used to test the proposed relationships. The proposed model proved to be fit. The hypotheses were supported, and implications were discussed.",https://doi.org/10.1016/j.techfore.2017.12.016,2019,Abdul-Nasser El-Kassar and Sanjay Kumar Singh,GREEN INNOVATION AND ORGANIZATIONAL PERFORMANCE: THE INFLUENCE OF BIG DATA AND THE MODERATING ROLE OF MANAGEMENT COMMITMENT AND HR PRACTICES,article
158,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Big Data is one of the recent technological advances with the strong applicability in almost every industry, including manufacturing. However, despite business opportunities offered by this technology, its adoption is still in early stage in many industries. Thus, this study aimed to identify and rank the significant factors influencing adoption of big data and in turn to predict the influence of big data adoption on manufacturing companies' performance using a hybrid approach of decision-making trial and evaluation laboratory (DEMATEL)- adaptive neuro-fuzzy inference systems (ANFIS). This study identified the critical adoption factors from literature review and categorized them into technological, organizational and environmental dimensions. Data was collected from 234 industrial managers who were involved in the decision-making process regarding IT procurement in Malaysian manufacturing companies. Research results showed that technological factors (perceived benefits, complexity, technology resources, big data quality and integration) have the highest influence on the big data adoption and firms' performance. This study is one of the pioneers in using DEMATEL-ANFIS approach in the big data adoption context. In addition to the academic contribution, findings of this study can hopefully assist manufacturing industries, big data service providers, and governments to precisely focus on vital factors found in this study in order to improve firm performance by adopting big data.",https://doi.org/10.1016/j.techfore.2018.07.043,2018,Elaheh Yadegaridehkordi and Mehdi Hourmand and Mehrbakhsh Nilashi and Liyana Shuib and Ali Ahani and Othman Ibrahim,INFLUENCE OF BIG DATA ADOPTION ON MANUFACTURING COMPANIES' PERFORMANCE: AN INTEGRATED DEMATEL-ANFIS APPROACH,article
159,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"This study examines the role of big data contractual and relational governance in big data decision-making performance of firms based in China. It investigates the mediation of big data analytics (BDA) capability in the association of contractual and relational governance with decision-making performance. Furthermore, moderating role of data-driven culture in the relationship of BDA capability and decision-making performance is examined. Data are collected from 108 Chinese firms engaged in big data-related activities. Structural equation modeling is employed to test the hypotheses. This study contributes towards the literature on big data management and governance mechanisms, by establishing the relationship of decision-making performance with big data contractual and relational governance directly and through the mediation of BDA capabilities. It also contributes towards knowledge based dynamic capabilities (KBDCs) view of firms, arguing that dynamic capabilities such as BDA capabilities can be influenced through knowledge sources and activities. We add to the discussions on whether contractual and relational governance are alternatives or they complement each other, by establishing the moderating role of big data relational governance in the relationship of contractual governance and decision-making performance. Finally, we argue that social capital can enhance KBDCs through contractual and relational governance in big data context.",https://doi.org/10.1016/j.techfore.2020.120315,2020,Saqib Shamim and Jing Zeng and Zaheer Khan and Najam Ul Zia,BIG DATA ANALYTICS CAPABILITY AND DECISION MAKING PERFORMANCE IN EMERGING MARKET FIRMS: THE ROLE OF CONTRACTUAL AND RELATIONAL GOVERNANCE MECHANISMS,article
160,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"ABSTRACT
The significance of big data analytics-powered artificial intelligence has grown in recent years. The literature indicates that big data analytics-powered artificial intelligence has the ability to enhance supply chain performance, but there is limited research concerning the reasons for which firms engaging in manufacturing activities adopt big data analytics-powered artificial intelligence. To address this gap, our study employs institutional theory and resource-based view theory to elucidate the way in which automotive firms configure tangible resources and workforce skills to drive technological enablement and improve sustainable manufacturing practices and furthermore develop circular economy capabilities. We tested the research hypothesis using primary data collected from 219 automotive and allied manufacturing companies operating in South Africa. The contribution of this work lies in the statistical validation of the theoretical framework, which provides insight regarding the role of institutional pressures on resources and their effects on the adoption of big data analytics-powered artificial intelligence, and how this affects sustainable manufacturing and circular economy capabilities under the moderating effects of organizational flexibility and industry dynamism.",https://doi.org/10.1016/j.techfore.2020.120420,2021,Surajit Bag and Jan Ham Christiaan Pretorius and Shivam Gupta and Yogesh K. Dwivedi,"ROLE OF INSTITUTIONAL PRESSURES AND RESOURCES IN THE ADOPTION OF BIG DATA ANALYTICS POWERED ARTIFICIAL INTELLIGENCE, SUSTAINABLE MANUFACTURING PRACTICES AND CIRCULAR ECONOMY CAPABILITIES",article
161,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The access of machine learning techniques in popular programming languages and the exponentially expanding big data from social media, news, surveys, and markets provide exciting challenges and invaluable opportunities for organizations and individuals to explore implicit information for decision making. Nevertheless, the users of machine learning usually find that these sophisticated techniques could incur a high level of tensions caused by the selection of the appropriate size of the training data set among other factors. In this paper, we provide a systematic way of resolving such tensions by examining practical examples of predicting popularity and sentiment of posts on Twitter and Facebook, blogs on Mashable, news on Google and Yahoo, the US house survey, and Bitcoin prices. Interesting results show that for the case of big data, using around 20% of the full sample often leads to a better prediction accuracy than opting for the full sample. Our conclusion is found to be consistent across a series of experiments. The managerial implication is that using more is not necessarily the best and users need to be cautious about such an important sensitivity as the simplistic approach may easily lead to inferior solutions with potentially detrimental consequences.",https://doi.org/10.1016/j.techfore.2020.120175,2020,Huamao Wang and Yumei Yao and Said Salhi,TENSION IN BIG DATA USING MACHINE LEARNING: ANALYSIS AND APPLICATIONS,article
162,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"This study aims to develop accounting standards, curriculums, and research to cope with the rapid development of big data. The study presents several potential convergence points between big data and different accounting techniques and theories. The study discusses how big data can overcome the data limitations of six accounting issues: financial reporting, performance measurement, audit evidence, risk management, corporate budgeting and activity-based techniques. It presents six exciting research questions for future research. Then, the study explains the potential convergence between big data and agency theory, stakeholders theory, and legitimacy theory. This theoretical study develops new convergence points between big data and accounting by reviewing the literature and proposing new ideas and research questions. The conclusion indicates a significant convergence between big data and accounting on the premise that data is the heart of accounting. Big data and advanced analytics have the potential to overcome the data limitations of accounting techniques that require estimations and predictions. A remarkable convergence is argued between big data and three accounting theories. Overall, the study presents helpful insights to members of the accounting and auditing community on the potential of big data.",https://doi.org/10.1016/j.techfore.2021.121171,2021,Awad Elsayed Awad Ibrahim and Ahmed A. Elamer and Amr Nazieh Ezat,THE CONVERGENCE OF BIG DATA AND ACCOUNTING: INNOVATIVE RESEARCH OPPORTUNITIES,article
163,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The introduction and use of ‘big data and analytics’ is an on-going issue of discussion in health sectors globally. Healthcare systems of developed countries are trying to create more value and better healthcare through data and use of big data technologies. With an increasing number of articles identifying the value creation of big data and analytics for clinical decision-making, this paper examines how big data is applied, or not applied, in clinical practice. Using social representation theory as a theoretical foundation the paper explores people's perceptions of big data across all levels (policy making, planning, funding, and clinical care) of the New Zealand healthcare sector. The findings show that although adoption of big data technologies is planned for population health and health management, the potential of big data for clinical care has yet to be explored in the New Zealand context. The findings also highlight concern over data quality. The paper provides recommendations for policy and practice particularly around the need for engagement and participation of all levels to discuss data quality as well as big-data-based changes such as precision medicine and technology-assisted clinical decision-making tools. Future avenues of research are suggested.",https://doi.org/10.1016/j.techfore.2021.121222,2022,Kasuni Weerasinghe and Shane L. Scahill and David J. Pauleen and Nazim Taskin,BIG DATA ANALYTICS FOR CLINICAL DECISION-MAKING: UNDERSTANDING HEALTH SECTOR PERCEPTIONS OF POLICY AND PRACTICE,article
164,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"A universal trend in advanced manufacturing countries is defining Industry 4.0, industrialized internet and future factories as a recent wave, which may transform the production and its related services. Further, big data analytics has emerged as a game changer in the business world due to its uses for increasing accuracy in decision-making and enhancing performance of sustainable industry 4.0 applications. This study intends to emphasize on how to support Industry 4.0 with knowledge based view. For the same, a conceptual model is framed and presented with essential components that are required for a real world implementation. The study used qualitative analysis and was guided by a knowledge-based theoretical framework. Thematic analysis resulted in the identification of a number of emergent categories. Key findings highlight significant gaps in conventional decision-making systems and demonstrate how big data enhances firms’ strategic and operational decisions as well as facilitates informational access for improved marketing performance. The resulting proposed model can provide managers with a reference point for using big data to line up firms’ activities for more effective marketing efforts and presents a conceptual basis for further empirical studies in this area.",https://doi.org/10.1016/j.techfore.2021.120986,2021,Shivam Gupta and Théo Justy and Shampy Kamboj and Ajay Kumar and Eivind Kristoffersen,BIG DATA AND FIRM MARKETING PERFORMANCE: FINDINGS FROM KNOWLEDGE-BASED VIEW,article
165,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Big data initiatives are critical for transforming traditional organizational decision making into data-driven decision making. However, prior information systems research has not paid enough attention to the impact of big data analytics usage on decision-making quality. Drawing on the dynamic capability theory, this study investigated the impact of big data analytics usage on decision-making quality and tested the mediating effect of data analytics capabilities. We collected data from 240 agricultural firms in China. The empirical results showed that big data analytics usage had a positive impact on decision-making quality and that data analytics capabilities played a mediating role in the relationship between big data analytics usage and decision-making quality. Hence, firms should not only popularize big data analytics usage in their business activities but also take measures to improve their data analytics capabilities, which will improve their decision-making quality toward competitive advantages.",https://doi.org/10.1016/j.techfore.2021.121355,2022,Lei Li and Jiabao Lin and Ye Ouyang and Xin (Robert) Luo,EVALUATING THE IMPACT OF BIG DATA ANALYTICS USAGE ON THE DECISION-MAKING QUALITY OF ORGANIZATIONS,article
166,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Digital technologies are growing in importance for accelerating firms’ circular economy transition. However, so far, the focus has primarily been on the technical aspects of implementing these technologies with limited research on the organizational resources and capabilities required for successfully leveraging digital technologies for circular economy. To address this gap, this paper explores the business analytics resources firms should develop and how these should be orchestrated towards a firm-wide capability. The paper proposes a conceptual model highlighting eight business analytics resources that, in combination, build a business analytics capability for the circular economy and how this relates to firms’ circular economy implementation, resource orchestration capability, and competitive performance. The model is based on the results of a thematic analysis of 15 semi-structured expert interviews with key positions in industry. Our approach is informed by and further develops, the theory of the resource-based view and the resource orchestration view. Based on the results, we develop a deeper understanding of the importance of taking a holistic approach to business analytics when leveraging data and analytics towards a more efficient and effective digital-enabled circular economy, the smart circular economy.",https://doi.org/10.1016/j.techfore.2021.120957,2021,Eivind Kristoffersen and Patrick Mikalef and Fenna Blomsma and Jingyue Li,TOWARDS A BUSINESS ANALYTICS CAPABILITY FOR THE CIRCULAR ECONOMY,article
167,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Leveraging data science can enable businesses to exploit data for competitive advantage by generating valuable insights. However, many industries cannot effectively incorporate data science into their business processes, as there is no comprehensive approach that allows strategic planning for organization-wide data science efforts and data assets. Accordingly, this study explores the Data Science Roadmapping (DSR) to guide organizations in aligning their business strategies with data-related, technological, and organizational resources. The proposed approach is built on the widely adopted technology roadmapping framework and customizes its context, architecture, and process by synthesizing data science, big data, and data-driven organization literature. Based on industry collaborations, the framework provides a hybrid and agile methodology comprising the recommended steps. We applied DSR with a research group with sector experience to create a comprehensive data science roadmap to validate and refine the framework. The results indicate that the framework facilitates DSR initiatives by creating a comprehensive roadmap capturing strategy, data, technology, and organizational perspectives. The contemporary literature illustrates prebuilt roadmaps to help businesses become data-driven. However, becoming data-driven also necessitates significant social change toward openness and trust. The DSR initiative can facilitate this social change by opening communication channels, aligning perspectives, and generating consensus among stakeholders.",https://doi.org/10.1016/j.techfore.2021.121264,2022,Kerem Kayabay and Mert Onuralp Gökalp and Ebru Gökalp and P. {Erhan Eren} and Altan Koçyiğit,DATA SCIENCE ROADMAPPING: AN ARCHITECTURAL FRAMEWORK FOR FACILITATING TRANSFORMATION TOWARDS A DATA-DRIVEN ORGANIZATION,article
168,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"This study aims to fill a gap in the literature by identifying, defining, and evaluating the critical success factors that impact the implementation of data intelligence in the public sector. Fourteen factors were identified, and then divided into three categories: organization, process, and technology. We used the analytical hierarchy process, a quantitative method of decision-making, to evaluate the importance of the factors presented in the study using data collected from nine experts. The results showed that technology, as a category, is the most important. The analysis also indicated that project management, information systems & data, and data quality are the most important factors among all fourteen critical success factors. We discuss the implications of the analysis for practitioners and researchers in the paper.",https://doi.org/10.1016/j.techfore.2021.121180,2021,Mohammad I. Merhi,EVALUATING THE CRITICAL SUCCESS FACTORS OF DATA INTELLIGENCE IMPLEMENTATION IN THE PUBLIC SECTOR USING ANALYTICAL HIERARCHY PROCESS,article
169,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The importance and relevance of the discipline of statistics with the merits of the evolving field of data science continues to be debated in academia and industry. Following a narrative literature review with over 100 scholarly and practitioner-oriented publications from statistics and data science, this article generates a pragmatic perspective on the relationships and differences between statistics and data science. Some data scientists argue that statistics is not necessary for data science as statistics delivers simple explanations and data science delivers results. Therefore, this article aims to stimulate debate and discourse among both academics and practitioners in these fields. The findings reveal the need for stakeholders to accept the inherent advantages and disadvantages within the science of statistics and data science. The science of statistics enables data science (aiding its reliability and validity), and data science expands the application of statistics to Big Data. Data scientists should accept the contribution and importance of statistics and statisticians must humbly acknowledge the novel capabilities made possible through data science and support this field of study with their theoretical and pragmatic expertise. Indeed, the emergence of data science does pose a threat to statisticians, but the opportunities for synergies are far greater.",https://doi.org/10.1016/j.techfore.2021.121111,2021,Hossein Hassani and Christina Beneki and Emmanuel Sirimal Silva and Nicolas Vandeput and Dag Øivind Madsen,THE SCIENCE OF STATISTICS VERSUS DATA SCIENCE: WHAT IS THE FUTURE?,article
170,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"To date, health care industry has not fully grasped the potential benefits to be gained from big data analytics. While the constantly growing body of academic research on big data analytics is mostly technology oriented, a better understanding of the strategic implications of big data is urgently needed. To address this lack, this study examines the historical development, architectural design and component functionalities of big data analytics. From content analysis of 26 big data implementation cases in healthcare, we were able to identify five big data analytics capabilities: analytical capability for patterns of care, unstructured data analytical capability, decision support capability, predictive capability, and traceability. We also mapped the benefits driven by big data analytics in terms of information technology (IT) infrastructure, operational, organizational, managerial and strategic areas. In addition, we recommend five strategies for healthcare organizations that are considering to adopt big data analytics technologies. Our findings will help healthcare organizations understand the big data analytics capabilities and potential benefits and support them seeking to formulate more effective data-driven analytics strategies.",https://doi.org/10.1016/j.techfore.2015.12.019,2018,Yichuan Wang and LeeAnn Kung and Terry Anthony Byrd,BIG DATA ANALYTICS: UNDERSTANDING ITS CAPABILITIES AND POTENTIAL BENEFITS FOR HEALTHCARE ORGANIZATIONS,article
171,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Big data is an important driver of disruptive innovation that may increase organizations' competitive advantage. To create innovative data combinations and decrease investments, big data is often shared among organizations, crossing organizational boundaries. However, these big data collaborations need to balance disruptive innovation and compliance to a strict data protection regime in the EU. This paper investigates how inter-organizational big data collaborations arrange and govern their activities in the context of this dilemma. We conceptualize big data as inter-organizational systems and build on IS and Organization Theory literature to develop four archetypical governance arrangements: Market, Hierarchy, Bazaar and Network. Subsequently, these arrangements are investigated in four big data collaboration use cases. The contributions of this study to literature are threefold. First, we conceptualize the organization behind big data collaborations as IOS governance. Second, we show that the choice for an inter-organizational governance arrangement highly depends on the institutional pressure from regulation and the type of data that is shared. In this way, we contribute to the limited body of research on the antecedents of IOS governance. Last, we highlight with four use cases how the principles of big data, specifically data maximization, clash with the principles of EU data protection regulation. Practically, our study provides guidelines for IT and innovation managers how to arrange and govern the sharing of data among multiple organizations.",https://doi.org/10.1016/j.techfore.2017.09.040,2018,Tijs {van den Broek} and Anne Fleur {van Veenstra},GOVERNANCE OF BIG DATA COLLABORATIONS: HOW TO BALANCE REGULATORY COMPLIANCE AND DISRUPTIVE INNOVATION,article
172,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"This paper draws on data from three organisational case studies and expert interviews to propose that persuasive practices are the precursors and enablers of analytical capability development. A bundle of seven practices was identified and observed to bridge multiple gaps between technical and non-technical colleagues on big data analytics (BDA) projects. The deployment of these practices varied according to the level of BDA maturity and featured a host of socio-material elements. This paper complements existing technical case studies with a fine-grained qualitative account of the managerial and human elements of BDA implementation. Effective deployment of persuasive practices potentially both embeds the benefits and mitigates the risks of BDA, sowing the seeds of many different forms of value.",https://doi.org/10.1016/j.techfore.2020.120300,2020,Jeffrey Hughes and Kirstie Ball,SOWING THE SEEDS OF VALUE? PERSUASIVE PRACTICES AND THE EMBEDDING OF BIG DATA ANALYTICS,article
173,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The analysis of the transformation and changes in scientific disciplines has always been a critical path for policymakers and researchers. The current study examines the changes in the research areas of data and information quality (DIQ). The aim of this study was to detect different types of changes occurring in the scientific areas including birth, death, growth, decline, merge, and splitting. A model has been developed for this data mining. To test the model, all DIQ articles published in online scientific citation indexing service or Web of Science (WOS) between 1970 and 2016 were extracted and analyzed using the given model. The study is related to the Big Data as well as the integration methods in Big Data which is the most important area in DIQ. It is demonstrated that the first and second emerging research areas are sub-disciplines of entity resolution and record linkage. Accordingly, linkage and privacy are the first emerging research area and the entity resolution using ontology is the second in DIQ. This is followed by the social media issues and genetic related DIQ issues.",https://doi.org/10.1016/j.techfore.2018.08.003,2018,Babak Sohrabi and Ahmad Khalilijafarabad,SYSTEMATIC METHOD FOR FINDING EMERGENCE RESEARCH AREAS AS DATA QUALITY,article
174,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The Data Big Bang that the development of the ICTs has raised is providing us with a stream of fresh and digitized data related to how people, companies and other organizations interact. To turn these data into knowledge about the underlying behavior of the social and economic agents, organizations and researchers must deal with such amount of unstructured and heterogeneous data. Succeeding in this task requires to carefully plan and organize the whole process of data analysis taking into account the particularities of the social and economic analyses, which include the wide variety of heterogeneous sources of information and a strict governance policy. Grounded on the data lifecycle approach, this paper develops a Big Data architecture that properly integrates most of the non-traditional information sources and data analysis methods in order to provide a specifically designed system for forecasting social and economic behaviors, trends and changes.",https://doi.org/10.1016/j.techfore.2017.07.027,2018,Desamparados Blazquez and Josep Domenech,BIG DATA SOURCES AND METHODS FOR SOCIAL AND ECONOMIC ANALYSES,article
175,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"The business concept of the circular economy (CE) has gained significant momentum among practitioners and researchers alike. However, successful adoption and implementation of this paradigm of managing business remains a challenge. In this article, we build a case for utilizing big data analytics (BDA) as a fundamental basis for informed and data driven decision making in supply chain networks supporting CE. We view this from a stakeholder perspective and argue that a collaborative association among all supply chain members can positively affect CE implementation. We propose a model highlighting the facilitating role of big data analytics for achieving shared sustainability goals. The model is based on integrating thematic categories coming out of 10 semi-structured interviews with key position holders in industry. We argue that mutual support and coordination driven by a stakeholder perspective coupled with holistic information processing and sharing along the entire supply chain network can effectively create a basis for achieving the triple bottom line of economic, ecological and social benefits. The proposed model is useful for managers in that it provides a reference point for aligning activities with the circular economy paradigm. The conceptual model provides a theoretical basis for future empirical research in this domain.",https://doi.org/10.1016/j.techfore.2018.06.030,2019,Shivam Gupta and Haozhe Chen and Benjamin T. Hazen and Sarabjot Kaur and Ernesto D.R. {Santibañez Gonzalez},CIRCULAR ECONOMY AND BIG DATA ANALYTICS: A STAKEHOLDER PERSPECTIVE,article
176,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"While there is a general recognition that breakthrough innovation is non-linear and requires an alignment between producers (supply) and users (demand), there is still a need for strategic intelligence about the emerging supply chains of new technological innovations. This technology delivery system (TDS) is an updated form of the TDS model and provides a promising chain-link approach to the supply side of innovation. Building on early research into supply-side TDS studies, we present a systematic approach to building a TDS model that includes four phases: (1) identifying the macroeconomic and policy environment, including market competition, financial investment, and industrial policy; (2) specifying the key public and private institutions; (3) addressing the core technical complements and their owners, then tracing their interactions through information linkages and technology transfers; and (4) depicting the market prospects and evaluating the potential profound influences on technological change and social developments. Our TDS methodology is illustrated using the field of Big Data & Analytics (“BDA”).",https://doi.org/10.1016/j.techfore.2017.09.012,2018,Ying Huang and Alan L. Porter and Scott W. Cunningham and Douglas K.R. Robinson and Jianhua Liu and Donghua Zhu,A TECHNOLOGY DELIVERY SYSTEM FOR CHARACTERIZING THE SUPPLY SIDE OF TECHNOLOGY EMERGENCE: ILLUSTRATED FOR BIG DATA & ANALYTICS,article
177,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"As society continues its rapid change to a digitized individual, corporate, and government environment it is prudent for researchers to investigate the zeitgeist of the global citizenry. The technological changes brought about by big data analytics are changing the way we gather and view data. This big data analytics sentiment research examines how Chinese and American respondents may view big data collection and analytics differently. The paper follows with an analysis of reported attitudes toward possible viewpoints from each country on various big data analytics topics ranging from individual to business and governmental foci. Hofstede's cultural dimensions are used to inform and frame our research hypotheses. Findings suggest that Chinese and American perspectives differ on individual data values, with the Chinese being more open to data collection and analytic techniques targeted toward individuals. Furthermore, support is found that US respondents have a more favorable view of businesses' use of data analytics. Finally, there is a strong difference in the attitudes toward governmental use of data, where US respondents do not favor governmental big data analytics usage and the Chinese respondents indicated a greater acceptance of governmental data usage. These findings are helpful in better understanding appropriate technological change and adoption from a societal perspective. Specifically, this research provides insights for corporate business and government entities suggesting how they might adjust their approach to big data collection and management in order to better support and sustain their organization's services and products.",https://doi.org/10.1016/j.techfore.2017.06.029,2018,Ryan C. LaBrie and Gerhard H. Steinke and Xiangmin Li and Joseph A. Cazier,BIG DATA ANALYTICS SENTIMENT: US-CHINA REACTION TO DATA COLLECTION BY BUSINESS AND GOVERNMENT,article
178,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"Although big data, big data analytics (BDA) and business intelligence have attracted growing attention of both academics and practitioners, a lack of clarity persists about how BDA has been applied in business and management domains. In reflecting on Professor Ayre's contributions, we want to extend his ideas on technological change by incorporating the discourses around big data, BDA and business intelligence. With this in mind, we integrate the burgeoning but disjointed streams of research on big data, BDA and business intelligence to develop unified frameworks. Our review takes on both technical and managerial perspectives to explore the complex nature of big data, techniques in big data analytics and utilisation of big data in business and management community. The advanced analytics techniques appear pivotal in bridging big data and business intelligence. The study of advanced analytics techniques and their applications in big data analytics led to identification of promising avenues for future research.",https://doi.org/10.1016/j.techfore.2018.06.009,2019,Jie Sheng and Joseph Amankwah-Amoah and Xiaojun Wang,TECHNOLOGY IN THE 21ST CENTURY: NEW CHALLENGES AND OPPORTUNITIES,article
179,14704,TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE,journal,00401625,"2,226",Q1,117,448,1099,35581,10127,1061,"9,01","79,42",United States,Northern America,Elsevier Inc.,1970-2020,Applied Psychology (Q1); Business and International Management (Q1); Management of Technology and Innovation (Q1),"21,116",8.593,0.02416,"This study investigates the literary corpus of the role and potential of data intelligence and analytics through the lenses of artificial intelligence (AI), big data, and the human–AI interface to improve overall decision-making processes. It investigates how data intelligence and analytics improve decision-making processes in the public sector. A bibliometric analysis of a database containing 161 English-language articles published between 2017 and 2021 is performed, providing a map of the knowledge produced and disseminated in previous studies. It provides insights into key topics, citation patterns, publication activities, the status of collaborations between contributors over past studies, aggregated data intelligence, and analytics research contributions. The study provides a retrospective review of published content in the field of data intelligence and analytics. The findings indicate that field research has been concentrated mainly on emerging technologies' intelligence capabilities rather than on human–artificial intelligence in decision-making performance in the public sector. This study extends an ambidexterity theory in decision support, which enlightens how this ambidexterity can be encouraged and how it affects decision outcomes. The study emphasises the importance of the public sector adoption of data intelligence and analytics, as well as its efficiency. Furthermore, this study expands how researchers and practitioners interpret and understand data intelligence and analytics, AI, and big data for effective public sector decision-making.",https://doi.org/10.1016/j.techfore.2021.121201,2022,Assunta {Di Vaio} and Rohail Hassan and Claude Alavoine,DATA INTELLIGENCE AND ANALYTICS: A BIBLIOMETRIC ANALYSIS OF HUMAN–ARTIFICIAL INTELLIGENCE IN PUBLIC SECTOR DECISION-MAKING EFFECTIVENESS,article
180,17466,NEUROBIOLOGY OF DISEASE,journal,09699961,"2,205",Q1,166,330,722,29350,4074,710,"5,44","88,94",United States,Northern America,Academic Press Inc.,1994-2020,Neurology (Q1),"21,360",5.996,0.02068,"We describe the infrastructure and functionality for a centralized preclinical and clinical data repository and analytic platform to support importing heterogeneous multi-modal data, automatically and manually linking data across modalities and sites, and searching content. We have developed and applied innovative image and electrophysiology processing methods to identify candidate biomarkers from MRI, EEG, and multi-modal data. Based on heterogeneous biomarkers, we present novel analytic tools designed to study epileptogenesis in animal model and human with the goal of tracking the probability of developing epilepsy over time.",https://doi.org/10.1016/j.nbd.2018.05.026,2019,Dominique Duncan and Paul Vespa and Asla Pitkänen and Adebayo Braimah and Niina Lapinlampi and Arthur W. Toga,BIG DATA SHARING AND ANALYSIS TO ADVANCE RESEARCH IN POST-TRAUMATIC EPILEPSY,article
181,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"The use of big data to help explain fluctuations in the broader economy and key business performance indicators is now so commonplace that in some instances it has even begun to rival more traditional measures. Big data sources can very often provide advantages when compared with these more traditional data sources, but with these advantages also come potential pitfalls. We lay out a checklist called SMALL that we have developed in order to help interested parties as they navigate the big data minefield. Based on a set of five questions, the SMALL checklist should help users of big data draw justifiable conclusions and avoid making mistakes in matters of interpretation. To demonstrate, we provide several case studies that demonstrate the subtle nuances of several of these new big data sets and show how the problems they face often closely relate to age-old concerns that more traditional data sources are also forced to tackle.",https://doi.org/10.1016/j.bushor.2021.06.004,2022,Scott A. Brave and R. Andrew Butters and Michael Fogarty,"THE PERILS OF WORKING WITH BIG DATA, AND A SMALL CHECKLIST YOU CAN USE TO RECOGNIZE THEM",article
182,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"Machine learning holds great promise for lowering product and service costs, speeding up business processes, and serving customers better. It is recognized as one of the most important application areas in this era of unprecedented technological development, and its adoption is gaining momentum across almost all industries. In view of this, we offer a brief discussion of categories of machine learning and then present three types of machine-learning usage at enterprises. We then discuss the trade-off between the accuracy and interpretability of machine-learning algorithms, a crucial consideration in selecting the right algorithm for the task at hand. We next outline three cases of machine-learning development in financial services. Finally, we discuss challenges all managers must confront in deploying machine-learning applications.",https://doi.org/10.1016/j.bushor.2019.10.005,2020,In Lee and Yong Jae Shin,"MACHINE LEARNING FOR ENTERPRISES: APPLICATIONS, ALGORITHM SELECTION, AND CHALLENGES",article
183,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"As companies become increasingly digital, growth hacking emerged as a new way of scaling businesses. While the term is fashionable in business, many executives remain confused about the concept. Even if firms have an idea of what growth hacking is, they may still be puzzled as to how to do it, creating a strategy-execution gap. Our article assists firms by bridging the growth hacking strategy-execution gap. First, we provide a growth hacking framework and deconstruct its building blocks: marketing, data analysis, coding, and the lean startup philosophy. We then present a taxonomy of 34 growth hacking patterns along the customer lifecycle of acquisition, activation, revenue, retention, and referral; categorize them on the two dimensions of resource intensity and time lag; and provide an example of how to apply the taxonomy in the case of a fitness application. Finally, we discuss seven opportunities and challenges of growth hacking that firms should keep in mind.",https://doi.org/10.1016/j.bushor.2019.09.001,2019,René Bohnsack and Meike Malena Liesner,WHAT THE HACK? A GROWTH HACKING TAXONOMY AND PRACTICAL APPLICATIONS FOR FIRMS,article
184,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"With the explosion of the digital universe, it is becoming increasingly important to understand how organizational decision making (i.e., the business-oriented perspective) is intertwined with an understanding of enterprise data assets (i.e., the data-oriented perspective). This article first compares the business- and data-oriented perspectives to describe how the two views mesh with each other. It then presents three elements in the data-oriented perspective that are collectively referred to as the data triad: (1) use, (2) design and storage, and (3) processes and people. In describing the data triad, this article highlights practices, architectural techniques, and example tools that are used to manage, access, analyze, and deliver data. By presenting different elements of the data-oriented perspective, this article broadly and concretely describes the data triad and how it can play a role in the redefined scope of work for data-driven business managers.",https://doi.org/10.1016/j.bushor.2016.06.001,2016,Vijay Khatri,MANAGERIAL WORK IN THE REALM OF THE DIGITAL UNIVERSE: THE ROLE OF THE DATA TRIAD,article
185,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"Big data represents a new technology paradigm for data that are generated at high velocity and high volume, and with high variety. Big data is envisioned as a game changer capable of revolutionizing the way businesses operate in many industries. This article introduces an integrated view of big data, traces the evolution of big data over the past 20 years, and discusses data analytics essential for processing various structured and unstructured data. This article illustrates the application of data analytics using merchant review data. The impacts of big data on key business performances are then evaluated. Finally, six technical and managerial challenges are discussed.",https://doi.org/10.1016/j.bushor.2017.01.004,2017,In Lee,"BIG DATA: DIMENSIONS, EVOLUTION, IMPACTS, AND CHALLENGES",article
186,20209,BUSINESS HORIZONS,journal,00076813,"2,174",Q1,87,64,278,2475,2066,227,"6,68","38,67",United Kingdom,Western Europe,Elsevier Ltd.,1957-2020,Business and International Management (Q1); Marketing (Q1),"7,443",6.361,0.00571,"User-generated content, such as online product reviews, is a valuable source of consumer insight. Such unstructured big data is generated in real-time, is easily accessed, and contains messages consumers want managers to hear. Analyzing such data has potential to revolutionize market research and competitive analysis, but how can the messages be extracted? How can the vast amount of data be condensed into insights to help steer businesses’ strategy? We describe a non-proprietary technique that can be applied by anyone with statistical training. Latent Dirichlet Allocation (LDA) can analyze huge amounts of text and describe the content as focusing on unseen attributes in a specific weighting. For example, a review of a graphic novel might be analyzed to focus 70% on the storyline and 30% on the graphics. Aggregating the content from numerous consumers allows us to understand what is, collectively, on consumers’ minds, and from this we can infer what consumers care about. We can even highlight which attributes are seen positively or negatively. The value of this technique extends well beyond the CMO's office as LDA can map the relative strategic positions of competitors where they matter most: in the minds of consumers.",https://doi.org/10.1016/j.bushor.2015.10.001,2016,Neil T. Bendle and Xin (Shane) Wang,UNCOVERING THE MESSAGE FROM THE MESS OF BIG DATA,article
187,14642,TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY,journal,08867798,"2,172",Q1,98,375,946,16500,6440,942,"6,53","44,00",United Kingdom,Western Europe,Elsevier Ltd.,1986-2020,Building and Construction (Q1); Geotechnical Engineering and Engineering Geology (Q1),"16,336",5.915,0.0149,"The perception of surrounding rock geological conditions ahead the tunnel face is essential for TBM safe and efficient tunnelling. This paper developed a perception approach of surrounding rock class based on TBM operational big data and combined unsupervised-supervised learning. In data preprocessing, four data mining techniques (i.e., Z-score, K-NN, Kalman filtering, and wavelet packet decomposition) were used to detect outliers, substitute outliers, suppress noise, and extract features, respectively. Then, GMM was used to revise the original surrounding rock class through clustering TBM load parameters and performance parameters in view of the shortcomings of the HC method in the TBM-excavated tunnel. After that, five various ensemble learning classification models were constructed to identify the surrounding rock class, in which model hyper-parameters were automatically tuned by Bayes optimization. In order to evaluate model performance, balanced accuracy, Kappa, F1-score, and training time were taken into account, and a novel multi-metric comprehensive ranking system was designed. Engineering application results indicated that LightGBM achieved the most superior performance with the highest comprehensive score of 6.9066, followed by GBDT (5.9228), XGBoost (5.4964), RF (3.7581), and AdaBoost (0.9946). Through the weighted purity reduction algorithm, the contributions of input features on the five models were quantitatively analyzed. Finally, the impact of class imbalance on model performance was discussed using the ADASYN algorithm, showing that eliminating class imbalance can further improve the model's perception ability.",https://doi.org/10.1016/j.tust.2021.104285,2022,Xin Yin and Quansheng Liu and Xing Huang and Yucong Pan,PERCEPTION MODEL OF SURROUNDING ROCK GEOLOGICAL CONDITIONS BASED ON TBM OPERATIONAL BIG DATA AND COMBINED UNSUPERVISED-SUPERVISED LEARNING,article
188,14642,TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY,journal,08867798,"2,172",Q1,98,375,946,16500,6440,942,"6,53","44,00",United Kingdom,Western Europe,Elsevier Ltd.,1986-2020,Building and Construction (Q1); Geotechnical Engineering and Engineering Geology (Q1),"16,336",5.915,0.0149,"This work explores the potential for predicting TBM performance using deep learning. It focuses on a 17.5-km-long tunnel excavated for the Yingsong Water Diversion Project in Northeastern China with its 728 days’ continuous monitoring of mechanical data. The prediction uses the deep belief network (DBN) proposed by Hinton et al. (2006),on the penetration rate, cutter rotation speed, torque, and thrust force. Field Penetration Index (FPI) is introduced to quantify TBM performance in the field. The DBN algorithm trains on nth number of preceding elements and predicts the performance of the n + 1th element. Prior to the implementation of the DBN, a pilot test was performed to find the optimal values for the network structural parameters (number of input nodes, number of hidden layers, number of nodes in the hidden layers, and learning rate). Predictions on FPIs in all the three rock types were then proceeded with good agreement with the field measured data. The mean relative errors for the predicted measured FPIs are generally less than 0.15 and the correlation coefficients (R) can be higher than 0.78. The predicted and measured FPI values along the length of the tunnel graphically follow the same trends. These results confirm the usefulness of big data and the deep learning in predicting TBM performance.",https://doi.org/10.1016/j.tust.2020.103636,2021,Shangxin Feng and Zuyu Chen and Hua Luo and Shanyong Wang and Yufei Zhao and Lipeng Liu and Daosheng Ling and Liujie Jing,TUNNEL BORING MACHINES (TBM) PERFORMANCE PREDICTION: A CASE STUDY USING BIG DATA AND DEEP LEARNING,article
189,22489,EUROPEAN JOURNAL OF OPERATIONAL RESEARCH,journal,03772217,"2,161",Q1,260,657,2080,32022,13341,2068,"6,02","48,74",Netherlands,Western Europe,Elsevier,1977-2021,Computer Science (miscellaneous) (Q1); Information Systems and Management (Q1); Management Science and Operations Research (Q1); Modeling and Simulation (Q1),"64,756",5.334,0.04764,"The popularity of big data and business analytics has increased tremendously in the last decade and a key challenge for organizations is in understanding how to leverage them to create business value. However, while the literature acknowledges the importance of these topics little work has addressed them from the organization's point of view. This paper investigates the challenges faced by organizational managers seeking to become more data and information-driven in order to create value. Empirical research comprised a mixed methods approach using (1) a Delphi study with practitioners through various forums and (2) interviews with business analytics managers in three case organizations. The case studies reinforced the Delphi findings and highlighted several challenge focal areas: organizations need a clear data and analytics strategy, the right people to effect a data-driven cultural change, and to consider data and information ethics when using data for competitive advantage. Further, becoming data-driven is not merely a technical issue and demands that organizations firstly organize their business analytics departments to comprise business analysts, data scientists, and IT personnel, and secondly align that business analytics capability with their business strategy in order to tackle the analytics challenge in a systemic and joined-up way. As a result, this paper presents a business analytics ecosystem for organizations that contributes to the body of scholarly knowledge by identifying key business areas and functions to address to achieve this transformation.",https://doi.org/10.1016/j.ejor.2017.02.023,2017,Richard Vidgen and Sarah Shaw and David B. Grant,MANAGEMENT CHALLENGES IN CREATING VALUE FROM BUSINESS ANALYTICS,article
190,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"For seismic random noise attenuation, deep learning has attracted much attention and achieved promising performance. However, compared with conventional methods, the denoising performance of supervised learning-based methods heavily depends on massive training samples with high-quality labeled data, which makes their generalization capabilities limited. Even though deep neural networks (DNNs) usually outperform the conventional denoising methods, their performance is not guaranteed since neural networks still lack good mathematical interpretability at present. To alleviate the dependency on labeled data and explore insights into the denoising system, we proposed an unsupervised denoising method based on model-based deep learning, which combined domain knowledge and a data-driven method. We designed a network based on the modified iterative soft threshold algorithm (ISTA), which omitted the soft threshold to alleviate uncertainties introduced by empirically selected thresholds. In this network, we set the dictionary and code as trainable parameters. A loss function with a smooth penalty was designed to ensure that the network training can be implemented in an unsupervised manner. In the proposed method, we set the denoised result by  $f-x$  deconvolution as the input for our network, and the further denoised data can be obtained after each epoch of the training, which means that our method does not need the testing procedure. Experiments on synthetic and field seismic data demonstrate that our method exhibits competitive performance compared to the conventional, supervised, and unsupervised methods, including  $f-x$  deconvolution, curvelet, the Denoising Convolutional Neural Network (DnCNN), and the integration of neural network and Block-matching and 3-D filtering method (NN + BM3D).",10.1109/TGRS.2022.3165037,2022,,LEARNING FROM NOISY DATA: AN UNSUPERVISED RANDOM DENOISING METHOD FOR SEISMIC DATA USING MODEL-BASED DEEP LEARNING,
191,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"It is widely known that strong noise can decrease the quality of seismic data. However, the anelastic attenuation could be more important to account for the weak amplitude and low quality of seismic data. Here, we develop an inversion framework to simultaneously compensate for the attenuation of seismic data and remove noise, thereby enhancing the quality of seismic data. Instead of directly applying a compensation operator to the input seismic data, we formulate an inverse problem that connects the sparse reflectivity model and the raw seismic data via the convolution and attenuation functions. The random noise is assumed to be the unpredicted part of the forward modeling process. We use the L2-norm regularization for the data misfit and impose a sparsity constraint onto the reflectivity series, e.g., using the L1-norm constraint. We use an iterative preconditioned conjugate gradient method to solve the L1-norm constrained least-squares optimization problem and obtain the reflectivity series. The denoised and compensated data are obtained by applying the convolution operator to the reflectivity. We use several synthetic and field seismic data to illustrate the effectiveness of the presented method.",10.1109/TGRS.2020.3010813,2021,,Q-COMPENSATED DENOISING OF SEISMIC DATA,
192,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"5-D data is the original recorded form in the 3-D seismic acquisition, which includes sufficient information from all five dimensions. However, environmental and economic logistic difficulties often severely impact the data acquisition geometry, leading to raw data with missing traces and strong contaminating random noise. This deficiency often causes troubles in subsequent processing. Thus, an efficient interpolation and denoising method is required to recover useful signals. Unfortunately, practical applications of many existing reconstruction algorithms are limited by their intensive computational cost when applied to the 5-D data. Additionally, the stability of these algorithms is also challenged by complex geological structures, which often degrades the reconstruction performance. To seek solutions to the aforementioned problems, we design a simple and effective framework for fast reconstruction and denoising of undersampled 5-D seismic data via a two-step process. First, we prepare the initial model from the original recordings by constructing a 3-D gather at each common offset point. This step effectively interpolates the missing traces in 3-D common offset gathers by exploiting the data coherency in the adjacent areas (i.e., nearby mid-points). In the second step, the processed 5-D data is reorganized into 3-D common midpoint gathers, with each of them further sorted into a 2-D section according to absolute offset values. Then a conventional 2-D processing algorithm (e.g., F-X prediction, wavelet thresholding, or multichannel singular spectrum analysis) is invoked to filter the obtained 2-D section. The proposed workflow has a low overall computational cost and preserves signal fidelity. We use this framework to simultaneously denoise and interpolate the low-quality and extremely sparse seismic data. The synthetic and field examples both demonstrate the superb performance of the proposed framework in comparison with conventional methods.",10.1109/TGRS.2021.3132257,2022,,SIMULTANEOUS RECONSTRUCTION AND DENOISING OF EXTREMELY SPARSE 5-D SEISMIC DATA BY A SIMPLE AND EFFECTIVE METHOD,
193,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Near-earth hyperspectral big data present both huge opportunities and challenges for spurring developments in agriculture and high-throughput plant phenotyping and breeding. In this article, we present data-driven approaches to address the calibration challenges for utilizing near-earth hyperspectral data for agriculture. A data-driven, fully automated calibration workflow that includes a suite of robust algorithms for radiometric calibration, bidirectional reflectance distribution function (BRDF) correction and reflectance normalization, soil and shadow masking, and image quality assessments was developed. An empirical method that utilizes predetermined models between camera photon counts (digital numbers) and downwelling irradiance measurements for each spectral band was established to perform radiometric calibration. A kernel-driven semiempirical BRDF correction method based on the Ross Thick-Li Sparse (RTLS) model was used to normalize the data for both changes in solar elevation and sensor view angle differences attributed to pixel location within the field of view. Following rigorous radiometric and BRDF corrections, novel rule-based methods were developed to conduct automatic soil removal; and a newly proposed approach was used for image quality assessment; additionally, shadow masking and plot-level feature extraction were carried out. Our results show that the automated calibration, processing, storage, and analysis pipeline developed in this work can effectively handle massive amounts of hyperspectral data and address the urgent challenges related to the production of sustainable bioenergy and food crops, targeting methods to accelerate plant breeding for improving yield and biomass traits.",10.1109/TGRS.2021.3091409,2022,,DATA-DRIVEN ARTIFICIAL INTELLIGENCE FOR CALIBRATION OF HYPERSPECTRAL BIG DATA,
194,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"In complex electromagnetic environments, synthetic aperture radar (SAR) is severely affected by radio frequency interference (RFI) from other systems, such as ground-based radar, cellular networks, and global positioning systems, and this interference cannot be neglected. Pulse RFI (PRFI), a common form of RFI, can hinder SAR signal processing and image interpretation to varying degrees. The time-domain notch filtering method designed for mitigating PRFI can locate and mitigate the evident PRFI covered in SAR echo data, but it is helpless against PRFI hidden in a strong echo signal. In this article, a three-step approach is proposed to tackle the PRFI problem. In the proposed approach, the first step is to detect and locate PRFI; this is based on eigenvalue decomposition (EVD) and the short-time Fourier transform (STFT). The second step is to notch PRFI, and this is based on a time-domain notch filter. The third step is to recover the notched signal using a novel matrix completion strategy, which integrates with a robust low-rank matrix completion (LRMC) technique—i.e.,the singular value thresholding (SVT) algorithm—and a well-known Lagrange interpolation technique. Experimental results via simulated SAR data, Sentinel-1 level-0 raw data, and L-band airborne SAR raw data demonstrate the performance of the proposed approach.",10.1109/TGRS.2022.3161368,2022,,"PULSE RFI MITIGATION IN SYNTHETIC APERTURE RADAR DATA VIA A THREE-STEP APPROACH: LOCATION, NOTCH, AND RECOVERY",
195,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"The majority of optical observations acquired via spaceborne Earth imagery are affected by clouds. While there is numerous prior work on reconstructing cloud-covered information, previous studies are, oftentimes, confined to narrowly defined regions of interest, raising the question of whether an approach can generalize to a diverse set of observations acquired at variable cloud coverage or in different regions and seasons. We target the challenge of generalization by curating a large novel data set for training new cloud removal approaches and evaluate two recently proposed performance metrics of image quality and diversity. Our data set is the first publically available to contain a global sample of coregistered radar and optical observations, cloudy and cloud-free. Based on the observation that cloud coverage varies widely between clear skies and absolute coverage, we propose a novel model that can deal with either extreme and evaluate its performance on our proposed data set. Finally, we demonstrate the superiority of training models on real over synthetic data, underlining the need for a carefully curated data set of real observations. To facilitate future research, our data set is made available online.",10.1109/TGRS.2020.3024744,2021,,MULTISENSOR DATA FUSION FOR CLOUD REMOVAL IN GLOBAL AND ALL-SEASON SENTINEL-2 IMAGERY,
196,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Synthetic aperture radar tomography (TomoSAR) has been extensively employed in 3-D reconstruction in dense urban areas using high-resolution SAR acquisitions. Compressive sensing (CS)-based algorithms are generally considered as the state-of-the art in super-resolving TomoSAR, in particular in the single look case. This superior performance comes at the cost of extra computational burdens, because of the sparse reconstruction, which cannot be solved analytically, and we need to employ computationally expensive iterative solvers. In this article, we propose a novel deep learning-based super-resolving TomoSAR inversion approach,  $\boldsymbol {\gamma }$ -Net, to tackle this challenge.  $\boldsymbol {\gamma }$ -Net adopts advanced complex-valued learned iterative shrinkage thresholding algorithm (CV-LISTA) to mimic the iterative optimization step in sparse reconstruction. Simulations show the height estimate from a well-trained  $\boldsymbol {\gamma }$ -Net approaches the Cramér-Rao lower bound (CRLB) while improving the computational efficiency by one to two orders of magnitude comparing to the first-order CS-based methods. It also shows no degradation in the super-resolution power comparing to the state-of-the-art second-order TomoSAR solvers, which are much more computationally expensive than the first-order methods. Specifically,  $\boldsymbol {\gamma }$ -Net reaches more than 90% detection rate in moderate super-resolving cases at 25 measurements at 6 dB SNR. Moreover, simulation at limited baselines demonstrates that the proposed algorithm outperforms the second-order CS-based method by a fair margin. Test on real TanDEM-X data with just six interferograms also shows high-quality 3-D reconstruction with high-density detected double scatterers.",10.1109/TGRS.2022.3164193,2022,,Γ-NET: SUPERRESOLVING SAR TOMOGRAPHIC INVERSION VIA DEEP LEARNING,
197,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Advances in remote sensing hardware have led to a significantly increased capability for high-quality data acquisition, which allows the collection of remotely sensed images with very high spatial, spectral, and radiometric resolution. This trend calls for the development of new techniques to enhance the way that such unprecedented volumes of data are stored, processed, and analyzed. An important approach to deal with massive volumes of information is data compression, related to how data are compressed before their storage or transmission. For instance, hyperspectral images (HSIs) are characterized by hundreds of spectral bands. In this sense, high-performance computing (HPC) and high-throughput computing (HTC) offer interesting alternatives. Particularly, distributed solutions based on cloud computing can manage and store huge amounts of data in fault-tolerant environments, by interconnecting distributed computing nodes so that no specialized hardware is needed. This strategy greatly reduces the processing costs, making the processing of high volumes of remotely sensed data a natural and even cheap solution. In this paper, we present a new cloud-based technique for spectral analysis and compression of HSIs. Specifically, we develop a cloud implementation of a popular deep neural network for non-linear data compression, known as autoencoder (AE). Apache Spark serves as the backbone of our cloud computing environment by connecting the available processing nodes using a master-slave architecture. Our newly developed approach has been tested using two widely available HSI data sets. Experimental results indicate that cloud computing architectures offer an adequate solution for managing big remotely sensed data sets.",10.1109/TGRS.2019.2929731,2019,,CLOUD DEEP NETWORKS FOR HYPERSPECTRAL IMAGE ANALYSIS,
198,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"In synthetic aperture radar (SAR) data processing, radio frequency interference (RFI) has been recognized as a challenging issue, which can significantly degrade the image quality, including amplitude, phase, geometry, and so on. Most of the RFI sources are direct waves transmitted from the ground. Recently, a new form of RFI, namely, the mutual RFI (MRFI), which is a kind of scatter-wave RFI originating from the nearby ground area simultaneously illuminated by different SAR satellites, has been reported. In this article, the signatures of MRFI are characterized, and an example case study between Chinese GaoFen-3 (GF-3) and European Sentinel-1A (S-1A) is analyzed. In order to remove the artifacts caused by MRFI on SAR images, a novel RFI detector based on spectrum energy cancellation (SEC), which has the capability of detecting MRFI, is developed. Two methods, i.e., the traditional notch filtering method and an improved eigen-subspace projection (ESP) method proposed in this article, are employed to mitigate MRFI. The former method has robust mitigation performance with a fast processing speed, whereas the latter has an improved mitigation accuracy and lower sidelobes for strong scatterers. The methods are designed for cases in which the MRFI has a different radar center frequency than the useful signal, and some of the data are free from MRFI. The conditions required for the proper use of the approach are discussed. In contrast to the conventional mitigating methods performed on the raw data domain, the proposed approach begins with the focused single-look complex (SLC) SAR data. The effectiveness of the proposed approach is demonstrated on several GF-3 SLC SAR images, which were contaminated by MRFI from the S-1A.",10.1109/TGRS.2022.3170363,2022,,OBSERVATION AND MITIGATION OF MUTUAL RFI BETWEEN SAR SATELLITES: A CASE STUDY BETWEEN CHINESE GAOFEN-3 AND EUROPEAN SENTINEL-1A,
199,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Currently, the spaceborne synthetic aperture radar (SAR) system transmits a great deal of data to the ground processing station and generates massive images daily, only a tiny fraction of which contains radio frequency interference (RFI). However, most of the existing RFI detection methods are based on the prior conditions in which the known image contains interference. In fact, it is difficult to learn whether SAR images contain RFIs without prescreening, so it is of great significance to the rapid and real-time screening and detection of RFI in SAR images. This article proposes a method to screen and detect RFI from massive SAR images simultaneously. 1) We construct an approximate RFI-free background image by using the preprocessed time-series SAR images acquired in the past. 2) We generate difference images based on the image change detection method and analyze them by using an adaptive threshold, then calculate the entropy of all difference images to complete the preliminary screening of the RFI-containing). According to the preliminary results, we remove the RFI-containing parts; after reconstructing the background, we repeat step 2 with the images to be detected and obtain the final screening and detection results. Massive experimental results based on Sentinel-1 images validate the performance of the proposed method.",10.1109/TGRS.2022.3191815,2022,,SIMULTANEOUS SCREENING AND DETECTION OF RFI FROM MASSIVE SAR IMAGES: A CASE STUDY ON EUROPEAN SENTINEL-1,
200,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Recently, deep learning methods have made significant progress in solving hyperspectral image (HSI) classification problems of high-dimensional features, band redundancy, and spectral mixture. However, the deep neural network is too complex, with a long training time and high energy consumption, making it difficult to deploy on edge computing devices. In order to solve the above problems, this article proposes a brain-inspired computing framework based on the spiking leaky integrate-and-fire neuron model for HSIs’ classification. Then, we design an approximate derivative algorithm to solve the nondifferentiable spike activity of the spiking neuron. The framework uses direct coding to generate spatiotemporal spikes for input HSI and achieves efficient extraction of spatial–spectral features through spiking standard convolution and spiking depthwise separable convolution. Extensive experiments are performed on four benchmark hyperspectral datasets and two public unmanned aerial vehicle-borne hyperspectral datasets. Experiments show that the proposed model has the advantages of high classification accuracy and fewer spiking time steps. The proposed model can save about ten times computational energy consumption compared with the CNN of the same architecture. This research has great significance for overcoming the technical bottleneck of HSI classification based on brain-inspired computing, solving the critical problems of mobile computing in unmanned autonomous systems, and realizing the engineering application of unmanned aerial vehicles and software-defined satellites. The source code will be made available at https://github.com/Katherine-Cao/HSI_SNN.",10.1109/TGRS.2022.3207098,2022,,HYPERSPECTRAL IMAGE CLASSIFICATION OF BRAIN-INSPIRED SPIKING NEURAL NETWORK BASED ON APPROXIMATE DERIVATIVE ALGORITHM,
201,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"A generalized continuous wave synthetic aperture radar (GCW-SAR) concept is proposed in this paper. By using full-duplex radio frontend and continuous wave signaling, the GCW-SAR system can overcome a number of limitations inherent within the existing SAR systems and achieve high-resolution and wide-swath remote sensing with low-power signal transmission. Unlike the conventional pulsed SAR and the frequency-modulated continuous-wave SAR, the GCW-SAR reconstructs a radar image by directly correlating the received 1-D raw data after self-interference cancellation with predetermined location-dependent reference signals. A fast imaging algorithm, called the piecewise constant Doppler (PCD) algorithm, is also proposed, which produces the radar image recursively in the azimuth direction without any intermediate step, such as range compression and migration compensation, as required by conventional algorithms. By removing the stop-and-go assumption or slow-time sampling in azimuth, the PCD algorithm not only achieves better imaging quality but also allows for more flexible waveform and system designs. Analyses and simulations show that the GCW-SAR tolerates significant self-interference and works well with a large selection of various system parameters. The work presented in this paper establishes a solid theoretical foundation for next-generation imaging radars.",10.1109/TGRS.2018.2849382,2018,,GENERALIZED CONTINUOUS WAVE SYNTHETIC APERTURE RADAR FOR HIGH RESOLUTION AND WIDE SWATH REMOTE SENSING,
202,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"We present a method that skeletonizes the first arriving seismic refractions by machine learning and inverts them for the subsurface velocity model. In this study, first arrivals can be compressed in a low-rank sense with their skeletal features extracted by a well-trained autoencoder. Empirical experiments suggest that the autoencoder’s  $1\times 1$  or  $2\times 1$  latent vectors vary continuously with respect to the input seismic data. It is, therefore, reasonable to introduce a misfit functional measuring the discrepancies between the predicted and the observed data in a low-dimensional latent space. The benefit of this approach is that an elaborated autoencoding neural network not only refines intrinsic information hidden in the refractions but also improves the quality of inversion for a reliable background velocity model. Numerical tests on both synthetic and field data demonstrate the effectiveness of this method, especially in recovering the low-to-intermediate wavenumber parts of the subsurface velocity distribution. Comparisons are made with the other three relevant methods, the wave-equation travel-time (WT) inversion, the envelope inversion, and the full waveform inversion (FWI). As expected, the cycle skipping problem is alleviated due to the reduction of dimensions of data space. This method outperforms the envelope inversion in resolution, and it is no worse than WT. Moreover, there is no need for careful manual travel-time picking with this methodology. In general, this inversion framework provides an extendable strategy to compress any input data for reconstructing high-dimensional physical parameters.",10.1109/TGRS.2020.3046093,2021,,SKELETONIZED WAVE-EQUATION REFRACTION INVERSION WITH AUTOENCODED WAVEFORMS,
203,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"A novel 3-D time-domain terahertz (THz) imaging system based on piecewise constant Doppler (PCD) algorithm and step-frequency continuous-wave (SFCW) signaling is proposed in this article. First, the SFCW THz imaging system configuration and the Gaussian beam propagation model are introduced. Then, the conventional time-domain correlation imaging algorithm is reviewed, and the closed-form expression of its point spread function (PSF) is derived to quantify the range and lateral resolutions. To reduce the computational complexity, a 2-D recursive imaging process based on the plane approximation of the range surface is proposed, by which the original PCD algorithm is extended for 3-D imaging with 2-D aperture synthesis. The 3-D PCD imaging principle, implementation, and complexity analysis are discussed afterward. Finally, simulation and experimental results are provided to validate the theoretical analysis of the 3-D time-domain THz imaging and demonstrate the high quality of the proposed imaging algorithm at a low computational cost.",10.1109/TGRS.2020.3031917,2021,,3-D TERAHERTZ IMAGING BASED ON PIECEWISE CONSTANT DOPPLER ALGORITHM AND STEP- FREQUENCY CONTINUOUS-WAVE SIGNALING,
204,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Synthetic aperture radar (SAR) images are affected by a speckle noise, which is a consequence of random fluctuations in the return signal from an object that is no bigger than a single image processing element and it is caused by coherent processing of backscattered signals from multiple distributed targets. Speckle within SAR images can be reduced using filtering methods. To preserve features within the SAR images, this paper proposes a noise removal based on scene and SAR data modeling. The proposed method is a model-based total variational optimization with the minimization of a cost function. The cost function consisted of energy and data fidelity terms. The energy term was modeled using optimal-dual-based l1 analysis. The data fidelity term modeled the amplitude of the SAR data, which was approximated using a Nakagami distribution. The minimization of the cost function was solved using a quasi-Newton approach. The experimental results showed good results in SAR feature preservation. The proposed method was evaluated numerically using quality metrics for synthetic generated data and real amplitude SAR data.",10.1109/TGRS.2018.2841191,2018,,OPTIMAL-DUAL-BASED  $L_1$  ANALYSIS FOR SPECKLE REDUCTION OF SAR DATA,
205,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Recorded seismograms are usually distorted by statics owing to complex geological conditions, such as lateral variations in sediment thickness or complex topographies. These distorted and discontinuous signals usually exist in either arrival times or amplitudes of waves, and they are most likely to be smeared as velocity perturbations along their associated raypaths. Therefore, statics may blur images of the target bodies or, even worse, introduce unexpected and false anomalies into subsurface structures. To partly resolve this problem, we develop a weighted statics correction method to estimate unwanted temporal shifts of traces using the closure-phase technique, which is utilized in astronomical imaging. In the proposed method, the source and receiver statics are regarded as independent quantities contributing to the waveform shifts based on their acquisition geometries. Numerical tests on both the synthetic and field cases show noticeable, although gradual, improvements in data quality compared to the conventional plus–minus (PM) method. In general, this method provides a straightforward strategy to reedit the travel times in seismic profiles without inverting for a near-surface velocity model. Moreover, it can be extended to any interferometrical methods in seismic data processing that satisfies the closure-phase conditions.",10.1109/TGRS.2022.3169519,2022,,A WEIGHTED CLOSURE-PHASE STATICS CORRECTION METHOD: SYNTHETIC AND FIELD DATA EXAMPLES,
206,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Pan-sharpening refers to the fusion of a low-resolution (LR) multispectral (MS) image and a high-resolution (HR) panchromatic (PAN) image to obtain an HR MS image (i.e., pan-sharpened MS image). From the point of view of variational complementary data fusion, it becomes an optimization problem with geometry and spectral preserving constraints. In this paper, a novel unified optimizing pan-sharpening model is proposed by integrating a data-generative fidelity term and a compound prior term, which incorporates both spatial fractional-order geometry and spectral-spatial low-rank priors. Specifically, the proposed model consists of three important ingredients: 1) data-generative fidelity term, which models the degradation relationship between the LR and HR MS images to enforce the geometry and spectral preserving constraints; 2) fractional-order total variation-based spatial fractional-order geometry prior term, which especially exploits the spatial fractional-order gradient feature consistence between the PAN and pan-sharpened MS images to transfer the spatial structure information of the PAN image into the pan-sharpened MS image; and 3) weighted nuclear norm-based spectral-spatial low-rank prior term, which exploits the nonlocal patches-based low-rank structural sparsity simultaneously in the pan-sharpened MS image and the LR MS image for further preserving image spatial structures and spectral information. Thus, the main novelty behind the proposed model is an optimizing mechanism by fully taking advantage of the spatial details and texture expressive power of the spatial fractional-order geometry prior as well as the spectral-spatial correlation preserving capacity of the low-rank prior. Finally, the proposed model can be implemented in an alternating direction method of multipliers framework, and thus, an efficient algorithm is presented. To verify the validity, the new proposed method is systematically compared with some state-of-the-art techniques using the Pleiades, GeoEye-1, QuickBird, and WorldView2 satellite data sets in the subjective, objective, and efficiency aspects. The results show that the proposed method performs better than the compared methods in terms of higher spatial and spectral qualities.",10.1109/TGRS.2017.2768386,2018,,A VARIATIONAL PAN-SHARPENING METHOD BASED ON SPATIAL FRACTIONAL-ORDER GEOMETRY AND SPECTRAL–SPATIAL LOW-RANK PRIORS,
207,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Seismic multicomponent, here refers to P-P wave (PP) and P- shear wave (SV), joint inversion is an important approach to improve the accuracy of S-wave velocity and density prediction. Compared with P-P wave data, converted wave data are more sensitive to these parameters. Thus, introducing these data to the seismic inversion could improve the inversion accuracy of S-wave velocity and density. Due to the travel-time gap between the multicomponent data, multicomponent inversion usually needs to be prepared for registration processing in advance. However, registration methods often suffer from matching errors, which ultimately affect the quality of the inversion results. Based on the optimal transmission idea, a registration-free multicomponent joint amplitude variation with offset/angle (AVO/AVA) inversion algorithm is developed in this article. The proposed method adopts the Earth mover’s distance between the synthetic P-SV wave and the observed P-P wave by calculating the optimal transport path. Besides  ${\ell _{1-2}}$  norm is exploited as the penalty norm, where the regularized misfit function is minimized by the alternating direction method of multipliers (ADMM) algorithm. The synthetic data test and real seismic data application show that the proposed method can retrieve the S-wave velocity and density information better than the conventional method. The proposed method can not only effectively avoid the cumbersome registration steps, but also minimize the registration error and avoid the subsequent error accumulation.",10.1109/TGRS.2021.3063271,2022,,REGISTRATION-FREE MULTICOMPONENT JOINT AVA INVERSION USING OPTIMAL TRANSPORT,
208,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"For applications based on hyperspectral imagery (HSI), selecting informative and representative bands without the degradation of performance is a challenging task in the context of big data. In this paper, an unsupervised band selection method, scalable one-pass self-representation learning (SOP-SRL), is proposed to address this problem by processing data in a streaming fashion without storing the entire data. SOP-SRL embeds band selection into a scalable self-representation learning, which is formulated as an adaptive linear combination of regression-based loss functions, with the row-sparsity constraint. To further enhance the representativeness of bands, the local similarity between samples constructed by the selected bands is dynamically measured by means of graph-based regularization term in the embedded space. Moreover, a cache with memory function that reflects the quality of bands in the historical data is designed to keep the consistency between data coming at different times and guide subsequent band selection. An efficient algorithm is developed to optimize the SOP-SRL model. The HSI classification is conducted on three public data sets, and the experimental results validate the superiority of SOP-SRL in terms of performance and time when compared with other state-of-the-art band selection methods.",10.1109/TGRS.2019.2890848,2019,,SCALABLE ONE-PASS SELF-REPRESENTATION LEARNING FOR HYPERSPECTRAL BAND SELECTION,
209,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Advances in space-based ocean surveillance systems have improved the detection of objects from high-quality remote-sensing big data. Previous studies mainly focused on finding and recognizing objects based on deep learning and statistical frameworks. Studies have not fully explored the transparent and reasonable decision-making process for the final predicted results, which is vital for civil and military applications. An explainable attention network for fine-grained ship image classification is proposed in the present study to bridge this gap. The present study seeks to increase attention to objects’ discriminative parts and explore intrinsic relationships between multiple attention parts and predicted outcomes. Several causal multi-attention maps are generated by combining the multi-head attention mechanism and structural causal model. The convolutional filters in the last layer of the network are divided into several groups, and each group is designed to express specific semantic information under supervision of the filter loss function. The results show which parts of the objects are adopted as the key factors for the network to make the final predicted outcome. In the training process, the network is designed to rapidly focus on the salient feature of objects and played a role in guiding other parts of the network to improve the explainable capability of the network without affecting the discrimination power or compromising the classification accuracy. Extensive experiments based on two public datasets show that the network is highly effective as indicated by high classification accuracy and explainable ability.",10.1109/TGRS.2022.3162195,2022,,AN EXPLAINABLE ATTENTION NETWORK FOR FINE-GRAINED SHIP CLASSIFICATION USING REMOTE-SENSING IMAGES,
210,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Over the past few years making use of deep networks, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs), classifying hyperspectral images has progressed significantly and gained increasing attention. In spite of being successful, these networks need an adequate supply of labeled training instances for supervised learning, which, however, is quite costly to collect. On the other hand, unlabeled data can be accessed in almost arbitrary amounts. Hence it would be conceptually of great interest to explore networks that are able to exploit labeled and unlabeled data simultaneously for hyperspectral image classification. In this article, we propose a novel graph-based semisupervised network called nonlocal graph convolutional network (nonlocal GCN). Unlike existing CNNs and RNNs that receive pixels or patches of a hyperspectral image as inputs, this network takes the whole image (including both labeled and unlabeled data) in. More specifically, a nonlocal graph is first calculated. Given this graph representation, a couple of graph convolutional layers are used to extract features. Finally, the semisupervised learning of the network is done by using a cross-entropy error over all labeled instances. Note that the nonlocal GCN is end-to-end trainable. We demonstrate in extensive experiments that compared with state-of-the-art spectral classifiers and spectral-spatial classification networks, the nonlocal GCN is able to offer competitive results and high-quality classification maps (with fine boundaries and without noisy scattered points of misclassification).",10.1109/TGRS.2020.2973363,2020,,NONLOCAL GRAPH CONVOLUTIONAL NETWORKS FOR HYPERSPECTRAL IMAGE CLASSIFICATION,
211,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Convolutional long short-term memory (ConvLSTM) has received much attention for hyperspectral image (HSI) classification due to its ability of modeling long-range correlations, which, however, is vulnerable to too many parameters and insufficient training, limiting its classification accuracy, especially for small samples. Different from it, traditional hand-crafted methods extract the features with basic attributes of HSIs, which can provide the lack of details and interpretability of deep semantic features. However, existing methods fail to incorporate their complementarity for HSI classification. As such, a Pseudo complex-valued (CV) Deformable ConvLSTM Neural Network with mutual Attention learning (APDCLNN) is proposed, providing a new way to realize the collaborative learning of hand-crafted and deep features for HSI classification. First, a 2-D pseudo CV deformable ConvLSTM (PDConvLSTM2D) cell is designed using deformable convolution and complex operations, with which a spatial–spectral PDConvLSTM2D neural network (SSPDCL2DNN) is built to extract scale- and spectral-enhanced deep spatial–spectral features. Then, 3-D Gabor filter is used to extract hand-crafted features, and a mutual attention-based multimodality feature learning and fusion (MAMLF) module is designed to integrate them into deep features for training and optimization of SSPDCL2DNN. Finally, an attention loss subnetwork is designed to refine the classification results. As we know, this is the first attempt to apply the idea of mutual attention learning to fuse hand-crafted and deep features for HSI classification. Extensive experiments on three widely used HSI datasets show the advantages of our model over other deep methods in terms of both quantitative and visual quality.",10.1109/TGRS.2022.3188791,2022,,PSEUDO COMPLEX-VALUED DEFORMABLE CONVLSTM NEURAL NETWORK WITH MUTUAL ATTENTION LEARNING FOR HYPERSPECTRAL IMAGE CLASSIFICATION,
212,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"This article investigates the presence of a new interferometric signal in multilooked synthetic aperture radar (SAR) interferograms that cannot be attributed to the atmospheric or Earth-surface topography changes. The observed signal is short-lived and decays with the temporal baseline; however, it is distinct from the stochastic noise attributed to temporal decorrelation. The presence of such a fading signal introduces a systematic phase component, particularly in short temporal baseline interferograms. If unattended, it biases the estimation of Earth surface deformation from SAR time series. Here, the contribution of the mentioned phase component is quantitatively assessed. The biasing impact on the deformation-signal retrieval is further evaluated. A quality measure is introduced to allow the prediction of the associated error with the fading signals. Moreover, a practical solution for the mitigation of this physical signal is discussed; special attention is paid to the efficient processing of Big Data from modern SAR missions such as Sentinel-1 and NISAR. Adopting the proposed solution, the deformation bias is shown to decrease significantly. Based on these analyses, we put forward our recommendations for efficient and accurate deformation-signal retrieval from large stacks of multilooked interferograms.",10.1109/TGRS.2020.3003421,2021,,STUDY OF SYSTEMATIC BIAS IN MEASURING SURFACE DEFORMATION WITH SAR INTERFEROMETRY,
213,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Two main problems must be solved in the geometric processing of satellite data: geometric registration and resampling. When the data must be geometrically registered over a reference map, and particularly when the output pixel size is not the same as the original pixel size, the quality of the resampling can determine the quality of the output, not only in the visual appearance of the image, but also in the numerically interpolated values when used in multitemporal or multisensor studies. The ""optimum"" interpolation algorithm for AVHRR data is defined over a 6/spl times/6 window in order to: consider overlapping effects among adjacent pixels. The response for each new pixel R(x, y) is determined as a linear combination of the response R/sub i/(x/sub i/y/sub i/) of the surrounding pixels in the window (i=1,36). The weighting coefficients /spl mu//sub i/ are calculated from the ground projection of the effective spatial response function for each AVHRR pixel, taking into account the particular viewing angle and geometry of the pixels on the ground. This method is intended to give an optimal interpolation of AVHRR scenes along all the scanline, in order to compensate for off-nadir radiometric alterations associated to the varying spatial resolution and the blurring introduced by the pixel overlaps. The optimum method, as mathematically defined, is highly expensive in CPU time. Then, a big effort is necessary to implement the algorithms so that they could be operationally applied. Two approaches are considered: a general numerical method and a pseudo-analytical approximation. A Landsat TM image corresponding to the same date of the AVHRR image is used to test the quality of the radiometric interpolation procedure.<>",10.1109/36.285196,1994,,AN OPTIMUM INTERPOLATION METHOD APPLIED TO THE RESAMPLING OF NOAA AVHRR DATA,
214,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"A novel framework is proposed for mitigating azimuth ambiguities in spaceborne stripmap synthetic aperture radar (SAR) images. The azimuth ambiguities in SAR images are localized by using a local mean SAR image, SAR system parameters, and a defined metric derived from azimuth antenna pattern. The defined metric helps isolate targets lying at locations of ambiguities. The mechanism for restoration of ambiguity regions is selected on the basis of size of ambiguity regions. A compressive imaging technique is employed to restore isolated ambiguity regions (smaller regions of interconnected pixels), whereas clustered regions (relatively bigger regions of interconnected pixels) are filled by using exemplar-based inpainting. The simulation results on a real TerraSAR-X data set demonstrated that the proposed scheme can effectively remove azimuth ambiguities and enhance SAR image quality.",10.1109/TGRS.2013.2279109,2014,,MITIGATION OF AZIMUTH AMBIGUITIES IN SPACEBORNE STRIPMAP SAR IMAGES USING SELECTIVE RESTORATION,
215,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"High-quality and large-scale image composites are increasingly important for a variety of applications. Yet a number of challenges still exist in the generation of composites with certain desirable qualities such as maintaining the spectral relationship between bands, reduced spatial noise, and consistency across scene boundaries so that large mosaics can be generated. We present a new method for generating pixel-based composite mosaics that achieves these goals. The method, based on a high-dimensional statistic called the `geometric median,' effectively trades a temporal stack of poor quality observations for a single high-quality pixel composite with reduced spatial noise. The method requires no parameters or expert-defined rules. We quantitatively assess its strengths by benchmarking it against two other pixel-based compositing approaches over Tasmania, which is one of the most challenging locations in Australia for obtaining cloud-free imagery.",10.1109/TGRS.2017.2723896,2017,,HIGH-DIMENSIONAL PIXEL COMPOSITES FROM EARTH OBSERVATION TIME SERIES,
216,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Tradeoffs between the spatial and temporal resolutions of current satellite instruments limit our ability to conduct high-quality and continuous monitoring of the earth’s surface dynamics. Spatiotemporal image fusion has become increasingly necessary to obtain remote sensing images with high spatiotemporal resolution. However, current learning-based methods concentrate on predicting images only from spatial similarity and neglect spectral correlations of remote sensing images, leading to significant spectral information loss. In this article, we develop a novel nonlocal tensor sparse representation-based semicoupled dictionary learning approach (SCDNTSR) for spatiotemporal fusion. In the SCDNTSR method, the spectral correlation and the spatial similarity of the nonlocal similar cubes are simultaneously exploited through the tensor–tensor product-based tensor sparse representation. Furthermore, the semicoupled mapping prior knowledge of sparse coefficients across the high- and low-spatial resolution (HSR\LSR) image spaces is exploited with the coupled dictionary to constrain the similarity of sparse coefficients to improve the prediction performance. In addition, to capture additional prior spatial information, the SCDNTSR provides a new method to determine the degradation relationship between the target HSR and LSR difference images with the help of the known HSR and LSR difference images. The proposed SCDNTSR method was tested on real datasets at both the Coleambally Irrigation Area study site and the Lower Gwydir Catchment study site. Results show that the proposed method outperforms five state-of-the-art methods, especially in maintaining the spectral information, proving the feasibility of integrating the degradation relationship, spatio-spectral-nonlocal correlation, and semicoupled mapping priors of the multisource data into the proposed model.",10.1109/TGRS.2021.3091157,2022,,SPATIOTEMPORAL REFLECTANCE FUSION VIA TENSOR SPARSE REPRESENTATION,
217,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Weather radar echo extrapolation, which predicts future echoes based on historical observations, is one of the complicated spatial–temporal sequence prediction tasks and plays a prominent role in severe convection and precipitation nowcasting. However, existing extrapolation methods mainly focus on a defective echo-motion extrapolation paradigm based on finite observational dynamics, neglecting that the actual echo sequence has a more complicated evolution process that contains both nonlinear motions and the lifecycle from initiation to decay, resulting in poor prediction precision and limited application ability. To complement this paradigm, we propose to incorporate a novel long-term evolution regularity memory (LERM) module into the network, which can memorize long-term echo-evolution regularities during training and be recalled for guiding extrapolation. Moreover, to resolve the blurry prediction problem and improve forecast accuracy, we also adopt a coarse–fine hierarchical extrapolation strategy and compositive loss function. We separate the extrapolation task into coarse and fine two levels which can reduce the downsampling loss and retain echo fine details. Except for the average reconstruction loss, we additionally employ adversarial loss and perceptual similarity loss to further improve the visual quality. Experimental results from two real radar echo datasets demonstrate the effectiveness of our methodology and show that it can accurately extrapolate the echo evolution while ensuring the echo details are realistic enough, even for the long term. Our method can further be improved in the future by integrating multimodal radar variables or introducing certain domain prior knowledge of physical mechanisms. It can also be applied to other spatial–temporal sequence prediction tasks, such as the prediction of satellite cloud images and wind field figures.",10.1109/TGRS.2022.3198851,2022,,REMNET: RECURRENT EVOLUTION MEMORY-AWARE NETWORK FOR ACCURATE LONG-TERM WEATHER RADAR ECHO EXTRAPOLATION,
218,17360,IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING,journal,15580644,"2,141",Q1,254,823,1908,30841,13865,1908,"6,87","37,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1980-2020,Earth and Planetary Sciences (miscellaneous) (Q1); Electrical and Electronic Engineering (Q1),"48,898",5.600,0.04379,"Aerial photography obtained by unmanned aerial vehicles (UAVs) is a rising market for their civil application. Small UAVs are believed to close gaps in niche markets, such as acquiring airborne image data for remote sensing purposes. Small UAVs can fly at low altitudes, in dangerous environments, and over long periods of time. However, their small lightweight construction leads to new problems, such as higher agility and more susceptibility to turbulence, which has a big impact on the quality of the data and their suitability for aerial photography. This paper investigates the use of fish-eye lenses to overcome field-of-view (FOV) issues for highly agile UAV platforms susceptible to turbulence. The fish-eye lens has the benefit of a large observation area (large FOV) and does not add additional weight to the aircraft, such as traditional mechanical stabilizing systems. We present the implementation of a fish-eye lens for aerial photography and mapping purposes, with potential use in remote sensing applications. We describe a detailed investigation from the fish-eye lens distortion to the registering of the images. Results of the process are presented using low-quality sensors typically found on small UAVs. The system was flown on a midsize platform (a more stable Cessna aircraft) and also on ARCAA's small (<10 kg) UAV platform. The effectiveness of the approach is compared for the two sized platforms.",10.1109/TGRS.2008.2009763,2009,,INVESTIGATION OF FISH-EYE LENSES FOR SMALL-UAV AERIAL PHOTOGRAPHY,
219,23916,ENVIRONMENTAL POLLUTION,journal,02697491,"2,136",Q1,227,2109,4204,129684,35383,4169,"8,04","61,49",United Kingdom,Western Europe,Elsevier Ltd.,"1970-1980, 1986-2020","Health, Toxicology and Mutagenesis (Q1); Medicine (miscellaneous) (Q1); Pollution (Q1); Toxicology (Q1)","84,491",8.071,0.07982,"An accurate estimation of population exposure to particulate matter with an aerodynamic diameter <2.5 μm (PM2.5) is crucial to hazard assessment and epidemiology. This study integrated annual data from 1146 in-home air monitors, air quality monitoring network, public applications, and traffic smart cards to determine the pattern of PM2.5 concentrations and activities in different microenvironments (including outdoors, indoors, subways, buses, and cars). By combining massive amounts of signaling data from cell phones, this study applied a spatio-temporally weighted model to improve the estimation of PM2.5 exposure. Using Shanghai as a case study, the annual average indoor PM2.5 concentration was estimated to be 29.3 ± 27.1 μg/m3 (n = 365), with an average infiltration factor of 0.63. The spatio-temporally weighted PM2.5 exposure was estimated to be 32.1 ± 13.9 μg/m3 (n = 365), with indoor PM2.5 contributing the most (85.1%), followed by outdoor (7.6%), bus (3.7%), subway (3.1%), and car (0.5%). However, considering that outdoor PM2.5 makes a significant contribution to indoor PM2.5, outdoor PM2.5 was responsible for most of the exposure in Shanghai. A heatmap of PM2.5 exposure indicated that the inner-city exposure index was significantly higher than that of the outskirts city, which demonstrated that the importance of spatial differences in population exposure estimation.",https://doi.org/10.1016/j.envpol.2019.07.034,2019,YuJie Ben and FuJun Ma and Hao Wang and Muhammad Azher Hassan and Romanenko Yevheniia and WenHong Fan and Yubiao Li and ZhaoMin Dong,A SPATIO-TEMPORALLY WEIGHTED HYBRID MODEL TO IMPROVE ESTIMATES OF PERSONAL PM2.5 EXPOSURE: INCORPORATING BIG DATA FROM MULTIPLE DATA SOURCES,article
220,23916,ENVIRONMENTAL POLLUTION,journal,02697491,"2,136",Q1,227,2109,4204,129684,35383,4169,"8,04","61,49",United Kingdom,Western Europe,Elsevier Ltd.,"1970-1980, 1986-2020","Health, Toxicology and Mutagenesis (Q1); Medicine (miscellaneous) (Q1); Pollution (Q1); Toxicology (Q1)","84,491",8.071,0.07982,"Cooking emission inventories always have poor spatial resolutions when applying with traditional methods, making their impacts on ambient air and human health remain obscure. In this study, we created a systematic dataset of cooking emission factors (CEFs) and applied it with a new data source, cooking-related point of interest (POI) data, to build up highly spatial resolved cooking emission inventories from the city scale. Averaged CEFs of six particulate and gaseous species (PM, OC, EC, NMHC, OVOCs, VOCs) were 5.92 ± 6.28, 4.10 ± 5.50, 0.05 ± 0.05, 22.54 ± 20.48, 1.56 ± 1.44, and 7.94 ± 6.27 g/h normalized in every cook stove, respectively. A three-field CEF index containing activity and emission factor species was created to identify and further build a connection with cooking-related POI data. A total of 95,034 cooking point sources were extracted from Beijing, as a study city. In downtown areas, four POI types were overlapped in the central part of the city and radiated into eight distinct directions from south to north. Estimated PM/VOC emissions caused by cooking activities in Beijing were 4.81/9.85 t per day. A 3D emission map showed an extremely unbalanced emission density in the Beijing region. Emission hotspots were seen in Central Business District (CBD), Sanlitun, and Wangjing in Chaoyang District and Willow and Zhongguancun in Haidian District. PM/VOC emissions could be as high as 16.6/42.0 kg/d in the searching radius of 2 km. For PM, the total emissions were 417.4, 389.0, 466.9, and 443.0 t between Q1 and Q4 2019 in Beijing, respectively. The proposed methodology is transferrable to other Chinese cities for deriving enhanced commercial cooking inventories and potentially highlighting the further importance of cooking emissions on air quality and human health.",https://doi.org/10.1016/j.envpol.2022.120320,2022,Pengchuan Lin and Jian Gao and Yisheng Xu and James J. Schauer and Jiaqi Wang and Wanqing He and Lei Nie,ENHANCED COMMERCIAL COOKING INVENTORIES FROM THE CITY SCALE THROUGH NORMALIZED EMISSION FACTOR DATASET AND BIG DATA,article
221,23916,ENVIRONMENTAL POLLUTION,journal,02697491,"2,136",Q1,227,2109,4204,129684,35383,4169,"8,04","61,49",United Kingdom,Western Europe,Elsevier Ltd.,"1970-1980, 1986-2020","Health, Toxicology and Mutagenesis (Q1); Medicine (miscellaneous) (Q1); Pollution (Q1); Toxicology (Q1)","84,491",8.071,0.07982,"Due to time- and expense- consuming of conventional indoor PM2.5 (particulate matter with aerodynamic diameter of less than 2.5 μm) sampling, the sample size in previous studies was generally small, which leaded to high heterogeneity in indoor PM2.5 exposure assessment. Based on 4403 indoor air monitors in Beijing, this study evaluated indoor PM2.5 exposure from 15th March 2016 to 14th March 2017. Indoor PM2.5 concentration in Beijing was estimated to be 38.6 ± 18.4 μg/m3. Specifically, the concentration in non-heating season was 34.9 ± 15.8 μg/m3, which was 24% lower than that in heating season (46.1 ± 21.2 μg/m3). A significant correlation between indoor and ambient PM2.5 (p < 0.05) was evident with an infiltration factor of 0.21, and the ambient PM2.5 contributed approximately 52% and 42% to indoor PM2.5 for non-heating and heating seasons, respectively. Meanwhile, the mean indoor/outdoor (I/O) ratio was estimated to be 0.73 ± 0.54. Finally, the adjusted PM2.5 exposure level integrating the indoor and outdoor impact was calculated to be 46.8 ± 27.4 μg/m3, which was approximately 42% lower than estimation only relied on ambient PM2.5 concentration. This study is the first attempt to employ big data from commercial air monitors to evaluate indoor PM2.5 exposure and risk in Beijing, which may be instrumental to indoor PM2.5 pollution control.",https://doi.org/10.1016/j.envpol.2018.05.030,2018,JinXing Zuo and Wei Ji and YuJie Ben and Muhammad Azher Hassan and WenHong Fan and Liam Bates and ZhaoMin Dong,USING BIG DATA FROM AIR QUALITY MONITORS TO EVALUATE INDOOR PM2.5 EXPOSURE IN BUILDINGS: CASE STUDY IN BEIJING,article
222,23916,ENVIRONMENTAL POLLUTION,journal,02697491,"2,136",Q1,227,2109,4204,129684,35383,4169,"8,04","61,49",United Kingdom,Western Europe,Elsevier Ltd.,"1970-1980, 1986-2020","Health, Toxicology and Mutagenesis (Q1); Medicine (miscellaneous) (Q1); Pollution (Q1); Toxicology (Q1)","84,491",8.071,0.07982,"In the past few decades, extensive epidemiological studies have focused on exploring the adverse effects of PM2.5 (particulate matters with aerodynamic diameters less than 2.5 μm) on public health. However, most of them failed to consider the dynamic changes of population distribution adequately and were limited by the accuracy of PM2.5 estimations. Therefore, in this study, location-based service (LBS) data from social media and satellite-derived high-quality PM2.5 concentrations were collected to perform highly spatiotemporal exposure assessments for thirteen cities in the Beijing-Tianjin-Hebei (BTH) region, China. The city-scale exposure levels and the corresponding health outcomes were first estimated. Then the uncertainties in exposure risk assessments were quantified based on in-situ PM2.5 observations and static population data. The results showed that approximately half of the population living in the BTH region were exposed to monthly mean PM2.5 concentration greater than 80 μg/m3 in 2015, and the highest risk was observed in December. In terms of all-cause, cardiovascular, and respiratory disease, the premature deaths attributed to PM2.5 were estimated to be 138,150, 80,945, and 18,752, respectively. A comparative analysis between five different exposure models further illustrated that the dynamic population distribution and accurate PM2.5 estimations showed great influence on environmental exposure and health assessments and need be carefully considered. Otherwise, the results would be considerably over- or under-estimated.",https://doi.org/10.1016/j.envpol.2019.06.057,2019,Yimeng Song and Bo Huang and Qingqing He and Bin Chen and Jing Wei and Rashed Mahmood,DYNAMIC ASSESSMENT OF PM2.5 EXPOSURE AND HEALTH RISK USING REMOTE SENSING AND GEO-SPATIAL BIG DATA,article
223,20107,SURVEY OF OPHTHALMOLOGY,journal,00396257,"2,131",Q1,132,69,235,6991,1131,199,"4,75","101,32",United States,Northern America,Elsevier USA,"1956-1970, 1972-2020",Ophthalmology (Q1),"7,296",6.048,0.00487,"Large population-based health administrative databases, clinical registries, and data linkage systems are a rapidly expanding resource for health research. Ophthalmic research has benefited from the use of these databases in expanding the breadth of knowledge in areas such as disease surveillance, disease etiology, health services utilization, and health outcomes. Furthermore, the quantity of data available for research has increased exponentially in recent times, particularly as e-health initiatives come online in health systems across the globe. We review some big data concepts, the databases and data linkage systems used in eye research—including their advantages and limitations, the types of studies previously undertaken, and the future direction for big data in eye research.",https://doi.org/10.1016/j.survophthal.2016.01.003,2016,Antony Clark and Jonathon Q. Ng and Nigel Morlet and James B. Semmens,BIG DATA AND OPHTHALMIC RESEARCH,article
224,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"Despite great potential, high hopes and big promises, the actual impact of big data on the public sector is not always as transformative as the literature would suggest. In this paper, we ascribe this predicament to an overly strong emphasis the current literature places on technical-rational factors at the expense of political decision-making factors. We express these two different emphases as two archetypical narratives and use those to illustrate that some political decision-making factors should be taken seriously by critiquing some of the core ‘techno-optimist’ tenets from a more ‘policy-pessimist’ angle. In the conclusion we have these two narratives meet ‘eye-to-eye’, facilitating a more systematized interrogation of big data promises and shortcomings in further research, paying appropriate attention to both technical-rational and political decision-making factors. We finish by offering a realist rejoinder of these two narratives, allowing for more context-specific scrutiny and balancing both technical-rational and political decision-making concerns, resulting in more realistic expectations about using big data for policymaking in practice.",https://doi.org/10.1016/j.giq.2019.05.010,2019,Simon Vydra and Bram Klievink,TECHNO-OPTIMISM AND POLICY-PESSIMISM IN THE PUBLIC SECTOR BIG DATA DEBATE,article
225,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"It is estimated that by 2050, 70% of the population will be urban (Nations Unies, 2014). This massive urbanization has created unprecedented challenges for cities and city managers which has led many of them to look for technological solutions to address them, including the use of Big Data, which is among the most considered technological support to help improve the overall operational and service delivery of cities. It is estimated that around 7 billion connected objects will soon be implemented in cities worldwide which will produce an unprecedented and massive amount of real-time data that will have to be managed, used, and analyzed effectively. If this massive amount of data is effectively managed and used, it can provide important benefits and produce real positive impacts on the functioning of cities. Nonetheless, despite these benefits, only a few cities are able to use and exploit big data, and some studies have shown that less than 0.5% of all the available data has been explored. The objective of this study is to understand the factors that influence cities to use big data and the nature of such use. Based on a field survey involving 106 municipalities, this study investigates the antecedents of big data use by cities and shows how different sets of antecedents influence three different types of big data use by cities.",https://doi.org/10.1016/j.giq.2021.101600,2021,Hamza Ali and Ryad Titah,IS BIG DATA USED BY CITIES? UNDERSTANDING THE NATURE AND ANTECEDENTS OF BIG DATA USE BY MUNICIPALITIES,article
226,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"Smart cities are expected to improve the efficiency and effectiveness of urban management, including public services, public security, and environmental protection, and to ultimately achieve Sustainable Development Goal (SDG) 11 for making cities inclusive, safe, resilient, and sustainable. Big data have been identified as a key enabler in the development of smart cities. However, our understanding of how different data sources should be managed and integrated remains limited. By analyzing data applications in the development of a sustainable smart city, this case study identified three phases of development, each requiring a different approach to orchestrating diverse data sources. A framework identifying the phases, data-related issues, data orchestration and its interaction with other resources, focal capabilities, and development approaches is developed. This study benefits both researchers and practitioners by making theoretical contributions and by offering practical insights in the fields of smart cities and big data.",https://doi.org/10.1016/j.giq.2021.101626,2022,Dan Zhang and L.G. Pee and Shan L. Pan and Lili Cui,"BIG DATA ANALYTICS, RESOURCE ORCHESTRATION, AND DIGITAL SUSTAINABILITY: A CASE STUDY OF SMART CITY DEVELOPMENT",article
227,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"The growing Artificial Intelligence (AI) age has been flooded with several innovations in algorithmic machine learning that may bring significant impacts to industries such as healthcare, agriculture, education, manufacturing, retail etc. But challenges such as data quality, privacy and lack of a skilled workforce limit the scope of AI implementation in emerging economies, particularly in the Public Manufacturing Sector (PMS). Therefore, to enhance the body of relevant literature, this study examines the existing challenges of AI implementation in PMS of India and explores the inter-relationships among them. The study has utilized the DEMATEL method for identification of the cause-and-effect group factors. The findings reveal that poor data quality, managers' lack of understanding of cognitive technologies, data privacy, problems in integrating cognitive projects and expensive technologies are the main challenges for AI implementation in PMS of India. Moreover, a model is proposed for industrial decision-makers and managers to take appropriate decisions to develop intelligent AI enabled systems for manufacturing organizations in emerging economies.",https://doi.org/10.1016/j.giq.2021.101624,2022,Manu Sharma and Sunil Luthra and Sudhanshu Joshi and Anil Kumar,IMPLEMENTING CHALLENGES OF ARTIFICIAL INTELLIGENCE: EVIDENCE FROM PUBLIC MANUFACTURING SECTOR OF AN EMERGING ECONOMY,article
228,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"The rise of Big, Open and Linked Data (BOLD) enables Big Data Algorithmic Systems (BDAS) which are often based on machine learning, neural networks and other forms of Artificial Intelligence (AI). As such systems are increasingly requested to make decisions that are consequential to individuals, communities and society at large, their failures cannot be tolerated, and they are subject to stringent regulatory and ethical requirements. However, they all rely on data which is not only big, open and linked but varied, dynamic and streamed at high speeds in real-time. Managing such data is challenging. To overcome such challenges and utilize opportunities for BDAS, organizations are increasingly developing advanced data governance capabilities. This paper reviews challenges and approaches to data governance for such systems, and proposes a framework for data governance for trustworthy BDAS. The framework promotes the stewardship of data, processes and algorithms, the controlled opening of data and algorithms to enable external scrutiny, trusted information sharing within and between organizations, risk-based governance, system-level controls, and data control through shared ownership and self-sovereign identities. The framework is based on 13 design principles and is proposed incrementally, for a single organization and multiple networked organizations.",https://doi.org/10.1016/j.giq.2020.101493,2020,Marijn Janssen and Paul Brous and Elsa Estevez and Luis S. Barbosa and Tomasz Janowski,DATA GOVERNANCE: ORGANIZING DATA FOR TRUSTWORTHY ARTIFICIAL INTELLIGENCE,article
229,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"This paper aims to contribute to a better understanding of the literature on open data in three ways. The first is to develop a descriptive analysis of journals and authors to identify the knowledge areas in which open data are applied. The second is to analyse the conceptual structure of the field using a bibliometric technique. The co-word analysis enabled us to create a map of the main themes that have been studied, identifying their importance and relevance. These themes were analysed and grouped. The third is to propose future research trends. According to our results, the main knowledge areas are Engineering, Health, Public Administration, Management and Education. The main themes are big data, open-linked data and data reuse. Finally, several research questions are proposed according to knowledge area and theme.",https://doi.org/10.1016/j.giq.2018.10.008,2019,Diego Corrales-Garay and Marta Ortiz-de-Urbina-Criado and Eva-María Mora-Valentín,"KNOWLEDGE AREAS, THEMES AND FUTURE RESEARCH ON OPEN DATA: A CO-WORD ANALYSIS",article
230,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"Dashboards visualize a consolidated set data for a certain purpose which enables users to see what is happening and to initiate actions. Dashboards can be used by governments to support their decision-making and policy processes or to communicate and interact with the public. The objective of this paper is to understand and to support the design of dashboards for creating transparency and accountability. Two smart city cases are investigated showing that dashboards can improve transparency and accountability, however, realizing these benefits was cumbersome and encountered various risks and challenges. Challenges include insufficient data quality, lack of understanding of data, poor analysis, wrong interpretation, confusion about the outcomes, and imposing a pre-defined view. These challenges can easily result in misconceptions, wrong decision-making, creating a blurred picture resulting in less transparency and accountability, and ultimately in even less trust in the government. Principles guiding the design of dashboards are presented. Dashboards need to be complemented by mechanisms supporting citizens' engagement, data interpretation, governance and institutional arrangements.",https://doi.org/10.1016/j.giq.2018.01.006,2020,Ricardo Matheus and Marijn Janssen and Devender Maheshwari,DATA SCIENCE EMPOWERING THE PUBLIC: DATA-DRIVEN DASHBOARDS FOR TRANSPARENT AND ACCOUNTABLE DECISION-MAKING IN SMART CITIES,article
231,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"A theoretical framework for big data analytics-enabled customer agility and responsiveness was developed from extant IS research. In on-demand service environments, customer agility involves dynamic capabilities in sensing and responding to citizens. Using this framework, a case study examined a large city government's 311 on-demand services which had leveraged big data analytics. While we found the localized big data analytics use by some of the 22 departments for enhanced customer agility and on-demand 311 services, city-wide systemic change in on-demand service delivery through big data analytics use was not evident. From the case study we identified key institutional mechanisms for linking customer agility to public value creation through 311 services. We posit how systemic use of big data analytics embedded into critical processes enables the government to co-create public values with citizens through 311 on-demand services, indicating the importance of creating a culture of analytics driven by strong political leadership.",https://doi.org/10.1016/j.giq.2017.11.002,2018,Akemi Takeoka Chatfield and Christopher G. Reddick,CUSTOMER AGILITY AND RESPONSIVENESS THROUGH BIG DATA ANALYTICS FOR PUBLIC VALUE CREATION: A CASE STUDY OF HOUSTON 311 ON-DEMAND SERVICES,article
232,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"Big data promises to transform public decision-making for the better by making it more responsive to actual needs and policy effects. However, much recent work on big data in public decision-making assumes a rational view of decision-making, which has been much criticized in the public administration debate. In this paper, we apply this view, and a more political one, to the context of big data and offer a qualitative study. We question the impact of big data on decision-making, realizing that big data – including its new methods and functions – must inevitably encounter existing political and managerial institutions. By studying two illustrative cases of big data use processes, we explore how these two worlds meet. Specifically, we look at the interaction between data analysts and decision makers. In this we distinguish between a rational view and a political view, and between an information logic and a decision logic. We find that big data provides ample opportunities for both analysts and decision makers to do a better job, but this doesn't necessarily imply better decision-making, because big data also provides opportunities for actors to pursue their own interests. Big data enables both data analysts and decision makers to act as autonomous agents rather than as links in a functional chain. Therefore, big data's impact cannot be interpreted only in terms of its functional promise; it must also be acknowledged as a phenomenon set to impact our policymaking institutions, including their legitimacy.",https://doi.org/10.1016/j.giq.2018.10.011,2019,H.G. {van der Voort} and A.J. Klievink and M. Arnaboldi and A.J. Meijer,RATIONALITY AND POLITICS OF ALGORITHMS. WILL THE PROMISE OF BIG DATA SURVIVE THE DYNAMICS OF PUBLIC DECISION MAKING?,article
233,14735,GOVERNMENT INFORMATION QUARTERLY,journal,0740624X,"2,121",Q1,103,76,205,5894,1946,193,"8,39","77,55",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,E-learning (Q1); Law (Q1); Library and Information Sciences (Q1); Sociology and Political Science (Q1),"5,379",7.279,0.00502,"Automated decision-making (ADM) systems may affect multiple aspects of our lives. In particular, they can result in systematic discrimination of specific population groups, in violation of the EU Charter of Fundamental Rights. One of the potential causes of discriminative behavior, i.e., unfairness, lies in the quality of the data used to train such ADM systems. Using a data quality measurement approach combined with risk management, both defined in ISO standards, we focus on balance characteristics and we aim to understand how balance indexes (Gini, Simpson, Shannon, Imbalance Ratio) identify discrimination risk in six large datasets containing the classification output of ADM systems. The best result is achieved using the Imbalance Ratio index. Gini and Shannon indexes tend to assume high values and for this reason they have modest results in both aspects: further experimentation with different thresholds is needed. In terms of policies, the risk-based approach is a core element of the EU approach to regulate algorithmic systems: in this context, balance measures can be easily assumed as risk indicators of propagation – or even amplification – of bias in the input data of ADM systems.",https://doi.org/10.1016/j.giq.2021.101619,2021,Antonio Vetrò and Marco Torchiano and Mariachiara Mecati,A DATA QUALITY APPROACH TO THE IDENTIFICATION OF DISCRIMINATION RISK IN AUTOMATED DECISION MAKING SYSTEMS,article
234,17191,INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS,journal,03603016,"2,117",Q1,248,584,1807,14085,6588,1167,"3,48","24,12",United States,Northern America,Elsevier Inc.,1975-2020,"Cancer Research (Q1); Oncology (Q1); Radiation (Q1); Radiology, Nuclear Medicine and Imaging (Q1)","50,525",7.038,0.03941,,https://doi.org/10.1016/j.ijrobp.2020.07.224,2020,A.L. Caissie and M.L. Mierzwa and C.D. Fuller and M. Rajaraman and A. Lin and A.M. McDonald and R.A. Popple and Y. Xiao and L. {van Dijk} and P. Balter and H. Fong and H. Ping and M. Kovoor and J. Lee and A. Rao and M.K. Martel and R.F. Thompson and B. Merz and J. Yao and C. Mayo,RADIOTHERAPY (RT) PATTERNS OF PRACTICE VARIABILITY IDENTIFIED AS A CHALLENGE TO REAL-WORLD BIG DATA: RECOMMENDATIONS FROM THE LEARNING FROM ANALYSIS OF MULTICENTER BIG DATA AGGREGATION (LAMBDA) CONSORTIUM,article
235,19419,COMPUTERS IN HUMAN BEHAVIOR,journal,07475632,"2,108",Q1,178,385,1597,26867,14501,1573,"7,83","69,78",United Kingdom,Western Europe,Elsevier Ltd.,1985-2021,Arts and Humanities (miscellaneous) (Q1); Human-Computer Interaction (Q1); Psychology (miscellaneous) (Q1),"45,035",6.829,0.05973,"Despite the wide usage of big data in tourism and the hospitality sector, little research has been done to understand the role of organizations’ capability of managing big data in value creation. This study bridges this gap by investigating how big data management capabilities lead to service innovation and high online quality ratings. Instead of treating big data management as a whole, we access big data management capabilities at the strategic and operational level. Using a sample of 202 hotels in Pakistan, we collected the primary data for big data capabilities, knowledge creation and service innovation; the secondary data about quality rating were collected from Booking.com. Structural equation modelling through SmartPLS was used for data analysis. The results indicated that big data management capabilities lead to high online quality ratings through the mediation of knowledge creation and service innovation. We contribute to the current literature by empirically testing how strategic level big data capabilities enable the firm to add value in innovativeness and positive online quality ratings through acquiring, contextualizing, experimenting and applying big data.",https://doi.org/10.1016/j.chb.2021.106777,2021,Saqib Shamim and Yumei Yang and Najam Ul Zia and Mahmood Hussain Shah,BIG DATA MANAGEMENT CAPABILITIES IN THE HOSPITALITY SECTOR: SERVICE INNOVATION AND CUSTOMER GENERATED ONLINE QUALITY RATINGS,article
236,19419,COMPUTERS IN HUMAN BEHAVIOR,journal,07475632,"2,108",Q1,178,385,1597,26867,14501,1573,"7,83","69,78",United Kingdom,Western Europe,Elsevier Ltd.,1985-2021,Arts and Humanities (miscellaneous) (Q1); Human-Computer Interaction (Q1); Psychology (miscellaneous) (Q1),"45,035",6.829,0.05973,"Big data analytics has recently emerged as an important research area due to the popularity of the Internet and the advent of the Web 2.0 technologies. Moreover, the proliferation and adoption of social media applications have provided extensive opportunities and challenges for researchers and practitioners. The massive amount of data generated by users using social media platforms is the result of the integration of their background details and daily activities. This enormous volume of generated data known as “big data” has been intensively researched recently. A review of the recent works is presented to obtain a broad perspective of the social media big data analytics research topic. We classify the literature based on important aspects. This study also compares possible big data analytics techniques and their quality attributes. Moreover, we provide a discussion on the applications of social media big data analytics by highlighting the state-of-the-art techniques, methods, and the quality attributes of various studies. Open research challenges in big data analytics are described as well.",https://doi.org/10.1016/j.chb.2018.08.039,2019,Norjihan Abdul Ghani and Suraya Hamid and Ibrahim Abaker {Targio Hashem} and Ejaz Ahmed,SOCIAL MEDIA BIG DATA ANALYTICS: A SURVEY,article
237,19419,COMPUTERS IN HUMAN BEHAVIOR,journal,07475632,"2,108",Q1,178,385,1597,26867,14501,1573,"7,83","69,78",United Kingdom,Western Europe,Elsevier Ltd.,1985-2021,Arts and Humanities (miscellaneous) (Q1); Human-Computer Interaction (Q1); Psychology (miscellaneous) (Q1),"45,035",6.829,0.05973,"This article provides an overview of extant literature addressing consumer interaction with cutting-edge technologies. Six focal cutting-edge technologies are identified: artificial intelligence, augmented reality, virtual reality, wearable technology, robotics and big data analytics. Our analysis shows research on consumer interaction with cutting-edge technologies is at a nascent stage, and there are several gaps requiring attention. To further advance knowledge, our article offers avenues for future interdisciplinary research addressing implications of consumer interaction with cutting-edge technologies. More specifically, we propose six main areas for future research namely: rethinking consumer behaviour models, identifying behavioural differences among different generations of consumers, understanding how consumers interact with automated services, ethics, privacy and the blackbox, consumer security concerns and consumer interaction with new-age technologies during and after a major global crisis such as the COVID-19 pandemic.",https://doi.org/10.1016/j.chb.2021.106761,2021,Nisreen Ameen and Sameer Hosany and Ali Tarhini,CONSUMER INTERACTION WITH CUTTING-EDGE TECHNOLOGIES: IMPLICATIONS FOR FUTURE RESEARCH,article
238,19419,COMPUTERS IN HUMAN BEHAVIOR,journal,07475632,"2,108",Q1,178,385,1597,26867,14501,1573,"7,83","69,78",United Kingdom,Western Europe,Elsevier Ltd.,1985-2021,Arts and Humanities (miscellaneous) (Q1); Human-Computer Interaction (Q1); Psychology (miscellaneous) (Q1),"45,035",6.829,0.05973,"The scale and complexity of big data quickly exceed the reach of direct human comprehension and increasingly require machine assistance to semantically analyze, organize, and interpret vast and diverse sources of big data in order to unlock its strategic value. Due to its volume, velocity, variety, and veracity, big data integration challenges overwhelm traditional integration approaches leaving many integration possibilities out of reach. Unlocking the value of big data requires innovative technology. Organizations must have the innovativeness and data capability to adopt the technology and harness its potential value. The Semantic Web (SW) technology has demonstrated its potential for integrating big data and has become important technology for tackling big data. Despite its importance to manage big data, little research has examined the determinants affecting SW adoption. Drawing upon the technology–organization–environment framework as a theory base, this study develops a research model explaining the factors affecting the adoption of SW technology from IT professionals' perspective, specifically in the context of corporate computing enterprises. We validate the proposed model using a set of empirical data collected from IT professionals including IT managers, system architects, software developers, and web developers. The findings suggest that perceived usefulness, perceived ease of use, organization's innovativeness, organization's data capability, and applicability to data management are important drivers of SW adoption. This study provides new insights on theories of organizational IT adoption from IT professionals' perspectives tailored to the context of SW technology.",https://doi.org/10.1016/j.chb.2018.04.014,2018,Dan J. Kim and John Hebeler and Victoria Yoon and Fred Davis,"EXPLORING DETERMINANTS OF SEMANTIC WEB TECHNOLOGY ADOPTION FROM IT PROFESSIONALS' PERSPECTIVE: INDUSTRY COMPETITION, ORGANIZATION INNOVATIVENESS, AND DATA MANAGEMENT CAPABILITY",article
239,27467,GYNECOLOGIC ONCOLOGY,journal,00908258,"2,105",Q1,162,480,1150,15477,5359,1087,"4,41","32,24",United States,Northern America,Academic Press Inc.,1972-2020,Obstetrics and Gynecology (Q1); Oncology (Q1),"29,012",5.482,0.02767,"Oncology is undergoing a data-driven metamorphosis. Armed with new and ever more efficient molecular and information technologies, we have entered an era where data is helping us spearhead the fight against cancer. This technology driven data explosion, often referred to as “big data”, is not only expediting biomedical discovery, but it is also rapidly transforming the practice of oncology into an information science. This evolution is critical, as results to-date have revealed the immense complexity and genetic heterogeneity of patients and their tumors, a sobering reminder of the challenge facing every patient and their oncologist. This can only be addressed through development of clinico-molecular data analytics that provide a deeper understanding of the mechanisms controlling the biological and clinical response to available therapeutic options. Beyond the exciting implications for improved patient care, such advancements in predictive and evidence-based analytics stand to profoundly affect the processes of cancer drug discovery and associated clinical trials.",https://doi.org/10.1016/j.ygyno.2016.02.022,2016,Guillaume Taglang and David B. Jackson,USE OF “BIG DATA” IN DRUG DISCOVERY AND CLINICAL TRIALS,article
240,29403,ENERGY POLICY,journal,03014215,"2,093",Q1,217,679,2165,40582,14111,2135,"6,29","59,77",United Kingdom,Western Europe,Elsevier BV,1973-2020,"Energy (miscellaneous) (Q1); Management, Monitoring, Policy and Law (Q1)","60,369",6.142,0.04319,"The upstream oil and gas industry has been contending with massive data sets and monolithic files for many years, but “Big Data” is a relatively new concept that has the potential to significantly re-shape the industry. Despite the impressive amount of value that is being realized by Big Data technologies in other parts of the marketplace, however, much of the data collected within the oil and gas sector tends to be discarded, ignored, or analyzed in a very cursory way. This viewpoint examines existing data management practices in the upstream oil and gas industry, and compares them to practices and philosophies that have emerged in organizations that are leading the way in Big Data. The comparison shows that, in companies that are widely considered to be leaders in Big Data analytics, data is regarded as a valuable asset—but this is usually not true within the oil and gas industry insofar as data is frequently regarded there as descriptive information about a physical asset rather than something that is valuable in and of itself. The paper then discusses how the industry could potentially extract more value from data, and concludes with a series of policy-related questions to this end.",https://doi.org/10.1016/j.enpol.2015.02.020,2015,Robert K. Perrons and Jesse W. Jensen,DATA AS AN ASSET: WHAT THE OIL AND GAS SECTOR CAN LEARN FROM OTHER INDUSTRIES ABOUT “BIG DATA”,article
241,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"In the context of next-generation radio telescopes, like the Square Kilometre Array (SKA), the efficient processing of large-scale data sets is extremely important. Convex optimization tasks under the compressive sensing framework have recently emerged and provide both enhanced image reconstruction quality and scalability to increasingly larger data sets. We focus herein mainly on scalability and propose two new convex optimization algorithmic structures able to solve the convex optimization tasks arising in radio-interferometric imaging. They rely on proximal splitting and forward-backward iterations and can be seen, by analogy, with the clean major-minor cycle, as running sophisticated clean-like iterations in parallel in multiple data, prior, and image spaces. Both methods support any convex regularization function, in particular, the well-studied ℓ1 priors promoting image sparsity in an adequate domain. Tailored for big-data, they employ parallel and distributed computations to achieve scalability, in terms of memory and computational requirements. One of them also exploits randomization, over data blocks at each iteration, offering further flexibility. We present simulation results showing the feasibility of the proposed methods as well as their advantages compared to state-of-the-art algorithmic solvers. Our matlab code is available online on GitHub.",10.1093/mnras/stw1859,2016,,SCALABLE SPLITTING ALGORITHMS FOR BIG-DATA INTERFEROMETRIC IMAGING IN THE SKA ERA,
242,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"In this paper, we introduce the results of the statistical analysis of atmospheric characteristics at the site of the Big Telescope Alt-azimuthal (BTA) of the Special Astrophysical Observatory (SAO) of the Russian Academy of Science (RAS). The BTA is the largest optical telescope in Eurasia and is located near Mt Pastukhova in the northern part of the Caucasus Mountains, at an altitude of 2070 m above sea level. The atmosphere of the Earth is a major challenge for observing and it limits the quality of astronomical images obtained by ground-based telescopes. The study of the atmosphere above astronomical observatories is important for the planning of observing time, for the optimization of instrument performance and for the development of adaptive optics systems. We discuss the results of a study of the meteorological conditions at the BTA site: total cloud cover, wind speed at the pressure level of 200 hPa, vertical motions, vertical profiles of the wind speed employing data from the ERA-Interim and National Centers for Environmental Prediction/National Center for Atmospheric Research (NCEP/NCAR) re-analysis data bases.",10.1093/mnras/staa156,2020,,ATMOSPHERIC PARAMETERS AT THE 6-M BIG TELESCOPE ALT-AZIMUTHAL SITE,
243,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"We present ProFit, a new code for Bayesian two-dimensional photometric galaxy profile modelling. ProFit consists of a low-level c++ library (libprofit), accessible via a command-line interface and documented API, along with high-level r (ProFit) and python (PyProFit) interfaces (available at github.com/ICRAR/libprofit, github.com/ICRAR/ProFit, and github.com/ICRAR/pyprofit, respectively). r ProFit is also available pre-built from cran; however, this version will be slightly behind the latest GitHub version. libprofit offers fast and accurate two-dimensional integration for a useful number of profiles, including Sérsic, Core-Sérsic, broken-exponential, Ferrer, Moffat, empirical King, point-source, and sky, with a simple mechanism for adding new profiles. We show detailed comparisons between libprofit and galfit. libprofit is both faster and more accurate than galfit at integrating the ubiquitous Sérsic profile for the most common values of the Sérsic index n (0.5 < n < 8). The high-level fitting code ProFit is tested on a sample of galaxies with both SDSS and deeper KiDS imaging. We find good agreement in the fit parameters, with larger scatter in best-fitting parameters from fitting images from different sources (SDSS versus KiDS) than from using different codes (ProFit versus galfit). A large suite of Monte Carlo-simulated images are used to assess prospects for automated bulge-disc decomposition with ProFit on SDSS, KiDS, and future LSST imaging. We find that the biggest increases in fit quality come from moving from SDSS- to KiDS-quality data, with less significant gains moving from KiDS to LSST.",10.1093/mnras/stw3039,2016,,PROFIT: BAYESIAN PROFILE FITTING OF GALAXY IMAGES,
244,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"We have performed a detailed analysis of the Czernik 3 (Cz3) open cluster by using deep near-infrared photometry taken with TIRCAM2 on the 3.6 m Devasthal optical telescope along with the recently available high-quality proper motion data from the Gaia DR2 and deep photometric data from Pan-STARRS1. The cluster has a highly elongated morphology with fractal distribution of stars. The core and cluster radii of the cluster are estimated as 0.5 and 1.2 pc, respectively. We have identified 45 stars as cluster members using the Gaia proper motion data. The distance and age of the cluster are found to be 3.5 ± 0.9 kpc and $0.9^{+0.3}_{-0.1}$ Gyr, respectively. The slope of the mass function `Γ′ in the cluster region, in the mass range ∼0.95 <M/M⊙ < 2.2, is found to be −1.01 ± 0.43. The cluster shows the signatures of mass segregation and is dynamically relaxed (dynamical age = 10 Myr). This along with its small size, big tidal radius, low density/large separation of stars, and elongated and distorted morphology indicates that the Cz3 is a loosely bound disintegrating cluster under the influence of external tidal interactions.",10.1093/mnras/staa2412,2020,,THE DISINTEGRATING OLD OPEN CLUSTER CZERNIK 3,
245,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"We create broad-band spectral energy distributions (SEDs) of 761 type 1 active galactic nuclei (AGN). The Scott et al. sample, created by a cross-correlation of the optical Sloan Digital Sky Survey Data Release 5 quasar catalogue and the 2XMMi catalogue of serendipitous X-ray sources, is further matched with the Faint Images of the Radio Sky at Twenty-cm catalogue of radio sources, the mid-infrared (MIR) Wide-field Infrared Survey Explorer all-sky data release, the Two Micron All Sky Survey near-infrared point source catalogue, the UKIRT Infrared Deep Sky Survey Data Release 9 Large Area Survey and the Galaxy Evolution Explorer all-sky and medium ultraviolet (UV) imaging surveys. This allows broad-band SEDs including up to 19 flux measurements covering log ν ∼ 9.2–18.1 to be created. We investigate variations in the SED shape by binning a subsample of 237 AGN with the best quality SEDs according to their X-ray spectral parameters, their quasar subtype and physical parameters such as luminosity, black hole mass and Eddington ratio. The AGN subpopulations show some significant differences in their SEDs; X-ray absorbed AGN show a deficit of emission at X-ray/UV frequencies and an excess in the MIR consistent with absorption and re-emission, radio-loud AGN show increased radio and X-ray emission consistent with the presence of a jet component in addition to the emission seen from radio-quiet AGN and the SEDs of narrow-line Seyfert 1s only differ from other type 1s in the X-ray regime, suggesting any physical differences are limited to their X-ray emitting region. Binning the AGN according to underlying physical parameters reveals more subtle differences in the SEDs. The X-ray spectral slope does not appear to have any influence or dependence on the multiwavelength emission in the rest of the SED. The contribution of X-rays to the bolometric luminosity is lower in higher luminosity sources, and relatively more emission in the optical/UV is seen in AGN with higher X-ray luminosities. Variations in the relative flux and peak frequency of the big blue bump are observed and may suggest higher inner disc temperatures with increasing accretion rates. Overall, we find that the diversity in the SED shapes is relatively small, and we find no apparent single driver for the variations.",10.1093/mnras/stt2341,2014,,DO THE SPECTRAL ENERGY DISTRIBUTIONS OF TYPE 1 ACTIVE GALACTIC NUCLEI SHOW DIVERSITY?,
246,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"One of the biggest problems faced by current and next-generation astronomical surveys is trying to produce large numbers of accurate cross-identifications across a range of wavelength regimes with varying data quality and positional uncertainty. Until recently, simple spatial ‘nearest neighbour’ associations have been sufficient for most applications. However as advances in instrumentation allow more sensitive images to be made, the rapid increase in the source density has meant that source confusion across multiple wavelengths is a serious problem. The field of far-IR and sub-mm astronomy has been particularly hampered by such problems. The poor angular resolution of current sub-mm and far-IR instruments is such that in a lot of cases, there are multiple plausible counterparts for each source at other wavelengths. Here we present a new automated method of producing associations between sources at different wavelengths using a combination of spatial and spectral energy distribution information set in a Bayesian framework. Testing of the technique is performed on both simulated catalogues of sources from GaLICS and real data from multiwavelength observations of the Subaru-XMM Deep Field. It is found that a single figure of merit, the Bayes factor, can be effectively used to describe the confidence in the match. Further applications of this technique to future Herschel data sets are discussed.",10.1111/j.1365-2966.2009.15522.x,2009,,A NEW APPROACH TO MULTIWAVELENGTH ASSOCIATIONS OF ASTRONOMICAL SOURCES,
247,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"The metal-poor (Z ≃ 1/100 Z⊙) damped Lyman α system (DLA) at redshift zabs = 3.049 84 in the zem ≃ 3.030 QSO SDSS J1419+0829 has near-ideal properties for an accurate determination of the primordial abundance of deuterium (D/H)p. We have analysed a high-quality spectrum of this object with software specifically designed to deduce the best-fitting value of D/H and to assess comprehensively the random and systematic errors affecting this determination. We find (D/H)DLA = (2.535 ± 0.05) × 10−5, which in turn implies Ωb, 0h2 = 0.0223 ± 0.0009, in very good agreement with Ωb, 0h2(CMB) = 0.0222 ± 0.0004 deduced from the angular power spectrum of the cosmic microwave background (CMB). If the value in this DLA is indeed the true (D/H)p produced by big bang nucleosynthesis (BBN), there may be no need to invoke non-standard physics nor early astration of D to bring together Ωb, 0 h2(BBN) and Ωb, 0 h2(CMB). The scatter between most of the reported values of (D/H)p in the literature may be due largely to unaccounted systematic errors and biases. Further progress in this area will require a homogeneous set of data comparable to those reported here and analysed in a self-consistent manner. Such an endeavour, while observationally demanding, has the potential of improving our understanding of BBN physics, including the relevant nuclear reactions, and the subsequent processing of light nuclides through stars.",10.1111/j.1365-2966.2012.21665.x,2012,,"A NEW, PRECISE MEASUREMENT OF THE PRIMORDIAL ABUNDANCE OF DEUTERIUM",
248,28218,MONTHLY NOTICES OF THE ROYAL ASTRONOMICAL SOCIETY,journal,13652966,"2,058",Q1,383,3653,10488,273464,99701,10487,"9,67","74,86",United Kingdom,Western Europe,Oxford University Press,1986-2020,Astronomy and Astrophysics (Q1); Space and Planetary Science (Q1),"191,209",5.287,0.22219,"We propose a new method of estimation of the black hole masses in active galactic nuclei (AGN) based on the normalized excess variance, σ2nxs. We derive a relation between σ2nxs, the length of the observation, T, the light-curve bin size, Δt, and the black hole mass, assuming that (i) the power spectrum above the high-frequency break, νbf, has a slope of −2, (ii) the high-frequency break scales with black hole mass, (iii) the power-spectrum amplitude (in frequency–power space) is universal and (iv) σ2nxs is calculated from observations of length T < 1/νbf. Values of black hole masses in AGN obtained with this method are consistent with estimates based on other techniques such as reverberation mapping or the MBH–stellar velocity dispersion relation. The method is formally equivalent to methods based on power spectrum scaling with mass, but the use of σ2nxs has the big advantage of being applicable to relatively low-quality data.",10.1111/j.1365-2966.2004.07829.x,2004,,BLACK HOLE MASS ESTIMATION FROM X-RAY VARIABILITY MEASUREMENTS IN ACTIVE GALACTIC NUCLEI,
249,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"This paper examines the challenges of leveraging big data in the humanitarian sector in support of UN Sustainable Development Goal 17 “Partnerships for the Goals”. The full promise of Big Data is underpinned by a tacit assumption that the heterogeneous ‘exhaust trail’ of data is contextually relevant and sufficiently granular to be mined for value. This promise, however, relies on relationality – that patterns can be derived from combining different pieces of data that are of corresponding detail or that there are effective mechanisms to resolve differences in detail. Here, we present empirical work integrating eight heterogeneous datasets from the humanitarian domain to provide evidence of the inherent challenge of complexity resulting from differing levels of data granularity. In clarifying this challenge, we explore the reasons why it is manifest, discuss strategies for addressing it and, as our principal contribution, identify five propositions to guide future research.",https://doi.org/10.1016/j.jbusres.2020.09.035,2021,David Bell and Mark Lycett and Alaa Marshan and Asmat Monaghan,EXPLORING FUTURE CHALLENGES FOR BIG DATA IN THE HUMANITARIAN DOMAIN,article
250,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Prior research articulated the importance of developing a big data analytics capability but did not show how to cultivate this development. Drawing on the literature on this topic, this study develops the concept of Big Data capability, which enhances our understanding of Big Data practice beyond that captured in previous literature on the concept of big data analytics capability. This study further highlights the strategic implications of the concept by testing its relationship to three strategic orientations and one aspect of organizational culture. Findings show that customer, entrepreneurial, and technology orientations, and developmental culture are important contributors to the development of Big Data capability.",https://doi.org/10.1016/j.jbusres.2019.07.016,2019,Canchu Lin and Anand Kunnathur,"STRATEGIC ORIENTATIONS, DEVELOPMENTAL CULTURE, AND BIG DATA CAPABILITY",article
251,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"The lack of sufficient big data-based approaches impedes the development of human resource management (HRM) research and practices. Although scholars have realized the importance of applying a big data approach to HRM research, clear guidance is lacking regarding how to integrate the two. Using a clustering algorithm based on the big data research paradigm, we first conduct a bibliometric review to quantitatively assess and scientifically map the evolution of the current big data HRM literature. Based on this systematic review, we propose a general theoretical framework described as “Inductive (Prediction paradigm: Data mining/Theory building) vs. Deductive (Explanation paradigm: Theory testing)”. In this framework, we discuss potential research questions, their corresponding levels of analysis, relevant methods, data sources and software. We then summarize the general procedures for conducting big data research within HRM research. Finally, we propose a future agenda for applying big data approaches to HRM research and identify five promising HRM research topics at the micro, meso and macro levels along with three challenges and limitations that HRM scholars may face in the era of big data.",https://doi.org/10.1016/j.jbusres.2021.04.019,2021,Yucheng Zhang and Shan Xu and Long Zhang and Mengxi Yang,BIG DATA AND HUMAN RESOURCE MANAGEMENT RESEARCH: AN INTEGRATIVE REVIEW AND NEW DIRECTIONS FOR FUTURE RESEARCH,article
252,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Big data analytics (BDA) has recently gained importance as an emerging technology for handling big data. The use of advanced techniques with differing levels of intelligence, such as descriptive, predictive, prescriptive, and autonomous analytics, is expected to create value for firms. By viewing BDA as a sociotechnical system, we conduct a meta-analysis of 107 individual studies to integrate prior evidence on the role of the technical and social factors of BDA in creating BDA business value. The findings underline the predominant role of the social components in enhancing firm performance, such as the BDA system’s human factors and a nurturing organizational structure, in contrast to the minor role of the technological factors. However, both the technical and social factors are found to be strong determinants of BDA business value. Through the combined lens of sociotechnical theory and the IS business value framework, we contribute to research and practice by enhancing the understanding of the main technical and social determinants of BDA business value at the firm level.",https://doi.org/10.1016/j.jbusres.2022.08.028,2022,Thuy Duong Oesterreich and Eduard Anton and Frank Teuteberg and Yogesh K Dwivedi,THE ROLE OF THE SOCIAL AND TECHNICAL FACTORS IN CREATING BUSINESS VALUE FROM BIG DATA ANALYTICS: A META-ANALYSIS,article
253,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"The use of social media for innovation requires firms to manage rapid information transfers, big data, and multiway communication. Yet managers lack clear insights on the way social media should be managed and current literature is dispersed across various research streams. In this article, the authors aim to develop a better understanding of how social media use should be leveraged for innovation. To achieve this objective, they build a systematic review of evidence from 177 scientific articles across four key management disciplines. They analyze research perspectives and conceptualizations of social media use for innovation and provide a framework of the drivers, contingencies and outcomes related to this topic. Next, they attempt to identify what is currently known about social media use for innovation. Last, they suggest critical areas for future inquiry on this important subject.",https://doi.org/10.1016/j.jbusres.2022.01.039,2022,Marie-Isabelle Muninger and Dominik Mahr and Wafa Hammedi,SOCIAL MEDIA USE: A REVIEW OF INNOVATION MANAGEMENT PRACTICES,article
254,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"The emerging Big Data integration imposes diverse challenges, compromising the sustainable business research practice. Heterogeneity, multi-dimensionality, velocity, and massive volumes that challenge Big Data paradigm may preclude the effective data and system integration processes. Business alignments get affected within and across joint ventures as enterprises attempt to adapt to changes in industrial environments rapidly. In the context of the Oil and Gas industry, we design integrated artefacts for a resilient multidimensional warehouse repository. With access to several decades of resource data in upstream companies, we incorporate knowledge-based data models with spatial-temporal dimensions in data schemas to minimize ambiguity in warehouse repository implementation. The design considerations ensure uniqueness and monotonic properties of dimensions, maintaining the connectivity between artefacts and achieving the business alignments. The multidimensional attributes envisage Big Data analysts a scope of business research with valuable new knowledge for decision support systems and adding further business values in geographic scales.",https://doi.org/10.1016/j.jbusres.2018.04.029,2018,Shastri L. Nimmagadda and Torsten Reiners and Lincoln C. Wood,ON BIG DATA-GUIDED UPSTREAM BUSINESS RESEARCH AND ITS KNOWLEDGE MANAGEMENT,article
255,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Although big data analytics have tremendous benefits for healthcare organizations, extant research has paid insufficient attention to the exploration of its business value. In order to bridge this knowledge gap, this study proposes a big data analytics-enabled business value model in which we use the resource-based theory (RBT) and capability building view to explain how big data analytics capabilities can be developed and what potential benefits can be obtained by these capabilities in the health care industries. Using this model, we investigate 109 case descriptions, covering 63 healthcare organizations to explore the causal relationships between the big data analytics capabilities and business value and the path-to-value chains for big data analytics success. Our findings provide new insights to healthcare practitioners on how to constitute big data analytics capabilities for business transformation and offer an empirical basis that can stimulate a more detailed investigation of big data analytics implementation.",https://doi.org/10.1016/j.jbusres.2016.08.002,2017,Yichuan Wang and Nick Hajli,EXPLORING THE PATH TO BIG DATA ANALYTICS SUCCESS IN HEALTHCARE,article
256,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Consumer analytics is at the epicenter of a Big Data revolution. Technology helps capture rich and plentiful data on consumer phenomena in real time. Thus, unprecedented volume, velocity, and variety of primary data, Big Data, are available from individual consumers. To better understand the impact of Big Data on various marketing activities, enabling firms to better exploit its benefits, a conceptual framework that builds on resource-based theory is proposed. Three resources—physical, human, and organizational capital—moderate the following: (1) the process of collecting and storing evidence of consumer activity as Big Data, (2) the process of extracting consumer insight from Big Data, and (3) the process of utilizing consumer insight to enhance dynamic/adaptive capabilities. Furthermore, unique resource requirements for firms to benefit from Big Data are discussed.",https://doi.org/10.1016/j.jbusres.2015.07.001,2016,Sunil Erevelles and Nobuyuki Fukawa and Linda Swayne,BIG DATA CONSUMER ANALYTICS AND THE TRANSFORMATION OF MARKETING,article
257,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Grounded in gestalt insight learning theory and organizational learning theory, we collected data from 280 middle and top-level managers to investigate the impact of each big data characteristic (i.e., data volume, data velocity, data variety, and data veracity) on firm innovation competency (i.e., exploitation competency and exploration competency), mediated through data-driven insight generation (i.e., descriptive insight, predictive insight, and prescriptive insight). Findings show that while data velocity, variety, and veracity enhance data-driven insight generation, data volume does not impact it. Additionally, results of the post hoc analysis indicate that while descriptive and predictive insights improve innovation competency, prescriptive insight does not affect it. These results provide interesting and unique theoretical and practical insights.",https://doi.org/10.1016/j.jbusres.2019.07.006,2019,Maryam Ghasemaghaei and Goran Calic,DOES BIG DATA ENHANCE FIRM INNOVATION COMPETENCY? THE MEDIATING ROLE OF DATA-DRIVEN INSIGHTS,article
258,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Organizations are looking for ways to harness the power of big data (BD) to improve their decision making. Despite its significance the effects of BD on decision-making quality has been given scant attention in the literature. In this paper factors influencing decision-making based on BD are identified using a case study. BD is collected from different sources that have various data qualities and are processed by various organizational entities resulting in the creation of a big data chain. The veracity (manipulation, noise), variety (heterogeneity of data) and velocity (constantly changing data sources) amplified by the size of big data calls for relational and contractual governance mechanisms to ensure BD quality and being able to contextualize data. The case study reveals that taking advantage of big data is an evolutionary process in which the gradually understanding of the potential of big data and the routinization of processes plays a crucial role.",https://doi.org/10.1016/j.jbusres.2016.08.007,2017,Marijn Janssen and Haiko {van der Voort} and Agung Wahyudi,FACTORS INFLUENCING BIG DATA DECISION-MAKING QUALITY,article
259,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Although big data analytics (BDA) is considered the next “frontier” in data science by creating potential business opportunities, the way to extract those opportunities is unclear. This paper aims to understand the antecedents of BDA value at a firm level. The authors performed a study using a mixed methodology approach. First, by carrying out a Delphi study to explore and rank the antecedents affecting the creation of BDA value. Based on the Delphi results, we propose an empirically validated model supported by a survey conducted on 175 European firms to explain the antecedents of BDA sustained value. The results show that the proposed model explains 62% of BDA sustained value at the firm level, where the most critical contributor is BDA use. We provide directions for managers to support their decisions on BDA strategy definition and refinement. For academics, we extend BDA value literature and outline some potential research opportunities.",https://doi.org/10.1016/j.jbusres.2018.12.072,2019,Nadine Côrte-Real and Pedro Ruivo and Tiago Oliveira and Aleš Popovič,UNLOCKING THE DRIVERS OF BIG DATA ANALYTICS VALUE IN FIRMS,article
260,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Customer experience (CX) has emerged as a sustainable source of competitive differentiation. Recent developments in big data analytics (BDA) have exposed possibilities to unlock customer insights for customer experience management (CXM). Research at the intersection of these two fields is scarce and there is a need for conceptual work that (1) provides an overview of opportunities to use BDA for CXM and (2) guides management practice and future research. The purpose of this paper is therefore to develop a strategic framework for CXM based on CX insights resulting from BDA. Our conceptualisation is comprehensive and is particularly relevant for researchers and practitioners who are less familiar with the potential of BDA for CXM. For managers, we provide a step-by-step guide on how to kick-start or implement our strategic framework. For researchers, we propose some opportunities for future studies in this promising research area.",https://doi.org/10.1016/j.jbusres.2020.01.022,2020,Maria Holmlund and Yves {Van Vaerenbergh} and Robert Ciuchita and Annika Ravald and Panagiotis Sarantopoulos and Francisco Villarroel Ordenes and Mohamed Zaki,CUSTOMER EXPERIENCE MANAGEMENT IN THE AGE OF BIG DATA ANALYTICS: A STRATEGIC FRAMEWORK,article
261,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Big data analytics has been widely regarded as a breakthrough technological development in academic and business communities. Despite the growing number of firms that are launching big data initiatives, there is still limited understanding on how firms translate the potential of such technologies into business value. The literature argues that to leverage big data analytics and realize performance gains, firms must develop strong big data analytics capabilities. Nevertheless, most studies operate under the assumption that there is limited heterogeneity in the way firms build their big data analytics capabilities and that related resources are of similar importance regardless of context. This paper draws on complexity theory and investigates the configurations of resources and contextual factors that lead to performance gains from big data analytics investments. Our empirical investigation followed a mixed methods approach using survey data from 175 chief information officers and IT managers working in Greek firms, and three case studies to show that depending on the context, big data analytics resources differ in significance when considering performance gains. Applying a fuzzy-set qualitative comparative analysis (fsQCA) method on the quantitative data, we show that there are four different patterns of elements surrounding big data analytics that lead to high performance. Outcomes of the three case studies highlight the inter-relationships between these elements and outline challenges that organizations face when orchestrating big data analytics resources.",https://doi.org/10.1016/j.jbusres.2019.01.044,2019,Patrick Mikalef and Maria Boura and George Lekakos and John Krogstie,BIG DATA ANALYTICS AND FIRM PERFORMANCE: FINDINGS FROM A MIXED-METHOD APPROACH,article
262,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"The advent and development of digital technologies have brought about a proliferation of online consumer reviews (OCRs), i.e., real-time customers’ evaluations of products, services, and brands. Increasingly, e-commerce platforms are using them to gain insights from customer feedback. Meanwhile, a new generation of big data analytics (BDA) companies are crowdsourcing large volumes of OCRs by means of controlled ad hoc online experiments and advanced machine learning (ML) techniques to forecast demand and determine the market potential for new products in several industries. We illustrate how this process is taking place for consumer goods companies by exploring the case of UK digital BDA company, SoundOut. Based on an in-depth qualitative analysis, we develop the consumer goods company innovation (CGCI) conceptual framework, which illustrates how digital BDA firms help consumer goods companies to test new products before they are launched on the market, and innovate. Theoretical and managerial implications are discussed.",https://doi.org/10.1016/j.jbusres.2020.09.012,2020,Marcello M. Mariani and Samuel {Fosso Wamba},EXPLORING HOW CONSUMER GOODS COMPANIES INNOVATE IN THE DIGITAL AGE: THE ROLE OF BIG DATA ANALYTICS COMPANIES,article
263,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Big Data (BD), with their potential to ascertain valued insights for enhanced decision-making process, have recently attracted substantial interest from both academics and practitioners. Big Data Analytics (BDA) is increasingly becoming a trending practice that many organizations are adopting with the purpose of constructing valuable information from BD. The analytics process, including the deployment and use of BDA tools, is seen by organizations as a tool to improve operational efficiency though it has strategic potential, drive new revenue streams and gain competitive advantages over business rivals. However, there are different types of analytic applications to consider. Therefore, prior to hasty use and buying costly BD tools, there is a need for organizations to first understand the BDA landscape. Given the significant nature of the BD and BDA, this paper presents a state-of-the-art review that presents a holistic view of the BD challenges and BDA methods theorized/proposed/employed by organizations to help others understand this landscape with the objective of making robust investment decisions. In doing so, systematically analysing and synthesizing the extant research published on BD and BDA area. More specifically, the authors seek to answer the following two principal questions: Q1 – What are the different types of BD challenges theorized/proposed/confronted by organizations? and Q2 – What are the different types of BDA methods theorized/proposed/employed to overcome BD challenges?. This systematic literature review (SLR) is carried out through observing and understanding the past trends and extant patterns/themes in the BDA research area, evaluating contributions, summarizing knowledge, thereby identifying limitations, implications and potential further research avenues to support the academic community in exploring research themes/patterns. Thus, to trace the implementation of BD strategies, a profiling method is employed to analyze articles (published in English-speaking peer-reviewed journals between 1996 and 2015) extracted from the Scopus database. The analysis presented in this paper has identified relevant BD research studies that have contributed both conceptually and empirically to the expansion and accrual of intellectual wealth to the BDA in technology and organizational resource management discipline.",https://doi.org/10.1016/j.jbusres.2016.08.001,2017,Uthayasankar Sivarajah and Muhammad Mustafa Kamal and Zahir Irani and Vishanth Weerakkody,CRITICAL ANALYSIS OF BIG DATA CHALLENGES AND ANALYTICAL METHODS,article
264,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Machine learning (ML) is expected to transform the business landscape in the near future completely. Hitherto, some successful ML case-stories have emerged. However, how organizations can derive business value (BV) from ML has not yet been substantiated. We assemble a conceptual model, grounded on the dynamic capabilities theory, to uncover key drivers of ML BV, in terms of financial and strategic performance. The proposed model was assessed by surveying 319 corporations. Our findings are that ML use, big data analytics maturity, platform maturity, top management support, and process complexity are, to some extent, drivers of ML BV. We also find that platform maturity has, to some degree, a moderator influence between ML use and ML BV, and between big data analytics maturity and ML BV. To the best of our knowledge, this is the first research to deliver such findings in the ML field.",https://doi.org/10.1016/j.jbusres.2020.05.053,2020,Carolina Reis and Pedro Ruivo and Tiago Oliveira and Paulo Faroleiro,ASSESSING THE DRIVERS OF MACHINE LEARNING BUSINESS VALUE,article
265,20550,JOURNAL OF BUSINESS RESEARCH,journal,01482963,"2,049",Q1,195,878,1342,73221,11507,1315,"7,38","83,40",United States,Northern America,Elsevier Inc.,1973-2021,Marketing (Q1),"46,935",7.550,0.03523,"Data analytics has gained importance in human resource management (HRM) for its ability to provide insights based on data-driven decision-making processes. However, integrating an analytics-based approach in HRM is a complex process, and hence, many organizations are unable to adopt HR Analytics (HRA). Using a framework synthesis approach, we first identify the challenges that hinder the practice of HRA and then develop a framework to explain the different factors that impact the adoption of HRA within organizations. This study identifies the key aspects related to the technological, organizational, environmental, data governance, and individual factors that influence the adoption of HRA. In addition, this paper determines 23 sub-dimensions of these five factors as the crucial aspects for successfully implementing and practicing HRA within organizations. We also discuss the implications of the framework for HR leaders, HR Managers, CEOs, IT Managers and consulting practitioners for effective adoption of HRA in organization.",https://doi.org/10.1016/j.jbusres.2021.03.054,2021,Sateesh.V. Shet and Tanuj Poddar and Fosso {Wamba Samuel} and Yogesh K. Dwivedi,EXAMINING THE DETERMINANTS OF SUCCESSFUL ADOPTION OF DATA ANALYTICS IN HUMAN RESOURCE MANAGEMENT – A FRAMEWORK FOR IMPLICATIONS,article
266,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Industry 4.0 (I4.0) defines a new paradigm to produce high-quality products at the low cost by reacting quickly and effectively to changing demands in the highly volatile global markets. In Industry 4.0, the adoption of Internet of Things (IoT)-enabled Wireless Sensors (WSs) in the manufacturing processes, such as equipment, machining, assembly, material handling, inspection, etc., generates a huge volume of data known as Industrial Big Data (IBD). However, the reliable and efficient gathering and transmission of this big data from the source sensors to the floor inspection system for the real-time monitoring of unexpected changes in the production and quality control processes is the biggest challenge for Industrial Wireless Sensor Networks (IWSNs). This is because of the harsh nature of the indoor industrial environment that causes high noise, signal fading, multipath effects, heat and electromagnetic interference, which reduces the transmission quality and trigger errors in the IWSNs. Therefore, this paper proposes a novel cross-layer data gathering approach called CBI4.0 for active monitoring and control of manufacturing processes in the Industry 4.0. The key aim of the proposed CBI4.0 scheme is to exploit the multi-channel and multi-radio architecture of the sensor network to guarantee quality of service (QoS) requirements, such as higher data rates, throughput, and low packet loss, corrupted packets, and latency by dynamically switching between different frequency bands in the Multichannel Wireless Sensor Networks (MWSNs). By performing several simulation experiments through EstiNet 9.0 simulator, the performance of the proposed CBI4.0 scheme is compared against existing studies in the automobile Industry 4.0. The experimental outcomes show that the proposed scheme outperforms existing schemes and is suitable for effective control and monitoring of various events in the automobile Industry 4.0.",https://doi.org/10.1016/j.jii.2021.100236,2021,Muhammad Faheem and Rizwan Aslam Butt and Rashid Ali and Basit Raza and Md. Asri Ngadi and Vehbi Cagri Gungor,CBI4.0: A CROSS-LAYER APPROACH FOR BIG DATA GATHERING FOR ACTIVE MONITORING AND MAINTENANCE IN THE MANUFACTURING INDUSTRY 4.0,article
267,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"The application of blockchain in food supply chains does not resolve conventional IoT data quality issues. Data on a blockchain may simply be immutable garbage. In response, this paper reports our observations and learnings from an ongoing beef supply chain project that integrates Blockchain and IoT for supply chain event tracking and beef provenance assurance and proposes two solutions for data integrity and trust in the Blockchain and IoT-enabled food supply chain. Rather than aiming for absolute truth, we explain how applying the notion of ‘common knowledge’ fundamentally changes oracle identity and data validity practices. Based on the learnings derived from leading an IoT supply chain project with a focus on beef exports from Australia to China, our findings unshackle IoT and Blockchain from being used merely to collect lag indicators of past states and liberate their potential as lead indicators of desired future states. This contributes: (a) to limit the possibility of capricious claims on IoT data performance, and; (b) to utilise mechanism design as an approach by which supply chain behaviours that increase the probability of desired future states being realised can be encouraged.",https://doi.org/10.1016/j.jii.2021.100261,2022,Warwick Powell and Marcus Foth and Shoufeng Cao and Valéri Natanelov,GARBAGE IN GARBAGE OUT: THE PRECARIOUS LINK BETWEEN IOT AND BLOCKCHAIN IN FOOD SUPPLY CHAINS,article
268,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Disruptive innovations are usually identified as ideas that are created ‘outside the box’. They are expected to fundamentally change existing business models and processes founded on technological applications. Disruptive innovations can be challenging to define. Information technology (IT) solutions focus on collecting, processing, and reporting different types of data. Commonly, is the solutions are expected (in cybernetics or self-regulating processes) to provide feedback to original processes and to steer them based on the data. To achieve continuous improvement with regard to environmental responsibility and profitability, new thinking and, in particular, accurate and reliable data are needed for decision-making. Very large data storages, known as big data, contain an increasing mass of different types of homogenous and non-homogenous information, as well as extensive time-series. New, innovative algorithms are required to reveal relevant information and opportunities hidden in these data storages. Global environmental challenges and zero-emission responsible production issues can only be solved using relevant and reliable continuous data as the basis. The final goal should be the creation of scalable environmental solutions based on disruptive innovations and accurate data. The aim of this paper is to determine the explicit steps for replacing silo-based reporting with company-wide, refined information, which enables decision-makers in all industries the chance to make responsible choices.",https://doi.org/10.1016/j.jii.2019.100105,2019,Esa Hämäläinen and Tommi Inkinen,INDUSTRIAL APPLICATIONS OF BIG DATA IN DISRUPTIVE INNOVATIONS SUPPORTING ENVIRONMENTAL REPORTING,article
269,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Typically, only a smaller portion of the monitorable operational data (e.g. from sensors and environment) from Offshore Support Vessels (OSVs) are used at present. Operational data, in addition to equipment performance data, design and construction data, creates large volumes of data with high veracity and variety. In most cases, such data richness is not well understood as to how to utilize it better during design and operation. It is, very often, too time consuming and resource demanding to estimate the final operational performance of vessel concept design solution in early design by applying simulations and model tests. This paper argues that there is a significant potential to integrate ship lifecycle data from different phases of its operation in large data repository for deliberate aims and evaluations. It is disputed discretely in the paper, evaluating performance of real similar type vessels during early stages of the design process, helps substantially improving and fine-tuning the performance criterion of the next generations of vessel design solutions. Producing learning from such a ship lifecycle data repository to find useful patterns and relationships among design parameters and existing fleet real performance data, requires the implementation of modern data mining techniques, such as big data and clustering concepts, which are introduced and applied in this paper. The analytics model introduced suggests and reviews all relevant steps of data knowledge discovery, including pre-processing (integration, feature selection and cleaning), processing (data analyzing) and post processing (evaluating and validating results) in this context.",https://doi.org/10.1016/j.jii.2018.02.002,2018,Niki Sadat Abbasian and Afshin Salajegheh and Henrique Gaspar and Per Olaf Brett,IMPROVING EARLY OSV DESIGN ROBUSTNESS BY APPLYING ‘MULTIVARIATE BIG DATA ANALYTICS’ ON A SHIP'S LIFE CYCLE,article
270,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Data quality management (DQM) is one of the most critical aspects to ensure successful applications of the Internet of Things (IoT). So far, most of the approaches for assuring data quality are typically data-centric, i.e., mainly focus on fixing data issues for specific values. However, organizations can also benefit from improving their capabilities of their DQM processes by developing organizational best DQM practices. In this regard, our investigation addresses how well organizations perform their DQM processes in the IoT domain. The main contribution of this study is to establish a framework for IoT DQM maturity. This framework is compliant with ISO 8000-61 (DQM: process reference model) and ISO 8000-62 (DQM: organizational process maturity assessment) and can be used to assess and improve the capabilities of the DQM processes for IoT data. The framework is composed of two elements. First, a process reference model (PRM) for IoT DQM is proposed by extending the PRM for DQM defined in ISO 8000-61, tailoring some existing processes and adding new ones. Second, a maturity model suitable for IoT data is proposed based on the PRM for IoT DQM. The maturity model, named IoT DQM3, is proposed by extending the maturity model defined in ISO 8000-62. However, in order to increase the usability of IoT DQM3, we consider adequate the proposition of a simplification of the IoT DQM3, by introducing a lightweight version to reduce assessment indicators and facilitate its industrial adoption. A simplified method to measure the capability of a process is also suggested considering the relationship of process attributes with the measurement stack defined in ISO 8000-63. The empirical validation of the maturity model is twofold. First, the appropriateness of the two models is surveyed with data quality experts who are currently working in various organizations around the world. Second, in order to demonstrate the feasibility of the proposal, the light-weight version is applied to a manufacturing company as a case study.",https://doi.org/10.1016/j.jii.2021.100256,2022,Sunho Kim and Ricardo Pérez-Castillo and Ismael Caballero and Downgwoo Lee,ORGANIZATIONAL PROCESS MATURITY MODEL FOR IOT DATA QUALITY MANAGEMENT,article
271,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Driven by the innovative improvement of information and communication technologies (ICTs) and their applications into manufacturing industry, the big data era in manufacturing is correspondingly arising, and the developing data mining techniques (DMTs) pave the way for pursuing the aims of smart production with the real-time, dynamic, self-adaptive and precise control. However, lots of factors in the ever-changing environment of manufacturing industry, such as, various of complex production processes, larger scale and uncertainties, more complicated constrains, coupling of operational performance, and so on, make production management face with more and more big challenges. The dynamic inflow of a large number of raw data which is collected from the physical manufacturing sites or generated in various related information systems, caused the heavy information overload problems. Indeed, most of traditional DMTs are not yet sufficient to process such big data for smart production management. Therefore, this paper reviews the development of DMTs in the big data era, and makes discussion on the applications of DMTs in production management, by selecting and analyzing the relevant papers since 2010. In the meantime, we point out limitations and put forward some suggestions about the smartness and further applications of DMTs used in production management.",https://doi.org/10.1016/j.jii.2017.08.001,2018,Ying Cheng and Ken Chen and Hemeng Sun and Yongping Zhang and Fei Tao,DATA AND KNOWLEDGE MINING WITH BIG DATA TOWARDS SMART PRODUCTION,article
272,21100787106,JOURNAL OF INDUSTRIAL INFORMATION INTEGRATION,journal,2452414X,"2,042",Q1,24,28,86,2152,1361,83,"12,26","76,86",Netherlands,Western Europe,Elsevier BV,2016-2020,Industrial and Manufacturing Engineering (Q1); Information Systems and Management (Q1),"1,149",10.063,0.00148,"Digital Twin was introduced over a decade ago, as an innovative all-encompassing tool, with perceived benefits including real-time monitoring, simulation, optimisation and accurate forecasting. However, the theoretical framework and practical implementations of digital twin (DT) are yet to fully achieve this vision at scale. Although an increasing number of successful implementations exist in research and industrial works, sufficient implementation details are not publicly available, making it difficult to fully assess their components and effectiveness, to draw comparisons, identify successful solutions, share lessons, and thus to jointly advance and benefit from the DT methodology. This work first presents a review of relevant DT research and industrial works, focusing on the key DT features, current approaches in different domains, and successful DT implementations, to infer the key DT components and properties, and to identify current limitations and reasons behind the delay in the widespread implementation and adoption of digital twin. This work identifies that the major reasons for this delay are: the fact the DT is still a fast evolving concept; the lack of a universal DT reference framework, e.g. DT standards are scarce and still evolving; problem- and domain-dependence; security concerns over shared data; lack of DT performance metrics; and reliance of digital twin on other fast-evolving technologies. Advancements in machine learning, Internet of Things (IoT) and big data have led to significant improvements in DT features such as real-time monitoring and accurate forecasting. Despite this progress and individual company-based efforts, certain research and implementation gaps exist in the field, which have so far prevented the widespread adoption of the DT concept and technology; these gaps are also discussed in this work. Based on reviews of past work and the identified gaps, this work then defines a conceptualisation of DT which includes its components and properties; these also validate the uniqueness of DT as a concept, when compared to similar concepts such as simulation, autonomous systems and optimisation. Real-life case studies are used to showcase the application of the conceptualisation. This work discusses the state-of-the-art in DT, addresses relevant and timely DT questions, and identifies novel research questions, thus contributing to a better understanding of the DT paradigm and advancing the theory and practice of DT and its allied technologies.",https://doi.org/10.1016/j.jii.2022.100383,2022,Angira Sharma and Edward Kosasih and Jie Zhang and Alexandra Brintrup and Anisoara Calinescu,"DIGITAL TWINS: STATE OF THE ART THEORY AND PRACTICE, CHALLENGES, AND OPEN RESEARCH QUESTIONS",article
273,25858,JOURNAL OF HAZARDOUS MATERIALS,journal,03043894,"2,034",Q1,284,2143,2994,126809,31399,2975,"10,39","59,17",Netherlands,Western Europe,Elsevier,1975-2021,"Environmental Chemistry (Q1); Environmental Engineering (Q1); Health, Toxicology and Mutagenesis (Q1); Pollution (Q1); Waste Management and Disposal (Q1)","137,983",10.588,0.07094,"Over the past few decades, data-driven machine learning (ML) has distinguished itself from hypothesis-driven studies and has recently received much attention in environmental toxicology. However, the use of ML in environmental toxicology remains in the early stages, with knowledge gaps, technical bottlenecks in data quality, high-dimensional/heterogeneous/small-sample data analysis and model interpretability, and a lack of an in-depth understanding of environmental toxicology. Given the above problems, we review the recent progress in the literature and highlight state-of-the-art toxicological studies using ML (such as learning and predicting toxicity in complicated biosystems and multiple-factor environmental scenarios of long-term and large-scale pollution). Beyond predicting simple biological endpoints by integrating untargeted omics and adverse outcome pathways, ML development should focus on revealing toxicological mechanisms. The integration of data-driven ML with other methods (e.g., omics analysis and adverse outcome pathway frameworks) endows ML with widely promising application in revealing toxicological mechanisms. High-quality databases and interpretable algorithms are urgently needed for toxicology and environmental science. Addressing the core issues and future challenges for ML in this review may narrow the knowledge gap between environmental toxicity and computational science and facilitate the control of environmental risk in the future.",https://doi.org/10.1016/j.jhazmat.2022.129487,2022,Xiaotong Wu and Qixing Zhou and Li Mu and Xiangang Hu,"MACHINE LEARNING IN THE IDENTIFICATION, PREDICTION AND EXPLORATION OF ENVIRONMENTAL TOXICOLOGY: CHALLENGES AND PERSPECTIVES",article
274,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"Big Data represents a promising area for value creation and frontier research. The potential to extract actionable insights from Big Data has gained increasing attention of both academics and practitioners operating in several industries. Marketing domain has become from the start a field for experiments with Big Data approaches, even if the adoption of Big Data solutions does not always generate effective value for the adopters. Therefore, the gap existing between the potential of value creation embedded in the Big Data paradigm and the current limited exploitation of this value represents an area of investigation that this paper aims to explore. In particular, by following a systematic literature review, this study aims at presenting a framework that outlines the multiple value directions that the Big Data paradigm can generate for the adopting organizations. Eleven distinct value directions have been identified and then grouped in five dimensions (Informational, Transactional, Transformational, Strategic, Infrastructural Value), which constitute the pillars of the proposed framework. Finally, the framework has been also preliminarily applied in three case studies conducted within three Italian based companies operating in different industries (e-commerce, fast-moving consumer goods, and banking) in the final aim to see its applicability in real business scenarios.",https://doi.org/10.1016/j.indmarman.2020.03.015,2020,Gianluca Elia and Gloria Polimeno and Gianluca Solazzo and Giuseppina Passiante,A MULTI-DIMENSION FRAMEWORK FOR VALUE CREATION THROUGH BIG DATA,article
275,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"Big Data represents a promising area for value creation and frontier research. The potential to extract actionable insights from Big Data has gained increasing attention of both academics and practitioners operating in several industries. Marketing domain has become from the start a field for experiments with Big Data approaches, even if the adoption of Big Data solutions does not always generate effective value for the adopters. Therefore, the gap existing between the potential of value creation embedded in the Big Data paradigm and the current limited exploitation of this value represents an area of investigation that this paper aims to explore. In particular, by following a systematic literature review, this study aims at presenting a framework that outlines the multiple value directions that the Big Data paradigm can generate for the adopting organizations. Eleven distinct value directions have been identified and then grouped in five dimensions (Informational, Transactional, Transformational, Strategic, Infrastructural Value), which constitute the pillars of the proposed framework. Finally, the framework has been also preliminarily applied in three case studies conducted within three Italian based companies operating in different industries (e-commerce, fast-moving consumer goods, and banking) in the final aim to see its applicability in real business scenarios.",https://doi.org/10.1016/j.indmarman.2019.08.004,2020,Gianluca Elia and Gloria Polimeno and Gianluca Solazzo and Giuseppina Passiante,A MULTI-DIMENSION FRAMEWORK FOR VALUE CREATION THROUGH BIG DATA,article
276,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"The complexity that characterises the dynamic nature of the various environmental factors makes it very compelling for firms to be capable of addressing the changing customers' needs. The current study examines the role of big data in new product success. We develop a qualitative research with case study approach to look at this. Specifically, we look at multiple cases to get in-depth understanding of customer agility for new product success with big data analytics. The findings of the study provide insight into the role of customer agility in new product success. This study unpacks the interconnectedness of the effective use of data aggregation tools, the effectiveness of data analysis tools and customer agility. It also explores the link between all of these factors and new product success. The study is reasonably telling in that it shows that the effective use of data aggregation and data analysis tools results in customer agility which in itself explains how an organisation senses and responds speedily to opportunities for innovation in the competitive marketing environment. The current study provides significant theoretical contributions by providing evidence for the role of big data analytics, big data aggregation tools, customer agility, organisational slack and environmental turbulence in new product success.",https://doi.org/10.1016/j.indmarman.2019.09.010,2020,Nick Hajli and Mina Tajvidi and Ayantunji Gbadamosi and Waqar Nadeem,UNDERSTANDING MARKET AGILITY FOR NEW PRODUCT SUCCESS WITH BIG DATA ANALYTICS,article
277,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"The emergence of digitally connected products and big data analytics (BDA) in industrial marketing has attracted academic and managerial interest in smart services. However, suppliers' provision of smart services and customers' adoption of these services have received scarce attention in the literature, demonstrating the need to address the changing nature of customer-supplier interactions in the digital era. Responding to prior research calls, this study utilizes ethnographic research and a storytelling lens to advance our knowledge of how stories and BDA can enhance customers' attitudes toward suppliers' smart services, their behavioral intentions and their actual adoption of smart services. The study's findings demonstrate that storytelling is a collective sensemaking and sensegiving process that occurs in interactions between customers and suppliers in which both parties contribute to the story development. The use of BDA in storytelling enhances customer sensemaking of smart services by highlighting the business value extracted from the digitized data of a reference customer. By synthesizing insights from servitization, storytelling, BDA and the customer reference literature, this study offers managers practical guidance regarding how to increase smart service sales. An example of a story used to facilitate customer adoption of a supplier's smart services in the manufacturing sector is provided.",https://doi.org/10.1016/j.indmarman.2019.12.004,2020,Valeriia Boldosova,TELLING STORIES THAT SELL: THE ROLE OF STORYTELLING AND BIG DATA ANALYTICS IN SMART SERVICE SALES,article
278,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"This study investigates the driving forces of a firm's assimilation of big data analytical intelligence (BDAI) and how the assimilation of BDAI improve customer relationship management (CRM) performance. Drawing on the resource-based view, this study argues that a firm's data-driven culture and the competitive pressure it faces in the industry motivate a firm's assimilation of BDAI. As a firm resource, BDAI enables an organization to develop superior mass-customization capability, which in turn positively influences its CRM performance. In addition, this study proposes that a firm's marketing capability can moderate the impact of BDAI assimilation on its mass-customization capability. Using survey data collected from 147 business-to-business companies, this study finds support for most of the hypotheses. The findings of this study uncover compelling insights about the dynamics involved in the process of using BDAI to improve CRM performance.",https://doi.org/10.1016/j.indmarman.2020.10.012,2020,Chubing Zhang and Xinchun Wang and Annie Peng Cui and Shenghao Han,LINKING BIG DATA ANALYTICAL INTELLIGENCE TO CUSTOMER RELATIONSHIP MANAGEMENT PERFORMANCE,article
279,22792,INDUSTRIAL MARKETING MANAGEMENT,journal,00198501,"2,022",Q1,136,314,465,27989,3787,450,"6,86","89,14",United States,Northern America,Elsevier Inc.,1971-2020,Marketing (Q1),"16,291",6.960,0.00901,"Artificial Intelligence (AI) could be an important foundation of competitive advantage in the market for firms. As such, firms use AI to achieve deep market engagement when the firm's data are employed to make informed decisions. This study examines the role of computer-mediated AI agents in detecting crises related to events in a firm. A crisis threatens organizational performance; therefore, a data-driven strategy will result in an efficient and timely reflection, which increases the success of crisis management. The study extends the situational crisis communication theory (SCCT) and Attribution theory frameworks built on big data and machine learning capabilities for early detection of crises in the market. This research proposes a structural model composed of a statistical and sentimental big data analytics approach. The findings of our empirical research suggest that knowledge extracted from day-to-day data communications such as email communications of a firm can lead to the sensing of critical events related to business activities. To test our model, we use a publicly available dataset containing 517,401 items belonging to 150 users, mostly senior managers of Enron during 1999 through the 2001 crisis. The findings suggest that the model is plausible in the early detection of Enron's critical events, which can support decision making in the market.",https://doi.org/10.1016/j.indmarman.2020.09.015,2020,Aydin Farrokhi and Farid Shirazi and Nick Hajli and Mina Tajvidi,USING ARTIFICIAL INTELLIGENCE TO DETECT CRISIS RELATED TO EVENTS: DECISION MAKING IN B2B BY ARTIFICIAL INTELLIGENCE,article
280,12391,LUNG CANCER,journal,01695002,"1,989",Q1,129,349,917,10507,4671,845,"4,71","30,11",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Cancer Research (Q1); Oncology (Q1); Pulmonary and Respiratory Medicine (Q1),"15,504",5.705,0.01966,"Introduction
Until the recent approval of immunotherapy after completing concurrent chemoradiotherapy (CCRT), there has been little progress in treating unresectable stage III non-small cell lung cancer (NSCLC). This prompted us to search real-world data (RWD) to better understand diagnosis and treatment patterns, and outcomes.
Methods
This non-interventional observational study used a unique, novel algorithm for big data analysis to collect and assess anonymized patient electronic medical records from a clinical data warehouse (CDW) over a 10-year period to capture real-world patterns of diagnosis, treatment, and outcomes of stage III NSCLC patients. We describe real-world patterns of diagnosis and treatment of patients with newly-diagnosed stage III NSCLC, and patients’ characteristics, and assessment of treatment outcomes.
Results
We analyzed clinical variables from 23,735 NSCLC patients. Stage III patients (N = 4138, 18.2 %) were diagnosed as IIIA (N = 2,547, 11.2 %) or IIIB (N = 1,591. 7.0 %). Treated stage III patients (N = 2530, 61.1 %) had a median age of 64.2 years, were mostly male (78.5 %) and had an ECOG performance status of 1 (65.2 %). Treatment comprised curative-intent surgery (N = 1,254, 49.6 %) with 705 receiving neoadjuvant therapy; definitive CRT (N = 648, 25.6 %); palliative CT (N = 270, 10.7 %), or thoracic RT (N = 170, 6.7 %). Median OS (range) for neoadjuvant, surgery, CRT, palliative chemotherapy, lung RT alone, and supportive care was 49.2 (42.0–56.5), 52.5 (43.1–61.9), 30.3 (26.6–34.0), 14.7 (13.0–16.4), 8.8 (6.2–11.3), and 2.0 (1.0–3.0) months, respectively.
Conclusions
This unique in-house algorithm enabled a rapid and comprehensive analysis of big data through a CDW, with daily automatic updates that documented real-world PFS and OS consistent with the published literature, and real-world treatment patterns and clinical outcomes in stage III NSCLC patients.",https://doi.org/10.1016/j.lungcan.2020.05.033,2020,Hyun Ae Jung and Jong-Mu Sun and Se-Hoon Lee and Jin Seok Ahn and Myung-Ju Ahn and Keunchil Park,"TEN-YEAR PATIENT JOURNEY OF STAGE III NON-SMALL CELL LUNG CANCER PATIENTS: A SINGLE-CENTER, OBSERVATIONAL, RETROSPECTIVE STUDY IN KOREA (REALTIME AUTOMATICALLY UPDATED DATA WAREHOUSE IN HEALTH CARE; UNIVERSE-ROOT STUDY)",article
281,21100405003,SCIENCE BULLETIN,journal,20959273,"1,983",Q1,112,365,833,12806,5639,616,"7,21","35,08",Netherlands,Western Europe,Elsevier BV,2015-2020,Multidisciplinary (Q1),"8,832",11.780,0.0164,"The United Nations 2030 Agenda for Sustainable Development provides an important framework for economic, social, and environmental action. A comprehensive indicator system to aid in the systematic implementation and monitoring of progress toward the Sustainable Development Goals (SDGs) is unfortunately limited in many countries due to lack of data. The availability of a growing amount of multi-source data and rapid advancements in big data methods and infrastructure provide unique opportunities to mitigate these data shortages and develop innovative methodologies for comparatively monitoring SDGs. Big Earth Data, a special class of big data with spatial attributes, holds tremendous potential to facilitate science, technology, and innovation toward implementing SDGs around the world. Several programs and initiatives in China have invested in Big Earth Data infrastructure and capabilities, and have successfully carried out case studies to demonstrate their utility in sustainability science. This paper presents implementations of Big Earth Data in evaluating SDG indicators, including the development of new algorithms, indicator expansion (for SDG 11.4.1) and indicator extension (for SDG 11.3.1), introduction of a biodiversity risk index as a more effective analysis method for SDG 15.5.1, and several new high-quality data products, such as global net ecosystem productivity, high-resolution global mountain green cover index, and endangered species richness. These innovations are used to present a comprehensive analysis of SDGs 2, 6, 11, 13, 14, and 15 from 2010 to 2020 in China utilizing Big Earth Data, concluding that all six SDGs are on schedule to be achieved by 2030.",https://doi.org/10.1016/j.scib.2022.07.015,2022,Huadong Guo and Dong Liang and Zhongchang Sun and Fang Chen and Xinyuan Wang and Junsheng Li and Li Zhu and Jinhu Bian and Yanqiang Wei and Lei Huang and Yu Chen and Dailiang Peng and Xiaosong Li and Shanlong Lu and Jie Liu and Zeeshan Shirazi,MEASURING AND EVALUATING SDG INDICATORS WITH BIG EARTH DATA,article
282,21100405003,SCIENCE BULLETIN,journal,20959273,"1,983",Q1,112,365,833,12806,5639,616,"7,21","35,08",Netherlands,Western Europe,Elsevier BV,2015-2020,Multidisciplinary (Q1),"8,832",11.780,0.0164,"Smart, real-time, low-cost, and distributed ecosystem monitoring is essential for understanding and managing rapidly changing ecosystems. However, new techniques in the big data era have rarely been introduced into operational ecosystem monitoring, particularly for fragile ecosystems in remote areas. We introduce the Internet of Things (IoT) techniques to establish a prototype ecosystem monitoring system by developing innovative smart devices and using IoT technologies for ecosystem monitoring in isolated environments. The developed smart devices include four categories: large-scale and nonintrusive instruments to measure evapotranspiration and soil moisture, in situ observing systems for CO2 and δ13C associated with soil respiration, portable and distributed devices for monitoring vegetation variables, and Bi-CMOS cameras and pressure trigger sensors for terrestrial vertebrate monitoring. These new devices outperform conventional devices and are connected to each other via wireless communication networks. The breakthroughs in the ecosystem monitoring IoT include new data loggers and long-distance wireless sensor network technology that supports the rapid transmission of data from devices to wireless networks. The applicability of this ecosystem monitoring IoT is verified in three fragile ecosystems, including a karst rocky desertification area, the National Park for Amur Tigers, and the oasis-desert ecotone in China. By integrating these devices and technologies with an ecosystem monitoring information system, a seamless data acquisition, transmission, processing, and application IoT is created. The establishment of this ecosystem monitoring IoT will serve as a new paradigm for ecosystem monitoring and therefore provide a platform for ecosystem management and decision making in the era of big data.",https://doi.org/10.1016/j.scib.2019.07.004,2019,Xin Li and Ning Zhao and Rui Jin and Shaomin Liu and Xiaomin Sun and Xuefa Wen and Dongxiu Wu and Yan Zhou and Jianwen Guo and Shiping Chen and Ziwei Xu and Mingguo Ma and Tianming Wang and Yonghua Qu and Xinwei Wang and Fangming Wu and Yuke Zhou,INTERNET OF THINGS TO NETWORK SMART DEVICES FOR ECOSYSTEM MONITORING,article
283,21100405003,SCIENCE BULLETIN,journal,20959273,"1,983",Q1,112,365,833,12806,5639,616,"7,21","35,08",Netherlands,Western Europe,Elsevier BV,2015-2020,Multidisciplinary (Q1),"8,832",11.780,0.0164,,https://doi.org/10.1016/j.scib.2019.09.011,2019,Peng Jia and Hong Xue and Shiyong Liu and Hao Wang and Lijian Yang and Therese Hesketh and Lu Ma and Hongwei Cai and Xin Liu and Yaogang Wang and Youfa Wang,OPPORTUNITIES AND CHALLENGES OF USING BIG DATA FOR GLOBAL HEALTH,article
284,29348,ENERGY,journal,03605442,"1,961",Q1,193,2315,6498,109602,49084,6476,"7,55","47,34",United Kingdom,Western Europe,Elsevier Ltd.,1976-2020,"Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1); Energy (miscellaneous) (Q1); Fuel Technology (Q1); Industrial and Manufacturing Engineering (Q1); Management, Monitoring, Policy and Law (Q1); Mechanical Engineering (Q1); Modeling and Simulation (Q1); Pollution (Q1); Renewable Energy, Sustainability and the Environment (Q1)","103,367",7.147,0.11575,"Measuring real-world fuel consumption of light duty vehicles can be challenging due to the limited collection of actual data. In this paper, we use big data retrieved from the record of real-world fuel consumptions of different brands of vehicles in different areas (n = 106,809 samples from 201 brands of vehicles and 34 cities) in China to build up a real-world fuel consumption rate (RFCR) model to estimate the fuel consumption given the driving conditions and figure out the main factors that affect actual fuel consumption in the real world. We find the average deviation of actual fuel consumptions and the fitting results of RFCR model is 4.22% , which does not significantly differ from zero, and the fuel consumptions calculated by RFCR model tend to be 1.40 L/100 km (about 25%) higher than the official reported data. Furthermore, we find that annual average temperature and altitude factors significantly influence the fuel consumption rate. The results indicate that there is a real world performance discrepancy between the theoretical fuel consumption released by authorities and that in the real world, and some green behaviors (choose light duty vehicles, reduce the use of air conditioning and change to manual transmission type) can reduce energy consumption of vehicles.",https://doi.org/10.1016/j.energy.2019.116388,2020,Tian Wu and Xiao Han and M. Mocarlo Zheng and Xunmin Ou and Hongbo Sun and Xiong Zhang,IMPACT FACTORS OF THE REAL-WORLD FUEL CONSUMPTION RATE OF LIGHT DUTY VEHICLES IN CHINA,article
285,78796,FIELD CROPS RESEARCH,journal,03784290,"1,951",Q1,150,191,798,10669,4752,795,"5,39","55,86",Netherlands,Western Europe,Elsevier,1978-2020,Agronomy and Crop Science (Q1); Soil Science (Q1),"24,118",5.224,0.01607,"Yield gaps and water productivity are key indicators to monitor the progress towards more sustainable and productive cropping systems. Individual farmers are collecting increasing amounts of data (‘big data’), which can help monitor the process of sustainable intensification at local level. In this study, we build upon such data to quantify the magnitude and identify the biophysical and management determinants of on-farm yield gaps and water productivity for the main arable crops cultivated in the Netherlands. The analysis focused on ware, seed and starch potatoes, sugar beet, spring onion, winter wheat and spring barley and covered the period 2015–2017. A crop modelling approach based on crop coefficients (kc) and daily weather data was used to estimate the potential yield (Yp), radiation intercepted and potential evapotranspiration (ETP) for each crop. Yield gaps were estimated to be ca. 10% of Yp for sugar beet, 25–30% of Yp for ware, seed and starch potato and spring barley, and 35–40% of Yp for spring onion and winter wheat. Variation in actual yields was associated with water availability in key periods of the growing season as well as with sowing and harvest dates. However, the R2 of the fitted regressions was rather low (20–49%). Current levels of crop water productivity ranged between 13 kg DM ha−1 mm−1 for spring barley, ca. 15 kg DM ha−1 mm−1 for seed potato, spring onion and winter wheat, 23 kg DM ha−1 mm−1 for ware potato and ca. 25 kg DM ha−1 mm−1 for starch potato and sugar beet. These values are about half of their potential, but increasing actual water productivity further is restricted by rainfall amount and distribution. However, doing so should not be prioritized over reducing environmental impacts of these intensive cropping systems in the short-term and may require large investments from farm to regional levels in the long-term. Although these findings are most relevant to similar cropping systems in NW Europe, the underlying methods are generic and can be used to benchmark crop performance in other cropping systems. Based on this work, we argue that ‘big data’ are currently most useful to describe cropping systems at regional scale and derive benchmarks of farm performance but not as much to predict and explain crop yield variability in time and space.",https://doi.org/10.1016/j.fcr.2020.107828,2020,João Vasco Silva and Tomás R. Tenreiro and Léon Spätjens and Niels P.R. Anten and Martin K. {van Ittersum} and Pytrik Reidsma,CAN BIG DATA EXPLAIN YIELD VARIABILITY AND WATER PRODUCTIVITY IN INTENSIVE CROPPING SYSTEMS?,article
286,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Researches about the fusion application of Big Data and blockchain have appeared for a long time, many information service providers have launched information service business based on Big Data and blockchain (hereafter, ISBD). However, in the green agri-food area, the ISBD application does not popularized. A vital reason is that many decision makers do not know how to make an optimal investment decision and coordinate chain members after adopting ISBD. The core of this problem is to study the issue of investment decision and coordination in a green agri-food supply chain. To solve this problem, firstly, combining with the status of Chinese agricultural development, we proposed a more suitable supply chain structure in the fusion application environment of Big Data and blockchain. Then, we chose a green agri-food supply chain with one producer and one retailer as research object and revised the demand function. Afterwards, considering the changes of agri-food freshness and greenness, we built and analysed the benefit models of producer and retailer before and after using ISBD, and then a cost-sharing and revenue-sharing contract was put forward to coordinate the supply chain. Findings: 1) When the total investment cost payed by producer and retailer is in a certain range, using ISBD will help chain members gain more benefits. 2) If chain members want to gain more benefits after using ISBD, they should try their best to optimize costs by extracting valuable information. Results can offer a theoretical guidance for producer and retailer in investing in ISBD, pricing decision and supply chain coordination after applying ISBD.",https://doi.org/10.1016/j.jclepro.2020.123646,2020,Pan Liu and Yue Long and Hai-Cao Song and Yan-Dong He,INVESTMENT DECISION AND COORDINATION OF GREEN AGRI-FOOD SUPPLY CHAIN CONSIDERING INFORMATION SERVICE BASED ON BLOCKCHAIN AND BIG DATA,article
287,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"With the development of the integrated energy Internet, energy structure optimization and emission reduction have led to higher requirements for developing various energy sources to enable coordinated and sustainable development. However, data-mining methods are rarely used to study the coordination of multi-energy generation in published research results. In this study, from the perspective of power industry emissions, coordinated generation of various energy sources, and balance of power generation and consumption, a data-mining algorithm was used to analyze the development of thermal power, hydropower, wind power, waste heat, gas, and other power sources. The chi-square automatic interaction detection tree (CHAID), logistic regression, and two-step clustering methods were applied. The results show that: a) CO2 and SO2 emissions were mainly affected by thermal power generation, whereas NOx emissions were jointly affected by thermal power, garbage power, and gas-fired power, and the emissions of various pollutants increased with an increase in power consumption. The optimal power-generation scheme under minimum emission can be obtained. b) There was a strong correlation between thermal power generation and residential electricity consumption, and renewable energy (wind energy, photovoltaic, hydropower) exhibited the highest correlation with the electricity consumption of the tertiary industry, which indicates that renewable energy generation can be promoted by managing electricity consumption in the tertiary industry. c) When the electricity demand of all users was small, the proportion of renewable energy power generation increased; in contrast, the thermal power generation was larger. This indicates the importance of improving the sustainable and stable power supply of renewable energy. This study provides a data analysis model for the coordinated development of multiple energies, which will contribute to the decision-making basis for controlling power emissions, improving the utilization rate of renewable energy, and optimizing the energy structure.",https://doi.org/10.1016/j.jclepro.2021.128154,2021,Dongfang Ren and Xiaopeng Guo and Cunbin Li,RESEARCH ON BIG DATA ANALYSIS MODEL OF MULTI ENERGY POWER GENERATION CONSIDERING POLLUTANT EMISSION—EMPIRICAL ANALYSIS FROM SHANXI PROVINCE,article
288,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"The future of humanity depends increasingly on the performance of cities. Big data provide new and powerful ways of studying and improving coupled urban environmental, social, and economic systems to achieve urban sustainability. However, the term big data has been defined variably, and its urban applications have so far been sporadic in terms of research topic and location. A comprehensive review of big data-based urban environment, society, and sustainability (UESS) research is much needed. The aim of this study was to summarize the big data-based UESS research using a systematic review approach in combination with bibliometric and thematic analyses. The results showed that the numbers of publications and citations of related articles have been increasing exponentially in recent years. The most frequently used big data in UESS research are human behavior data, and the major analytical methods are of five types: classification, clustering, regression, association rules, and social network analysis. The major research topics of big data-based UESS research include urban mobility, urban land use and planning, environmental sustainability, public health and safety, social equity, tourism, resources and energy utilization, real estate, and retail, accommodation and catering. Big data benefit UESS research by proving a people-oriented perspective, timely and real-time information, and fine-resolution spatial dynamics. In addition, several obstacles were identified to applying big data in UESS research, which are related to data quality and acquisition, data storage and management, data security and privacy, data cleaning and preprocessing, and data analysis and information mining. To move forward, future research should integrate multiple big data sources, develop and utilize new methods such as deep learning and cloud computing, and expand the application fields to focus on the interactions between human activities and urban environments. This review can contribute to understanding the current situation of big data-based UESS research, and provide a reference for studies of this topic in the future.",https://doi.org/10.1016/j.jclepro.2020.123142,2020,Lingqiang Kong and Zhifeng Liu and Jianguo Wu,A SYSTEMATIC REVIEW OF BIG DATA-BASED URBAN SUSTAINABILITY RESEARCH: STATE-OF-THE-SCIENCE AND FUTURE DIRECTIONS,article
289,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Smart manufacturing has received increased attention from academia and industry in recent years, as it provides competitive advantage for manufacturing companies making industry more efficient and sustainable. As one of the most important technologies for smart manufacturing, big data analytics can uncover hidden knowledge and other useful information like relations between lifecycle decisions and process parameters helping industrial leaders to make more-informed business decisions in complex management environments. However, according to the literature, big data analytics and smart manufacturing were individually researched in academia and industry. To provide theoretical foundations for the research community to further develop scientific insights in applying big data analytics to smart manufacturing, it is necessary to summarize the existing research progress and weakness. In this paper, through combining the key technologies of smart manufacturing and the idea of ubiquitous servitization in the whole lifecycle, the term of sustainable smart manufacturing was coined. A comprehensive overview of big data in smart manufacturing was conducted, and a conceptual framework was proposed from the perspective of product lifecycle. The proposed framework allows analyzing potential applications and key advantages, and the discussion of current challenges and future research directions provides valuable insights for academia and industry.",https://doi.org/10.1016/j.jclepro.2018.11.025,2019,Shan Ren and Yingfeng Zhang and Yang Liu and Tomohiko Sakao and Donald Huisingh and Cecilia M.V.B. Almeida,"A COMPREHENSIVE REVIEW OF BIG DATA ANALYTICS THROUGHOUT PRODUCT LIFECYCLE TO SUPPORT SUSTAINABLE SMART MANUFACTURING: A FRAMEWORK, CHALLENGES AND FUTURE RESEARCH DIRECTIONS",article
290,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Big data analytics is becoming very popular concept in academia as well as in industry. It has come up with new decision tools to design data-driven supply chains. The manufacturing industry is under huge pressure to integrate sustainable practices into their overall business for sustainbale operations management. The purpose of this study is to analyse the predictors of sustainable business performance through big data analytics in the context of developing countries. Data was collected from manufacturing firms those have adopted sustainable practices. A hybrid Structural Equation Modelling - Artificial Neural Network model is used to analyse 316 responses of Indian professional experts. Factor analysis results shows that management and leadership style, state and central-government policy, supplier integration, internal business process, and customer integration have a significant influence on big data analytics and sustainability practices. Furthermore, the results obtained from structural equation modelling were feed as input to the artificial neural network model. The study findings shows that management and leadership style, state and central-government policy as the two most important predictors of big data analytics and sustainability practices. The results provide unique insights into manufacturing firms to improve their sustainable business performance from an operations management viewpoint. The study provides theoretical and practical insights into big data implementation issues in accomplishing sustainability practices in business organisations of emerging economies.",https://doi.org/10.1016/j.jclepro.2019.03.181,2019,Rakesh D. Raut and Sachin Kumar Mangla and Vaibhav S. Narwane and Bhaskar B. Gardas and Pragati Priyadarshinee and Balkrishna E. Narkhede,LINKING BIG DATA ANALYTICS AND OPERATIONAL SUSTAINABILITY PRACTICES FOR SUSTAINABLE BUSINESS MANAGEMENT,article
291,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Today, in many organizations, the debate about the difference in core capabilities has become an important factor for market competition. Companies, based on the field of activity, decide to strengthen some of their capabilities, capacities, and expertise. Therefore, the focus of an organization on the strengths and efforts to develop its sustainability will lead to a competitive advantage in the marketplace. Due to changes in environmental factors, organizations have focused on carbon emissions in procurement and transportation that have the highest carbon footprint. This paper proposes a multi-objective, eco-sustainability model for a supply chain. The objectives are to minimize overall costs, maximize the efficiency of transportation vehicles and minimize information fraud in the process of information sharing within supply chain elements. Big data is considered in the amount of information exchanged between customers and other elements of the proposed supply chain; since there are frauds in information sharing then using big data 5Vs the model is adapted to control the cost of information loss leading to customer dissatisfaction. Since uncertainty is inevitable in the real environments, in this research hybrid uncertainty is considered. Because two sources of uncertainty are considered in most of the parameters, thus it is necessary to robustify the decision-making process. The model is a mixed integer nonlinear program including big data for an optimal sustainable procurement and transportation decision. A heuristic method is used to solve the big data problem that makes use of a robust fuzzy stochastic programming approach. The proposed model can prevent disturbances by using a scenario-based stochastic programming approach. An effective hybrid robust fuzzy stochastic method is also employed for controlling uncertainty in parameters and risk taking out of outbound decisions. To solve the multi-objective model, augmented ε-constraint method is utilized. The model performance is investigated in a comprehensive computational study.",https://doi.org/10.1016/j.jclepro.2020.120640,2020,Hadi Gholizadeh and Hamed Fazlollahtabar and Mohammad Khalilzadeh,A ROBUST FUZZY STOCHASTIC PROGRAMMING FOR SUSTAINABLE PROCUREMENT AND LOGISTICS UNDER HYBRID UNCERTAINTY USING BIG DATA,article
292,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Remanufacturing is deemed to be an effective method for recycling resources, achieving sustainable production. However, little importance of remanufacturing has been attached in PLM. Surely, there are many problems in implementation of the remanufacturing strategy, such as inability to effectively reduce uncertainty, lack of product multi-life-cycle remanufacturing process tracking management, lack of smart enabling technology application in the full lifecycle that focusing on multi-life-cycle remanufacturing. After analyzing the reasons, through integrating smart enabling technologies, a new PLM paradigm focusing on the multi-life-cycle remanufacturing process: Big Data driven Hierarchical Digital Twin Predictive Remanufacturing (BDHDTPREMfg) is proposed. And the definition of BDHDTPREMfg is proposed. A big data driven layered architecture and the hierarchical CPS-Digital-Twin(CPSDT) reconfiguration control mechanism of BDHDTPREMfg are respectively developed. Then, this paper presents an application scenario of BDHDTPREMfg to validate the feasibility and effectiveness. Based on the above application analysis, the benefits of penetrating BDHDTPREMfg into the entire lifecycle are demonstrated. The summary of this paper and future research work is discussed in the end.",https://doi.org/10.1016/j.jclepro.2019.119299,2020,Yankai Wang and Shilong Wang and Bo Yang and Lingzi Zhu and Feng Liu,"BIG DATA DRIVEN HIERARCHICAL DIGITAL TWIN PREDICTIVE REMANUFACTURING PARADIGM: ARCHITECTURE, CONTROL MECHANISM, APPLICATION SCENARIO AND BENEFITS",article
293,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Big data has caused the scientific community to re-examine the scientific research methodologies and has triggered a revolution in scientific thinking. As a branch of scientific research, production safety management is also exploring methods to take advantage of big data. This research aims to provide a theoretical basis for promoting the application of big data in production safety management. First, four different types of production safety management paradigms were identified, namely small-data-based, static-oriented, interpretation-based and causal-oriented paradigm, and the challenges to these paradigms in the presence of big data were introduced. Second, the opportunities of employing big data in production safety management were identified from four aspects, including better predict the future production safety phenomena, promote production safety management highlight relevance, achieve the balance between deductive and inductive approaches and promote the interdisciplinary development of production safety management. Third, the paradigm shifting trend of production safety management was concluded, and the discipline foundation of the new paradigm was considered as the integration of data science, production management and safety science. Fourth, a new big-data-driven production safety management paradigm was developed, which consists of the logical line of production safety management, the macro-meso-micro data spectrum, the key big data analytics, and the four-dimensional morphology. At last, the strengths (e.g., supporting better-informed safety description, safety inquisition, safety prediction) and future research direction (e.g., theory research focuses on safety-related data mining/capturing/cleansing) of the new paradigm were discussed. The research results not only can provide theoretical and practical basis for big-data-driven production safety management, but also can offer advice to managerial consideration and scholarly investigation.",https://doi.org/10.1016/j.jclepro.2019.05.245,2019,Lang Huang and Chao Wu and Bing Wang,"CHALLENGES, OPPORTUNITIES AND PARADIGM OF APPLYING BIG DATA TO PRODUCTION SAFETY MANAGEMENT: FROM A THEORETICAL PERSPECTIVE",article
294,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"This paper presents a multi-objective optimization model for a green supply chain management scheme that minimizes the inherent risk occurred by hazardous materials, associated carbon emission and economic cost. The model related parameters are capitalized on a big data analysis. Three scenarios are proposed to improve green supply chain management. The first scenario divides optimization into three options: the first involves minimizing risk and then dealing with carbon emissions (and thus economic cost); the second minimizes both risk and carbon emissions first, with the ultimate goal of minimizing overall cost; and the third option attempts to minimize risk, carbon emissions, and economic cost simultaneously. This paper provides a case study to verify the optimization model. Finally, the limitations of this research and approach are discussed to lay a foundation for further improvement.",https://doi.org/10.1016/j.jclepro.2016.03.006,2017,Rui Zhao and Yiyun Liu and Ning Zhang and Tao Huang,AN OPTIMIZATION MODEL FOR GREEN SUPPLY CHAIN MANAGEMENT BY USING A BIG DATA ANALYTIC APPROACH,article
295,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"The purpose of this paper is to propose and test a theoretical framework to explain resilience in supply chain networks for sustainability using unstructured Big Data, based upon 36,422 items gathered in the form of tweets, news, Facebook, WordPress, Instagram, Google+, and YouTube, and structured data, via responses from 205 managers involved in disaster relief activities in the aftermath of Nepal earthquake in 2015. The paper uses Big Data analysis, followed by a survey which was analyzed using content analysis and confirmatory factor analysis (CFA). The results of the analysis suggest that swift trust, information sharing and public–private partnership are critical enablers of resilience in supply chain networks. The current study used cross-sectional data. However the hypotheses of the study can be tested using longitudinal data to attempt to establish causality. The article advances the literature on resilience in disaster supply chain networks for sustainability in that (i) it suggests the use of Big Data analysis to propose and test particular frameworks in the context of resilient supply chains that enable sustainability; (ii) it argues that swift trust, public private partnerships, and quality information sharing link to resilience in supply chain networks; and (iii) it uses the context of Nepal, at the moment of the disaster relief activities to provide contemporaneous perceptions of the phenomenon as it takes place.",https://doi.org/10.1016/j.jclepro.2016.03.059,2017,Thanos Papadopoulos and Angappa Gunasekaran and Rameshwar Dubey and Nezih Altay and Stephen J. Childe and Samuel Fosso-Wamba,THE ROLE OF BIG DATA IN EXPLAINING DISASTER RESILIENCE IN SUPPLY CHAINS FOR SUSTAINABILITY,article
296,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"With continuous collaborative research in sensor technology, communication technology, plant science, computer science and engineering science, Internet of Things (IoT) in agriculture has made a qualitative leap through environmental sensor networks, non-destructive imaging, spectral analysis, robotics, machine vision and laser radar technology. Physical and chemical analysis can continuously obtain environmental data, experimental metadata (including text, image and spectral, 3D point cloud and real-time growth data) through integrated automation platform equipment and technical means. Based on data on multi-scale, multi-environmental and multi-mode plant traits that constitute big data on plant phenotypes, genotype–phenotype–envirotype relationship in the omics system can be explored deeply. Detailed information on the formation mechanism of specific biological traits can promote the process of functional genomics, plant molecular breeding and efficient cultivation. This study summarises the development background, research process and characteristics of high-throughput plant phenotypes. A systematic review of the research progress of IoT in agriculture and plant high-throughput phenotypes is conducted, including the acquisition and analysis of plant phenotype big data, phenotypic trait prediction and multi-recombination analysis based on plant phenomics. This study proposes key techniques for current plant phenotypes, and looks forward to the research on plant phenotype detection technology in the field environment, fusion and data mining of plant phenotype multivariate data, simultaneous observation of multi-scale phenotype platform and promotion of a comprehensive high-throughput phenotype technology.",https://doi.org/10.1016/j.jclepro.2020.123651,2021,Jiangchuan Fan and Ying Zhang and Weiliang Wen and Shenghao Gu and Xianju Lu and Xinyu Guo,THE FUTURE OF INTERNET OF THINGS IN AGRICULTURE: PLANT HIGH-THROUGHPUT PHENOTYPIC PLATFORM,article
297,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"The energy industry is at a crossroads. Digital technological developments have the potential to change our energy supply, trade, and consumption dramatically. The new digitalization model is powered by the artificial intelligence (AI) technology. The integration of energy supply, demand, and renewable sources into the power grid will be controlled autonomously by smart software that optimizes decision-making and operations. AI will play an integral role in achieving this goal. This study focuses on the use of AI techniques in the energy sector. This study aims to present a realistic baseline that allows researchers and readers to compare their AI efforts, ambitions, new state-of-the-art applications, challenges, and global roles in policymaking. We covered three major aspects, including: i) the use of AI in solar and hydrogen power generation; (ii) the use of AI in supply and demand management control; and (iii) recent advances in AI technology. This study explored how AI techniques outperform traditional models in controllability, big data handling, cyberattack prevention, smart grid, IoT, robotics, energy efficiency optimization, predictive maintenance control, and computational efficiency. Big data, the development of a machine learning model, and AI will play an important role in the future energy market. Our study’s findings show that AI is becoming a key enabler of a complex, new and data-related energy industry, providing a key magic tool to increase operational performance and efficiency in an increasingly cut-throat environment. As a result, the energy industry, utilities, power system operators, and independent power producers may need to focus more on AI technologies if they want meaningful results to remain competitive. New competitors, new business strategies, and a more active approach to customers would require informed and flexible regulatory engagement with the associated complexities of customer safety, privacy, and information security. Given the pace of development in information technology, AI and data analysis, regulatory approvals for new services and products in the new Era of digital energy markets can be enforced as quickly and efficiently as possible.",https://doi.org/10.1016/j.jclepro.2021.125834,2021,Tanveer Ahmad and Dongdong Zhang and Chao Huang and Hongcai Zhang and Ningyi Dai and Yonghua Song and Huanxin Chen,"ARTIFICIAL INTELLIGENCE IN SUSTAINABLE ENERGY INDUSTRY: STATUS QUO, CHALLENGES AND OPPORTUNITIES",article
298,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"Self-reported life satisfaction of China's population has not improved as much as expected during the economic boom, which was accompanied by a significant decline in environmental performance. Is environmental pollution the culprit for the lagging subjective well-being? To explore this issue, this paper adopts the sentiment analysis method to construct a real-time daily subjective well-being metric at the city level based on the big data of online search traces. Using daily data from 13 Chinese cities centred on Beijing between August 2014 and December 2019, we look at the corelation between subjective well-being and air pollution and the heterogeneity in this relationship based on two separate identification strategies. We find that air pollutants are negatively correlated with subjective well-being, and well-being tends to decline more from pollution during hot seasons. In addition, residents in wealthier regions tend to be more sensitive to air pollution. This result may be explained by the differences in the subjective perception of air pollution and personal preferences at different levels of income. These findings provide information about the concerns of the public to the central government, thereby helping it take appropriate actions to respond to the dynamics of subjective well-being.",https://doi.org/10.1016/j.jclepro.2022.134380,2022,Lu Cheng and Zhifu Mi and Yi-Ming Wei and Shidong Wang and Klaus Hubacek,DIRTY SKIES LOWER SUBJECTIVE WELL-BEING,article
299,19167,JOURNAL OF CLEANER PRODUCTION,journal,09596526,"1,937",Q1,200,5126,10603,304498,103295,10577,"9,56","59,40",United Kingdom,Western Europe,Elsevier Ltd.,1993-2021,"Environmental Science (miscellaneous) (Q1); Industrial and Manufacturing Engineering (Q1); Renewable Energy, Sustainability and the Environment (Q1); Strategy and Management (Q1)","170,352",9.297,0.18299,"In the age of “Internet+”, many Internet service platforms (ISPs) in China have been widely introduced to the closed-loop supply chain (CLSC). To further study the role of the Internet service platform, this paper considers a CLSC composed of a manufacturer, a retailer and an Internet service platform who invests in research and development (R&D), advertising and Big Data marketing, and develops the goodwill dynamic model based on the differential game theory. The construction of a goodwill dynamic model has two purposes, namely, to increase sales and the return rate. The optimal decisions for 3 players under two different cooperative scenarios are obtained, namely, the retailer payment scenario (scenario D) and the manufacturer cost-sharing scenario (scenario S). The supply chain members gain more profit or achieve a higher level of goodwill for products under certain conditions, i.e., a high residual value from remanufacturing, a high sharing rate of residual value from the retailer's recycled products, and a low recycling cost. Interestingly, the wholesale price increases with the residual value of recycled products when goodwill effectiveness is low, while the price declines when goodwill effectiveness is high. After comparing two cooperative scenarios, the result shows that an Internet service platform will invest more in Big Data marketing under the manufacturer cost-sharing scenario, and cooperation between the manufacturer and the Internet service platform can help improve the goodwill of enterprises or products. Moreover, the manufacturer cost-sharing scenario is payoff-Pareto-improving in most cases through the coordination of a cost-sharing rate, and the effectiveness of Big Data marketing exerts a positive effect on goodwill and the development of the industry. In addition, the retailer has “free rider” tendencies in the manufacturer cost-sharing scenario. The results encourage more enterprises to enhance the value of goodwill through cooperation with Internet service platforms because Internet service platforms conveniently utilize Big Data marketing to increase the sales of products and the collecting rate of used products, which in turn helps environmental sustainability.",https://doi.org/10.1016/j.jclepro.2019.01.310,2019,Zehua Xiang and Minli Xu,DYNAMIC COOPERATION STRATEGIES OF THE CLOSED-LOOP SUPPLY CHAIN INVOLVING THE INTERNET SERVICE PLATFORM,article
300,21100318415,COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL,journal,20010370,"1,908",Q1,45,357,255,28093,2022,255,"7,89","78,69",Sweden,Western Europe,Research Network of Computational and Structural Biotechnology,2012-2020,Biochemistry (Q1); Biophysics (Q1); Biotechnology (Q1); Computer Science Applications (Q1); Genetics (Q1); Structural Biology (Q2),"3,620",7.271,0.00677,"We review the current applications of artificial intelligence (AI) in functional genomics. The recent explosion of AI follows the remarkable achievements made possible by “deep learning”, along with a burst of “big data” that can meet its hunger. Biology is about to overthrow astronomy as the paradigmatic representative of big data producer. This has been made possible by huge advancements in the field of high throughput technologies, applied to determine how the individual components of a biological system work together to accomplish different processes. The disciplines contributing to this bulk of data are collectively known as functional genomics. They consist in studies of: i) the information contained in the DNA (genomics); ii) the modifications that DNA can reversibly undergo (epigenomics); iii) the RNA transcripts originated by a genome (transcriptomics); iv) the ensemble of chemical modifications decorating different types of RNA transcripts (epitranscriptomics); v) the products of protein-coding transcripts (proteomics); and vi) the small molecules produced from cell metabolism (metabolomics) present in an organism or system at a given time, in physiological or pathological conditions. After reviewing main applications of AI in functional genomics, we discuss important accompanying issues, including ethical, legal and economic issues and the importance of explainability.",https://doi.org/10.1016/j.csbj.2021.10.009,2021,Claudia Caudai and Antonella Galizia and Filippo Geraci and Loredana {Le Pera} and Veronica Morea and Emanuele Salerno and Allegra Via and Teresa Colombo,AI APPLICATIONS IN FUNCTIONAL GENOMICS,article
301,21100318415,COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL,journal,20010370,"1,908",Q1,45,357,255,28093,2022,255,"7,89","78,69",Sweden,Western Europe,Research Network of Computational and Structural Biotechnology,2012-2020,Biochemistry (Q1); Biophysics (Q1); Biotechnology (Q1); Computer Science Applications (Q1); Genetics (Q1); Structural Biology (Q2),"3,620",7.271,0.00677,"Infectious diseases, including vector-borne diseases transmitted by arthropods, are a leading cause of morbidity and mortality worldwide. In the era of big data, addressing broad-scale, fundamental questions regarding the complex dynamics of these diseases will increasingly require the integration of diverse datasets to produce new biological knowledge. This review provides a current snapshot of the systematic assessment of the relationships between microbial pathogens, arthropod vectors and mammalian hosts using data mining and machine learning. We employ PRISMA to identify 32 key papers relevant to this topic. Our analysis shows an increasing use of data mining and machine learning tasks and techniques, including prediction, classification, clustering, association rules mining, and deep learning, over the last decade. However, it also reveals a number of critical challenges in applying these to the study of vector-host-pathogen interactions at various systems biology levels. Here, relevant studies, current limitations and future directions are discussed. Furthermore, the quality of data in relevant papers was assessed using the FAIR (Findable, Accessible, Interoperable, Reusable) compliance criteria to evaluate and encourage reproducibility and shareability of research outcomes. Although shortcomings in their application remain, data mining and machine learning have significant potential to break new ground in understanding fundamental aspects of vector-host-pathogen relationships and their application in this field should be encouraged. In particular, while predictive modeling, feature engineering and supervised machine learning are already being used in the field, other data mining and machine learning methods such as deep learning and association rules analysis lag behind and should be implemented in combination with established methods to accelerate hypothesis and knowledge generation in the domain.",https://doi.org/10.1016/j.csbj.2020.06.031,2020,Diing D.M. Agany and Jose E. Pietri and Etienne Z. Gnimpieba,ASSESSMENT OF VECTOR-HOST-PATHOGEN RELATIONSHIPS USING DATA MINING AND MACHINE LEARNING,article
302,21100318415,COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL,journal,20010370,"1,908",Q1,45,357,255,28093,2022,255,"7,89","78,69",Sweden,Western Europe,Research Network of Computational and Structural Biotechnology,2012-2020,Biochemistry (Q1); Biophysics (Q1); Biotechnology (Q1); Computer Science Applications (Q1); Genetics (Q1); Structural Biology (Q2),"3,620",7.271,0.00677,"Big Data pervades nearly all areas of life sciences, yet the analysis of large integrated data sets remains a major challenge. Moreover, the field of life sciences is highly fragmented and, consequently, so is its data, knowledge, and standards. This, in turn, makes integrated data analysis and knowledge gathering across sub-fields a demanding task. At the same time, the integration of various research angles and data types is crucial for modelling the complexity of organisms and biological processes in a holistic manner. This is especially valid in the context of drug development and chemical safety assessment where computational methods can provide solutions for the urgent need of fast, effective, and sustainable approaches. At the same time, such computational methods require the development of methodologies suitable for an integrated and data centred Big Data view. Here we discuss Knowledge Graphs (KG) as a solution to a data centred analysis approach for drug and chemical development and safety assessment. KGs are knowledge bases, data analysis engines, and knowledge discovery systems all in one, allowing them to be used from simple data retrieval, over meta-analysis to complex predictive and knowledge discovery systems. Therefore, KGs have immense potential to advance the data centred approach, the re-usability, and informativity of data. Furthermore, they can improve the power of analysis, and the complexity of modelled processes, all while providing knowledge in a natively human understandable network data model.",https://doi.org/10.1016/j.csbj.2022.08.061,2022,Alisa Pavel and Laura A. Saarimäki and Lena Möbus and Antonio Federico and Angela Serra and Dario Greco,THE POTENTIAL OF A DATA CENTRED APPROACH & KNOWLEDGE GRAPH DATA REPRESENTATION IN CHEMICAL SAFETY AND DRUG DESIGN,article
303,17876,RADIOTHERAPY AND ONCOLOGY,journal,01678140,"1,892",Q1,157,470,1026,14846,5131,959,"5,14","31,59",Ireland,Western Europe,Elsevier Ireland Ltd,1983-2020,"Hematology (Q1); Oncology (Q1); Radiology, Nuclear Medicine and Imaging (Q1)","22,462",6.280,0.02494,"Big data are no longer an obstacle; now, by using artificial intelligence (AI), previously undiscovered knowledge can be found in massive data collections. The radiation oncology clinic daily produces a large amount of multisource data and metadata during its routine clinical and research activities. These data involve multiple stakeholders and users. Because of a lack of interoperability, most of these data remain unused, and powerful insights that could improve patient care are lost. Changing the paradigm by introducing powerful AI analytics and a common vision for empowering big data in radiation oncology is imperative. However, this can only be achieved by creating a clinical data science community in radiation oncology. In this work, we present why such a community is needed to translate multisource data into clinical decision aids.",https://doi.org/10.1016/j.radonc.2020.09.054,2020,Joanna Kazmierska and Andrew Hope and Emiliano Spezi and Sam Beddar and William H. Nailon and Biche Osong and Anshu Ankolekar and Ananya Choudhury and Andre Dekker and Kathrine Røe Redalen and Alberto Traverso,FROM MULTISOURCE DATA TO CLINICAL DECISION AIDS IN RADIATION ONCOLOGY: THE NEED FOR A CLINICAL DATA SCIENCE COMMUNITY,article
304,22377,VALUE IN HEALTH,journal,10983015,"1,859",Q1,103,211,572,8179,2291,532,"3,67","38,76",United Kingdom,Western Europe,Elsevier Ltd.,1998-2020,"Health Policy (Q1); Medicine (miscellaneous) (Q1); Public Health, Environmental and Occupational Health (Q1)","12,642",5.725,0.01786,,https://doi.org/10.1016/j.jval.2021.11.1002,2022,A Miracolo and M Mills and P Kanavos,POSB319 PREDICTIVE ANALYTIC TECHNIQUES AND BIG DATA FOR IMPROVED HEALTH OUTCOMES IN THE CONTEXT OF VALUE BASED HEALTH CARE AND COVERAGE DECISIONS: A SCOPING REVIEW,article
305,22377,VALUE IN HEALTH,journal,10983015,"1,859",Q1,103,211,572,8179,2291,532,"3,67","38,76",United Kingdom,Western Europe,Elsevier Ltd.,1998-2020,"Health Policy (Q1); Medicine (miscellaneous) (Q1); Public Health, Environmental and Occupational Health (Q1)","12,642",5.725,0.01786,"Next-generation sequencing (NGS) is considered to be a prominent example of “big data” because of the quantity and complexity of data it produces and because it presents an opportunity to use powerful information sources that could reduce clinical and health economic uncertainty at a patient level. One obstacle to translating NGS into routine health care has been a lack of clinical trials evaluating NGS technologies, which could be used to populate cost-effectiveness analyses (CEAs). A key question is whether big data can be used to partially support CEAs of NGS. This question has been brought into sharp focus with the creation of large national sequencing initiatives. In this article we summarize the main methodological and practical challenges of using big data as an input into CEAs of NGS. Our focus is on the challenges of using large observational datasets and cohort studies and linking these data to the genomic information obtained from NGS, as is being pursued in the conduct of large genomic sequencing initiatives. We propose potential solutions to these key challenges. We conclude that the use of genomic big data to support and inform CEAs of NGS technologies holds great promise. Nevertheless, health economists face substantial challenges when using these data and must be cognizant of them before big data can be confidently used to produce evidence on the cost-effectiveness of NGS.",https://doi.org/10.1016/j.jval.2018.06.016,2018,Sarah Wordsworth and Brett Doble and Katherine Payne and James Buchanan and Deborah A. Marshall and Christopher McCabe and Dean A. Regier,USING “BIG DATA” IN THE COST-EFFECTIVENESS ANALYSIS OF NEXT-GENERATION SEQUENCING TECHNOLOGIES: CHALLENGES AND POTENTIAL SOLUTIONS,article
306,22377,VALUE IN HEALTH,journal,10983015,"1,859",Q1,103,211,572,8179,2291,532,"3,67","38,76",United Kingdom,Western Europe,Elsevier Ltd.,1998-2020,"Health Policy (Q1); Medicine (miscellaneous) (Q1); Public Health, Environmental and Occupational Health (Q1)","12,642",5.725,0.01786,,https://doi.org/10.1016/j.jval.2019.04.303,2019,Z.G. Hui and Q. Guo and W.Z. Shi and M.C. Gong and C. Liu and H. Xu and H. Li,PCN181 THE NATIONAL CANCER BIG DATA PLATFORM OF CHINA: VISION AND STATUS,article
307,22350,INFECTIOUS DISEASE CLINICS OF NORTH AMERICA,journal,08915520,"1,854",Q1,96,57,190,4523,1000,168,"5,20","79,35",United Kingdom,Western Europe,W.B. Saunders Ltd,1987-2020,Infectious Diseases (Q1); Microbiology (medical) (Q1),"4,090",5.982,0.00687,,https://doi.org/10.1016/j.idc.2019.05.009,2019,Aadia I. Rana and Michael J. Mugavero,HOW BIG DATA SCIENCE CAN IMPROVE LINKAGE AND RETENTION IN CARE,article
308,24931,AUTOMATION IN CONSTRUCTION,journal,09265805,"1,837",Q1,121,364,779,20472,7433,778,"9,16","56,24",Netherlands,Western Europe,Elsevier,1992-2020,Building and Construction (Q1); Civil and Structural Engineering (Q1); Control and Systems Engineering (Q1),"16,738",7.700,0.01309,"A building's strategic asset management (SAM) capability has traditionally been limited by its site-based management. With the emergence of needs from clients about delivering a long-term portfolio-based building asset management plan that minimizes the asset risk and optimizes the value of their asset portfolios, SAM Units have emerged as a new business form to provide various SAM services to their clients. However, the quality of their current data model is still hindered by many issues, such as missing important attributes and the lack of customized information flow guidance. In addition, there is a gap in integrating their existing data collection with various data sources and Building Information Modeling (BIM) to enhance their data quality. By evaluating a SAM Unit's portfolio case study, this paper identifies the factors limiting the quality of SAM Units' data model and develops a guide to integrating various data sources better. We develop a BIM-integrated portfolio-based SAM information flow framework and a detailed hierarchical portfolio-based non-geometric data structure. The proposed framework and data structure will help SAM professionals, building asset owners, and other facilities management professionals embrace the benefits of managing the portfolio-based SAM data.",https://doi.org/10.1016/j.autcon.2021.104070,2022,Zigeng Fang and Yan Liu and Qiuchen Lu and Michael Pitt and Sean Hanna and Zhichao Tian,BIM-INTEGRATED PORTFOLIO-BASED STRATEGIC ASSET DATA QUALITY MANAGEMENT,article
309,19532,ACCIDENT ANALYSIS AND PREVENTION,journal,00014575,"1,816",Q1,152,385,1041,20484,5984,1034,"5,55","53,21",United Kingdom,Western Europe,Elsevier Ltd.,1969-2020,"Human Factors and Ergonomics (Q1); Law (Q1); Public Health, Environmental and Occupational Health (Q1); Safety, Risk, Reliability and Quality (Q1)","25,323",4.993,0.0204,"Each year, 1.35 million people are killed on the world’s roads and another 20–50 million are seriously injured. Morbidity or serious injury from road traffic collisions is estimated to increase to 265 million people between 2015 and 2030. Current road safety management systems rely heavily on manual data collection, visual inspection and subjective expert judgment for their effectiveness, which is costly, time-consuming, and sometimes ineffective due to under-reporting and the poor quality of the data. A range of innovations offers the potential to provide more comprehensive and effective data collection and analysis to improve road safety. However, there has been no systematic analysis of this evidence base. To this end, this paper provides a systematic review of the state of the art. It identifies that digital technologies - Artificial Intelligence (AI), Machine-Learning, Image-Processing, Internet-of-Things (IoT), Smartphone applications, Geographic Information System (GIS), Global Positioning System (GPS), Drones, Social Media, Virtual-reality, Simulator, Radar, Sensor, Big Data – provide useful means for identifying and providing information on road safety factors including road user behaviour, road characteristics and operational environment. Moreover, the results show that digital technologies such as AI, Image processing and IoT have been widely applied to enhance road safety, due to their ability to automatically capture and analyse data while preventing the possibility of human error. However, a key gap in the literature remains their effectiveness in real-world environments. This limits their potential to be utilised by policymakers and practitioners.",https://doi.org/10.1016/j.aap.2021.106543,2022,Mehran {Eskandari Torbaghan} and Manu Sasidharan and Louise Reardon and Leila C.W. Muchanga-Hvelplund,UNDERSTANDING THE POTENTIAL OF EMERGING DIGITAL TECHNOLOGIES FOR IMPROVING ROAD SAFETY,article
310,13120,SEMINARS IN ONCOLOGY,journal,00937754,"1,812",Q1,133,51,150,2969,690,124,"4,21","58,22",United Kingdom,Western Europe,W.B. Saunders Ltd,1974-2020,Hematology (Q1); Oncology (Q1),"5,713",4.929,0.00455,"Pediatric cancer is a rare disease with a low annual incidence, which presents a significant challenge in being able to collect enough data to fuel clinical discoveries. Big data registry trials hold promise to advance the study of pediatric cancers by allowing for the combination of traditional randomized controlled trials with the power of larger cohort sizes. The emergence of big data resources and data-sharing initiatives are becoming transformative for pediatric cancer diagnosis and treatment. This review discusses the uses of big data in pediatric cancer, existing pediatric cancer registry initiatives and research, the challenges in harmonizing these data to improve accessibility for study, and building pediatric data commons and other important future endeavors.",https://doi.org/10.1053/j.seminoncol.2020.02.006,2020,Ajay Major and Suzanne M. Cox and Samuel L. Volchenboum,USING BIG DATA IN PEDIATRIC ONCOLOGY: CURRENT APPLICATIONS AND FUTURE DIRECTIONS,article
311,29295,JOURNAL OF TRANSPORT GEOGRAPHY,journal,09666923,"1,809",Q1,108,264,515,15444,2931,514,"5,21","58,50",United Kingdom,Western Europe,Elsevier BV,1993-2020,"Environmental Science (miscellaneous) (Q1); Geography, Planning and Development (Q1); Transportation (Q1)","11,719",4.986,0.01053,"Accessibility metrics are gaining momentum in public transportation planning and policy-making. However, critical user experience issues such as crowding discomfort and travel time unreliability are still not considered in those accessibility indicators. This paper aims to apply a methodology to build spatiotemporal crowding data and estimate travel time variability in a congested public transport network to improve accessibility calculations. It relies on using multiple big data sources available in most transit systems such as smart card and automatic vehicle location (AVL) data. São Paulo, Brazil, is used as a case study to show the impact of crowding and travel time variability on accessibility to jobs. Our results evidence a population-weighted average reduction of 56.8% in accessibility to jobs in a regular workday morning peak due to crowding discomfort, as well as reductions of 6.2% due to travel time unreliability and 59.2% when both are combined. The findings of this study can be of invaluable help to public transport planners and policymakers, as they show the importance of including both aspects in accessibility indicators for better decision making. Despite some limitations due to data quality and consistency throughout the study period, the proposed approach offers a new way to leverage big data in public transport to enhance policy decisions.",https://doi.org/10.1016/j.jtrangeo.2020.102671,2020,Renato Arbex and Claudio B. Cunha,ESTIMATING THE INFLUENCE OF CROWDING AND TRAVEL TIME VARIABILITY ON ACCESSIBILITY TO JOBS IN A LARGE PUBLIC TRANSPORT NETWORK USING SMART CARD BIG DATA,article
312,29295,JOURNAL OF TRANSPORT GEOGRAPHY,journal,09666923,"1,809",Q1,108,264,515,15444,2931,514,"5,21","58,50",United Kingdom,Western Europe,Elsevier BV,1993-2020,"Environmental Science (miscellaneous) (Q1); Geography, Planning and Development (Q1); Transportation (Q1)","11,719",4.986,0.01053,"This paper aims to estimate the causal effect of accidents on traffic congestion and vice versa. In order to identify both effects of this two-way relationship, I use dynamic panel data techniques and open access ‘big data’ of highway traffic and accidents in England for the period 2012–2014. The research design is based on the daily-and-hourly specific mean reversion pattern of highway traffic, which can be used to define a recurrent congestion benchmark. Using this benchmark, I am able to identify the causal effect of accidents on non-recurrent traffic congestion. A positive relationship between traffic congestion and road accidents would yield multiplicative benefits for policies that aim at reducing either of these issues. Additionally, I explore the duration of the effect of an accident on congestion, the ‘rubbernecking’ effect, as well as heterogeneous effects in the most congested highway segments. Then, I test the use of methods which employ the bulk of information in big data and other methods using a very reduced sample. In my application, both approaches produce similar results. Finally, I find a non-linear negative effect of traffic congestion on the probability of an accident.",https://doi.org/10.1016/j.jtrangeo.2017.10.006,2019,Ilias Pasidis,CONGESTION BY ACCIDENT? A TWO-WAY RELATIONSHIP FOR HIGHWAYS IN ENGLAND,article
313,29295,JOURNAL OF TRANSPORT GEOGRAPHY,journal,09666923,"1,809",Q1,108,264,515,15444,2931,514,"5,21","58,50",United Kingdom,Western Europe,Elsevier BV,1993-2020,"Environmental Science (miscellaneous) (Q1); Geography, Planning and Development (Q1); Transportation (Q1)","11,719",4.986,0.01053,"This paper considers the implications of so-called ‘big data’ for the analysis, modelling and planning of transport systems. The primary conceptual focus is on the needs of the practical context of medium-term planning and decision-making, from which perspective the paper seeks to achieve three goals: (i) to try to identify what is truly ‘special’ about big data; (ii) to provoke debate on the future relationship between transport planning and big data; and (iii) to try to identify promising themes for research and application. Differences in the information that can be derived from the data compared to more traditional surveys are discussed, and the respects in which they may impact on the role of models in supporting transport planning and decision-making are identified. It is argued that, over time, changes to the nature of data may lead to significant differences in both modelling approaches and in the expectations placed upon them. Furthermore, it is suggested that the potential widespread availability of data to commercial actors and travellers will affect the performance of the transport systems themselves, which might be expected to have knock-on effects for planning functions. We conclude by proposing a series of research challenges that we believe need to be addressed and warn against adaptations based on minimising change from the status quo.",https://doi.org/10.1016/j.jtrangeo.2017.11.004,2019,Dave Milne and David Watling,BIG DATA AND UNDERSTANDING CHANGE IN THE CONTEXT OF PLANNING TRANSPORT SYSTEMS,article
314,21100907125,ISCIENCE,journal,25890042,"1,805",Q1,27,1073,724,65016,3676,717,"5,08","60,59",United States,Northern America,Elsevier Inc.,2018-2020,Multidisciplinary (Q1),"5,235",5.458,0.0123,"Summary
Early quantitative structure-activity relationship (QSAR) technologies have unsatisfactory versatility and accuracy in fields such as drug discovery because they are based on traditional machine learning and interpretive expert features. The development of Big Data and deep learning technologies significantly improve the processing of unstructured data and unleash the great potential of QSAR. Here we discuss the integration of wet experiments (which provide experimental data and reliable verification), molecular dynamics simulation (which provides mechanistic interpretation at the atomic/molecular levels), and machine learning (including deep learning) techniques to improve QSAR models. We first review the history of traditional QSAR and point out its problems. We then propose a better QSAR model characterized by a new iterative framework to integrate machine learning with disparate data input. Finally, we discuss the application of QSAR and machine learning to many practical research fields, including drug development and clinical trials.",https://doi.org/10.1016/j.isci.2021.103052,2021,Jiashun Mao and Javed Akhtar and Xiao Zhang and Liang Sun and Shenghui Guan and Xinyu Li and Guangming Chen and Jiaxin Liu and Hyeon-Nae Jeon and Min Sung Kim and Kyoung Tai No and Guanyu Wang,COMPREHENSIVE STRATEGIES OF MACHINE-LEARNING-BASED QUANTITATIVE STRUCTURE-ACTIVITY RELATIONSHIP MODELS,article
315,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"Light-duty gasoline vehicles (LDGVs) have made up >90 % of vehicle fleets in China since 2019, moreover, with a high annual growth rate (> 10 %) since 2017. Hence, accurate estimates of air pollutant emissions of these fast-changing LDGVs are vital for air quality management, human healthcare, and ecological protection. However, this issue is poorly quantified due to insufficient reserves of timely updated LDGV emission factors, which are dependent on real-world activity levels. Here we constructed a big dataset of explicit emission profiles (e.g., emission factors and accumulated mileages) for 159,051 LDGVs based on an official I/M database by matching real-time traffic dynamics via real-world traffic monitoring (e.g., traffic volumes and speeds). Consequently, we provide robust evidence that the emission factors of these LDGVs follow a clear heavy-tailed distribution. The top 10 % emitters contributed >60 % to the total fleet emissions, while the bottom 50 % contributed <10 %. Such emission factors were effectively reduced by 75.7–86.2 % as official emission standards upgraded gradually (i.e., from China 2 to China 5) within 13 years from 2004 to 2017. Nevertheless, such achievements would be offset once traffic congestion occurred. In the real world, the typical traffic congestions (i.e., vehicle speed <5 km/h) can lead to emissions 5– 9 times higher than those on non-congested roads (i.e., vehicle speed >50 km/h). These empirical analyses enabled us to propose future traffic scenarios that could harmonize emission standards and traffic congestion. Practical approaches on vehicle emission controls under realistic conditions are proposed, which would provide new insights for future urban vehicle emission management.",https://doi.org/10.1016/j.scitotenv.2022.157581,2022,Xue Chen and Linhui Jiang and Yan Xia and Lu Wang and Jianjie Ye and Tangyan Hou and Yibo Zhang and Mengying Li and Zhen Li and Zhe Song and Jiali Li and Yaping Jiang and Pengfei Li and Xiaoye Zhang and Yang Zhang and Daniel Rosenfeld and John H. Seinfeld and Shaocai Yu,QUANTIFYING ON-ROAD VEHICLE EMISSIONS DURING TRAFFIC CONGESTION USING UPDATED EMISSION FACTORS OF LIGHT-DUTY GASOLINE VEHICLES AND REAL-WORLD TRAFFIC MONITORING BIG DATA,article
316,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"Climate change and environmental management are issues of global concern. The advent of the era of Big Data has created a new research platform for the assessment of environmental governance and policies. However, little is known about Big Data application to climate change and environmental management research. This paper adopts bibliometric analysis in conjunction with network analysis to systematically evaluate the publications on carbon emissions and environmental management based on Big Data and Streaming Data using R package and VOSviewer software. The analysis involves 274 articles after rigorous screening and includes citation analysis, co-citation analysis, and co-word analysis. Main findings include (1) Carbon emissions and environmental management based on big data and streaming data is an emerging multidisciplinary research topic, which has been applied in the fields of computer science, supply chain design, transportation, carbon price assessment, environmental policy evaluation, and CO2 emissions reduction. (2) This field has attracted the attention of nations which are major contributors to the world economy. In particular, European and American scholars have made the main contributions to this topic, and Chinese researchers have also had great impact. (3) The research content of this topic is primarily divided into four categories, including empirical studies of specific industries, air pollution governance, technological innovation, and low-carbon transportation. Our findings suggest that future research should bring greater depth of practical and modeling analysis to environmental policy assessment based on Big Data.",https://doi.org/10.1016/j.scitotenv.2020.138984,2020,Yuan Su and Yanni Yu and Ning Zhang,CARBON EMISSIONS AND ENVIRONMENTAL MANAGEMENT BASED ON BIG DATA AND STREAMING DATA: A BIBLIOMETRIC ANALYSIS,article
317,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"Anthropogenic marine debris is a persistent threat to oceans, imposing risks to ecosystems and the communities they support. Whilst an understanding of marine debris risks is steadily advancing, monitoring at spatial and temporal scales relevant to management remains limited. Citizen science projects address this shortcoming but are often critiqued on data accuracy and potential bias in sampling efforts. Here we present 10-years of Australia's largest marine debris database - the Australian Marine Debris Initiative (AMDI), in which we perform systematic data filtering, test for differences between collecting groups, and report patterns in marine debris. We defined five stages of data filtering to address issues in data quality and to limit inference to ocean-facing sandy beaches. Significant differences were observed in the average accumulation of items between filtered and remaining data. Further, differences in sampling were compared between collecting groups at the same site (e.g., government, NGOs, and schools), where no significant differences were observed. The filtering process removed 21% of events due to data quality issues and a further 42% of events to restrict analyses to ocean-facing sandy beaches. The remaining 7275 events across 852 sites allowed for an assessment of debris patterns at an unprecedented spatial and temporal resolution. Hard plastics were the most common material found on beaches both nationally and regionally, consisting of up to 75% of total debris. Nationally, land and sea-sourced items accounted for 48% and 7% of debris, respectively, with most debris found on the east coast of Australia. This study demonstrates the value of citizen science datasets with broad spatial and temporal coverage, and the importance of data filtering to improve data quality. The citizen science presented provides an understanding of debris patterns on Australia's ocean beaches and can serve as a foundation for future source reduction plans.",https://doi.org/10.1016/j.scitotenv.2021.150742,2022,Jordan Gacutan and Emma L. Johnston and Heidi Tait and Wally Smith and Graeme F. Clark,CONTINENTAL PATTERNS IN MARINE DEBRIS REVEALED BY A DECADE OF CITIZEN SCIENCE,article
318,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"Remote sensing image products (e.g. brightness of nighttime lights and land cover/land use types) have been widely used to disaggregate census data to produce gridded population maps for large geographic areas. The advent of the geospatial big data revolution has created additional opportunities to map population distributions at fine resolutions with high accuracy. A considerable proportion of the geospatial data contains semantic information that indicates different categories of human activities occurring at exact geographic locations. Such information is often lacking in remote sensing data. In addition, the remarkable progress in machine learning provides toolkits for demographers to model complex nonlinear correlations between population and heterogeneous geographic covariates. In this study, a typical type of geospatial big data, points-of-interest (POIs), was combined with multi-source remote sensing data in a random forests model to disaggregate the 2010 county-level census population data to 100 × 100 m grids. Compared with the WorldPop population dataset, our population map showed higher accuracy. The root mean square error for population estimates in Beijing, Shanghai, Guangzhou, and Chongqing for this method and WorldPop were 27,829 and 34,193, respectively. The large under-allocation of the population in urban areas and over-allocation in rural areas in the WorldPop dataset was greatly reduced in this new population map. Apart from revealing the effectiveness of POIs in improving population mapping, this study promises the potential of geospatial big data for mapping other socioeconomic parameters in the future.",https://doi.org/10.1016/j.scitotenv.2018.12.276,2019,Tingting Ye and Naizhuo Zhao and Xuchao Yang and Zutao Ouyang and Xiaoping Liu and Qian Chen and Kejia Hu and Wenze Yue and Jiaguo Qi and Zhansheng Li and Peng Jia,IMPROVED POPULATION MAPPING FOR CHINA USING REMOTELY SENSED AND POINTS-OF-INTEREST DATA WITHIN A RANDOM FORESTS MODEL,article
319,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"Insurance plays a crucial role in human efforts to adapt to environmental hazards. Effective insurance can serve as both a measure to distribute, and a method to communicate risk. In order for insurance to fulfil these roles successfully, policy pricing and cover choices must be risk-based and founded on accurate information. This is reliant on a robust evidence base forming the foundation of policy choices. This paper focuses on the evidence available to insurers and emergent innovation in the use of data. The main risk considered is coastal flooding, for which the insurance sector offers an option for potential adaptation, capable of increasing resilience. However, inadequate supply and analysis of data have been highlighted as factors preventing insurance from fulfilling this role. Research was undertaken to evaluate how data are currently, and could potentially, be used within risk evaluations for the insurance industry. This comprised of 50 interviews with those working and associated with the London insurance market. The research reveals new opportunities, which could facilitate improvements in risk-reflective pricing of policies. These relate to a new generation of data collection techniques and analytics, such as those associated with satellite-derived data, IoT (Internet of Things) sensors, cloud computing, and Big Data solutions. Such technologies present opportunities to reduce moral hazard through basing predictions and pricing of risk on large empirical datasets. The value of insurers' claims data is also revealed, and is shown to have the potential to refine, calibrate, and validate models and methods. The adoption of such data-driven techniques could enable insurers to re-evaluate risk ratings, and in some instances, extend coverage to locations and developments, previously rated as too high a risk to insure. Conversely, other areas may be revealed more vulnerable, which could generate negative impacts for residents in these regions, such as increased premiums. However, the enhanced risk awareness generated, by new technology, data and data analytics, could positively alter future planning, development and investment decisions.",https://doi.org/10.1016/j.scitotenv.2019.01.114,2019,Alexander G. Rumson and Stephen H. Hallett,INNOVATIONS IN THE USE OF DATA FACILITATING INSURANCE AS A RESILIENCE MECHANISM FOR COASTAL FLOOD RISK,article
320,25349,SCIENCE OF THE TOTAL ENVIRONMENT,journal,00489697,"1,795",Q1,244,6929,13278,455970,106837,13125,"7,96","65,81",Netherlands,Western Europe,Elsevier,"1970, 1972-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Pollution (Q1); Waste Management and Disposal (Q1),"210,143",7.963,0.23082,"An accurate characterization of spatial-temporal emission patterns and speciation of volatile organic compounds (VOCs) for multiple chemical mechanisms is important to improving the air quality ensemble modeling. In this study, we developed a 2017-based high-resolution (3 km × 3 km) model-ready emission inventory for Guangdong Province (GD) by updating estimation methods, emission factors, activity data, and allocation profiles. In particular, a full-localized speciation profile dataset mapped to five chemical mechanisms was developed to promote the determination of VOC speciation, and two dynamic approaches based on big data were used to improve the estimation of ship emissions and open fire biomass burning (OFBB). Compared with previous emissions, more VOC emissions were classified as oxygenated volatile organic compound (OVOC) species, and their contributions to the total ozone formation potential (OFP) in the Pearl River Delta (PRD) region increased by 17%. Formaldehyde became the largest OFP species in GD, accounting for 11.6% of the total OFP, indicating that the model-ready emission inventory developed in this study is more reactive. The high spatial-temporal variability of ship sources and OFBB, which were previously underestimated, was also captured by using big data. Ship emissions during typhoon days and holidays decreased by 23–55%. 95% of OFBB emissions were concentrated in 9% of the GD area and 31% of the days in 2017, demonstrating their strong spatial-temporal variability. In addition, this study revealed that GD emissions have changed rapidly in recent years due to the leap-forward control measures implemented, and thus, they needed to be updated regularly. All of these updates led to a 5–17% decrease in the emission uncertainty for most pollutants. The results of this study provide a reference for how to reduce uncertainties in developing model-ready emission inventories.",https://doi.org/10.1016/j.scitotenv.2020.144535,2021,Zhijiong Huang and Zhuangmin Zhong and Qinge Sha and Yuanqian Xu and Zhiwei Zhang and Lili Wu and Yuzheng Wang and Lihang Zhang and Xiaozhen Cui and MingShuang Tang and Bowen Shi and Chuanzeng Zheng and Zhen Li and Mingming Hu and Linlin Bi and Junyu Zheng and Min Yan,AN UPDATED MODEL-READY EMISSION INVENTORY FOR GUANGDONG PROVINCE BY INCORPORATING BIG DATA AND MAPPING ONTO MULTIPLE CHEMICAL MECHANISMS,article
321,27843,ANNUAL REVIEWS IN CONTROL,journal,13675788,"1,780",Q1,80,55,145,5080,1435,132,"9,15","92,36",United Kingdom,Western Europe,Elsevier Ltd.,1996-2020,Control and Systems Engineering (Q1); Software (Q1),"2,756",6.091,0.0039,"Industrial process data are usually mixed with missing data and outliers which can greatly affect the statistical explanation abilities for traditional data-driven modeling methods. In this sense, more attention should be paid on robust data mining methods so as to investigate those stable and reliable modeling prototypes for decision-making. This paper gives a systematic review of various state-of-the-art data preprocessing tricks as well as robust principal component analysis methods for process understanding and monitoring applications. Afterwards, comprehensive robust techniques have been discussed for various circumstances with diverse process characteristics. Finally, big data perspectives on potential challenges and opportunities have been highlighted for future explorations in the community.",https://doi.org/10.1016/j.arcontrol.2018.09.003,2018,Jinlin Zhu and Zhiqiang Ge and Zhihuan Song and Furong Gao,REVIEW AND BIG DATA PERSPECTIVES ON ROBUST DATA MINING APPROACHES FOR INDUSTRIAL PROCESS MODELING WITH OUTLIERS AND MISSING DATA,article
322,21196,DRUG DISCOVERY TODAY,journal,13596446,"1,778",Q1,175,258,667,19752,5142,630,"7,17","76,56",United Kingdom,Western Europe,Elsevier Ltd.,1996-2020,Drug Discovery (Q1); Pharmacology (Q1),"18,695",7.851,0.0174,"The objective of this paper is to identify the extent to which real world data (RWD) is being utilized, or could be utilized, at scale in drug development. Through screening peer-reviewed literature, we have cited specific examples where RWD can be used for biomarker discovery or validation, gaining a new understanding of a disease or disease associations, discovering new markers for patient stratification and targeted therapies, new markers for identifying persons with a disease, and pharmacovigilance. None of the papers meeting our criteria was specifically geared toward novel targets or indications in the biopharmaceutical sector; the majority were focused on the area of public health, often sponsored by universities, insurance providers or in combination with public health bodies such as national insurers. The field is still in an early phase of practical application, and is being harnessed broadly where it serves the most direct need in public health applications in early, rare and novel disease incidents. However, these exemplars provide a valuable contribution to insights on the use of RWD to create novel, faster and less invasive approaches to advance disease understanding and biomarker discovery. We believe that pharma needs to invest in making better use of Electronic Health Records and the need for more precompetitive collaboration to grow the scale of this ‘big denominator’ capability, especially given the needs of precision medicine research.",https://doi.org/10.1016/j.drudis.2017.12.002,2018,Gurparkash Singh and Duane Schulthess and Nigel Hughes and Bart Vannieuwenhuyse and Dipak Kalra,REAL WORLD BIG DATA FOR CLINICAL RESEARCH AND DRUG DEVELOPMENT,article
323,21196,DRUG DISCOVERY TODAY,journal,13596446,"1,778",Q1,175,258,667,19752,5142,630,"7,17","76,56",United Kingdom,Western Europe,Elsevier Ltd.,1996-2020,Drug Discovery (Q1); Pharmacology (Q1),"18,695",7.851,0.0174,"Advancing a new drug to market requires substantial investments in time as well as financial resources. Crucial bioactivities for drug candidates, including their efficacy, pharmacokinetics (PK), and adverse effects, need to be investigated during drug development. With advancements in chemical synthesis and biological screening technologies over the past decade, a large amount of biological data points for millions of small molecules have been generated and are stored in various databases. These accumulated data, combined with new machine learning (ML) approaches, such as deep learning, have shown great potential to provide insights into relevant chemical structures to predict in vitro, in vivo, and clinical outcomes, thereby advancing drug discovery and development in the big data era.",https://doi.org/10.1016/j.drudis.2020.07.005,2020,Linlin Zhao and Heather L. Ciallella and Lauren M. Aleksunes and Hao Zhu,ADVANCING COMPUTER-AIDED DRUG DISCOVERY (CADD) BY BIG DATA AND DATA-DRIVEN MACHINE LEARNING MODELING,article
324,16956,CITIES,journal,02642751,"1,771",Q1,90,419,732,28409,4866,723,"6,19","67,80",United Kingdom,Western Europe,Elsevier Ltd.,1983-2020,"Development (Q1); Sociology and Political Science (Q1); Tourism, Leisure and Hospitality Management (Q1); Urban Studies (Q1)","11,076",5.835,0.01251,"While commerce is one of the key activities in cities, its spatial description still requires further attention, especially by considering the different dimensions of commercial space: physical, economic and socio-symbolic. The latter is becoming more and more important in an era where consumption is at the centre of social relations. Further, although data availability has been an enduring obstacle in commercial research, we are witnessing the advent of new data sources, and social-network big data is an opportunity to unveil the places to which consumers attribute prestige or symbolic capital, at the extent of entire metropolitan areas. This paper compares the physical, economic and socio-symbolic dimensions of commercial spaces through the analysis of three different commercial data sources: cadastral micro-data, business register and social-network big data. For the case of Madrid Metropolitan Area, the three databases are compared with correlation analysis and density maps, coming out as partly redundant and partly complementary. Getis-Ord's hotspot statistics integrated into a cluster analysis enable a comprehensive understanding of commercial environments, enriching previous spatial hierarchies. The spatial distribution of symbolic capital unveils a relation with socio-spatial segregation and paves the way to new reflections on the spatiality of consumption as a social practice.",https://doi.org/10.1016/j.cities.2020.102859,2020,José Carpio-Pinedo and Javier Gutiérrez,CONSUMPTION AND SYMBOLIC CAPITAL IN THE METROPOLITAN SPACE: INTEGRATING ‘OLD’ RETAIL DATA SOURCES WITH SOCIAL BIG DATA,article
325,16956,CITIES,journal,02642751,"1,771",Q1,90,419,732,28409,4866,723,"6,19","67,80",United Kingdom,Western Europe,Elsevier Ltd.,1983-2020,"Development (Q1); Sociology and Political Science (Q1); Tourism, Leisure and Hospitality Management (Q1); Urban Studies (Q1)","11,076",5.835,0.01251,"Cities worldwide are attempting to transform themselves into smart cities. Recent cases and studies show that a key factor in this transformation is the use of urban big data from stakeholders and physical objects in cities. However, the knowledge and framework for data use for smart cities remain relatively unknown. This paper reports findings from an analysis of various use cases of big data in cities worldwide and the authors' four projects with government organizations toward developing smart cities. Specifically, this paper classifies the urban data use cases into four reference models and identifies six challenges in transforming data into information for smart cities. Furthermore, building upon the relevant literature, this paper proposes five considerations for addressing the challenges in implementing the reference models in real-world applications. The reference models, challenges, and considerations collectively form a framework for data use for smart cities. This paper will contribute to urban planning and policy development in the modern data-rich economy.",https://doi.org/10.1016/j.cities.2018.04.011,2018,Chiehyeon Lim and Kwang-Jae Kim and Paul P. Maglio,"SMART CITIES WITH BIG DATA: REFERENCE MODELS, CHALLENGES, AND CONSIDERATIONS",article
326,16956,CITIES,journal,02642751,"1,771",Q1,90,419,732,28409,4866,723,"6,19","67,80",United Kingdom,Western Europe,Elsevier Ltd.,1983-2020,"Development (Q1); Sociology and Political Science (Q1); Tourism, Leisure and Hospitality Management (Q1); Urban Studies (Q1)","11,076",5.835,0.01251,"With current decentralization trends and polycentric planning efforts, the urban spatial structures of Chinese cities have been changing tremendously. To detect the true urban polycentric pattern of Chinese cities, this article analyzed the urban polycentricity characteristics of 294 cities. The natural cities were delineated by points of interest (POIs), and road networks constituted street blocks. Based on check-in data and new spatial units, centers within both metropolitan areas and central cities were identified and examined. We discovered that all Chinese cities have at least one natural city in their metropolitan areas because of rapid urban sprawl. Although a monocentric structure is still the most common urban spatial structure, 110 Chinese cities displayed different degrees of polycentricity at the metropolitan level. Many natural cities beyond central cities contribute to polycentric development at the metropolitan level. Central cities have maintained their original vitality and importance, most Chinese cities have dispersed urban structures in central cities, and 45 central cities are polycentric. The spatial structures in metropolitan areas are more polycentric than those in central cities. The only 36 cities with polycentric urban structures at both the metropolitan and central city levels are all national or regional central cities in eastern China.",https://doi.org/10.1016/j.cities.2021.103298,2021,Yongqiang Lv and Lin Zhou and Guobiao Yao and Xinqi Zheng,DETECTING THE TRUE URBAN POLYCENTRIC PATTERN OF CHINESE CITIES IN MORPHOLOGICAL DIMENSIONS: A MULTISCALE ANALYSIS BASED ON GEOSPATIAL BIG DATA,article
327,13121,SEMINARS IN RADIATION ONCOLOGY,journal,10534296,"1,761",Q1,93,40,129,2575,654,118,"5,29","64,38",United Kingdom,Western Europe,W.B. Saunders Ltd,1991-2020,"Oncology (Q1); Radiology, Nuclear Medicine and Imaging (Q1); Cancer Research (Q2)","2,837",5.934,0.00271,"In oncology, the term “big data” broadly describes the rapid acquisition and generation of massive amounts of information, typically from population cancer registries, electronic health records, or large-scale genetic sequencing studies. The challenge of using big data in cancer research lies in interdisciplinary collaboration and information processing to unify diverse data sources and provide valid analytics to harness meaningful information. This article provides an overview of how big data approaches can be applied in cancer research, and how they can be used to translate information into new ways to ultimately make informed decisions that improve cancer care and delivery.",https://doi.org/10.1016/j.semradonc.2019.05.002,2019,Chiaojung Jillian Tsai and Nadeem Riaz and Scarlett Lin Gomez,BIG DATA IN CANCER RESEARCH: REAL-WORLD RESOURCES FOR PRECISION ONCOLOGY TO IMPROVE CANCER CARE DELIVERY,article
328,13121,SEMINARS IN RADIATION ONCOLOGY,journal,10534296,"1,761",Q1,93,40,129,2575,654,118,"5,29","64,38",United Kingdom,Western Europe,W.B. Saunders Ltd,1991-2020,"Oncology (Q1); Radiology, Nuclear Medicine and Imaging (Q1); Cancer Research (Q2)","2,837",5.934,0.00271,"The application of big data to the quality assurance of radiation therapy is multifaceted. Big data can be used to detect anomalies and suboptimal quality metrics through both statistical means and more advanced machine learning and artificial intelligence. The application of these methods to clinical practice is discussed through examples of guideline adherence, contour integrity, treatment delivery mechanics, and treatment plan quality. The ultimate goal is to apply big data methods to direct measures of patient outcomes for care quality. The era of big data and machine learning is maturing and the implementation for quality assurance promises to improve the quality of care for patients.",https://doi.org/10.1016/j.semradonc.2019.05.006,2019,Todd R. McNutt and Kevin L. Moore and Binbin Wu and Jean L. Wright,USE OF BIG DATA FOR QUALITY ASSURANCE IN RADIATION THERAPY,article
329,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"Scientific literature about building occupants’ behaviour and the related energy performance analyses document about several strategies to monitor window operation, including different sensors and data series lengths. In this framework, the primary goal of this study is to propose effective guidelines for minimum experiment durations and their reliability. A six-year-long database from a living laboratory was used as a benchmark; and a recursive strategy enabled to split it into more than 2,500 subsets, supporting two main steps. First, information theory concepts were used to calculate uncertainty and subsets’ divergence were compared to the full database. Second, the subsets were used to train deep neural networks and evaluate the influence of monitoring lengths combined with different kinds of environmental data (i.e. indoor or outdoor). From the information-theoretic metrics, the results support that indoor-related variables can reduce most of the uncertainty related to window operation. Besides, subsets influenced by autumn and winter diverge the most compared to the full database. Considering the modelling approach, the results demonstrated that by including indoor-related variables, higher shares of reliably-performing models were achieved, and smaller subsets were needed. Seasonality has also played a major role along these lines. As a consequence, the conclusions supported the feasibility of nine-month-long field studies, starting in summer or spring, when indoor and outdoor variables are monitored.",https://doi.org/10.1016/j.enbuild.2022.112197,2022,Mateus Bavaresco and Ioannis Kousis and Ilaria Pigliautile and Anna {Laura Pisello} and Cristina Piselli and Enedir Ghisi,ARE YEARS-LONG FIELD STUDIES ABOUT WINDOW OPERATION EFFICIENT? A DATA-DRIVEN APPROACH BASED ON INFORMATION THEORY AND DEEP LEARNING,article
330,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"This study applies big data mining, machine learning analysis technique and uses the Waikato Environment for Knowledge Analysis (WEKA) as a tool to discuss the convenience stores energy consumption performance in Taiwan which consists of (a). Influential factors of architectural space environment and geographical conditions; (b). Influential factors of management type; (c). Influential factors of business equipment; (d). Influential factors of local climatic conditions; (e). Influential factors of service area socioeconomic conditions. The survey data of 1,052 chain convenience stores belong to 7-Eleven, Family Mart and Hi-Life groups by Taiwan Architecture and Building Center (TABC) in 2014. The implicit knowledge will be explored in order to improve the traditional analysis technique which is unlikely to build a model for complex, inexact and uncertain dynamic energy consumption system for convenience stores. The analysis process comprises of (a). Problem definition and objective setting; (b). Data source selection; (c). Data collection; (d). Data preprocessing/preparation; (e). Data attributes selection; (f). Data mining and model construction; (g). Results analysis and evaluation; (h). Knowledge discovery and dissemination. The key factors influencing the convenience stores energy consumption and the influence intensity order can be explored by data attributes selection. The numerical prediction model for energy consumption is built by applying regression analysis and classification techniques. The optimization thresholds of various influential factors are obtained. The different cluster data are compared by using clustering analysis to verify the correlation between the factors influencing the convenience stores energy consumption characteristic. The implicit knowledge of energy consumption characteristic obtained by the aforesaid analysis can be used to (a). Provide the owners with accurate predicted energy consumption performance to optimize architectural space, business equipment and operations management mode; (b). The design planners can obtain the optimum design proposal of Cost Performance Ratio (C/P) by planning the thresholds of various key factors and the validation of prediction model; (c). Provide decision support for government energy and environment departments, to make energy saving and carbon emission reduction policies, in order to estimate and set the energy consumption scenarios of convenience store industry.",https://doi.org/10.1016/j.enbuild.2018.03.021,2018,Chung-Feng {Jeffrey Kuo} and Chieh-Hung Lin and Ming-Hao Lee,ANALYZE THE ENERGY CONSUMPTION CHARACTERISTICS AND AFFECTING FACTORS OF TAIWAN'S CONVENIENCE STORES-USING THE BIG DATA MINING APPROACH,article
331,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"The rapid development of building energy consumption monitoring platforms makes engineering data more diverse, which facilitates the goal of reducing emissions. It is increasingly acknowledged that data preprocessing deserves the same attention as intelligent algorithms. In this work, the data quality issue of the engineering big data from non-demonstration complexes in China are analyzed thoroughly, and the analysis is based on clustering-based algorithms. We can conclude that the data of the hourly power of equipment groups are quality and stable, which is suitable for the benchmark to check other data. The quality of the data about pipes is acceptable. The number of data types about cooling towers is less, and the quality is worse. Regarding other data, the quality is unstable, so researchers should deal with those case-by-case. According to the above analysis, we proposed a convenient, rule-based data preprocessing framework that utilizes the law of physics, ensuring the strong coupling of multi-variants. After the data preprocessing, these engineering data are more reliable and can be used to improve performance or train models. Additionally, the proposed framework is more suitable for preprocessing multi-variant engineering data.",https://doi.org/10.1016/j.enbuild.2022.112372,2022,Ruikai He and Tong Xiao and Shunian Qiu and Jiefan Gu and Minchen Wei and Peng Xu,A RULE-BASED DATA PREPROCESSING FRAMEWORK FOR CHILLER ROOMS INSPIRED BY THE ANALYSIS OF ENGINEERING BIG DATA,article
332,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"With buildings consuming nearly 40% of energy in developed countries, it is important to accurately estimate and understand the building energy efficiency in a city. A better understanding of building energy efficiency is beneficial for reducing overall household energy use and providing guidance for future housing improvement and retrofit. In this research, we propose a deep learning-based multi-source data fusion framework to estimate building energy efficiency. We consider the traditional factors associated with the building energy efficiency from the Energy Performance Certificate (EPC) for 160,000 properties (30,000 buildings) in Glasgow, UK (e.g., property structural attributes and morphological attributes), as well as the Google Street View (GSV) building façade images as a complement. We compare the performance improvements between our data-fusion framework with traditional morphological attributes and image-only models. The results show that including the building façade images from GSV, the overall model accuracy increases from 79.7% to 86.8%. A further investigation and explanation of the deep learning model are conducted to understand the relationships between building features and building energy efficiency by using SHapley Additive exPlanations (SHAP). Our research demonstrates the potential of using multi-source data in building energy efficiency prediction with high accuracy and short inference time. Our paper also helps understand building energy efficiency at the city level to help achieve the net-zero target by 2050.",https://doi.org/10.1016/j.enbuild.2022.112331,2022,Maoran Sun and Changyu Han and Quan Nie and Jingying Xu and Fan Zhang and Qunshan Zhao,UNDERSTANDING BUILDING ENERGY EFFICIENCY WITH ADMINISTRATIVE AND EMERGING URBAN BIG DATA BY DEEP LEARNING IN GLASGOW,article
333,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"Building operations account for the largest proportion of energy use throughout the building life cycle. The energy saving potential is considerable taking into account the existence of a wide variety of building operation deficiencies. The advancement in information technologies has made modern buildings to be not only energy-intensive, but also information-intensive. Massive amounts of building operational data, which are in essence the reflection of actual building operating conditions, are available for knowledge discovery. It is very promising to extract potentially useful insights from big building operational data, based on which actionable measures for energy efficiency enhancement are devised. Data mining is an advanced technology for analyzing big data. It consists of two main types of data analytics, i.e., supervised and unsupervised analytics. Despite of the power of supervised analytics in predictive modeling, unsupervised analytics are more practical and promising in discovering novel knowledge given limited prior knowledge. This paper provides a comprehensive review on the current utilization of unsupervised data analytics in mining massive building operational data. The commonly used unsupervised analytics are summarized according to their knowledge representations and applications. The challenges and opportunities are elaborated as guidance for future research in this multi-disciplinary field.",https://doi.org/10.1016/j.enbuild.2017.11.008,2018,Cheng Fan and Fu Xiao and Zhengdao Li and Jiayuan Wang,UNSUPERVISED DATA ANALYTICS IN MINING BIG BUILDING OPERATIONAL DATA FOR ENERGY EFFICIENCY ENHANCEMENT: A REVIEW,article
334,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"Improving the energy efficiency of the buildings is a worldwide hot topic nowadays. To assist comprehensive analysis and smart management, high-quality historical data records of the energy consumption is one of the key bases. However, the energy data records in the real world always contain different kinds of problems. The most common problem is missing data. It is also one of the most frequently reported data quality problems in big data/machine learning/deep learning related literature in energy management. However, limited studied have been conducted to comprehensively discuss different kinds of missing data situations, including random missing, continuous missing, and large proportionally missing. Also, the methods used in previous literature often rely on linear statistical methods or traditional machine learning methods. Limited study has explored the feasibility of advanced deep learning and transfer learning techniques in this problem. To this end, this study proposed a methodology, namely the hybrid Long Short Term Memory model with Bi-directional Imputation and Transfer Learning (LSTM-BIT). It integrates the powerful modeling ability of deep learning networks and flexible transferability of transfer learning. A case study on the electric consumption data of a campus lab building was utilized to test the method. Results show that LSTM-BIT outperforms other methods with 4.24% to 47.15% lower RMSE under different missing rates.",https://doi.org/10.1016/j.enbuild.2020.109941,2020,Jun Ma and Jack C.P. Cheng and Feifeng Jiang and Weiwei Chen and Mingzhu Wang and Chong Zhai,A BI-DIRECTIONAL MISSING DATA IMPUTATION SCHEME BASED ON LSTM AND TRANSFER LEARNING FOR BUILDING ENERGY DATA,article
335,29359,ENERGY AND BUILDINGS,journal,03787788,"1,737",Q1,184,705,2402,39338,15832,2394,"6,33","55,80",Netherlands,Western Europe,Elsevier BV,"1970, 1977-2020",Building and Construction (Q1); Civil and Structural Engineering (Q1); Electrical and Electronic Engineering (Q1); Mechanical Engineering (Q1),"51,254",5.879,0.04387,"With the advances of information technologies, today's building automation systems (BASs) are capable of managing building operational performance in an efficient and convenient way. Meanwhile, the amount of real-time monitoring and control data in BASs grows continually in the building lifecycle, which stimulates an intense demand for powerful big data analysis tools in BASs. Existing big data analytics adopted in the building automation industry focus on mining cross-sectional relationships, whereas the temporal relationships, i.e., the relationships over time, are usually overlooked. However, building operations are typically dynamic and BAS data are essentially multivariate time series data. This paper presents a time series data mining methodology for temporal knowledge discovery in big BAS data. A number of time series data mining techniques are explored and carefully assembled, including the Symbolic Aggregate approXimation (SAX), motif discovery, and temporal association rule mining. This study also develops two methods for the efficient post-processing of knowledge discovered. The methodology has been applied to analyze the BAS data retrieved from a real building. The temporal knowledge discovered is valuable to identify dynamics, patterns and anomalies in building operations, derive temporal association rules within and between subsystems, assess building system performance and spot opportunities in energy conservation.",https://doi.org/10.1016/j.enbuild.2015.09.060,2015,Cheng Fan and Fu Xiao and Henrik Madsen and Dan Wang,TEMPORAL KNOWLEDGE DISCOVERY IN BIG BAS DATA FOR BUILDING ENERGY MANAGEMENT,article
336,26874,BUILDING AND ENVIRONMENT,journal,03601323,"1,736",Q1,154,754,1692,43938,12000,1687,"6,90","58,27",United Kingdom,Western Europe,Elsevier BV,1976-2020,"Building and Construction (Q1); Civil and Structural Engineering (Q1); Environmental Engineering (Q1); Geography, Planning and Development (Q1)","38,699",6.456,0.02925,"Life cycle assessment (LCA) and life cycle cost (LCC) are two primary methods used to assess the environmental and economic feasibility of building construction. An estimation of the building's life span is essential to carrying out these methods. However, given the diverse factors that affect the building's life span, it was estimated typically based on its main structural type. However, different buildings have different life spans. Simply assuming that all buildings with the same structural type follow an identical life span can cause serious estimation errors. In this study, we collected 1,812,700 records describing buildings built and demolished in South Korea, analysed the actual life span of each building, and developed a building life-span prediction model using deep-learning and traditional machine learning. The prediction models examined in this study produced root mean square errors of 3.72–4.6 and the coefficients of determination of 0.932–0.955. Among those models, a deep-learning based prediction model was found the most powerful. As anticipated, the conventional method of determining a building's life expectancy using a discrete set of specific factors and associated assumptions of life span did not yield realistic results. This study demonstrates that an application of deep learning to the LCA and LCC of a building is a promising direction, effectively guiding business planning and critical decision making throughout the construction process.",https://doi.org/10.1016/j.buildenv.2021.108267,2021,Sukwon Ji and Bumho Lee and Mun Yong Yi,BUILDING LIFE-SPAN PREDICTION FOR LIFE CYCLE ASSESSMENT AND LIFE CYCLE COST USING MACHINE LEARNING: A BIG DATA APPROACH,article
337,26874,BUILDING AND ENVIRONMENT,journal,03601323,"1,736",Q1,154,754,1692,43938,12000,1687,"6,90","58,27",United Kingdom,Western Europe,Elsevier BV,1976-2020,"Building and Construction (Q1); Civil and Structural Engineering (Q1); Environmental Engineering (Q1); Geography, Planning and Development (Q1)","38,699",6.456,0.02925,"The proliferation of urban sensing, IoT, and big data in cities provides unprecedented opportunities for a deeper understanding of occupant behaviour and energy usage patterns at the urban scale. This enables data-driven building and energy models to capture the urban dynamics, specifically the intrinsic occupant and energy use behavioural profiles that are not usually considered in traditional models. Although there are related reviews, none investigated urban data for use in modelling occupant behaviour and energy use at multiple scales, from buildings to neighbourhood to city. This survey paper aims to fill this gap by providing a critical summary and analysis of the works reported in the literature. We present the different sources of occupant-centric urban data that are useful for data-driven modelling and categorise the range of applications and recent data-driven modelling techniques for urban behaviour and energy modelling, along with the traditional stochastic and simulation-based approaches. Finally, we present a set of recommendations for future directions in data-driven modelling of occupant behaviour and energy in buildings at the urban scale.",https://doi.org/10.1016/j.buildenv.2020.106964,2020,Flora D. Salim and Bing Dong and Mohamed Ouf and Qi Wang and Ilaria Pigliautile and Xuyuan Kang and Tianzhen Hong and Wenbo Wu and Yapan Liu and Shakila Khan Rumi and Mohammad Saiedur Rahaman and Jingjing An and Hengfang Deng and Wei Shao and Jakub Dziedzic and Fisayo Caleb Sangogboye and Mikkel Baun Kjærgaard and Meng Kong and Claudia Fabiani and Anna Laura Pisello and Da Yan,"MODELLING URBAN-SCALE OCCUPANT BEHAVIOUR, MOBILITY, AND ENERGY IN BUILDINGS: A SURVEY",article
338,15061,AGRICULTURAL SYSTEMS,journal,0308521X,"1,694",Q1,107,197,511,12414,3229,503,"5,52","63,02",United Kingdom,Western Europe,Elsevier BV,1976-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1),"9,779",5.370,0.00937,"The COVID-19 outbreak was an unprecedented situation that uncovered forgotten interconnections and interdependencies between agriculture, society, and economy, whereas it also brought to the fore the vulnerability of agrifood production to external disturbances. Building upon the ongoing experience of the COVID-19 pandemic, in this short communication, we discuss three potential mechanisms that, in our opinion, can mitigate the impacts of major crises or disasters in agriculture: resilience-promoting policies, community marketing schemes, and smart farming technology. We argue that resilience-promoting policies should focus on the development of crisis management plans and enhance farmers' capacity to cope with external disturbances. We also stress the need to promote community marketing conduits that ensure an income floor for farmers while in parallel facilitating consumer access to agrifood products when mainstream distribution channels under-serve them. Finally, we discuss some issues that need to be solved to ensure that smart technology and big data can help farmers overcome external shocks.",https://doi.org/10.1016/j.agsy.2020.103023,2021,Evagelos D. Lioutas and Chrysanthi Charatsari,ENHANCING THE ABILITY OF AGRICULTURE TO COPE WITH MAJOR CRISES OR DISASTERS: WHAT THE EXPERIENCE OF COVID-19 TEACHES US,article
339,15061,AGRICULTURAL SYSTEMS,journal,0308521X,"1,694",Q1,107,197,511,12414,3229,503,"5,52","63,02",United Kingdom,Western Europe,Elsevier BV,1976-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1),"9,779",5.370,0.00937,"Smart Farming is a development that emphasizes the use of information and communication technology in the cyber-physical farm management cycle. New technologies such as the Internet of Things and Cloud Computing are expected to leverage this development and introduce more robots and artificial intelligence in farming. This is encompassed by the phenomenon of Big Data, massive volumes of data with a wide variety that can be captured, analysed and used for decision-making. This review aims to gain insight into the state-of-the-art of Big Data applications in Smart Farming and identify the related socio-economic challenges to be addressed. Following a structured approach, a conceptual framework for analysis was developed that can also be used for future studies on this topic. The review shows that the scope of Big Data applications in Smart Farming goes beyond primary production; it is influencing the entire food supply chain. Big data are being used to provide predictive insights in farming operations, drive real-time operational decisions, and redesign business processes for game-changing business models. Several authors therefore suggest that Big Data will cause major shifts in roles and power relations among different players in current food supply chain networks. The landscape of stakeholders exhibits an interesting game between powerful tech companies, venture capitalists and often small start-ups and new entrants. At the same time there are several public institutions that publish open data, under the condition that the privacy of persons must be guaranteed. The future of Smart Farming may unravel in a continuum of two extreme scenarios: 1) closed, proprietary systems in which the farmer is part of a highly integrated food supply chain or 2) open, collaborative systems in which the farmer and every other stakeholder in the chain network is flexible in choosing business partners as well for the technology as for the food production side. The further development of data and application infrastructures (platforms and standards) and their institutional embedment will play a crucial role in the battle between these scenarios. From a socio-economic perspective, the authors propose to give research priority to organizational issues concerning governance issues and suitable business models for data sharing in different supply chain scenarios.",https://doi.org/10.1016/j.agsy.2017.01.023,2017,Sjaak Wolfert and Lan Ge and Cor Verdouw and Marc-Jeroen Bogaardt,BIG DATA IN SMART FARMING – A REVIEW,article
340,20838,TRANSPORT POLICY,journal,0967070X,"1,687",Q1,96,201,494,11238,2674,486,"5,12","55,91",United Kingdom,Western Europe,Elsevier Ltd.,1993-2020,"Geography, Planning and Development (Q1); Law (Q1); Transportation (Q1)","9,048",4.674,0.0091,"This study sets out to assess whether there is a knowledge gap between the research frontier and the consultation business in how transport data are collected, managed and analysed. The consulting business plays an important role in applying data and methods as they typically carry out public tasks in various parts of the transport system, which are becoming more and more specialised. At the same time, big data has emerged with the promise to provide new, more and better information to help understand society and execute policies more efficiently – what we refer to as the data driven transition. We conduct a literature review to identify the state of the art within international research and compare this with results from interviews and with a survey sent to representatives from the Norwegian consultation business. We find that there is a considerable gap between international researchers and the consulting business within the entire process of collection, management and analysis of traffic data, and that this gap is increasing with the emergence of the data driven transition. Finally, we argue that the results are applicable to other countries as well. Action should be taken to keep the consultants up to speed, which will require efforts from several actors, including governmental agencies, the education institutions, the consulting business and researchers.",https://doi.org/10.1016/j.tranpol.2019.05.016,2019,Hanne Seter and Petter Arnesen and Odd André Hjelkrem,THE DATA DRIVEN TRANSPORT RESEARCH TRAIN IS LEAVING THE STATION. CONSULTANTS ALL ABOARD?,article
341,50089,JOURNAL OF HYDROLOGY,journal,00221694,"1,684",Q1,226,1336,2587,87508,15250,2563,"5,76","65,50",Netherlands,Western Europe,Elsevier,"1949, 1963-2020",Water Science and Technology (Q1),"73,620",5.722,0.04972,"Flood susceptibility assessment for identifying flood-prone areas plays a significant role in flood hazard mitigation. Machine learning is an optional assessment method because of its high objectivity and computational efficiency, but how to get enough and accurate information of historical flood locations to train the machine learning models has been a key problem. In recent years, news media data from both news websites and social media accounts has emerged as a promising source for natural science studies. However, the application of news media data in urban flood susceptibility assessment is still inadequate. This study proposed an approach to fill this gap. Firstly, flood locations were extracted from news media data based on a named entity recognition (NER) model. Then, a frequency or distance-based data quality control method was employed to improve the representativeness of the extracted flooded locations. Finally, flood conditioning factors with information of historical flood locations were input into a Support Vector Machine (SVM) model for flood susceptibility assessment. We took the central city of Dalian, China as a case study. The T-test results show that there was no significant difference between the distributions of most flood conditioning factors at the flood locations from the news media data and the official planning report. In the obtained flood susceptibility map, the high flood susceptibility areas got a recall of 90% compared with the high flood hazard areas in the planning report. Performing data quality control in the frequency-based method can improve the precision of the flood susceptibility map by up to 5%, while the distance-based method is ineffective. This study provides an example and offers the value of applying new data sources and modern deep learning techniques for urban flood management.",https://doi.org/10.1016/j.jhydrol.2022.128312,2022,Shengnan Fu and Heng Lyu and Ze Wang and Xin Hao and Chi Zhang,EXTRACTING HISTORICAL FLOOD LOCATIONS FROM NEWS MEDIA DATA BY THE NAMED ENTITY RECOGNITION (NER) MODEL TO ASSESS URBAN FLOOD SUSCEPTIBILITY,article
342,24443,CONSTRUCTION AND BUILDING MATERIALS,journal,09500618,"1,662",Q1,170,3583,7707,175521,52599,7705,"6,50","48,99",United Kingdom,Western Europe,Elsevier Ltd.,1987-2020,Building and Construction (Q1); Civil and Structural Engineering (Q1); Materials Science (miscellaneous) (Q1),"123,941",6.141,0.09849,"Intensive big data nanoindentation (BDNi) characterization was performed to reveal the cross-scale mechanical properties of, and hence distinguish the different phases in, inorganic–organic hybrid oilwell cement-elastomer composites, hydrothermally cured at 160 °C and 20 MPa for 28 days. Totally-three emulsified and particulate elastomers, including styrene-butadiene latex (SBL) emulsion (6, 12, and 14 wt.%), polypropylene (PP) powder (12 wt.%), and nitrile rubber (NR) powder (6 wt.%), and a weighting agent, hematite (50 wt.%), were used as additives to finely adjust the mechanical properties and microstructure of the hybrid composites, which were respectively examined by the BDNi and mercury intrusion porosimetry and scanning electron microscopy. BDNi data were statistically deconvoluted by the Gaussian mixture modeling (GMM) to discern mechanically distinct phases and their Young’s moduli and hardness at the micro/nano scale and the bulk composites’ properties at the macro scale. Results show that the SBL emulsion can be more homogeneously dispersed into the cement matrix, due to its emulsified soft consistency and hydrophilicity, resulting in the formation of soft coatings on, and softer infills intermixed with, the cement hydration products (CHPs). In contrast, the two hydrophobic, inert, particulate elastomers, PP and NR powders, only act as isolated soft inclusions embedded in the hydrated cement matrix. The NR melts at high temperatures and permeates into the pores of the cement matrix, leading to the formation of complex intervened micromorphology and hence functions better than the PP. All elastomers can effectively reduce the composites’ Young’s moduli: with increasing the elastomer contents, while the modulus of a BDNi-identified major CHP phase decreases from 20.9 to 11.3 GPa, the bulk composites’ counterpart from 17.3 to 10.7 GPa. The BDNi enables the identification of multiple mechanically distinct phases in the hybrid composites and quantification of the property changes of these phases.",https://doi.org/10.1016/j.conbuildmat.2022.129190,2022,Yucheng Li and Yunhu Lu and Li Liu and Shengmin Luo and Li He and Yongfeng Deng and Guoping Zhang,BIG DATA NANOINDENTATION CHARACTERIZATION OF CROSS-SCALE MECHANICAL PROPERTIES OF OILWELL CEMENT-ELASTOMER COMPOSITES,article
343,17337,IEEE TRANSACTIONS ON ANTENNAS AND PROPAGATION,journal,15582221,"1,652",Q1,200,982,2583,28135,14591,2574,"5,19","28,65",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Condensed Matter Physics (Q1); Electrical and Electronic Engineering (Q1),"46,705",4.388,0.03845,"Currently, there is increasing interest in analogue multibeam antennas whose beams can be flexibly steered to arbitrary directions. In a previous paper, we presented the theoretical framework for synthesizing flexible multiple beams using generalized joined coupler (GJC) matricec. The synthesis method was to optimize the array excitation vectors to approximate known distributions. In this paper, we present a more robust optimization method to optimize the multibeams directly in order to control the half-power beamwidth, the sidelobe levels and nulls for mitigating system interference. The effectiveness of the proposed method is demonstrated by numerical examples. We reveal how the quality of the multiple beams is inherently determined by the dimensions of the GJC matrix. Experimental results of a 3 × 10 Nolen-like GJC matrix are presented for the first time to validate the proposed method in realizing low sidelobe multibeams.",10.1109/TAP.2022.3220976,2022,,OPTIMIZATION OF MULTIBEAM ANTENNAS EMPLOYING GENERALIZED JOINED COUPLER MATRIX,
344,8000153138,COMPUTER SCIENCE REVIEW,journal,15740137,"1,646",Q1,44,54,61,7789,891,61,"12,49","144,24",Ireland,Western Europe,Elsevier Ireland Ltd,2007-2020,Computer Science (miscellaneous) (Q1); Theoretical Computer Science (Q1),"1,249",7.872,0.00195,"The rapid growth of urban populations worldwide imposes new challenges on citizens’ daily lives, including environmental pollution, public security, road congestion, etc. New technologies have been developed to manage this rapid growth by developing smarter cities. Integrating the Internet of Things (IoT) in citizens’ lives enables the innovation of new intelligent services and applications that serve sectors around the city, including healthcare, surveillance, agriculture, etc. IoT devices and sensors generate large amounts of data that can be analyzed to gain valuable information and insights that help to enhance citizens’ quality of life. Deep Learning (DL), a new area of Artificial Intelligence (AI), has recently demonstrated the potential for increasing the efficiency and performance of IoT big data analytics. In this survey, we provide a review of the literature regarding the use of IoT and DL to develop smart cities. We begin by defining the IoT and listing the characteristics of IoT-generated big data. Then, we present the different computing infrastructures used for IoT big data analytics, which include cloud, fog, and edge computing. After that, we survey popular DL models and review the recent research that employs both IoT and DL to develop smart applications and services for smart cities. Finally, we outline the current challenges and issues faced during the development of smart city services.",https://doi.org/10.1016/j.cosrev.2020.100303,2020,Safa Ben Atitallah and Maha Driss and Wadii Boulila and Henda Ben Ghézala,LEVERAGING DEEP LEARNING AND IOT BIG DATA ANALYTICS TO SUPPORT THE SMART CITIES DEVELOPMENT: REVIEW AND FUTURE DIRECTIONS,article
345,8000153138,COMPUTER SCIENCE REVIEW,journal,15740137,"1,646",Q1,44,54,61,7789,891,61,"12,49","144,24",Ireland,Western Europe,Elsevier Ireland Ltd,2007-2020,Computer Science (miscellaneous) (Q1); Theoretical Computer Science (Q1),"1,249",7.872,0.00195,"This survey presents the concept of Big Data. Firstly, a definition and the features of Big Data are given. Secondly, the different steps for Big Data data processing and the main problems encountered in big data management are described. Next, a general overview of an architecture for handling it is depicted. Then, the problem of merging Big Data architecture in an already existing information system is discussed. Finally this survey tackles semantics (reasoning, coreference resolution, entity linking, information extraction, consolidation, paraphrase resolution, ontology alignment) in the Big Data context.",https://doi.org/10.1016/j.cosrev.2015.05.002,2015,Cheikh {Kacfah Emani} and Nadine Cullot and Christophe Nicolle,UNDERSTANDABLE BIG DATA: A SURVEY,article
346,19700194105,SUSTAINABLE CITIES AND SOCIETY,journal,22106707,"1,645",Q1,61,705,1286,43818,10974,1284,"8,53","62,15",Netherlands,Western Europe,Elsevier BV,2011-2020,"Civil and Structural Engineering (Q1); Geography, Planning and Development (Q1); Renewable Energy, Sustainability and the Environment (Q1); Transportation (Q1)","14,373",7.587,0.01684,"Smart Sustainable Cities (SSC) consist of multiple stakeholders, who must cooperate in order for SSCs to be successful. Housing is an important challenge and in many cities, therefore, a key stakeholder are social housing organisations. This paper introduces a qualitative case study of a social housing provider in the UK who implemented a business intelligence project (a method to assess data networks within an organisation) to increase data quality and data interoperability. Our analysis suggests that creating pathways for different information systems within an organisation to ‘talk to’ each other is the first step. Some of the issues during the project implementation include the lack of training and development, organisational reluctance to change, and the lack of a project plan. The challenges faced by the organisation during this project can be helpful for those implementing SSCs. Currently, many SSC frameworks and models exist, yet most seem to neglect localised challenges faced by the different stakeholders. This paper hopes to help bridge this gap in the SSC research agenda.",https://doi.org/10.1016/j.scs.2018.02.015,2018,Caroline Duvier and P.B. Anand and Crina Oltean-Dumbrava,DATA QUALITY AND GOVERNANCE IN A UK SOCIAL HOUSING INITIATIVE: IMPLICATIONS FOR SMART SUSTAINABLE CITIES,article
347,19700194105,SUSTAINABLE CITIES AND SOCIETY,journal,22106707,"1,645",Q1,61,705,1286,43818,10974,1284,"8,53","62,15",Netherlands,Western Europe,Elsevier BV,2011-2020,"Civil and Structural Engineering (Q1); Geography, Planning and Development (Q1); Renewable Energy, Sustainability and the Environment (Q1); Transportation (Q1)","14,373",7.587,0.01684,"Smart City and IoT improves the performance of health, transportation, energy and reduce the consumption of resources. Among the smart city services, Big Data analytics is one of the imperative technologies that have a vast perspective to reach sustainability, enhanced resilience, effective quality of life and quick management of resources. This paper focuses on the privacy of big data in the context of smart health to support smart cities. Furthermore, the trade-off between the data privacy and utility in big data analytics is the foremost concern for the stakeholders of a smart city. The majority of smart city application databases focus on preserving the privacy of individuals with different disease data. In this paper, we propose a trust-based hybrid data privacy approach named as “MIDR-Angelization” to assure privacy and utility in big data analytics when sharing same disease data of patients in IoT industry. Above all, this study suggests that privacy-preserving policies and practices to share disease and health information of patients having the same disease should consider detailed disease information to enhance data utility. An extensive experimental study performed on a real-world dataset to measure instance disclosure risk which shows that the proposed scheme outperforms its counterpart in terms of data utility and privacy.",https://doi.org/10.1016/j.scs.2018.04.014,2018,Adeel Anjum and Tahir Ahmed and Abid Khan and Naveed Ahmad and Mansoor Ahmad and Muhammad Asif and Alavalapati Goutham Reddy and Tanzila Saba and Nayma Farooq,PRIVACY PRESERVING DATA BY CONCEPTUALIZING SMART CITIES USING MIDR-ANGELIZATION,article
348,19700194105,SUSTAINABLE CITIES AND SOCIETY,journal,22106707,"1,645",Q1,61,705,1286,43818,10974,1284,"8,53","62,15",Netherlands,Western Europe,Elsevier BV,2011-2020,"Civil and Structural Engineering (Q1); Geography, Planning and Development (Q1); Renewable Energy, Sustainability and the Environment (Q1); Transportation (Q1)","14,373",7.587,0.01684,"The effects of human activities and land cover changes on urban thermal field patterns are closely related to the land surface temperature (LST) and air temperature. At present, the number of studies on the quantitative relationship between these two indexes and the effect of the observational scale on their influence is insufficient. In this study, spatial analysis methods such as geographic modeling were combined with remote sensing images, meteorological data, and points of insert and used to investigate the composition and scale of the factors influencing the temperature field in Beijing. The results showed that there are differences in the positive and negative correlations between LST and air temperature and various influencing factors. At a spatial resolution of 90 m, LST had a strong linear relationship with the average air temperature. Indicators reflecting elements of human activity, such as buildings, roads, and entertainment, were easily measured by meteorological stations at a small scale, and the natural green space ratio could also be easily captured by satellite thermal sensors at small scales. These results have substantial implications for environmental impact assessments in areas experiencing an increasing urban heat island effect due to rapid urbanization.",https://doi.org/10.1016/j.scs.2020.102024,2020,Huang Huanchun and Yang Hailin and Deng Xin and Hao Cui and Liu Zhifeng and Liu Wei and Zeng Peng,ANALYZING THE INFLUENCING FACTORS OF URBAN THERMAL FIELD INTENSITY USING BIG-DATA-BASED GIS,article
349,19700194105,SUSTAINABLE CITIES AND SOCIETY,journal,22106707,"1,645",Q1,61,705,1286,43818,10974,1284,"8,53","62,15",Netherlands,Western Europe,Elsevier BV,2011-2020,"Civil and Structural Engineering (Q1); Geography, Planning and Development (Q1); Renewable Energy, Sustainability and the Environment (Q1); Transportation (Q1)","14,373",7.587,0.01684,"Undoubtedly, sustainable development has inspired a generation of scholars and practitioners in different disciplines into a quest for the immense opportunities created by the development of sustainable urban forms for human settlements that will enable built environments to function in a more constructive and efficient way. However, there are still significant challenges that need to be addressed and overcome. The issue of such forms has been problematic and difficult to deal with, particularly in relation to the evaluation and improvement of their contribution to the goals of sustainable development. As it is an urban world where the informational and physical landscapes are increasingly being merged, sustainable urban forms need to embrace and leverage what current and future ICT has to offer as innovative solutions and sophisticated methods so as to thrive—i.e. advance their contribution to sustainability. The need for ICT of the new wave of computing to be embedded in such forms is underpinned by the recognition that urban sustainability applications are deemed of high relevance to the contemporary research agenda of computing and ICT. To unlock and exploit the underlying potential, the field of sustainable urban planning is required to extend its boundaries and broaden its horizons beyond the ambit of the built form of cities to include technological innovation opportunities. This paper explores and substantiates the real potential of ICT of the new wave of computing to evaluate and improve the contribution of sustainable urban forms to the goals of sustainable development. This entails merging big data and context-aware technologies and their applications with the typologies and design concepts of sustainable urban forms to achieve multiple hitherto unrealized goals. In doing so, this paper identifies models of smart sustainable city and their technologies and applications and models of sustainable urban form and their design concepts and typologies. In addition, it addresses the question of how these technologies and applications can be amalgamated with these design concepts and typologies in ways that ultimately evaluate and improve the contribution of sustainable urban forms to the goals of sustainable development. The overall aim of this paper suits a mix of three methodologies: literature review, thematic analysis, and secondary (qualitative) data analysis to achieve different but related objectives. The study identifies four technologies and two classes of applications pertaining to models of smart sustainable city as well as three design concepts and four typologies related to models of sustainable urban form. Finally, this paper proposes a Matrix to help scholars and planners in understanding and analyzing how and to what extent the contribution of sustainable urban forms to sustainability can be improved through ICT of the new wave of computing as to the underlying novel technologies and their applications, as well as a data-centric approach into investigating and evaluating this contribution and a simulation method for strategically optimizing it.",https://doi.org/10.1016/j.scs.2017.04.012,2017,Simon Elias Bibri and John Krogstie,ICT OF THE NEW WAVE OF COMPUTING FOR SUSTAINABLE URBAN FORMS: THEIR BIG DATA AND CONTEXT-AWARE AUGMENTED TYPOLOGIES AND DESIGN CONCEPTS,article
350,17391,IEEE TRANSACTIONS ON SIGNAL PROCESSING,journal,19410476,"1,638",Q1,270,418,1352,18642,10818,1346,"7,53","44,60",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1991-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1),"39,639",4.931,0.04147,"On par with data-intensive applications, the sheer size of modern linear regression problems creates an ever-growing demand for efficient solvers. Fortunately, a significant percentage of the data accrued can be omitted while maintaining a certain quality of statistical inference with an affordable computational budget. This work introduces means of identifying and omitting less informative observations in an online and data-adaptive fashion. Given streaming data, the related maximum-likelihood estimator is sequentially found using first- and second-order stochastic approximation algorithms. These schemes are well suited when data are inherently censored or when the aim is to save communication overhead in decentralized learning setups. In a different operational scenario, the task of joint censoring and estimation is put forth to solve large-scale linear regressions in a centralized setup. Novel online algorithms are developed enjoying simple closed-form updates and provable (non)asymptotic convergence guarantees. To attain desired censoring patterns and levels of dimensionality reduction, thresholding rules are investigated too. Numerical tests on real and synthetic datasets corroborate the efficacy of the proposed data-adaptive methods compared to data-agnostic random projection-based alternatives.",10.1109/TSP.2016.2546225,2016,,ONLINE CENSORING FOR LARGE-SCALE REGRESSIONS WITH APPLICATION TO STREAMING BIG DATA,
351,17391,IEEE TRANSACTIONS ON SIGNAL PROCESSING,journal,19410476,"1,638",Q1,270,418,1352,18642,10818,1346,"7,53","44,60",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1991-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1),"39,639",4.931,0.04147,"In this paper, we consider a multiuser wireless system with one full duplex (FD) base station (BS) serving a set of half duplex (HD) mobile users. To cope with the in-band self-interference (SI) and co-channel interference, we formulate a quality-of-service (QoS) based linear transceiver design problem. The problem jointly optimizes the downlink (DL) and uplink (UL) beamforming vectors of the BS and the transmission powers of UL users so as to provide both the DL and UL users with guaranteed signal-to-interference-plus-noise ratio performance, using a minimum UL and DL transmission sum power. The considered system model not only takes into account noise caused by nonideal RF circuits, analog/digital SI cancellation but also constrains the average signal power at the input of the analog-to-digital converter (ADC) for avoiding signal distortion due to finite ADC precision. The formulated design problem is not convex and challenging to solve in general. We first show that for a special case with a worst case SI channel estimation error, the QoS-based linear transceiver design problem is globally solvable by a polynomial time bisection algorithm. For the general case, we propose a suboptimal algorithm based on alternating optimization (AO). The AO algorithm is guaranteed to converge to a Karush-Kuhn-Tucker solution. To improve the computational efficiency of the AO algorithm, we further develop a fixed-point method by extending the classical uplink-downlink duality in HD systems to the FD system. Simulation results are presented to demonstrate the performance of the proposed algorithms and the comparison with HD systems.",10.1109/TSP.2018.2806344,2018,,QOS-BASED LINEAR TRANSCEIVER OPTIMIZATION FOR FULL-DUPLEX MULTIUSER COMMUNICATIONS,
352,17391,IEEE TRANSACTIONS ON SIGNAL PROCESSING,journal,19410476,"1,638",Q1,270,418,1352,18642,10818,1346,"7,53","44,60",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1991-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1),"39,639",4.931,0.04147,"In this paper, we study how to maintain the communication quality for high-speed users by utilizing array processing techniques. In conventional phase-array approaches, the phase lags among array antennas need to be updated frequently to tune the array transmission direction, thereby rendering considerable operational costs. To alleviate this, we develop a novel frequency diverse array (FDA) approach. The key point is introducing small frequency offsets across array antennas to generate a time-variant beampattern, making it possible that the FDA beampattern peak automatically accompanies the quickly-moving user without the need of refreshing the frequency offsets, which is referred to as a user-centric beampattern. In this work, we consider two cases of interests: 1) one base station (BS) equipped with an FDA serves a user moving quickly along a relatively short track; 2) multiple BSs cooperatively serve the user along a much longer track. In the single-BS case, we optimize the frequency offsets such that the beampattern peak maximally accompanies the user. In the multi-BS case, we further incorporate BS activation to well balance the service quality and the BS maintenance cost. Two low-complexity algorithms are designed to iteratively solve the two problems with stationary convergence guarantee. Simulations confirm that with the same implementation complexity, the FDA approach serves the high-speed user better than the phase-array approach.",10.1109/TSP.2021.3054988,2021,,HIGH-SPEED USER-CENTRIC BEAMPATTERN SYNTHESIS VIA FREQUENCY DIVERSE ARRAY,
353,17391,IEEE TRANSACTIONS ON SIGNAL PROCESSING,journal,19410476,"1,638",Q1,270,418,1352,18642,10818,1346,"7,53","44,60",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1991-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1),"39,639",4.931,0.04147,"This paper concentrates on a robust transmit optimization problem for the multiuser multi-input single-output (MISO) downlink scenario and under inaccurate channel state information (CSI). This robust problem deals with a general-rank transmit covariance design and follows a safe rate-constrained formulation under spherically bounded CSI uncertainties. Curiously, simulation results in previous works suggested that the robust problem admits rank-one optimal transmit covariances in most cases. Such a numerical finding is appealing because transmission with rank-one covariances can be easily realized by single-stream transmit beamforming. This gives rise to a fundamentally important question, namely, whether we can theoretically identify conditions under which the robust problem admits a rank-one solution. In this paper, we identify one such condition. Simply speaking, we show that the robust problem is guaranteed to admit a rank-one solution if the CSI uncertainties are not too large and the multiuser channel is not too poorly conditioned. To establish the aforementioned condition, we develop a novel duality framework, through which an intimate relationship between the robust problem and a related maximin problem is revealed. Our condition involves only a simple expression with respect to the multiuser channel and other system parameters. In particular, unlike other sufficient rank-one conditions that have appeared in the literature, ours is verifiable. The application of our analysis framework to several other CSI uncertainty models is also discussed.",10.1109/TSP.2017.2649488,2017,,UNRAVELING THE RANK-ONE SOLUTION MYSTERY OF ROBUST MISO DOWNLINK TRANSMIT OPTIMIZATION: A VERIFIABLE SUFFICIENT CONDITION VIA A NEW DUALITY RESULT,
354,24657,CHEMOSPHERE,journal,00456535,"1,632",Q1,248,3039,6460,173496,46391,6428,"7,04","57,09",United Kingdom,Western Europe,Elsevier Ltd.,1972-2021,"Chemistry (miscellaneous) (Q1); Environmental Chemistry (Q1); Environmental Engineering (Q1); Health, Toxicology and Mutagenesis (Q1); Medicine (miscellaneous) (Q1); Pollution (Q1); Public Health, Environmental and Occupational Health (Q1)","127,067",7.086,0.0979,"According to Eurostat, the EU production of chemicals hazardous to health reached 211 million tonnes in 2019. Thus, the possibility that some of these chemical compounds interact negatively with the human endocrine system has received, especially in the last decade, considerable attention from the scientific community. It is obvious that given the large number of chemical compounds it is impossible to use in vitro/in vivo tests for identifying all the possible toxic interactions of these chemicals and their metabolites. In addition, the poor availability of highly curated databases from which to retrieve and download the chemical, structure, and regulative information about all food contact chemicals has delayed the application of in silico methods. To overcome these problems, in this study we use robust computational approaches, based on a combination of highly curated databases and molecular docking, in order to screen all food contact chemicals against the nuclear receptor family in a cost and time-effective manner.",https://doi.org/10.1016/j.chemosphere.2021.133422,2022,Pietro Cozzini and Francesca Cavaliere and Giulia Spaggiari and Gianluca Morelli and Marco Riani,COMPUTATIONAL METHODS ON FOOD CONTACT CHEMICALS: BIG DATA AND IN SILICO SCREENING ON NUCLEAR RECEPTORS FAMILY,article
355,39563,INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION,journal,15698432,"1,623",Q1,98,16,523,1076,3348,520,"6,62","67,25",Netherlands,Western Europe,Elsevier,1998-2020,"Computers in Earth Sciences (Q1); Earth-Surface Processes (Q1); Global and Planetary Change (Q1); Management, Monitoring, Policy and Law (Q1)","11,556",5.933,0.01275,"Remote Sensing (RS) has been used in urban mapping for a long time; however, the complexity and diversity of urban functional patterns are difficult to be captured by RS only. Emerging Geospatial Big Data (GBD) are considered as the supplement to RS data, and help to contribute to our understanding of urban lands from physical aspects (i.e., urban land cover) to socioeconomic aspects (i.e., urban land use). Integrating RS and GBD could be an effective way to combine physical and socioeconomic aspects with great potential for high-quality urban land use classification. In this study, we reviewed the existing literature and focused on the state-of-the-art and perspective of the urban land use categorization by integrating RS and GBD. Specifically, the commonly used RS features (e.g., spectral, textural, temporal, and spatial features) and GBD features (e.g., spatial, temporal, semantic, and sequence features) were identified and analyzed in urban land use classification. The integration strategies for RS and GBD features were categorized into feature-level integration (FI) and decision-level integration (DI). To be more specific, the FI method integrates the RS and GBD features and classifies urban land use types using the integrated feature sets; the DI method processes RS and GBD independently and then merges the classification results based on decision rules. We also discussed other critical issues, including analysis unit setting, parcel segmentation, parcel labeling of land use types, and data integration. Our findings provide a retrospect of different features from RS and GBD, strategies of RS and GBD integration, and their pros and cons, which could help to define the framework for future urban land use mapping and better support urban planning, urban environment assessment, urban disaster monitoring and urban traffic analysis.",https://doi.org/10.1016/j.jag.2021.102514,2021,Jiadi Yin and Jinwei Dong and Nicholas A.S. Hamm and Zhichao Li and Jianghao Wang and Hanfa Xing and Ping Fu,INTEGRATING REMOTE SENSING AND GEOSPATIAL BIG DATA FOR URBAN LAND USE MAPPING: A REVIEW,article
356,39563,INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION,journal,15698432,"1,623",Q1,98,16,523,1076,3348,520,"6,62","67,25",Netherlands,Western Europe,Elsevier,1998-2020,"Computers in Earth Sciences (Q1); Earth-Surface Processes (Q1); Global and Planetary Change (Q1); Management, Monitoring, Policy and Law (Q1)","11,556",5.933,0.01275,"Urban Geography studies forms, social fabrics, and economic structures of cities from a geographic perspective. Catalysed by the increasingly abundant spatial big data, Urban Geography seeks new models and research paradigms to explain urban phenomena and address urban issues. Recent years have witnessed significant advances in spatially-explicit geospatial artificial intelligence (GeoAI), which integrates spatial studies and AI, primarily focusing on incorporating spatial thinking and concept into deep learning models for urban studies. This paper provides an overview of techniques and applications of spatially-explicit GeoAI in Urban Geography based on 581 papers identified using a systematic review approach. We examined and screened papers in three scopes of Urban Geography (Urban Dynamics, Social Differentiation of Urban Areas, and Social Sensing) and found that although GeoAI is a trending topic in geography and the applications of deep neural network-based methods are proliferating, the development of spatially-explicit GeoAI models is still at their early phase. We identified three challenges of existing models and advised future research direction towards developing multi-scale explainable spatially-explicit GeoAI. This review paper acquaints beginners with the basics of GeoAI and state-of-the-art and serve as an inspiration to attract more research in exploring the potential of spatially-explicit GeoAI in studying the socio-economic dimension of the city and urban life.",https://doi.org/10.1016/j.jag.2022.102936,2022,Pengyuan Liu and Filip Biljecki,A REVIEW OF SPATIALLY-EXPLICIT GEOAI APPLICATIONS IN URBAN GEOGRAPHY,article
357,18965,MOLECULAR PHYLOGENETICS AND EVOLUTION,journal,10557903,"1,612",Q1,159,208,978,16985,3802,968,"3,89","81,66",United States,Northern America,Academic Press Inc.,1992-2020,"Ecology, Evolution, Behavior and Systematics (Q1); Genetics (Q1); Molecular Biology (Q2)","22,497",4.286,0.02216,"Assessing support for molecular phylogenies is difficult because the data is heterogeneous in quality and overwhelming in quantity. Traditionally, node support values (bootstrap frequency, Bayesian posterior probability) are used to assess confidence in tree topologies. Other analyses to assess the quality of phylogenetic data (e.g. Lento plots, saturation plots, trait consistency) and the resulting phylogenetic trees (e.g. internode certainty, parameter permutation tests, topological tests) exist but are rarely applied. Here we argue that a single qualitative analysis is insufficient to assess support of a phylogenetic hypothesis and relate data quality to tree quality. We use six molecular markers to infer the phylogeny of Blattodea and apply various tests to assess relationship support, locus quality, and the relationship between the two. We use internode-certainty calculations in conjunction with bootstrap scores, alignment permutations, and an approximately unbiased (AU) test to assess if the molecular data unambiguously support the phylogenetic relationships found. Our results show higher support for the position of Lamproblattidae, high support for the termite phylogeny, and low support for the position of Anaplectidae, Corydioidea and phylogeny of Blaberoidea. We use Lento plots in conjunction with mutation-saturation plots, calculations of locus homoplasy to assess locus quality, identify long branch attraction, and decide if the tree’s relationships are the result of data biases. We conclude that multiple tests and metrics need to be taken into account to assess tree support and data robustness.",https://doi.org/10.1016/j.ympev.2018.05.007,2018,Dominic Evangelista and France Thouzé and Manpreet Kaur Kohli and Philippe Lopez and Frédéric Legendre,TOPOLOGICAL SUPPORT AND DATA QUALITY CAN ONLY BE ASSESSED THROUGH MULTIPLE TESTS IN REVIEWING BLATTODEA PHYLOGENY,article
358,5100155103,JOURNAL OF INFORMETRICS,journal,17511577,"1,605",Q1,76,79,276,3786,1696,245,"5,66","47,92",Netherlands,Western Europe,Elsevier BV,2007-2020,Applied Mathematics (Q1); Computer Science Applications (Q1); Library and Information Sciences (Q1); Management Science and Operations Research (Q1); Modeling and Simulation (Q1); Statistics and Probability (Q1),"4,326",5.107,0.00554,"This study presents a unique approach in investigating the knowledge diffusion structure for the field of data quality through an analysis of the main paths. We study a dataset of 1880 papers to explore the knowledge diffusion path, using citation data to build the citation network. The main paths are then investigated and visualized via social network analysis. This paper takes three different main path analyses, namely local, global, and key-route, to depict the knowledge diffusion path and additionally implements the g-index and h-index to evaluate the most important journals and researchers in the data quality domain.",https://doi.org/10.1016/j.joi.2014.05.001,2014,Yu Xiao and Louis Y.Y. Lu and John S. Liu and Zhili Zhou,KNOWLEDGE DIFFUSION PATH ANALYSIS OF DATA QUALITY LITERATURE: A MAIN PATH ANALYSIS,article
359,15576,EUROPEAN NEUROPSYCHOPHARMACOLOGY,journal,0924977X,"1,603",Q1,112,154,383,9717,1610,371,"3,85","63,10",Netherlands,Western Europe,Elsevier,1990-2020,Neurology (Q1); Neurology (clinical) (Q1); Pharmacology (Q1); Pharmacology (medical) (Q1); Psychiatry and Mental Health (Q1); Biological Psychiatry (Q2),"8,999",4.600,0.01119,"Current limitations impeding on data reproducibility are often poor statistical design, underpowered studies, lack of robust data, lack of methodological detail, biased reporting and lack of open data sharing, coupled with wrong research incentives. To improve data reproducibility, robustness and quality for brain disease research, a Preclinical Data Forum Network was formed under the umbrella of the European College of Neuropsychopharmacology (ECNP). The goal of this network, members of which met for the first time in October 2014, is to establish a forum to collaborate in precompetitive space, to exchange and develop best practices, and to bring together the members from academia, pharmaceutical industry, publishers, journal editors, funding organizations, public/private partnerships and non-profit advocacy organizations. To address the most pertinent issues identified by the Network, it was decided to establish a data sharing platform that allows open exchange of information in the area of preclinical neuroscience and to develop an educational scientific program. It is also planned to reach out to other organizations to align initiatives to enhance efficiency, and to initiate activities to improve the clinical relevance of preclinical data. Those Network activities should contribute to scientific rigor and lead to robust and relevant translational data. Here we provide a synopsis of the proceedings from the inaugural meeting.",https://doi.org/10.1016/j.euroneuro.2015.05.011,2015,Thomas Steckler and Katja Brose and Magali Haas and Martien J. Kas and Elena Koustova and Anton Bespalov,THE PRECLINICAL DATA FORUM NETWORK: A NEW ECNP INITIATIVE TO IMPROVE DATA QUALITY AND ROBUSTNESS FOR (PRECLINICAL) NEUROSCIENCE,article
360,20063,BIOCHEMICAL PHARMACOLOGY,journal,00062952,"1,595",Q1,198,513,993,40185,5594,983,"5,29","78,33",United States,Northern America,Elsevier Inc.,1958-2020,Biochemistry (Q1); Pharmacology (Q1),"33,633",5.858,0.01736,"The tremendous expansion of data analytics and public and private big datasets presents an important opportunity for pre-clinical drug discovery and development. In the field of life sciences, the growth of genetic, genomic, transcriptomic and proteomic data is partly driven by a rapid decline in experimental costs as biotechnology improves throughput, scalability, and speed. Yet far too many researchers tend to underestimate the challenges and consequences involving data integrity and quality standards. Given the effect of data integrity on scientific interpretation, these issues have significant implications during preclinical drug development. We describe standardized approaches for maximizing the utility of publicly available or privately generated biological data and address some of the common pitfalls. We also discuss the increasing interest to integrate and interpret cross-platform data. Principles outlined here should serve as a useful broad guide for existing analytical practices and pipelines and as a tool for developing additional insights into therapeutics using big data.",https://doi.org/10.1016/j.bcp.2018.03.014,2018,John F. Brothers and Matthew Ung and Renan Escalante-Chong and Jermaine Ross and Jenny Zhang and Yoonjeong Cha and Andrew Lysaght and Jason Funt and Rebecca Kusko,"INTEGRITY, STANDARDS, AND QC-RELATED ISSUES WITH BIG DATA IN PRE-CLINICAL DRUG DISCOVERY",article
361,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"With the rapid development of in-vehicle communication technology and the integration of big data intelligent technology, intelligent algorithms for vehicle communication used to predict traffic flow and location information have been widely used. Aiming at the problem that the gravitational algorithm is difficult to minimize the complex function and easily fall into the local optimum, this paper proposes an improved IGSA algorithm. First, a gridding algorithm is introduced to initialize the population, and under the premise of ensuring the randomness of the initial individuals, improving the ergodicity of the population is conducive to improving the quality of the solution; then, an adaptive location-based update strategy of decreasing inertia weights is proposed. this strategy inherits the advantages of linearly decreasing weights, and adaptively adjusts the weights according to the fitness value to further improve the optimization performance. The optimization simulation of 8 classic test functions shows that the IGSA algorithm is an effective algorithm for solving complex optimization problems. Finally, the IGSA algorithm is used to predict the geographic location problem in the vehicle GPS data. The IGSA algorithm is used to optimize the extreme learning method to optimize the hyperparameters and establish a vehicle GPS data prediction model. Simulation results verify the feasibility of the method.",10.1109/TITS.2020.3001188,2021,,INTELLIGENT GROUP PREDICTION ALGORITHM OF GPS TRAJECTORY BASED ON VEHICLE COMMUNICATION,
362,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Intelligent Transportation Systems (ITS) is a smart-transportation system for road-side assistance and data exchange support by integrating cloud and wireless networks. ITS facilitates vehicle-to-vehicle and vehicle-to-anything (V2X) data exchanges for satisfying user demands. The rate of big data granting to the vehicular users is interrupted by the fundamental attributes such as mobility and link instability of the vehicles. To address the issues in vehicular data exchange big data, this article introduces displacement-aware service endowment scheme with the benefits of data offloading. Displacement-aware big data endowment ensures responsive availability of vehicle request information despite unfavorable location and density factors. The time congruency in V2V and V2X data exchanges are adopted for minimizing data exchange dropouts. In the data offloading phase, extraneous information and big data responses are detained based on data exchange relevance to improve congestion free big data endowment. The distinct methods work in a co-operative manner to improve big data quality of fast configuring smart vehicles to provide reliable big data in smart city environments.",10.1109/TITS.2021.3078753,2022,,DISPLACEMENT-AWARE SERVICE ENDOWMENT SCHEME FOR IMPROVING INTELLIGENT TRANSPORTATION SYSTEMS DATA EXCHANGE,
363,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Clustering of large-scale vehicle trajectories is an important aspect for understanding urban traffic patterns, particularly for optimizing public transport routes and frequencies and improving the decisions made by authorities. Existing trajectory clustering schemes are not well suited to large numbers of trajectories in dense city road networks due to the difficulty in finding a representative distance measure between trajectories that can scale to very large datasets. In this paper, we propose a novel Dijkstra-based dynamic time warping distance measure, trajDTW between two trajectories, which is suitable for large numbers of overlapping trajectories in a dense road network as found in major cities around the world. We also propose a novel fast-clusiVAT algorithm that can suggest the number of clusters in a trajectory dataset and identify and visualize the trajectories belonging to each cluster. We conduct experiments on a large-scale taxi trajectory dataset consisting of 3.28 million trajectories obtained from the GPS traces of 15 061 taxis within Singapore over a period of one month. Our analysis finds 13 trajectory clusters spanning the major expressways of Singapore, each of which can be further divided into two sub-clusters based on the travel direction. For each cluster, we provide a time-based distribution of trajectories to yield insights into how urban mobility patterns change with the time of day. We compare the trajectory clusters obtained using our approach with those obtained using popular general and trajectory specific clustering frameworks: DBSCAN, OPTICS, NETSCAN, and NEAT. We demonstrate that the clusters obtained using our novel fast-clusiVAT framework are better than those obtained using other clustering schemes, evaluated based on two internal cluster validity measures: Dunn's and Silhouette indices. Moreover, our fast-clusiVAT algorithm achieves significant speedup over a comparable approach without loss of cluster quality.",10.1109/TITS.2018.2854775,2018,,FAST AND SCALABLE BIG DATA TRAJECTORY CLUSTERING FOR UNDERSTANDING URBAN MOBILITY,
364,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"With the rapid development of intelligent transportation systems (ITS), traffic data plays a more and more important role. Low quality traffic data has become a challenging issue in the implementation of ITS. Inspired by the fact that traffic data have strong spatio-temporal correlation, we propose a quality improving model for traffic data, which correlates spatial and temporal features to fix abnormal data. We call it STAP, a spatio-temporal correlative estimating model which firstly proposes an anomalies detection algorithm based on an improved Random Forest model, and then classifies traditional features and extracts spatial and temporal features respectively. Finally the model proposes an XGboost-based data estimation algorithm to fix abnormal data. We conduct experiments on real traffic data collected from a big China city, Changsha, and the results show that the STAP model is effective in improving data quality.",10.1109/TITS.2020.3025948,2022,,STAP: A SPATIO-TEMPORAL CORRELATIVE ESTIMATING MODEL FOR IMPROVING QUALITY OF TRAFFIC DATA,
365,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"As one of the most important properties of road, the adaption to roads with different macro-textures may significantly affect the autonomous driving technologies since road texture directly affects the skidding resistance and tire noise. Therefore, it is of great significance to detect and analyze the road macro texture with respect to different pavement types and service conditions. Generally, transportation engineers may face problems such as small dataset size, unbalanced dataset, etc. To solve these problems, this study aims to recognize the pavement texture using the deep learning approaches. The pavement texture data was first visualized using image processing methods, and then augmented using the traditional methods as well as a deep learning approach, i.e. Generative Adversarial Network (GAN) model. The Random Forest (RF) algorithm and the DenseNet network were both employed, where the overall classification accuracy of the original dataset was 50% and 59%, respectively, and the accuracy of the data augmented by the traditional methods was 58% and 70%, respectively. Test results show that, after 250,000 generations of training, GAN model was able to generate new pavement texture images with high quality, and the classification accuracy on the test dataset using DenseNet improved to 82%. It was discovered that the deep learning methods had a better performance for pavement texture recognition than manual classification and traditional machine learning methods. Furthermore, it was also found that adding noise in the original datasets as an augmentation method had a negative impact on the classification accuracy.",10.1109/TITS.2022.3140586,2022,,DATA AUGMENTATION AND INTELLIGENT RECOGNITION IN PAVEMENT TEXTURE USING A DEEP LEARNING,
366,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"With increasing popularity of related applications of mobile crowdsensing, especially in the field of Internet of Vehicles (IoV), task allocation has attracted wide attention. How to select appropriate participants is a key problem in vehicle-based crowdsensing networks. Some traditional methods choose participants based on minimizing distance, which requires participants to submit their current locations. In this case, participants' location privacy is violated, which influences disclosure of participants' sensitive information. Many privacy preserving task allocation mechanisms have been proposed to encourage users to participate in mobile crowdsensing. However, most of them assume that different participants' task completion quality is the same, which is not reasonable in reality. In this paper, we propose an optimal location privacy preserving and service quality guaranteed task allocation in vehicle-based crowdsensing networks. Specifically, we utilize differential privacy to preserve participants' location privacy, where every participant can submit the obfuscated location to the platform instead of the real one. Based on the obfuscated locations, we design an optimal problem to minimize the moving distance and maximize the task completion quality simultaneously. In order to solve this problem, we decompose it into two linear optimization problems. We conduct extensive experiments to demonstrate the effectiveness of our proposed mechanism.",10.1109/TITS.2021.3086837,2021,,OPTIMAL LOCATION PRIVACY PRESERVING AND SERVICE QUALITY GUARANTEED TASK ALLOCATION IN VEHICLE-BASED CROWDSENSING NETWORKS,
367,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Intelligent vehicular network (IVN) is the underlying support for the connected vehicles and smart city, but there are several challenges for IVN data processing due to the dynamic structure of the vehicular network. Graph processing, as one of the essential machine learning and big data processing paradigm, which provide a set of big data processing scheme, is well-designed to processing the connected data. In this paper, we discussed the research challenges of IVN data processing and motivated us to address these challenges by using graph processing technologies. We explored the characteristics of the widely used graph algorithms and graph processing frameworks on GPU. Furthermore, we proposed several graph-based optimization technologies for IVN data processing. The experimental results show the graph processing technologies on GPU can archive excellent performance on IVN data.",10.1109/TITS.2022.3158045,2022,,GRAPH-ENABLED INTELLIGENT VEHICULAR NETWORK DATA PROCESSING,
368,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"This paper proposes a robust obstacle detection and recognition method for driver assistance systems. Unlike existing methods, our method aims to detect and recognize obstacles on the road rather than all the obstacles in the view. The proposed method involves two stages aiming at an increased quality of the results. The first stage is to locate the positions of obstacles on the road. In order to accurately locate the on-road obstacles, we propose an obstacle detection method based on the U-V disparity map generated from a stereo vision system. The proposed U-V disparity algorithm makes use of the V-disparity map that provides a good representation of the geometric content of the road region to extract the road features, and then detects the on-road obstacles using our proposed realistic U-disparity map that eliminates the foreshortening effects caused by the perspective projection of pinhole imaging. The proposed realistic U-disparity map greatly improves the detection accuracy of the distant obstacles compared with the conventional U-disparity map. Second, the detection results of our proposed U-V disparity algorithm are put into a context-aware Faster-RCNN that combines the interior and contextual features to improve the recognition accuracy of small and occluded obstacles. Specifically, we propose a context-aware module and apply it into the architecture of Faster-RCNN. The experimental results on two public datasets show that our proposed method achieves state-of-the-art performance under various driving conditions.",10.1109/TITS.2019.2909275,2020,,ROBUST OBSTACLE DETECTION AND RECOGNITION FOR DRIVER ASSISTANCE SYSTEMS,
369,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Internet of Vehicles (IoVs) is highly characterized by collaborative environment data sensing, computing and processing. Emerging Big Data and Artificial Intelligence (AI) technologies show significant advantages and efficiency for knowledge sharing among intelligent vehicles. However, it is challenging to guarantee the security and privacy of knowledge during the sharing process. Moreover, conventional AI-based algorithms cannot work properly in distributed vehicular networks. In this paper, a hierarchical blockchain framework and a hierarchical federated learning algorithm are proposed for knowledge sharing, by which vehicles learn environmental data through machine learning methods and share the learning knowledge with each others. The proposed hierarchical blockchain framework is feasible for the large scale vehicular networks. The hierarchical federated learning algorithm is designed to meet the distributed pattern and privacy requirement of IoVs. Knowledge sharing is then modeled as a trading market process to stimulate sharing behaviours, and the trading process is formulated as a multi-leader and multi-player game. Simulation results show that the proposed hierarchical algorithm can improve the sharing efficiency and learning quality. Furthermore, the blockchain-enabled framework is able to deal with certain malicious attacks effectively.",10.1109/TITS.2020.3002712,2021,,A HIERARCHICAL BLOCKCHAIN-ENABLED FEDERATED LEARNING ALGORITHM FOR KNOWLEDGE SHARING IN INTERNET OF VEHICLES,
370,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Effective extraction of road boundaries plays a significant role in intelligent transportation applications, including autonomous driving, vehicle navigation, and mapping. This paper presents a new method to automatically extract 3-D road boundaries from mobile laser scanning (MLS) data. The proposed method includes two main stages: supervoxel generation and 3-D road boundary extraction. Supervoxels are generated by selecting smooth points as seeds and assigning points into facets centered on these seeds using several attributes (e.g., geometric, intensity, and spatial distance). 3-D road boundaries are then extracted using the α-shape algorithm and the graph cuts-based energy minimization algorithm. The proposed method was tested on two data sets acquired by a RIEGL VMX-450 MLS system. Experimental results show that road boundaries can be robustly extracted with an average completeness over 95%, an average correctness over 98%, and an average quality over 94% on two data sets. The effectiveness and superiority of the proposed method over the state-of-the-art methods is demonstrated.",10.1109/TITS.2017.2701403,2018,,3-D ROAD BOUNDARY EXTRACTION FROM MOBILE LASER SCANNING DATA VIA SUPERVOXELS AND GRAPH CUTS,
371,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"In the edge computing-supported Internet of Vehicles (IoV), the edge servers (ESs) are distributed near the road side units (RSUs) to process the transmitted data for various IoV services in real time. Generally, due to the budget constraints, the ES scale is limited. If the ESs are not appropriately placed, it may cause the unbalanced load distribution of the ESs. Therefore, how to place a constant number of ESs with the goal of avoiding the risk of overload and improving the quality of services remains a challenge. To tackle this challenge, a quantified edge server placement strategy, named QESP, is fully investigated, to improve the coverage rate, the workload balance and reduce the average waiting time of services in the IoV. Technically, binary encoding and quantum encoding are fully leveraged to model the ES locations. Then, the niched pareto genetic algorithm II (NPGA-II) and the quantum rotation gate are adopted to obtain the appropriate solutions for the ES placement problem. Furthermore, an assessment function is devised to find the optimal scheme among the solutions obtained. Finally, the validity of QESP is evaluated by using real-world vehicular big data.",10.1109/TITS.2021.3116960,2022,,QUANTIFIED EDGE SERVER PLACEMENT WITH QUANTUM ENCODING IN INTERNET OF VEHICLES,
372,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Determining the best route for logging trucks is difficult as many road features needs to be considered. There are methodologies to determine a good weight setting for these features based on inverse optimization, allowing them to be combined into one objective. The distance of the minimum-cost route on a network where the arc costs are determined by this weighted objective will then form the basis of invoicing. From detailed collected and agreed routes acting as the most preferred solutions, we can evaluate the quality of our proposed approach. Multiple sources of information are used, e.g., lidar, aerial photos, and GIS databases are collected and made available. There has been a demand from end-users to also include vertical and horizontal curvature as road features in the route selection. Since such values are not directly collected or stored in databases, they must be analyzed and estimated using geographical information. We propose a methodology for computing vertical and horizontal curvatures that represent the perception of such features, as well as processes to clean and complement inaccurate coordinates in the data. The proposed decision tools work very well in practice and are implemented in the intelligent transport planning system called calibrated route finder (CRF). CRF has been used on national level for distance calculation and route selection on since 2010, and the proposed use of vertical and horizontal curvatures was implemented during 2014. Today, over 50% of all forest sector transport invoicing in Sweden is based on the system.",10.1109/TITS.2015.2503424,2016,,USING ANALYTICS IN THE IMPLEMENTATION OF VERTICAL AND HORIZONTAL CURVATURE IN ROUTE CALCULATION,
373,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"The customized bus (CB) is an innovative type of transit service that can provide a personalized efficient transit services for passengers and environmental friendliness and congestion alleviation in metropolitan areas. This work develops an integrated optimization method for CB stop deployment, route design, and timetable development optimization problems while meeting travel demands as much as possible to obtain system-optimal CB service plans. Through the perspective of space-time network, the CB service design problem (CBSDP) is formulated as an integrated optimization model with the objectives of maximizing passenger accessibility and minimizing operating cost. An inconvenience index of passengers is introduced in the problem to measure the service quality, and the total number of stops for all involved CB routes is set as one of the objectives to optimize the total cost of the CB system. A heuristic approach is applied to generate efficient solutions for the CBSDP. Two types of instance, namely, a numerical experiment and a real-world instance, are implemented to demonstrate the performance of the proposed method. We also conduct a series of sensitive analyses to explore the influences of various parameters on the CB system for capturing the interaction among stops, routes, and timetables. Final results show that the CB plans obtained by the proposed method can provide efficient services by balancing passenger convenience and operating cost.",10.1109/TITS.2020.3048520,2021,,"INTEGRATED OPTIMIZATION FOR COMMUTING CUSTOMIZED BUS STOP PLANNING, ROUTING DESIGN, AND TIMETABLE DEVELOPMENT WITH PASSENGER SPATIAL-TEMPORAL ACCESSIBILITY",
374,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"This paper presents an arc-routing problem with time-dependent penalty cost (ARPTPC), which arises from a practical application in garbage collection service. ARPTPC considers the minimization of service cost, traveling cost and penalty cost. While the first two parts are known as the traditional objectives of arc-routing problems, the third part is determined by the parking pattern and service period on each arc. We formulate the problem by using a mixed integer linear model. To solve it, we design a dynamic programming to determine the optimal service beginning time on each edge when a routing sequence is given. We then propose a problem-specific intelligent heuristic search approach involving six neighborhood operators, a priority maintenance mechanism and a perturbation process. Through numerical experiments, we demonstrate that the proposed approach is able to produce satisfactory solutions of ARPTPC. Additional experiments are also carried out to analyze the effects of operators and parameters on solution quality.",10.1109/TITS.2020.2973806,2021,,PLANNING OF GARBAGE COLLECTION SERVICE: AN ARC-ROUTING PROBLEM WITH TIME-DEPENDENT PENALTY COST,
375,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Random traffic flow load (TFL) simulation is an important analysis method for bridge design and safety assessment, and accurate TFL modelling is a prerequisite for high-quality simulation. The existing TFL modelling methods almost all rely on the load data monitored by the weigh-in-motion system (WIM system). However, the WIM system has natural defects such as unsatisfactory measurement accuracy at low speed and the inability to measure vehicle lengths and transverse positions in the lane, limiting the improvement of TFL simulation accuracy. Regarding this, a TFL monitoring system that integrates the functions of machine vision and WIM system is developed in this paper. In this system, a deep learning method is applied, for the accurate detection of vehicles and wheels in the video, and the extraction of key parameters for TFL modelling based on detection results. According to the long-term monitoring value, statistical distributions of key parameters are determined, and then an intelligent TFL model is derived from the Intelligent Driver Model (IDM), considering the car-following behavior of vehicles. Correspondingly, this paper further suggests a TFL simulation method and achieves an accurate TFL simulation. A cable-stayed bridge is taken as an example to verify the feasibility of the method. The results show that, compared to the modelling and simulation methods that only rely on the WIM system, the proposed method not only reduces the measurement error of vehicle dimensions by nearly 4 times, but also performs higher resolution in time measurement. The proposed method effectively overcomes the shortcomings of existing schemes and has good application potential in engineering.",10.1109/TITS.2022.3140276,2022,,INTELLIGENT SIMULATION METHOD OF BRIDGE TRAFFIC FLOW LOAD COMBINING MACHINE VISION AND WEIGH-IN-MOTION MONITORING,
376,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"In the Internet of Vehicles (IoV), vehicles communicate wirelessly with other vehicles, sensors, pedestrians, and roadside units. IoV is aimed at improving road safety, driving comfort, and traffic efficiency. However, IoV is exposed to a range of threats to security and privacy. The presence of dishonest and misbehaving peers in the system is of a major concern, which may put lives in danger. Thus, establishing trust among these probable untrusted vehicles is one of the most significant challenges of such a network. The critical pitfalls of existing and traditional mechanisms are scalability, a single point of failure, maintaining the quality of service, verification, and revocation and dealing with sparsity, consistency, availability, efficiency, robustness, privacy concerns are some of the biggest challenges to be addressed. Blockchain technology, with its great success in applications like cryptocurrencies and smart contracts, is considered as one of the potential candidates to build trust in IoV. In this paper, we propose a blockchain-based decentralized trust management scheme using smart contracts. Specifically, we introduce the concept of blockchain sharding for reducing the load on the main blockchain and increasing the transaction throughput. Our proposal has two key contributions: blockchain to maintain and update reliable and consistent trust values across the network and incentive scheme to encourage peers to perform well. We also conduct extensive experiments, which demonstrate the implementation feasibility of proposed mechanisms in the real world.",10.1109/TITS.2020.3004041,2021,,BLOCKCHAIN-BASED ADAPTIVE TRUST MANAGEMENT IN INTERNET OF VEHICLES USING SMART CONTRACT,
377,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Railway track geometry varies along routes depending on topographical, operational and safety constraints. Tracks are prone to degrade over time due to various factors, with deviations from the original geometry design having potential implications for comfort and safety. Regular inspections are carried out to evaluate track condition and determine whether maintenance interventions should be undertaken to correct track geometry. The dynamic measurement of track geometry parameters generates large volumes of data that must be analysed to evaluate track degradation. This work comprehensively explains how track quality is evaluated, introducing four main categories of factors affecting it. These are track design, loading, environment and maintenance. The most common techniques applied to evaluate track condition and predict degradation and faults, categorised into statistical, Machine Learning, Big Data and other, are also introduced. Specifically, the influence of each factor on track geometry is stated and the common techniques applied to each factor determined from this review. The utility of loading and maintenance data for fault prediction depend on the availability of records, whilst the impact of environmental conditions is expected to become increasingly important due to climate change. Artificial Neural Networks, Bayesian models and regression are the most applied techniques for determining track degradation behaviour and fault prediction, considering several different factors in their models. Increasingly sophisticated algorithms can consider multiple factors in tandem to predict faults based on the unique conditions of specified tracks.",10.1109/TITS.2022.3214121,2022,,REVIEW OF DATA ANALYTICS FOR CONDITION MONITORING OF RAILWAY TRACK GEOMETRY,
378,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Unsupervised learning methods have achieved remarkable performance in monocular depth estimation and camera pose, which mostly solve the multi-task learning problem by using their inner geometry consistency as the self-supervision signal. While most existing approaches mostly adopt the generative model to obtain the depth map prediction, so in the resolution of depth map there is room for improvement. To this end, we present our unsupervised learning architecture based on adversarial learning model, which is used for unsupervised learning of high-resolution single view depth and camera pose. Specifically, we present a multi-scale deep convolutional Generative Adversarial Network (GAN) based learning system, which consists of three networks (pose estimation network PCNN, Generator-D and Discriminator-D for depth map prediction). Furthermore, in order to generate high-resolution depth map, we propose a multi-scale GAN model (MSGAN) to decompose the hard high-quality image generation problem into more manageable sub-problems through a coarse-to-fine process. Then, we modify the overall generation architecture of GAN model by changing the down-sampling and up-sampling components to improve the quality and accuracy of the depth map prediction. Finally, in order to improve the rate of convergence, we use the Least Square Error to increase the penalty for outliers. Detailed quantitative and qualitative evaluations of the proposed framework on the KITTI dataset show that the proposed method provides better results for both pose estimation and depth recovery.",10.1109/TITS.2021.3093592,2022,,UNSUPERVISED LEARNING OF DEPTH ESTIMATION AND CAMERA POSE WITH MULTI-SCALE GANS,
379,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"With the development of location-based services and smart terminals, skyline query technique has been used widely in intelligent transportation systems. In skyline queries, the areas and keywords queried by users have a great impact on the quality of the query results and users may only be interested in the closer results of the skyline query. However, current approaches for the continuous skyline query limit the area of the skyline query to a specific area in the road network, which leads to that many useful query results cannot be retrieved. To this end, an innovative continuous skyline query approach in city range is proposed in this paper, where a multi-scale area divisions of the urban road network are provided to find the optimize query scale and area. In our approach, first, the dominant area of each intersection node in the road network is established based on the Voronoi. Then, all Points of Interest ( $POI\text{s}$ ) are divided into the dominant area of each intersection node. After that, the intersection node aggregation algorithm ( $INAA$ ), link remolding algorithm ( $LMA$ ) and link fitting algorithm ( $LFA$ ) are proposed to reduce the number of intersection nodes in the road network, so as to increase the dominant area of the remaining intersection nodes and the number of POIs in these nodes. Finally, a better query scale by considering the efficiency and quality of the query is given through the studies.",10.1109/TITS.2020.3001577,2021,,CONTINUOUS ROAD NETWORK-BASED SKYLINE QUERY FOR MOVING OBJECTS,
380,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"The work on this paper studies the combined effect of vehicle dynamics, sampling period and the quality of inter-vehicle sensing and communication on the performance of platoon control. First, we induce the sampled control protocol from continuous–time linear consensus protocol by employing zero–order hold circuit and periodic sampling technology, then by virtue of the obtained sampled control protocol, the continuous–time platoon system is equivalently transformed into a discrete–time system. Second, for the inter–vehicle communication with ideal channel and under undirected information flow topology (UIFT), the stability thresholds of control gains are explicitly established by solving a discrete–time simultaneous stabilization problem, bilinear transformation and the Routh-Hurwitz stability criterion. Meanwhile, to ensure the fastest asymptotic stability of the platoon dynamics, we propose an optimal asymptotic convergence factor and a correspondingly optimal sampled control protocol. Third, For the inter–vehicle communication with identical fading networks and under UIFT, through solving a modified Riccati inequality, we provide a sampled control protocol depending not only on information flow topology (IFT) and sampling period, but also on the statistics of the inter–vehicle communication channel. Besides, employing Lyapunov inequality in probability theory, we show a necessary condition for the sampled control protocol ensuring the platoon dynamics mean square stable. Finally, simulations are performed to demonstrate the theory’s discoveries.",10.1109/TITS.2022.3150565,2022,,COOPERATIVE SPACING SAMPLED CONTROL OF VEHICLE PLATOON CONSIDERING UNDIRECTED TOPOLOGY AND ANALOG FADING NETWORKS,
381,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"It is an irreversible trend to build a green and sustainable vehicular network facing with the dramatic increase in urban traffic. Reducing energy consumption has been an important aspect for green transportation. Reconfigurable intelligent surface (RIS) is considered as a promising technology to enhance the communication quality with higher energy efficiency. In this paper, we focus on the RIS-assisted vehicular networks. We obtain the closed-form analytical expressions for outage probability, ergodic achievable rate and average energy efficiency. A series of insights are further explored. Based on these, we discuss the performance under high SNR case, as well as, weak interference case. And then, the approximations in simpler form expressions are provided for each case, respectively. Outage diversity order and high SNR rate slope are also investigated. In addition, we propose a power allocation algorithm to maximize the ergodic achievable sum rate guaranteeing the outage probability and average energy efficiency. Numerical results show that our analytical results agree well with the Monte Carlo simulations in various network configurations. Besides, our proposed power allocation scheme significantly enhances the ergodic achievable sum rate compared with the equal power strategy.",10.1109/TITS.2022.3205037,2022,,AN EFFICIENT POWER ALLOCATION ALGORITHM FOR GREEN RECONFIGURABLE INTELLIGENT SURFACE ASSISTED VEHICULAR NETWORK,
382,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Lane-level positioning and map matching are some of the biggest challenges for navigation systems. Additionally, in safety applications or in those with critical performance requirements (such as satellite-based electronic fee collection), integrity becomes a key word for the navigation community. In this scenario, it is clear that a navigation system that can operate at the lane level while providing integrity parameters that are capable of monitoring the quality of the solution can bring important benefits to these applications. This paper presents a pioneering novel solution to the problem of combined positioning and map matching with integrity provision at the lane level. The system under consideration hybridizes measurements from a global navigation satellite system (GNSS) receiver, an odometer, and a gyroscope, along with the road information stored in enhanced digital maps, by means of a multiple-hypothesis particle-filter-based algorithm. A set of experiments in real environments in France and Germany shows the very good results obtained in terms of positioning, map matching, and integrity consistency, proving the feasibility of our proposal.",10.1109/TITS.2009.2031625,2010,,"LANE-LEVEL INTEGRITY PROVISION FOR NAVIGATION AND MAP MATCHING WITH GNSS, DEAD RECKONING, AND ENHANCED MAPS",
383,18378,IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS,journal,15580016,"1,591",Q1,153,595,1026,20731,9523,1015,"8,41","34,84",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2000-2020,Automotive Engineering (Q1); Computer Science Applications (Q1); Mechanical Engineering (Q1),"20,072",6.492,0.02555,"Electrification of passenger vehicles has been viewed by many as a way to significantly reduce carbon emissions, operate vehicles more efficiently, and reduce oil dependence. Due to the potential benefits of electric vehicle (EV), many federal and local governments have allocated considerable funding and taken a number of legislative and regulatory steps to promote EV deployment and adoption. With this momentum, it is not difficult to see that in the near future, EVs could gain a significant market penetration, particularly in densely populated urban areas with systemic air quality problems. We will soon face one of the biggest challenges: how to improve the efficiency for the EV transportation system? This research aims to contribute to this field by proposing an analytical model that determines a time-dependent optimal velocity profile for an EV in order to minimize the electricity usage along a chosen route by systematically considering road characteristics and real-time traffic conditions. In particular, the proposed multistage optimal control model uniquely considers the impact of the presence of intersection queues in both temporal and spatial dimensions, which has been ignored in most traditional speed control models even for internal combustion engine vehicles. In addition, to facilitate the real-time operations, an approximation model, which simplifies the optimal speed profile, is further developed to increase the computation efficiency. The testing using the field data collected from a six-intersection signalized arterial corridor shows that the optimal velocity profile can significantly save energy for an EV, and the computational efficiency of the proposed approximation model is suitable for real-time applications.",10.1109/TITS.2015.2422778,2015,,ENERGY-OPTIMAL SPEED CONTROL FOR ELECTRIC VEHICLES ON SIGNALIZED ARTERIALS,
384,24772,KNOWLEDGE-BASED SYSTEMS,journal,09507051,"1,587",Q1,121,716,1187,36777,11094,1181,"9,42","51,36",Netherlands,Western Europe,Elsevier,1987-2020,Artificial Intelligence (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Software (Q1),"22,261",8.038,0.02794,"Information extraction using distributed sensors has been widely used to obtain information knowledge from various regions or areas. Vehicle traffic data extraction is one of the ways to gather information in order to get the traffic condition information. This research intends to predict and visualize the traffic conditions in a particular road region. Traffic data was obtained from Department of Transport UK. These data are collected using hundreds of sensors for 24 h. Thus, the size of data is very huge. In order to get the behavior of the traffic condition, we need to analyze the huge dataset which was obtained from the sensors. The uses of conventional data mining methods are not sufficient to use, due to the process of knowledge building that should store data temporary in the memory. The fact that data is continuously becoming larger over time, therefore we need to find a method that could automatically adapt to process data in the form of streams. We use method called FIMT-DD (Fast Incremental Model Trees-Drift Detection) to analyze and predict the very large traffic dataset. Based on the prediction system that we have developed, we also visualize the prediction of traffic flow condition within generated sensor point in the real map simulation.",https://doi.org/10.1016/j.knosys.2015.10.028,2016,Ari Wibisono and Wisnu Jatmiko and Hanief Arief Wisesa and Benny Hardjono and Petrus Mursanto,TRAFFIC BIG DATA PREDICTION AND VISUALIZATION USING FAST INCREMENTAL MODEL TREES-DRIFT DETECTION (FIMT-DD),article
385,24772,KNOWLEDGE-BASED SYSTEMS,journal,09507051,"1,587",Q1,121,716,1187,36777,11094,1181,"9,42","51,36",Netherlands,Western Europe,Elsevier,1987-2020,Artificial Intelligence (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Software (Q1),"22,261",8.038,0.02794,"Modern applications of Big Data are transcending from being scalable solutions of data processing and analysis, to now provide advanced functionalities with the ability to exploit and understand the underpinning knowledge. This change is promoting the development of tools in the intersection of data processing, data analysis, knowledge extraction and management. In this paper, we propose TITAN, a software platform for managing all the life cycle of science workflows from deployment to execution in the context of Big Data applications. This platform is characterised by a design and operation mode driven by semantics at different levels: data sources, problem domain and workflow components. The proposed platform is developed upon an ontological framework of meta-data consistently managing processes and models and taking advantage of domain knowledge. TITAN comprises a well-grounded stack of Big Data technologies including Apache Kafka for inter-component communication, Apache Avro for data serialisation and Apache Spark for data analytics. A series of use cases are conducted for validation, which comprises workflow composition and semantic meta-data management in academic and real-world fields of human activity recognition and land use monitoring from satellite images.",https://doi.org/10.1016/j.knosys.2021.107489,2021,Antonio Benítez-Hidalgo and Cristóbal Barba-González and José García-Nieto and Pedro Gutiérrez-Moncayo and Manuel Paneque and Antonio J. Nebro and María del Mar Roldán-García and José F. Aldana-Montes and Ismael Navas-Delgado,TITAN: A KNOWLEDGE-BASED PLATFORM FOR BIG DATA WORKFLOW MANAGEMENT,article
386,24772,KNOWLEDGE-BASED SYSTEMS,journal,09507051,"1,587",Q1,121,716,1187,36777,11094,1181,"9,42","51,36",Netherlands,Western Europe,Elsevier,1987-2020,Artificial Intelligence (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Software (Q1),"22,261",8.038,0.02794,"Today, big data processing has become a challenging task due to the amount of data collected using various sensors increasingly significantly. To build knowledge and predict the data, traditional data mining methods calculate all numerical attributes into the memory simultaneously. The data stream method is a solution for processing and calculating data. The method streams incrementally in batch form; therefore, infrastructure memory is sufficient to develop knowledge. The existing method for data stream prediction is FIMT-DD (Fast Incremental Model Tree-Drift Detection). Using this method, knowledge is developed in tree form for every instance. In this paper, enhanced FIMT-DD is proposed using ARDEV (Average Restrain Divider of Evaluation Value). ARDEV utilizes the Chernoff bound approach with error evaluation, improvement in learning rate, modification of perceptron rule calculation, and utilization of activation function. Standard FIMT-DD separates the tree formation process and perceptron prediction. The proposed method evaluates and connects the development of the tree for knowledge formation and the perceptron rule for prediction. The prediction accuracy of the proposed method is measured using MAE, RMSE and MAPE. From the experiment performed, the utilization of ARDEV enhancement shows significant improvement in terms of accuracy prediction. Statistically, the overall accuracy prediction improvement is approximately 6.99 % compared to standard FIMT-DD with a traffic dataset.",https://doi.org/10.1016/j.knosys.2019.03.019,2019,Ari Wibisono and Devvi Sarwinda,AVERAGE RESTRAIN DIVIDER OF EVALUATION VALUE (ARDEV) IN DATA STREAM ALGORITHM FOR BIG DATA PREDICTION,article
387,28611,GEOFORUM,journal,00167185,"1,584",Q1,116,284,773,20662,3032,725,"3,54","72,75",United Kingdom,Western Europe,Elsevier BV,1970-2020,Sociology and Political Science (Q1),"11,684",3.901,0.0159,"Global health threats such as the recent Ebola and Zika virus outbreaks require rapid and robust responses to prevent, reduce and recover from disease dispersion. As part of broader big data and digital humanitarianism discourses, there is an emerging interest in data produced through mobile phone communications for enhancing the data environment in such circumstances. This paper assembles user perspectives and critically examines existing evidence and future potential of mobile phone data derived from call detail records (CDRs) and two-way short message service (SMS) platforms, for managing and responding to humanitarian disasters caused by communicable disease outbreaks. We undertake a scoping review of relevant literature and in-depth interviews with key informants to ascertain the: (i) information that can be gathered from CDRs or SMS data; (ii) phase(s) in the disease disaster management cycle when mobile data may be useful; (iii) value added over conventional approaches to data collection and transfer; (iv) barriers and enablers to use of mobile data in disaster contexts; and (v) the social and ethical challenges. Based on this evidence we develop a typology of mobile phone data sources, types, and end-uses, and a decision-tree for mobile data use, designed to enable effective use of mobile data for disease disaster management. We show that mobile data holds great potential for improving the quality, quantity and timing of selected information required for disaster management, but that testing and evaluation of the benefits, constraints and limitations of mobile data use in a wider range of mobile-user and disaster contexts is needed to fully understand its utility, validity, and limitations.",https://doi.org/10.1016/j.geoforum.2016.07.019,2016,Jonathan Cinnamon and Sarah K. Jones and W. Neil Adger,EVIDENCE AND FUTURE POTENTIAL OF MOBILE PHONE DATA FOR DISEASE DISASTER MANAGEMENT,article
388,31405,JOURNAL OF ARCHAEOLOGICAL SCIENCE,journal,03054403,"1,572",Q1,126,137,365,10414,1239,362,"3,04","76,01",United States,Northern America,Academic Press Inc.,1974-2020,Archeology (Q1); Archeology (arts and humanities) (Q1); History (Q1),"17,761",3.216,0.01111,"As spatial technology has evolved and become integrated in to archaeology, we face a new set of challenges posed by the sheer size and complexity of data we use and produce. In this paper I discuss the prospects and problems of Geospatial Big Data (GBD) – broadly defined as data sets with locational information that exceed the capacity of widely available hardware, software, and/or human resources. While the datasets we create today remain within available resources, we nonetheless face the same challenges as many other fields that use and create GBD, especially in apprehensions over data quality and privacy. After reviewing the kinds of archaeological geospatial data currently available I discuss the near future of GBD in writing culture histories, making decisions, and visualizing the past. I use a case study from New Zealand to argue for the value of taking a data quantity-in-use approach to GBD and requiring applications of GBD in archaeology be regularly accompanied by a Standalone Quality Report.",https://doi.org/10.1016/j.jas.2017.06.003,2017,Mark D. McCoy,GEOSPATIAL BIG DATA AND ARCHAEOLOGY: PROSPECTS AND PROBLEMS TOO GREAT TO IGNORE,article
389,17370,IEEE TRANSACTIONS ON POWER DELIVERY,journal,19374208,"1,570",Q1,188,397,865,8168,5173,859,"5,47","20,57",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1985-2020,Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1),"23,291",4.131,0.01563,"Modern electric grid usages extensive non-linear loads leading to the increased harmonic current injection in the system. This paper proposes a data-driven algorithm based on a sparse decomposition approach with the Overcomplete Hybrid Dictionary (OHD) and provides in-depth mathematical analysis to detect and mitigate harmonics in emerging electric power systems. The sparse decomposition method is widely used in image processing applications with significant advantages to big-data applications. However, its application is not properly addressed in electric grids' applications despite massive data generation in a smart grid environment. Hence, in this paper, the performance evaluation of a sparse decomposition-based algorithm using a greedy approach is proposed and carried out in a real-time simulation environment for Distribution Static Compensator (DSTATCOM) application for the real-time detection, classification, and mitigation of PQ events to show its suitability and effectiveness. Finally, the experimental results on a small-scale laboratory setup are presented to validate the effectiveness of the proposed sparse-based control algorithm for DSTATCOM in real-time applications. The comparative result shows that the proposed sparse-based method is advantageous for off-line PQ signal processing and capable of real-time detection, classification, and control of the power apparatus for harmonics mitigation.",10.1109/TPWRD.2022.3160613,2022,,DATA ANALYTICS BASED POWER QUALITY INVESTIGATIONS IN EMERGING ELECTRIC POWER SYSTEM USING SPARSE DECOMPOSITION,
390,17370,IEEE TRANSACTIONS ON POWER DELIVERY,journal,19374208,"1,570",Q1,188,397,865,8168,5173,859,"5,47","20,57",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1985-2020,Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1),"23,291",4.131,0.01563,"Noise in power-quality (PQ) signals has been the biggest hurdle in wavelet-based detection and time localization of PQ events. The well-known threshold-based denoising techniques, used in the signal-processing area, do not perform well with practical PQ waveform data. This paper proposes a simple yet effective denoising technique using inter and intrascale dependencies of wavelet coefficients to denoise PQ waveform data for enhanced detection and time localization of PQ disturbances. Utilizing the fact that the wavelet coefficients are not only correlated with its local neighborhood within the subband but also across the subband, the proposed method exploits the local structure of wavelet coefficients as well as high correlation of adjacent wavelet scales. The effectiveness of the proposed approach is tested and demonstrated with both simulated and measured power-line disturbance data, and the results show that the proposed scheme significantly outperforms existing methods used to denoise PQ data.",10.1109/TPWRD.2009.2027482,2010,,ENHANCED DETECTION OF POWER-QUALITY EVENTS USING INTRA AND INTERSCALE DEPENDENCIES OF WAVELET COEFFICIENTS,
391,22992,JOURNAL OF RETAILING AND CONSUMER SERVICES,journal,09696989,"1,568",Q1,89,346,555,27784,4555,550,"7,77","80,30",United Kingdom,Western Europe,Elsevier Ltd.,1994-2021,Marketing (Q1),"10,506",7.135,0.00876,"Big data analytics (BDA) adoption has gained attention in both practical and theoretical circles owing to the opportunities and advantages that can be reaped from it. In theory, the majority of researchers have evidenced the benefits of BDA, although barriers to its adoption have also been mentioned. This study draws upon the technology-organisation-environment framework and resource-based view theory to propose an integrated model that examines the drivers and impact of BDA adoption in the retail industry in Jordan. The proposed single model encapsulates the aspects of BDA adoption and performance. The study makes use of an online questionnaire survey to collect the required data, and the research model is eventually validated based on 132 responses gathered from the retail industry in Jordan. The findings highlight two major observations. The first is that relative advantage, organisational readiness, top management support, government support, data variety and data velocity all have a significant influence over BDA adoption. The second observation is that a significant association exists between BDA adoption and firm performance, providing information on the way firms can enhance their BDA adoption for enhanced performance. This study contributes to literature dedicated to examining BDA in terms of its drivers and impact on performance and can be used as a reference in developing nations.",https://doi.org/10.1016/j.jretconser.2022.103129,2023,Abdalwali Lutfi and Mahmaod Alrawad and Adi Alsyouf and Mohammed Amin Almaiah and Ahmad Al-Khasawneh and Akif Lutfi Al-Khasawneh and Ahmad Farhan Alshira'h and Malek Hamed Alshirah and Mohamed Saad and Nahla Ibrahim,DRIVERS AND IMPACT OF BIG DATA ANALYTIC ADOPTION IN THE RETAIL INDUSTRY: A QUANTITATIVE INVESTIGATION APPLYING STRUCTURAL EQUATION MODELING,article
392,22992,JOURNAL OF RETAILING AND CONSUMER SERVICES,journal,09696989,"1,568",Q1,89,346,555,27784,4555,550,"7,77","80,30",United Kingdom,Western Europe,Elsevier Ltd.,1994-2021,Marketing (Q1),"10,506",7.135,0.00876,"Big data analytics (BDA) has emerged as a significant area of research for both researchers and practitioners in the retail industry, indicating the importance and influence of solving data-related problems in contemporary business organization. The present study utilised a quantitative-methods approach to investigate factors affecting retailers' adoption of BDA across three countries. A survey questionnaire was used to collect data from managers and decision-makers in the retail industry. Data of 2278 respondents were analysed through structural equation modelling. The findings revealed that security concerns, external support, top management support, and rational decision making culture have a greater effect on BDA adoption in developed countries UK than in UAE and Egypt. However, competition intensity and firm size have a greater effect on BDA adoption in UAE and Egypt than in UK. Finally, human variables (competence of information system's staff and staff's information system knowledge) have a greater effect on BDA adoption in Egypt than UK and UAE. The findings indicate that a “one-size-fits-all” approach is insufficient in capturing the heterogeneity of managers across countries. Implications for practice and theory were demonstrated.",https://doi.org/10.1016/j.jretconser.2021.102827,2022,Mayada Abd El-Aziz Youssef and Riyad Eid and Gomaa Agag,CROSS-NATIONAL DIFFERENCES IN BIG DATA ANALYTICS ADOPTION IN THE RETAIL INDUSTRY,article
393,20896,TELEMATICS AND INFORMATICS,journal,07365853,"1,567",Q1,66,96,483,6939,3832,438,"7,45","72,28",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,Communication (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1); Law (Q1),"5,351",6.182,0.00899,"Social Networking Services (SNSs) connect people worldwide, where they communicate through sharing contents, photos, videos, posting their first-hand opinions, comments, and following their friends. Social networks are characterized by velocity, volume, value, variety, and veracity, the 5 V’s of big data. Hence, big data analytic techniques and frameworks are commonly exploited in Social Network Analysis (SNA). By the ever-increasing growth of social networks, the analysis of social data, to describe and find communication patterns among users and understand their behaviors, has attracted much attention. In this paper, we demonstrate how big data analytics meets social media, and a comprehensive review is provided on big data analytic approaches in social networks to search published studies between 2013 and August 2020, with 74 identified papers. The findings of this paper are presented in terms of main journals/conferences, yearly distributions, and the distribution of studies among publishers. Furthermore, the big data analytic approaches are classified into two main categories: Content-oriented approaches and network-oriented approaches. The main ideas, evaluation parameters, tools, evaluation methods, advantages, and disadvantages are also discussed in detail. Finally, the open challenges and future directions that are worth further investigating are discussed.",https://doi.org/10.1016/j.tele.2020.101517,2021,Sepideh {Bazzaz Abkenar} and Mostafa {Haghi Kashani} and Ebrahim Mahdipour and Seyed Mahdi Jameii,"BIG DATA ANALYTICS MEETS SOCIAL MEDIA: A SYSTEMATIC REVIEW OF TECHNIQUES, OPEN ISSUES, AND FUTURE DIRECTIONS",article
394,20896,TELEMATICS AND INFORMATICS,journal,07365853,"1,567",Q1,66,96,483,6939,3832,438,"7,45","72,28",United Kingdom,Western Europe,Elsevier Ltd.,1984-2020,Communication (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1); Law (Q1),"5,351",6.182,0.00899,"From the viewpoint of big data as a socio-technical phenomenon, this study examines the associated assumptions and biases critically and contextually. The research analyzes the big data phenomenon from a socio-technical systems theory perspective: cultural, technological, and scholarly phenomena that rest on the interplay of technology, analysis, and mythology provoking extensive utopian and dystopian rhetoric. It examines the development of big data by reviewing this theory, identifying key components of the big data ecosystem, and explaining how these components are likely to evolve over time. Despite extensive investment and proactive drive, uncertainty exists concerning the evolution of big data and the impact on the new information milieu. Significant concerns recently addressed are in the areas of privacy, data quality, access, curation, preservation, and use. This study provides insight into these challenges and opportunities through the lens of a socio-technical analysis of big data development, which includes social dynamics, political discourse, and technological choices inherent in the design and development of next-generation ICT ecology. The policy implications of big data are addressed using Korean information initiatives to highlight key considerations as the country progresses in this new ecology era.",https://doi.org/10.1016/j.tele.2014.09.006,2015,Dong-Hee Shin and Min Jae Choi,ECOLOGICAL VIEWS OF BIG DATA: PERSPECTIVES AND ISSUES,article
395,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,,https://doi.org/10.1016/j.dss.2019.113172,2019,James R. Marsden and David E. Pingry and Jason B. Thatcher,PERSPECTIVES ON NUMERICAL DATA QUALITY IN IS RESEARCH,article
396,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"We present a probability-based metric for semantic consistency using a set of uncertain rules. As opposed to existing metrics for semantic consistency, our metric allows to consider rules that are expected to be fulfilled with specific probabilities. The resulting metric values represent the probability that the assessed dataset is free of internal contradictions with regard to the uncertain rules and thus have a clear interpretation. The theoretical basis for determining the metric values are statistical tests and the concept of the p-value, allowing the interpretation of the metric value as a probability. We demonstrate the practical applicability and effectiveness of the metric in a real-world setting by analyzing a customer dataset of an insurance company. Here, the metric was applied to identify semantic consistency problems in the data and to support decision-making, for instance, when offering individual products to customers.",https://doi.org/10.1016/j.dss.2018.03.011,2018,Bernd Heinrich and Mathias Klier and Alexander Schiller and Gerit Wagner,ASSESSING DATA QUALITY – A PROBABILITY-BASED METRIC FOR SEMANTIC CONSISTENCY,article
397,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"Where a technology is its life cycle can make a difference in the data generated by or about adopting, using or implementing that technology. As a result, it is arguable that adoption, usage or implementation data generated early in a technology's life cycle is directly comparable to data generated later in the life cycle. In particular, comparisons of early and late data can result in a number of disparate results and limit replicability, because of biases in the data and non-stationary data. This paper suggests that it can be important for information systems researchers to disclose an estimate of the location in the technology's life cycle, as part of their analysis. The data life cycle discussion is then extended to the notion of “data phase triangulation,” which is contrasted with “methodology triangulation” and “data (collection) triangulation.” In addition, we discuss the importance of being able to use the findings from life cycle-based research to “push” a technology from one phase to another phase.",https://doi.org/10.1016/j.dss.2019.113139,2019,Daniel E. O'Leary,TECHNOLOGY LIFE CYCLE AND DATA QUALITY: ACTION AND TRIANGULATION,article
398,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"We argue that there are major, persistent numerical data quality issues in IS academic research. These issues undermine the ability to replicate our research – a critical element of scientific investigation and analysis. In IS empirical and analytics research articles, the amount of space devoted to the details of data collection, validation, and/or quality pales in comparison to the space devoted to the evaluation and selection of relatively sophisticated model form(s) and estimation technique(s). Yet erudite modeling and estimation can yield no immediate value or be meaningfully replicated without high quality data inputs. The purpose of this paper is: 1) to detail potential quality issues with data types currently used in IS research, and 2) to start a wider and deeper discussion of data quality in IS research. No data type is inherently of low quality and no data type guarantees high quality. As researchers, our empirical research must always address data quality issues and provide the information necessary to determine What, When, Where, How, Who, and Which.",https://doi.org/10.1016/j.dss.2018.10.007,2018,James R. Marsden and David E. Pingry,NUMERICAL DATA QUALITY IN IS RESEARCH AND THE IMPLICATIONS FOR REPLICATION,article
399,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"Anecdotal evidence suggests that, despite the large variety of data, the huge volume of generated data, and the fast velocity of obtaining data (i.e., big data), quality of big data is far from perfect. Therefore, many firms defer collecting and integrating big data as they have concerns regarding the impact of utilizing big data on data diagnosticity (i.e., retrieval of valuable information from data) and firm decision making quality. In this study, we use the Organizational Learning Theory and Wang and Strong's data quality framework to explore the impact of processing big data on firm decision quality and the mediating role of data quality (DQ) and data diagnosticity on this relationship. We validate the proposed research model using survey data from 130 firms, obtained from data analysts and IT managers. Results confirm the critical role of DQ in increasing data diagnosticity and improving firm decision quality when processing big data; suggesting important implications for practice and theory. Findings also reveal that while big data utilization positively impacts contextual DQ, accessibility DQ, and representational DQ, interestingly, it negatively impacts intrinsic DQ. Furthermore, findings show that while intrinsic DQ, contextual DQ, and representational DQ significantly increase data diagnosticity, accessibility DQ does not influence it. Most importantly, the findings show that big data utilization does not significantly impact the quality of firm decisions and it is fully mediated through DQ and data diagnosticity. The results of this study contribute to practice by providing important guidelines for managers to improve firm decision quality through the use of big data.",https://doi.org/10.1016/j.dss.2019.03.008,2019,Maryam Ghasemaghaei and Goran Calic,CAN BIG DATA IMPROVE FIRM DECISION QUALITY? THE ROLE OF DATA QUALITY AND DATA DIAGNOSTICITY,article
400,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"An IS researcher may obtain Big Data from primary or secondary data sources. Sometimes, acquiring primary Big Data is infeasible due to availability, accessibility, cost, time, and/or complexity considerations. In this paper, we focus on Big Data-based IS research and discuss ways in which one may, post hoc, establish quality thresholds for numerical Big Data obtained from secondary sources. We also present guidelines for developing journal policies aimed at ensuring the veracity and verifiability of such data when used for research purposes.",https://doi.org/10.1016/j.dss.2019.113135,2019,Anita Lee-Post and Ram Pakath,"NUMERICAL, SECONDARY BIG DATA QUALITY ISSUES, QUALITY THRESHOLD ESTABLISHMENT, & GUIDELINES FOR JOURNAL POLICY DEVELOPMENT",article
401,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"In recent years an increasing number of academic disciplines, including IS, have sourced digital trace data for their research. Notwithstanding the potential of such data in (re)investigations of various phenomena of interest that would otherwise be difficult or impossible to study using other sources of data, we view the quality of digital trace data as an underappreciated issue in IS research. To initiate a discussion of how to evaluate and report on the quality of digital trace data in IS research, we couch our arguments within the broader tradition of research on data quality. We explain how the uncontrolled nature of digital trace data creates unique challenges for IS researchers, who need to collect, store, retrieve, and transform those data for the purpose of numerical analysis. We then draw parallels with concepts and patterns commonly used in data analysis projects and argue that, although IS researchers probably apply such concepts and patterns, this is not reported in publications, undermining the reader's ability to assess the reliability, statistical power and replicability of the findings. Using the case of GitHub to illustrate such challenges, we develop a preliminary set of guidelines to help researchers consider and report on the quality of the digital trace data they use in their research. Our work contributes to the debate on data quality and provides relevant recommendations for scholars and IS journals at a time when a growing number of publications are relying on digital trace data.",https://doi.org/10.1016/j.dss.2019.113133,2019,Gregory Vial,REFLECTIONS ON QUALITY REQUIREMENTS FOR DIGITAL TRACE DATA IN IS RESEARCH,article
402,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"Big data analytics (BDA) are gaining importance in all aspects of business management. This is driven by both the presence of large-scale data and management's desire to root decisions in data. Extant research demonstrates that supply chain and operations management functions are among the biggest sources and users of data in the company. Therefore, their decision-making processes would benefit from increased use of BDA technologies. However, there is still a lack of understanding of what determines a company's ability to build BDA capability to gain a competitive advantage. In this study, we attempt to answer this fundamental question by identifying the factors that assist a company in or inhibit it from building its BDA capability and maximizing its gains through BDA technologies. We base our findings on a qualitative analysis of data collected from field visits, interviews with senior management, and secondary resources. We find that, in addition to technical capacity, competitive landscape and intra-firm power dynamics play an important role in building BDA capability and using BDA technologies.",https://doi.org/10.1016/j.dss.2020.113382,2020,Ashish Kumar Jha and Maher A.N. Agi and Eric W.T. Ngai,A NOTE ON BIG DATA ANALYTICS CAPABILITY DEVELOPMENT IN SUPPLY CHAIN,article
403,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"The low quality of data in information systems poses enormous risks to business operations and decision making. In this paper, a single-period resource allocation problem for controlling the information system's data quality problem is considered. We develop a Data-Quality-Petri net to capture the process through which data quality problem generates, propagates, and accumulates in the information system. The net considers not only the factors leading to the production of the data quality problem by the data operation nodes and the data flow structure, but also the data transfer ratio of the nodes. Then, we propose a nonlinear programming optimization model with control resource constraints. The result of the model provides an optimal strategy to allocate resources for minimizing the expected data quality problem of an information system. Further, we examine the impact of the data flow structure on optimal resource allocation. The result shows that the optimal resource input level for a data operation node is proportional to its potential for downstream propagation. A warehouse management system of an e-commerce company is utilized to illustrate the model. Our study provides a method for data managers to control the information system's data quality problem by employing a process perspective.",https://doi.org/10.1016/j.dss.2020.113381,2020,Qi Liu and Gengzhong Feng and Xi Zhao and Wenlong Wang,MINIMIZING THE DATA QUALITY PROBLEM OF INFORMATION SYSTEMS: A PROCESS-BASED METHOD,article
404,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"Using service-oriented decision support systems (DSS in cloud) is one of the major trends for many organizations in hopes of becoming more agile. In this paper, after defining a list of requirements for service-oriented DSS, we propose a conceptual framework for DSS in cloud, and discus about research directions. A unique contribution of this paper is its perspective on how to servitize the product oriented DSS environment, and demonstrate the opportunities and challenges of engineering service oriented DSS in cloud. When we define data, information and analytics as services, we see that traditional measurement mechanisms, which are mainly time and cost driven, do not work well. Organizations need to consider value of service level and quality in addition to the cost and duration of delivered services. DSS in CLOUD enables scale, scope and speed economies. This article contributes new knowledge in service science by tying the information technology strategy perspectives to the database and design science perspectives for a broader audience.",https://doi.org/10.1016/j.dss.2012.05.048,2013,Haluk Demirkan and Dursun Delen,LEVERAGING THE CAPABILITIES OF SERVICE-ORIENTED DECISION SUPPORT SYSTEMS: PUTTING ANALYTICS AND BIG DATA IN CLOUD,article
405,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"To succeed in their business processes, organizations need data that not only attains suitable levels of quality for the task at hand, but that can also be considered as usable for the business. However, many researchers ground the potential usability of the data on its quality. Organizations would benefit from receiving recommendations on the usability of the data before its use. We propose that the recommendation on the usability of the data be supported by a decision process, which includes a context-dependent data-quality assessment based on business rules. Ideally, this recommendation would be generated automatically. Decision Model and Notation (DMN) enables the assessment of data quality based on the evaluation of business rules, and also, provides stakeholders (e.g., data stewards) with sound support for the automation of the whole process of generation of a recommendation regarding usability based on data quality. The main contribution of the proposal involves designing and enabling both DMN-driven mechanisms and a guiding methodology (DMN4DQ) to support the automatic generation of a decision-based recommendation on the potential usability of a data record in terms of its level of data quality. Furthermore, the validation of the proposal is performed through the application of a real dataset.",https://doi.org/10.1016/j.dss.2020.113450,2021,Álvaro Valencia-Parra and Luisa Parody and Ángel Jesús Varela-Vaca and Ismael Caballero and María Teresa Gómez-López,DMN4DQ: WHEN DATA QUALITY MEETS DMN,article
406,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"Forecasting tourism demand has important implications for both policy makers and companies operating in the tourism industry. In this research, we applied methods and tools of social network and semantic analysis to study user-generated content retrieved from online communities which interacted on the TripAdvisor travel forum. We analyzed the forums of 7 major European capital cities, over a period of 10 years, collecting more than 2,660,000 posts, written by about 147,000 users. We present a new methodology of analysis of tourism-related big data and a set of variables which could be integrated into traditional forecasting models. We implemented Factor Augmented Autoregressive and Bridge models with social network and semantic variables which often led to a better forecasting performance than univariate models and models based on Google Trend data. Forum language complexity and the centralization of the communication network – i.e. the presence of eminent contributors – were the variables that contributed more to the forecasting of international airport arrivals.",https://doi.org/10.1016/j.dss.2019.113075,2019,Andrea {Fronzetti Colladon} and Barbara Guardabascio and Rosy Innarella,USING SOCIAL NETWORK AND SEMANTIC ANALYSIS TO ANALYZE ONLINE TRAVEL FORUMS AND FORECAST TOURISM DEMAND,article
407,21933,DECISION SUPPORT SYSTEMS,journal,01679236,"1,564",Q1,151,115,342,7152,2672,338,"7,04","62,19",Netherlands,Western Europe,Elsevier,1985-2020,Arts and Humanities (miscellaneous) (Q1); Developmental and Educational Psychology (Q1); Information Systems (Q1); Information Systems and Management (Q1); Management Information Systems (Q1),"13,580",5.795,0.0081,"The rapid growth of big data environment imposes new challenges that traditional knowledge discovery and data mining process (KDDM) models are not adequately suited to address. We propose a snail shell process model for knowledge discovery via data analytics (KDDA) to address these challenges. We evaluate the utility of the KDDA process model using real-world analytic case studies at a global multi-media company. By comparing against traditional KDDM models, we demonstrate the need and relevance of the snail shell model, particularly in addressing faster turnaround and frequent model updates that characterize knowledge discovery in the big data environment.",https://doi.org/10.1016/j.dss.2016.07.003,2016,Yan Li and Manoj A. Thomas and Kweku-Muata Osei-Bryson,A SNAIL SHELL PROCESS MODEL FOR KNOWLEDGE DISCOVERY VIA DATA ANALYTICS,article
408,18080,ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING,journal,07365845,"1,561",Q1,93,139,404,6448,2949,400,"7,35","46,39",United Kingdom,Western Europe,Elsevier Ltd.,"1984-1994, 1996-2021",Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Mathematics (miscellaneous) (Q1); Software (Q1),"6,215",5.666,0.0057,"Advanced manufacturing is one of the core national strategies in the US (AMP), Germany (Industry 4.0) and China (Made-in China 2025). The emergence of the concept of Cyber Physical System (CPS) and big data imperatively enable manufacturing to become smarter and more competitive among nations. Many researchers have proposed new solutions with big data enabling tools for manufacturing applications in three directions: product, production and business. Big data has been a fast-changing research area with many new opportunities for applications in manufacturing. This paper presents a systematic literature review of the state-of-the-art of big data in manufacturing. Six key drivers of big data applications in manufacturing have been identified. The key drivers are system integration, data, prediction, sustainability, resource sharing and hardware. Based on the requirements of manufacturing, nine essential components of big data ecosystem are captured. They are data ingestion, storage, computing, analytics, visualization, management, workflow, infrastructure and security. Several research domains are identified that are driven by available capabilities of big data ecosystem. Five future directions of big data applications in manufacturing are presented from modelling and simulation to real-time big data analytics and cybersecurity.",https://doi.org/10.1016/j.rcim.2019.101861,2020,Yesheng Cui and Sami Kara and Ka C. Chan,MANUFACTURING BIG DATA ECOSYSTEM: A SYSTEMATIC LITERATURE REVIEW,article
409,18080,ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING,journal,07365845,"1,561",Q1,93,139,404,6448,2949,400,"7,35","46,39",United Kingdom,Western Europe,Elsevier Ltd.,"1984-1994, 1996-2021",Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Mathematics (miscellaneous) (Q1); Software (Q1),"6,215",5.666,0.0057,"Today, in a smart manufacturing environment based on the Industry 4.0 paradigm, people, technological infrastructure and machinery equipped with sensors can constantly generate and communicate a huge volume of data, also known as Big Data. The manufacturing industry takes advantage of Big Data and analytics evolution by improving its capability to bring out valuable information and knowledge from industrial processes, production systems and sensors. The adoption of model-based frameworks in the Big Data Analytics pipeline can better address user configuration requirements (e.g. type of analysis to perform, type of algorithm to be applied) and also provide more transparency and clearness on the execution of workflows and data processing. In the current state of art, an application of a model-based framework in a manufacturing scenario is missing. Therefore, in this study, by means of a case study research focused on data from sensors associated with Computer Numerical Control machines, the configuration and execution of a Big Data Analytics pipeline with a Model-based Big Data Analytics-as-a-Service framework is described. The case study provides to theoreticians and managerial experts useful evidence for managing real-time data analytics and deploying a workflow that addresses specific analytical goals, driven by user requirements and developer models, in a complex manufacturing domain.",https://doi.org/10.1016/j.rcim.2022.102331,2022,Angelo Corallo and Anna Maria Crespino and Mariangela Lazoi and Marianna Lezzi,MODEL-BASED BIG DATA ANALYTICS-AS-A-SERVICE FRAMEWORK IN SMART MANUFACTURING: A CASE STUDY,article
410,18080,ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING,journal,07365845,"1,561",Q1,93,139,404,6448,2949,400,"7,35","46,39",United Kingdom,Western Europe,Elsevier Ltd.,"1984-1994, 1996-2021",Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Mathematics (miscellaneous) (Q1); Software (Q1),"6,215",5.666,0.0057,"From the last decade, additive manufacturing (AM) has been evolving speedily and has revealed the great potential for energy-saving and cleaner environmental production due to a reduction in material and resource consumption and other tooling requirements. In this modern era, with the advancements in manufacturing technologies, academia and industry have been given more interest in smart manufacturing for taking benefits for making their production more sustainable and effective. In the present study, the significant techniques of smart manufacturing, sustainable manufacturing, and additive manufacturing are combined to make a unified term of sustainable and smart additive manufacturing (SSAM). The paper aims to develop framework by combining big data analytics, additive manufacturing, and sustainable smart manufacturing technologies which is beneficial to the additive manufacturing enterprises. So, a framework of big data-driven sustainable and smart additive manufacturing (BD-SSAM) is proposed which helped AM industry leaders to make better decisions for the beginning of life (BOL) stage of product life cycle. Finally, an application scenario of the additive manufacturing industry was presented to demonstrate the proposed framework. The proposed framework is implemented on the BOL stage of product lifecycle due to limitation of available resources and for fabrication of AlSi10Mg alloy components by using selective laser melting (SLM) technique of AM. The results indicate that energy consumption and quality of the product are adequately controlled which is helpful for smart sustainable manufacturing, emission reduction, and cleaner production.",https://doi.org/10.1016/j.rcim.2020.102026,2021,Arfan Majeed and Yingfeng Zhang and Shan Ren and Jingxiang Lv and Tao Peng and Saad Waqar and Enhuai Yin,A BIG DATA-DRIVEN FRAMEWORK FOR SUSTAINABLE AND SMART ADDITIVE MANUFACTURING,article
411,16313,FUEL,journal,00162361,"1,560",Q1,213,2396,5152,119785,35895,5139,"6,88","49,99",Netherlands,Western Europe,Elsevier BV,"1922, 1970-2021",Chemical Engineering (miscellaneous) (Q1); Energy Engineering and Power Technology (Q1); Fuel Technology (Q1); Organic Chemistry (Q1),"98,202",6.609,0.08033,"In this paper, the droplet size distributions of high-velocity airblast atomization were analyzed. The spray measurement was performed by a Phase-Doppler anemometer at several points and different diameters across the spray for diesel oil, light heating oil, crude rapeseed oil, and water. The atomizing gauge pressure and the liquid preheating temperature varied from 0.3 to 2.4 bar and 25 to 100 °C, respectively. Approximately 400 million individual droplets were recorded; therefore, a big data evaluation technique was applied. 18 of the most commonly used probability density functions (PDF) were fitted to the histogram of each measuring point and evaluated by their relative log-likelihood. Among the three-parameter PDFs, Generalized Extreme Value and Burr PDFs provided the most desirable result to describe a complete drop size distribution. With restriction to two-parameter PDFs, the Nakagami PDF unexpectedly outperformed all the others, including Weibull (Rosin-Rammler) PDF, which is commonly used in atomization. However, if the spray is characterized by a single value, such as the Sauter Mean Diameter, i.e. an expected value-like parameter is of primary importance over the distribution, Gamma PDF is the best option, used in several papers of the atomization literature.",https://doi.org/10.1016/j.fuel.2020.117792,2020,András Urbán and Axel Groniewsky and Milan Malý and Viktor Józsa and Jan Jedelský,APPLICATION OF BIG DATA ANALYSIS TECHNIQUE ON HIGH-VELOCITY AIRBLAST ATOMIZATION: SEARCHING FOR OPTIMUM PROBABILITY DENSITY FUNCTION,article
412,13760,HABITAT INTERNATIONAL,journal,01973975,"1,542",Q1,78,117,365,8006,2114,361,"5,46","68,43",United Kingdom,Western Europe,Elsevier Ltd.,"1970, 1976-2020",Nature and Landscape Conservation (Q1); Urban Studies (Q1),"8,872",5.369,0.00827,"Urban studies attempt to identify the geographic areas with restricted access to healthy and affordable foods (defined as food deserts in the literature). While prior publications have reported the socioeconomic disparities in healthy food accessibility, little evidence has been released from developing countries, especially in China. This paper proposes a geo-big data approach to measuring transit-varying healthy food accessibility and applies it to identify the food deserts within Shenzhen, China. In particular, we develop a crawling tool to harvest the daily travel time from each community (8117) to each healthy food store (102) from the Baidu Map under four transport modes (walking, public transit, private car, and bicycle) during 17:30–20:30 in June 2016. Based on the travel time calculations, we develop four travel time indicators to measure the healthy food accessibility: the minimum, the maximum, the weighted average, and the standard deviation. Results show that the four accessibility indicators generate different estimations and the nearest service (minimum time) alone fails to reflect the multidimensional nature of healthy food accessibility. The communities within Shenzhen present quite different typology with respect to healthy food accessibility under different transport modes. Multilevel additive regression is further applied to examine the associations between healthy food accessibility and nested socioeconomic characteristics at two geographic levels (community and district). We discover that the associations are divergent with transport modes and with geographic levels. More specifically, significant social equalities in healthy food accessibility are identified via walking, public transit, and bicycle in Shenzhen. Based on the associations, we finally map the food deserts and propose corresponding planning strategies. The methods demonstrated in this study should offer deeper spatial insights into intra-urban foodscapes and provide more nuanced understanding of food deserts in urban settings of developing countries.",https://doi.org/10.1016/j.habitatint.2017.04.007,2017,Shiliang Su and Zekun Li and Mengya Xu and Zhongliang Cai and Min Weng,"A GEO-BIG DATA APPROACH TO INTRA-URBAN FOOD DESERTS: TRANSIT-VARYING ACCESSIBILITY, SOCIAL INEQUALITIES, AND IMPLICATIONS FOR URBAN PLANNING",article
413,22305,SURGERY,journal,00396060,"1,532",Q1,162,487,1520,10740,4267,1108,"2,40","22,05",United States,Northern America,Mosby Inc.,1937-2020,Surgery (Q1),"25,223",3.982,0.02493,"The term big data has been popularized over the past decade and is often used to refer to data sets that are too large or complex to be analyzed by traditional means. Although the term has been utilized for some time in business and engineering, the concept of big data is relatively new to medicine. The reception from the medical community has been mixed; however, the widespread utilization of electronic health records in the United States, the creation of large clinical data sets and national registries that capture information on numerous vectors affecting healthcare delivery and patient outcomes, and the sequencing of the human genome are all opportunities to leverage big data. This review was inspired by a lively panel discussion on big data that took place at the 75th Central Surgical Association Annual Meeting. The authors’ aim was to describe big data, the methodologies used to analyze big data, and their practical clinical application.",https://doi.org/10.1016/j.surg.2018.06.022,2018,Adrienne N. Cobb and Andrew J. Benjamin and Erich S. Huang and Paul C. Kuo,BIG DATA: MORE THAN BIG DATA SETS,article
414,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"In any knowledge discovery process the value of extracted knowledge is directly related to the quality of the data used. Big Data problems, generated by massive growth in the scale of data observed in recent years, also follow the same dictate. A common problem affecting data quality is the presence of noise, particularly in classification problems, where label noise refers to the incorrect labeling of training instances, and is known to be a very disruptive feature of data. However, in this Big Data era, the massive growth in the scale of the data poses a challenge to traditional proposals created to tackle noise, as they have difficulties coping with such a large amount of data. New algorithms need to be proposed to treat the noise in Big Data problems, providing high quality and clean data, also known as Smart Data. In this paper, two Big Data preprocessing approaches to remove noisy examples are proposed: an homogeneous ensemble and an heterogeneous ensemble filter, with special emphasis in their scalability and performance traits. The obtained results show that these proposals enable the practitioner to efficiently obtain a Smart Dataset from any Big Data classification problem.",https://doi.org/10.1016/j.ins.2018.12.002,2019,Diego García-Gil and Julián Luengo and Salvador García and Francisco Herrera,ENABLING SMART DATA: NOISE FILTERING IN BIG DATA CLASSIFICATION,article
415,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"In online review systems, a participant's level of knowledge impacts his/her posting behaviors, and an increase in knowledge occurs when the participant reads the reviews posted on the systems. To capture the collective dynamics of posting reviews, we used real-world big data collected over 153 months to drive an agent-based model for replicating the operation process of online review systems. The model explains the effects of clicking position (e.g., on a review webpage's serial list) and the number of items per webpage on posting contributions. Reading reviews from the last webpage only, or from the first webpage and last webpage simultaneously, can promote a greater review volume than reading reviews in other positions. This illustrates that representing primacy (first items) and recency (recent items) within one page simultaneously, or displaying recent items in reverse chronological order, are relatively better strategies for the webpage display of online reviews. The number of items plays a nonlinear moderating role in bridging the clicking position and posting behavior, and we determine the optimal number of items. To effectively establish strategies for webpage design in online review systems, business managers must switch from reliance on experience to reliance on an agent-based model as a decision support system for the formalized webpage design of online review systems.",https://doi.org/10.1016/j.ins.2019.09.053,2020,Guoyin Jiang and Xiaodong Feng and Wenping Liu and Xingjun Liu,CLICKING POSITION AND USER POSTING BEHAVIOR IN ONLINE REVIEW SYSTEMS: A DATA-DRIVEN AGENT-BASED MODELING APPROACH,article
416,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"In state-of-the-art big-data applications, the process of building machine learning models can be very challenging due to continuous changes in data structures and the need for human interaction to tune the variables and models over time. Hence, expedited learning in rapidly changing environments is required. In this work, we address this challenge by implementing concepts from the field of intrinsically motivated computational learning, also known as artificial curiosity (AC). In AC, an autonomous agent acts to optimize its learning about itself and its environment by receiving internal rewards based on prediction errors. We present a novel method of intrinsically motivated learning, based on the curiosity loop, to learn the data structures in large and varied datasets. An autonomous agent learns to select a subset of relevant features in the data, i.e., feature selection, to be used later for model construction. The agent optimizes its learning about the data structure over time without requiring external supervision. We show that our method, called the Curious Feature Selection (CFS) algorithm, positively impacts the accuracy of learning models on three public datasets.",https://doi.org/10.1016/j.ins.2019.02.009,2019,Michal Moran and Goren Gordon,CURIOUS FEATURE SELECTION,article
417,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"In big data era, information integration often requires abundant data extracted from massive data sources. Due to a large number of data sources, data source selection plays a crucial role in information integration, since it is costly and even impossible to access all data sources. Data Source selection should consider both efficiency and effectiveness issues. For efficiency, the approach should scale to large data source amount. From effectiveness aspect, data quality and overlapping of sources are to be considered. In this paper, we study source selection problem in Big Data and propose methods which can scale to datasets with up to millions of data sources and guarantee the quality of results. Motivated by this, we propose a new metric taking the expected number of true values a source can provide as a criteria to evaluate the contribution of a data source. Based on our proposed index, we present a scalable algorithm and two pruning strategies to improve the efficiency without sacrificing precision. Experimental results on both real world and synthetic data sets show that our methods can select sources providing a large proportion of true values efficiently and can scale to massive data sources.",https://doi.org/10.1016/j.ins.2018.11.029,2019,Yiming Lin and Hongzhi Wang and Jianzhong Li and Hong Gao,DATA SOURCE SELECTION FOR INFORMATION INTEGRATION IN BIG DATA ERA,article
418,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"Clustering technique plays a critical role in data mining, and has received great success to solve application problems like community analysis, image retrieval, personalized recommendation, activity prediction, etc. This paper first reviews the traditional clustering and the emerging multiple clustering methods, respectively. Although the existing methods have superior performance on some small or certain datasets, they fall short when clustering is performed on CPSS big data because of the high cost of computation and storage. With the powerful cloud computing, this challenge can be effectively addressed, but it brings enormous threat to individual or company’s privacy. Currently, privacy preserving data mining has attracted widespread attention in academia. Compared to other reviews, this paper focuses on privacy preserving clustering technique, guiding a detailed overview and discussion. Specifically, we introduce a novel privacy-preserving tensor-based multiple clustering, propose a privacy-preserving tensor-based multiple clustering analytic and service framework, and give an illustrated case study on the public transportation dataset. Furthermore, we indicate the remaining challenges of privacy preserving clustering and discuss the future significant research in this area.",https://doi.org/10.1016/j.ins.2019.10.019,2020,Yaliang Zhao and Samwel K. Tarus and Laurence T. Yang and Jiayu Sun and Yunfei Ge and Jinke Wang,PRIVACY-PRESERVING CLUSTERING FOR BIG DATA IN CYBER-PHYSICAL-SOCIAL SYSTEMS: SURVEY AND PERSPECTIVES,article
419,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"The era of Big Data has arrived along with large volume, complex and growing data generated by many distinct sources. Nowadays, nearly every aspect of the modern society is impacted by Big Data, involving medical, health care, business, management and government. It has been receiving growing attention of researches from many disciplines including natural sciences, life sciences, engineering and even art & humanities. It also leads to new research paradigms and ways of thinking on the path of development. Lots of developed and under-developing tools improve our ability to make more felicitous decisions than what we have made ever before. This paper presents an overview on Big Data including four issues, namely: (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art techniques for decision making in Big Data; (iii) felicitous decision making applications of Big Data in social science; and (iv) the current challenges of Big Data as well as possible future directions.",https://doi.org/10.1016/j.ins.2016.07.007,2016,Hai Wang and Zeshui Xu and Hamido Fujita and Shousheng Liu,TOWARDS FELICITOUS DECISION MAKING: AN OVERVIEW ON CHALLENGES AND TRENDS OF BIG DATA,article
420,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"It is already true that Big Data has drawn huge attention from researchers in information sciences, policy and decision makers in governments and enterprises. As the speed of information growth exceeds Moore’s Law at the beginning of this new century, excessive data is making great troubles to human beings. However, there are so much potential and highly useful values hidden in the huge volume of data. A new scientific paradigm is born as data-intensive scientific discovery (DISD), also known as Big Data problems. A large number of fields and sectors, ranging from economic and business activities to public administration, from national security to scientific researches in many areas, involve with Big Data problems. On the one hand, Big Data is extremely valuable to produce productivity in businesses and evolutionary breakthroughs in scientific disciplines, which give us a lot of opportunities to make great progresses in many fields. There is no doubt that the future competitions in business productivity and technologies will surely converge into the Big Data explorations. On the other hand, Big Data also arises with many challenges, such as difficulties in data capture, data storage, data analysis and data visualization. This paper is aimed to demonstrate a close-up view about Big Data, including Big Data applications, Big Data opportunities and challenges, as well as the state-of-the-art techniques and technologies we currently adopt to deal with the Big Data problems. We also discuss several underlying methodologies to handle the data deluge, for example, granular computing, cloud computing, bio-inspired computing, and quantum computing.",https://doi.org/10.1016/j.ins.2014.01.015,2014,C.L. {Philip Chen} and Chun-Yang Zhang,"DATA-INTENSIVE APPLICATIONS, CHALLENGES, TECHNIQUES AND TECHNOLOGIES: A SURVEY ON BIG DATA",article
421,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"Decision support systems aim to help a decision maker with selecting the option from a set of available options that best meets her or his needs. In multi-criteria based decision support approaches, a suitability degree is computed for each option, reflecting how suitable that option is considering the preferences of the decision maker. Nowadays, it becomes more and more common that data of different quality, originating from different data sets and different data providers have to be integrated and processed in order to compute the suitability degrees. Also, data sets can be very large such that their data become commonly prone to incompleteness, imprecision and uncertainty. Hence, not all data used for decision making can be trusted to the same extent and consequently, neither the results of computations with such data can be trusted to the same extent. For this reason, data quality assessment becomes an important aspect of a decision making process. To correctly inform the users, it is essential to communicate not only the computed suitability degrees of the available options, but also the confidence about these suitability degrees as can be derived from data quality assessment. In this paper a novel multi-dimensional approach for data quality assessment in multi-criteria decision making, supporting the computation of associated confidence degrees, is presented. Providing confidence information adds an extra dimension to the decision making process and leads to more soundly decisions. The added value of the approach is illustrated with aspects of a geographic decision making process.",https://doi.org/10.1016/j.ins.2017.09.008,2018,Guy {De Tré} and Robin {De Mol} and Antoon Bronselaer,HANDLING VERACITY IN MULTI-CRITERIA DECISION-MAKING: A MULTI-DIMENSIONAL APPROACH,article
422,15134,INFORMATION SCIENCES,journal,00200255,"1,524",Q1,184,928,2184,40007,17554,2168,"7,89","43,11",United States,Northern America,Elsevier Inc.,1968-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Information Systems and Management (Q1); Software (Q1); Theoretical Computer Science (Q1),"44,038",6.795,0.04908,"Due to the uncertainty of the value of big data, it is difficult to directly give a reasonable price for big data. Auction is an effective method of distributing goods to the bidder with the highest valuation. Hence, the use of auction strategy can not only guarantee the interests of data sellers, but also conform to market principles. However, existing data auction mechanisms are centralized. It is hard to build trust among sellers, buyers and auctioneers. An open and anonymous online environment may cause entities involved in data auctions to collude to manipulate the results of data auctions. This will cause the price of auction data to fail to reach a fair and truthful level. Therefore, the first anti-collusion data auction mechanism based on smart contract is proposed. Through a well-designed anti-collusion data auction algorithm, mutual distrust and rational buyers and sellers safely participate in the data auction without a trusted third party. The data auction mechanism designed in the smart contract can effectively prevent collusion and realize the fairness and truthfulness of data auction. The webpack in the Truffle Boxes is used to implement the data auction mechanism, and the anti-collusion property of the mechanism has been verified. The source code of the smart contract has been uploaded to GitHub.",https://doi.org/10.1016/j.ins.2020.10.053,2021,Wei Xiong and Li Xiong,ANTI-COLLUSION DATA AUCTION MECHANISM BASED ON SMART CONTRACT,article
423,15673,JOURNAL OF RURAL STUDIES,journal,07430167,"1,497",Q1,104,280,573,20744,2862,557,"4,43","74,09",United Kingdom,Western Europe,Elsevier Ltd.,1985-2020,"Development (Q1); Forestry (Q1); Geography, Planning and Development (Q1); Sociology and Political Science (Q1)","9,142",4.849,0.01005,"The myriad potential benefits of digital farming hinge on the promise of increased accuracy, which allows ‘doing more with less’ through precise, data-driven operations. Yet, precision farming's foundational claim of increased accuracy has hardly been the subject of comprehensive examination. Drawing on social science studies of big data, this article examines digital agriculture's (in)accuracies and their repercussions. Based on an examination of the daily functioning of the various components of yield mapping, it finds that digital farming is often ‘precisely inaccurate’, with the high volume and granularity of big data erroneously equated with high accuracy. The prevailing discourse of ‘ultra-precise’ digital technologies ignores farmers' essential efforts in making these technologies more accurate, via calibration, corroboration and interpretation. We suggest that there is the danger of a ‘precision trap’. Namely, an exaggerated belief in the precision of big data that over time leads to an erosion of checks and balances (analogue data, farmer observation et cetera) on farms. The danger of ‘precision traps’ increases with the opacity of algorithms, with shifts from real-time measurement and advice towards forecasting, and with farmers' increased remoteness from field operations. Furthermore, we identify an emerging ‘precision divide’: unequally distributed precision benefits resulting from the growing algorithmic divide between farmers focusing on staple crops, catered well by technological innovation on the one hand, and farmers cultivating other crops, who have to make do with much less advanced or applicable algorithms on the other. Consequently, for the latter farms digital farming may feel more like ‘imprecision farming’.",https://doi.org/10.1016/j.jrurstud.2021.07.024,2021,Oane Visser and Sarah Ruth Sippel and Louis Thiemann,IMPRECISION FARMING? EXAMINING THE (IN)ACCURACY AND RISKS OF DIGITAL AGRICULTURE,article
424,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"Predictive resource allocation is an emerging approach to improve the performance of mobile systems as human behavior is reported predictable by leveraging big data analytics. Yet what information can be predicted by big data, what information need to be predicted for wireless access optimization, how to translate the information, and how to exploit the synthetic knowledge for allocating radio resources are not well understood and largely explored. In this paper, we are concerned with the latter two issues. In particular, we devise an energy-saving resource planning and allocation policy for multiple base stations (BSs) to serve mobile users with non-real-time (NRT) traffic by exploiting the user, network, and application levels of context information, where RT traffic may occupy partial resources of each BS. Inspired by the solution from an energy minimization problem with future instantaneous information, a low complexity multi-timescale predictive policy is proposed. Upon the arrival of each NRT user request, the resource planning is made with the user and network level context information, defined as the average channel gains of the NRT users and the statistics of residual bandwidth after serving RT traffic, with which the scheduling, power allocation, and BS sleeping can be accomplished after instantaneous channel information and residual network resource are available at each BS in each time slot. Simulation results show that the proposed policy can dramatically reduce the energy consumed by the BSs for serving the NRT traffic.",10.1109/TCOMM.2016.2608822,2016,,ENERGY-SAVING PREDICTIVE RESOURCE PLANNING AND ALLOCATION,
425,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"Mobile edge computing (MEC) is an enabling technology for low-latency AI applications, by caching AI services originally deployed in remote data centers to 5G base stations in network edge. Due to limited computing resource of 5G base stations, not all services can be cached in base stations to meet the resource demands of user requests. Also, if the workload of a 5G base station reaches to its resource capacity, the energy consumption of the base station will be pushed up exponentially. To reduce the energy consumption and overcome resource limitations on base stations, an alternative is to allow the base stations to collaborate with each other to admit user requests. In this paper, we investigate the problem of collaborative service caching and request offloading between a 5G-enabled MEC and remote data centers, while meeting the quality of service (QoS) requirements of users, and resource capacities on base stations that are operated by multiple selfish network service providers. We aim to maximize the total payoff of all base stations. To this end, we first propose a two-stage optimization framework: In the first stage, we develop a mechanism that adopts a best-reply rule for dynamically distributed coalition formation. In the second stage, we propose a near-optimal payoff allocation method by devising a randomized algorithm with a provable approximation ratio. We then evaluate the performance of the proposed optimization framework by extensive experimental simulations. Simulation results show that the proposed framework outperforms its counterparts by achieving at least 30% higher payoff and 20% lower energy consumption of base stations.",10.1109/TCOMM.2021.3125034,2022,,ENERGY-AWARE COLLABORATIVE SERVICE CACHING IN A 5G-ENABLED MEC WITH UNCERTAIN PAYOFFS,
426,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"Explosive growth of mobile data demand may impose a heavy traffic burden on fronthaul links of cloud-based small cell networks (C-SCNs), which deteriorates users' quality of service (QoS) and requires substantial power consumption. This paper proposes an efficient maximum distance separable (MDS) coded caching framework for a cache-enabled C-SCNs, aiming at reducing long-term power consumption while satisfying users' QoS requirements in short-term transmissions. To achieve this goal, the cache resource in small-cell base stations (SBSs) needs to be reasonably updated by taking into account users' content preferences, SBS collaboration, and characteristics of wireless links. Specifically, without assuming any prior knowledge of content popularity, we formulate a mixed timescale problem to jointly optimize cache updating, multicast beamformers in fronthaul and edge links, and SBS clustering. Nevertheless, this problem is anti-causal because an optimal cache updating policy depends on future content requests and channel state information. To handle it, by properly leveraging historical observations, we propose a two-stage updating scheme by using Frobenius-Norm penalty and inexact block coordinate descent method. Furthermore, we derive a learning-based design, which can obtain effective trade-off between accuracy and computational complexity. Simulation results demonstrate the effectiveness of the proposed two-stage framework.",10.1109/TCOMM.2020.2970986,2020,,JOINT LONG-TERM CACHE UPDATING AND SHORT-TERM CONTENT DELIVERY IN CLOUD-BASED SMALL CELL NETWORKS,
427,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"The key challenges in live video multicasting include how to properly form multicast groups, select video versions and allocate wireless resources, in order to guarantee the quality of experience (QoE) while ensuring low latency delivery. To address these challenges, in this paper, a novel multicast framework that leverages the advantages of network-assisted dynamic adaptive streaming over HTTP and cloud radio access networks is proposed, where a multicast assistant server is deployed at the edge of a mobile network. Under this architecture, a joint user grouping, version selection, and bandwidth allocation method is designed to optimize the sum of users’ utilities. In particular, a two-step scheme is proposed to solve this complex problem. The number of multicast groups is first automatically determined and a user clustering method is presented. Then, group-level version selection and spectrum assignment algorithms are performed at different time scales. Simulation results demonstrate that our proposed scheme can improve at least 7% QoE compared to baseline methods.",10.1109/TCOMM.2021.3115480,2022,,"JOINT USER GROUPING, VERSION SELECTION, AND BANDWIDTH ALLOCATION FOR LIVE VIDEO MULTICASTING",
428,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"In this paper, we consider the joint base station (BS) association, power control, and beamforming problem for an uplink SISO/SIMO cellular network under the max-min fairness criterion. We first prove a strange discrepancy: a normalized fixed point (NFP) iterative algorithm has geometric convergence to global optima, but it only has pseudo-polynomial time complexity and thus whether the problem is NP-hard or not is an open question. In this paper, we resolve this discrepancy by proving that this problem is indeed polynomial-time solvable. Our proof is based on converting this mixed integer programming (MIP) problem to a series of auxiliary convex problems. Our results fill in a gap in the understanding of the computational complexity of BS association problem. Another implication of our result is that the uplink SIMO problem is easy, but either changing uplink to downlink or changing SIMO to MIMO will make the problem NP-hard. Empirically, the polynomial time algorithm converges much slower than the NFP algorithm, leaving open the question of whether a polynomial time algorithm that converges fast in practice exists for this problem.",10.1109/TCOMM.2019.2914448,2019,,GLOBALLY OPTIMAL JOINT UPLINK BASE STATION ASSOCIATION AND BEAMFORMING,
429,18931,IEEE TRANSACTIONS ON COMMUNICATIONS,journal,15580857,"1,468",Q1,214,584,1484,22352,11163,1482,"7,32","38,27",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"1963-1964, 1970-2020",Electrical and Electronic Engineering (Q1),"22,320",5.083,0.03055,"In this paper, we investigate the resource allocation of mobile edge computing (MEC) in cognitive capacity harvesting networks (CCHNs) when non-orthogonal multiple-access (NOMA) technique is adopted. Different from traditional studies for NOMA-MEC networks, we aim at minimizing the total cost of CCHN while satisfying the quality-of-service (QoS) of secondary users (SUs). We adopt the mechanism of time division multiple access (TDMA) when several NOMA groups use the same spectrum, and consider both the waiting delay and transmission delay during data offloading with the optimization of transmission order of NOMA groups. We formulate the considered problem as a mixed integer non-linear programming (MINLP). We show that the transmit power and the allocated computing resource for each SU can be derived when the transmission time and transmission order of the NOMA groups are given. Based on this, the considered problem can be decomposed into a transmission time and order optimization subproblem, a cellular resource block (CRB) selection subproblem and a cognitive radio (CR) router selection subproblem. To solve the transmission time and order optimization subproblem, we first simplify the delay constraint via theoretic analysis, and then propose a binary segmentation (B-Seg) algorithm and a transmission order adjustment (TOA) algorithm to find the optimal transmission time and transmission order of NOMA groups, respectively. To solve the CRB selection subproblem and the CR router selection subproblem, a bigger requirement first (BRF) algorithm and a game-based iteration (GBI) algorithm are respectively proposed. Simulation results show that the proposed algorithms can significantly improve the system performance.",10.1109/TCOMM.2022.3188841,2022,,TDMA-NOMA BASED COMPUTATION OFFLOADING FOR COGNITIVE CAPACITY HARVESTING NETWORKS WITH TRANSMISSION ORDER OPTIMIZATION,
430,21524,ENVIRONMENTAL RESEARCH,journal,00139351,"1,460",Q1,136,1355,1688,80881,11076,1650,"6,28","59,69",United States,Northern America,Academic Press Inc.,1967-2020,Biochemistry (Q1); Environmental Science (miscellaneous) (Q1),"28,576",6.498,0.03426,"Recent rapid technological advances are producing exposure data sets for which there are no available data quality assessment tools. At the same time, regulatory agencies are moving in the direction of data quality assessment for environmental risk assessment and decision-making. A transparent and systematic approach to evaluating exposure data will aid in those efforts. Any approach to assessing data quality must consider the level of quality needed for the ultimate use of the data. While various fields have developed approaches to assess data quality, there is as yet no general, user-friendly approach to assess both measured and modeled data in the context of a fit-for-purpose risk assessment. Here we describe ExpoQual, an instrument developed for this purpose which applies recognized parameters and exposure data quality elements from existing approaches for assessing exposure data quality. Broad data streams such as quantitative measured and modeled human exposure data as well as newer and developing approaches can be evaluated. The key strength of ExpoQual is that it facilitates a structured, reproducible and transparent approach to exposure data quality evaluation and provides for an explicit fit-for-purpose determination. ExpoQual was designed to minimize subjectivity and to include transparency in aspects based on professional judgment. ExpoQual is freely available on-line for testing and user feedback (exposurequality.com).",https://doi.org/10.1016/j.envres.2019.01.039,2019,Judy S. LaKind and Cian O’Mahony and Thomas Armstrong and Rosalie Tibaldi and Benjamin C. Blount and Daniel Q. Naiman,EXPOQUAL: EVALUATING MEASURED AND MODELED HUMAN EXPOSURE DATA,article
431,21524,ENVIRONMENTAL RESEARCH,journal,00139351,"1,460",Q1,136,1355,1688,80881,11076,1650,"6,28","59,69",United States,Northern America,Academic Press Inc.,1967-2020,Biochemistry (Q1); Environmental Science (miscellaneous) (Q1),"28,576",6.498,0.03426,"The Korean CHildren's ENvironmental health Study (Ko-CHENS) is a nationwide prospective birth cohort showing the correlation between the environmental exposures and the health effects to prevent the environmental diseases in children, and it provides the guidelines for the environmental hazardous factors, applying the life-course approach to the environmental-health management system. The Ko-CHENS consists of 5000 Core and 65,000 Main Cohorts. The children in the Core Cohort are followed up at 6 months, every year before their admission into the elementary school, and every 3 years from the first year after this admission. The children in the Cohort will be followed up through the data links (Statistics Korea, National Health Insurance Service [NHIS], and Ministry of Education). The individual biospecimens will be analyzed for 19 substances. The long-term-storage biological samples will be used for the further substance analysis. The Ko-CHENS will investigate whether the environmental variables including the perinatal outdoor and indoor factors and the greenness contribute causally to the health outcomes in the children and adolescents. In addition to the individual surveys, the assessments of the outdoor exposures and health outcomes will use the national air-quality monitoring data and claim data of the NHIS, respectively. The two big-data forms of the Ko-CHENS are as follows: The Ko-CHENS data that can be linked with the nationally registered NHIS health-related database, including the medical utilization and the periodic health screening, and the birth/mortality database in the Statistics; the other is the Big-CHENS dataset that is based on the NHIS mother delivery code, for which the follow-up of almost 97% of the total birth population is expected. The Ko-CHENS is a very cost-effective study that fully exploits the existing national big-data systems with the data linkage.",https://doi.org/10.1016/j.envres.2018.12.009,2019,Kyoung Sook Jeong and Suejin Kim and Woo Jin Kim and Hwan-Cheol Kim and Jisuk Bae and Yun-Chul Hong and Mina Ha and Kangmo Ahn and Ji-Young Lee and Yangho Kim and Eunhee Ha,COHORT PROFILE: BEYOND BIRTH COHORT STUDY – THE KOREAN CHILDREN'S ENVIRONMENTAL HEALTH STUDY (KO-CHENS),article
432,21524,ENVIRONMENTAL RESEARCH,journal,00139351,"1,460",Q1,136,1355,1688,80881,11076,1650,"6,28","59,69",United States,Northern America,Academic Press Inc.,1967-2020,Biochemistry (Q1); Environmental Science (miscellaneous) (Q1),"28,576",6.498,0.03426,"The effect of height on pollen concentration is not well documented and little is known about the near-ground vertical profile of airborne pollen. This is important as most measuring stations are on roofs, but patient exposure is at ground level. Our study used a big data approach to estimate the near-ground vertical profile of pollen concentrations based on a global study of paired stations located at different heights. We analyzed paired sampling stations located at different heights between 1.5 and 50 m above ground level (AGL). This provided pollen data from 59 Hirst-type volumetric traps from 25 different areas, mainly in Europe, but also covering North America and Australia, resulting in about 2,000,000 daily pollen concentrations analyzed. The daily ratio of the amounts of pollen from different heights per location was used, and the values of the lower station were divided by the higher station. The lower station of paired traps recorded more pollen than the higher trap. However, while the effect of height on pollen concentration was clear, it was also limited (average ratio 1.3, range 0.7–2.2). The standard deviation of the pollen ratio was highly variable when the lower station was located close to the ground level (below 10 m AGL). We show that pollen concentrations measured at >10 m are representative for background near-ground levels.",https://doi.org/10.1016/j.envres.2019.04.027,2019,Jesús Rojo and Jose Oteros and Rosa Pérez-Badia and Patricia Cervigón and Zuzana Ferencova and A. Monserrat Gutiérrez-Bustillo and Karl-Christian Bergmann and Gilles Oliver and Michel Thibaudon and Roberto Albertini and David {Rodríguez-De la Cruz} and Estefanía Sánchez-Reyes and José Sánchez-Sánchez and Anna-Mari Pessi and Jukka Reiniharju and Annika Saarto and M. Carmen Calderón and César Guerrero and Daniele Berra and Maira Bonini and Elena Chiodini and Delia Fernández-González and José García and M. Mar Trigo and Dorota Myszkowska and Santiago Fernández-Rodríguez and Rafael Tormo-Molina and Athanasios Damialis and Franziska Kolek and Claudia Traidl-Hoffmann and Elena Severova and Elsa Caeiro and Helena Ribeiro and Donát Magyar and László Makra and Orsolya Udvardy and Purificación Alcázar and Carmen Galán and Katarzyna Borycka and Idalia Kasprzyk and Ed Newbigin and Beverley Adams-Groom and Godfrey P. Apangu and Carl A. Frisk and Carsten A. Skjøth and Predrag Radišić and Branko Šikoparija and Sevcan Celenk and Carsten B. Schmidt-Weber and Jeroen Buters,NEAR-GROUND EFFECT OF HEIGHT ON POLLEN EXPOSURE,article
433,21100202157,TOURISM MANAGEMENT PERSPECTIVES,journal,22119736,"1,454",Q1,43,140,277,12102,1824,274,"6,77","86,44",United States,Northern America,Elsevier USA,2012-2020,"Tourism, Leisure and Hospitality Management (Q1)","3,902",6.586,0.00445,"This study aims to provide a comprehensive network analysis to understand the current state of big data research in tourism by investigating multi-disciplinary contributions relevant to big data. A comprehensive network analytical method, which includes co-citation, clustering and trend analysis, is applied to systematically analyse publications from 2008 to 2017. Two unique data sets from Web of Science are collected. The first data set focuses on big data research in tourism and hospitality. The second data set involves other disciplines, such as computer science, for a comparison with tourism. Results suggest that applications of social media and user-generated content are gaining momentum, whereas theory-based studies on big data in tourism remain limited. Tourism and other relevant domains have similar concerns with the challenges involved in big data, such as privacy, data quality and appropriate data use. This comparative network analysis has implications for future big data research in tourism.",https://doi.org/10.1016/j.tmp.2019.100608,2020,Xin Li and Rob Law,NETWORK ANALYSIS OF BIG DATA RESEARCH IN TOURISM,article
434,21100202157,TOURISM MANAGEMENT PERSPECTIVES,journal,22119736,"1,454",Q1,43,140,277,12102,1824,274,"6,77","86,44",United States,Northern America,Elsevier USA,2012-2020,"Tourism, Leisure and Hospitality Management (Q1)","3,902",6.586,0.00445,"Utilizing a scientometric review of global trends and structure from 388 bibliographic records over two decades (1999–2018), this study seeks to advance the building of comprehensive knowledge maps that draw upon global travel demand studies. The study, using the techniques of co-citation analysis, collaboration network and emerging trends analysis, identified major disciplines that provide knowledge and theories for tourism demand forecasting, many trending research topics, the most critical countries, institutions, publications, and articles, and the most influential researchers. The increasing interest and output for big data and machine learning techniques in the field were visualized via comprehensive knowledge maps. This research provides meaningful guidance for researchers, operators and decision makers who wish to improve the accuracy of tourism demand forecasting.",https://doi.org/10.1016/j.tmp.2020.100715,2020,Chengyuan Zhang and Shouyang Wang and Shaolong Sun and Yunjie Wei,KNOWLEDGE MAPPING OF TOURISM DEMAND FORECASTING RESEARCH,article
435,21100202157,TOURISM MANAGEMENT PERSPECTIVES,journal,22119736,"1,454",Q1,43,140,277,12102,1824,274,"6,77","86,44",United States,Northern America,Elsevier USA,2012-2020,"Tourism, Leisure and Hospitality Management (Q1)","3,902",6.586,0.00445,"Previous research studied the spatiotemporal patterns in different visitor segments but lacks evidence of the segmentation of resident tourists and non-resident tourists in multi-city travel. To fill this gap, this study conducts a big data study using hotel check-in registers. The exploratory data analysis visualizes the spatiotemporal patterns and the differences between resident tourists and non-resident tourists. Then, the spatiotemporal patterns are measured by the length of stay and the number of visited cities. The regression shows that both the length of stay and the number of visited cities of non-resident tourists are higher than those of resident tourists. Moreover, non-resident tourists reduce their length of stay and their number of visited cities more than resident tourists on three-day holidays, while they increase their number of visited cities less than resident tourists on seven-day holidays. This study has significant implications for understanding spatiotemporal patterns and visitors' segmentations.",https://doi.org/10.1016/j.tmp.2021.100860,2021,Yuquan Xu and Xiaobin Ran and Yuewen Liu and Wei Huang,COMPARING DIFFERENCES IN THE SPATIOTEMPORAL PATTERNS BETWEEN RESIDENT TOURISTS AND NON-RESIDENT TOURISTS USING HOTEL CHECK-IN REGISTERS,article
436,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"The Internet of Things (IoT) and the relevant technologies have had a significant impact on smart farming as a major sub-domain within the field of agriculture. Modern technology supports data collection from IoT devices through several farming processes. The extensive amount of collected smart farming data can be utilized for daily decision making and analysis such as yield prediction, growth analysis, quality maintenance, animal and aquaculture, as well as farm management. This survey focuses on three major aspects of contemporary smart farming. First, it highlights various types of big data generated through smart farming and makes a broad categorization of such data. Second, this paper discusses a comprehensive set of typical applications of big data in smart farming. Third, it identifies and introduces the principal big data and machine learning techniques that are utilized in smart farming data analysis. In doing so, this survey also identifies some of the major, current challenges in smart farming big data analysis.This paper provides a discussion on potential pathways toward more effective smart farming through relevant analytics-guided decision making.",https://doi.org/10.1016/j.compind.2022.103624,2022,Sandya De Alwis and Ziwei Hou and Yishuo Zhang and Myung Hwan Na and Bahadorreza Ofoghi and Atul Sajjanhar,"A SURVEY ON SMART FARMING DATA, APPLICATIONS AND TECHNIQUES",article
437,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"With the increasing amount of available data, computing power and network speed for a decreasing cost, the manufacturing industry is facing an unprecedented amount of data to process, understand and exploit. Phenomena such as Big Data, the Internet-of-Things, Closed-Loop Product Lifecycle Management, and the advances of Smart Factories tend to produce humanly unmanageable quantities of data. The paper approaches the aforesaid context by assuming that any data processing automation is not only desirable but rather necessary in order to prevent prohibitive data analytics costs. This study focuses on highlighting the major specificities of engineering data and the data-processing difficulties which are inherent to data coming from the manufacturing industry. The artificial intelligence field of research is able to provide methods and tools to address some of the identified issues. A special attention was paid to provide a literature review of the most recent (in 2017) applications, that could present a high potential for the manufacturing industry, in the fields of machine learning and deep learning. In order to illustrate the proposed work, a case study was conducted on the challenging research question of object recognition in heterogeneous formats (3D models, photos and videos) with deep learning techniques. The DICE project – DMU Imagery Comparison Engine – is presented and has been completely open-sourced in order to encourage reuse and improvements of the proposed case-study. This project also leads to the development of an open-source research dataset of 2000 CAD Models, called DMU-Net available at: https://www.dmu-net.org.",https://doi.org/10.1016/j.compind.2018.04.005,2018,Jonathan Dekhtiar and Alexandre Durupt and Matthieu Bricogne and Benoit Eynard and Harvey Rowson and Dimitris Kiritsis,"DEEP LEARNING FOR BIG DATA APPLICATIONS IN CAD AND PLM – RESEARCH REVIEW, OPPORTUNITIES AND CASE STUDY",article
438,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"Big Data Analytics (BDA) has attracted significant attention from both academicians and practitioners alike as it provides several ways to improve strategic, tactical and operational capabilities to eventually create a positive impact on the economic performance of organizations. In the present study, twelve significant barriers against BDA implementation are identified and assessed in the context of Indian manufacturing Supply Chains (SC). These barriers are modeled using an integrated two-stage approach, consisting of Interpretive Structural Modeling (ISM) in the first stage and Decision-Making Trial and Evaluation Laboratory (DEMATEL) in the second stage. The approach developed provides the interrelationships between the identified constructs and their intensities. Moreover, Fuzzy MICMAC technique is applied to analyze the high impact (i.e., high driving power) barriers. Results show that four constructs, namely lack of top management support, lack of financial support, lack of skills, and lack of techniques or procedures, are the most significant barriers. This study aids policy-makers in conceptualizing the mutual interaction of the barriers for developing policies and strategies to improve the penetration of BDA in manufacturing SC.",https://doi.org/10.1016/j.compind.2020.103368,2021,Rakesh D. Raut and Vinay Surendra Yadav and Naoufel Cheikhrouhou and Vaibhav S. Narwane and Balkrishna E. Narkhede,BIG DATA ANALYTICS: IMPLEMENTATION CHALLENGES IN INDIAN MANUFACTURING SUPPLY CHAINS,article
439,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"For the past few years, we have been hearing about Industry 4.0 (or the fourth industrial revolution), which promises to improve productivity, flexibility, quality, customer satisfaction and employee well-being. To assess whether these goals are achieved, it is necessary to implement a performance management system (PMS). However, a PMS must take into account the various challenges associated with Industry 4.0, including the availability of large amounts of data. While it represents an opportunity for companies to improve performance, big data does not necessarily mean good data. It can be uncertain, imprecise, ambiguous, etc. Uncertainty is one of the major challenges and it is essential to take it into account when computing performance indicators to increase confidence in decision making. To address this issue, we propose a method to model uncertainty in key performance indicators (KPIs). Our work allows associating with each indicator an uncertainty noted m, computed on the basis of the theory of belief functions. The KPI and its associated uncertainty form a pair (KP I, m). The method developed allows calculating this uncertainty m for the input data of the performance management system. We show how these modeled uncertainties should be propagated to the KPIs. For these KPI uncertainties, we have defined rules to support decision-making. The method developed, based on the theory of belief functions, is part of a methodology we propose to define and extract smart data from massive data. To our knowledge, this is the first attempt to use this theory to model uncertain performance indicators. Our work has shown its effectiveness and its applicability to a case of bottle filling line simulation. In addition to these results, this work opens up new perspectives, particularly for taking uncertainty into account in expert opinions and in industrial risk assessment.",https://doi.org/10.1016/j.compind.2022.103666,2022,Amel Souifi and Zohra Cherfi Boulanger and Marc Zolghadri and Maher Barkallah and Mohamed Haddar,UNCERTAINTY OF KEY PERFORMANCE INDICATORS FOR INDUSTRY 4.0: A METHODOLOGY BASED ON THE THEORY OF BELIEF FUNCTIONS,article
440,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"Recently, with the development of “Industry 4.0”, “Oil and Gas 4.0” has also been put on the agenda in the past two years. Some companies and experts believe that “Oil and Gas 4.0” can completely change the status quo of the oil and gas industry, which can bring huge benefits because it accelerates the digitization and intelligentization of the oil and gas industry. However, the “Oil and Gas 4.0” is still in its infancy. Therefore, this paper systematically introduces the concept and core technologies of “Oil and Gas 4.0”, such as big data and the industrial Internet of Things (IIoT). Moreover, this paper analyzes typical application scenarios of the oil and gas industry chain (upstream, midstream and downstream) through examples, such as intelligent oilfield, intelligent pipeline, and intelligent refinery. It is concluded that the essence of “Oil and Gas 4.0” is a data-driven intelligence system based on the highly digitization. To the best of our knowledge, this is the first academic peer-reviewed paper on the “Oil and Gas 4.0” era, aiming to let more oil and gas industry personnel understand its benefits and application scenarios, so as to better apply it to practical engineering in the future. In the discussion section, this paper also analyzes the opportunities and difficulties that may be brought about by the “Oil and Gas 4.0” era. Finally, relevant policy recommendations are proposed.",https://doi.org/10.1016/j.compind.2019.06.007,2019,Hongfang Lu and Lijun Guo and Mohammadamin Azimi and Kun Huang,OIL AND GAS 4.0 ERA: A SYSTEMATIC REVIEW AND OUTLOOK,article
441,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"Big Data is dominating the landscape as data originated in many sources keeps piling up. Information Technology (IT) business companies are making tremendous efforts to keep the pace with this wave of innovative technologies. This study aims to identify how the different IT companies are aligned with emerging Big Data technologies. The approach consisted in analyzing 11,505 news published between 2013 and 2016 and aggregated through Google News. The companies were categorized according to their position in the 2017 Gartner Magic Quadrant for advanced analytics. A text mining and topic modeling procedure assisted in summarizing the main findings. Leaders dominated a large fraction of the published news. Challengers are making a significant effort in investing in predictive analytics, overlooking other technologies such as those related to data preparation and integration. The results helped to shed light on the emerging field of Big Data from a corporate perspective.",https://doi.org/10.1016/j.compind.2018.03.018,2018,João Canito and Pedro Ramos and Sérgio Moro and Paulo Rita,UNFOLDING THE RELATIONS BETWEEN COMPANIES AND TECHNOLOGIES UNDER THE BIG DATA UMBRELLA,article
442,19080,COMPUTERS IN INDUSTRY,journal,01663615,"1,432",Q1,100,115,323,6926,3165,319,"9,96","60,23",Netherlands,Western Europe,Elsevier,1979-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1),"6,018",7.635,0.00584,"Data-intensive environments enable us to capture information and knowledge about the physical surroundings, to optimise our resources, enjoy personalised services and gain unprecedented insights into our lives. However, to obtain these endeavours extracted from the data, this data should be generated, collected and the insight should be exploited. Following an argumentation reasoning approach for data processing and building on the theoretical background of data management, we highlight the importance of data sharing agreements (DSAs) and quality attributes for the proposed data processing mechanism. The proposed approach is taking into account the DSAs and usage policies as well as the quality attributes of the data, which were previously neglected compared to existing methods in the data processing and management field. Previous research provided techniques towards this direction; however, a more intensive research approach for processing techniques should be introduced for the future to enhance the value creation from the data and new strategies should be formed around this data generated daily from various devices and sources.",https://doi.org/10.1016/j.compind.2017.09.002,2018,Erisa Karafili and Konstantina Spanaki and Emil C. Lupu,AN ARGUMENTATION REASONING APPROACH FOR DATA PROCESSING,article
443,23911,ANALYTICA CHIMICA ACTA,journal,00032670,"1,403",Q1,203,897,2235,45034,14014,2228,"6,27","50,21",Netherlands,Western Europe,Elsevier,1947-2020,Analytical Chemistry (Q1); Biochemistry (Q1); Environmental Chemistry (Q1); Spectroscopy (Q1),"58,170",6.558,0.03972,"Efficient and reliable analysis of chemical analytical data is a great challenge due to the increase in data size, variety and velocity. New methodologies, approaches and methods are being proposed not only by chemometrics but also by other data scientific communities to extract relevant information from big datasets and provide their value to different applications. Besides common goal of big data analysis, different perspectives and terms on big data are being discussed in scientific literature and public media. The aim of this comprehensive review is to present common trends in the analysis of chemical analytical data across different data scientific fields together with their data type-specific and generic challenges. Firstly, common data science terms used in different data scientific fields are summarized and discussed. Secondly, systematic methodologies to plan and run big data analysis projects are presented together with their steps. Moreover, different analysis aspects like assessing data quality, selecting data pre-processing strategies, data visualization and model validation are considered in more detail. Finally, an overview of standard and new data analysis methods is provided and their suitability for big analytical chemical datasets shortly discussed.",https://doi.org/10.1016/j.aca.2018.05.038,2018,Ewa Szymańska,MODERN DATA SCIENCE FOR ANALYTICAL CHEMICAL DATA – A COMPREHENSIVE REVIEW,article
444,22504,CANADIAN JOURNAL OF CARDIOLOGY,journal,0828282X,"1,395",Q1,90,342,921,9052,2482,691,"2,49","26,47",Canada,Northern America,Elsevier Inc.,1985-2020,Cardiology and Cardiovascular Medicine (Q1),"8,782",5.223,0.01509,,https://doi.org/10.1016/j.cjca.2019.09.018,2020,George A. Heckman and John P. Hirdes and Robert S. McKelvie,THE ROLE OF PHYSICIANS IN THE ERA OF BIG DATA,article
445,21100780794,ENGINEERING,journal,20958099,"1,376",Q1,45,186,372,9769,3152,324,"6,73","52,52",United Kingdom,Western Europe,Elsevier Ltd.,2015-2020,Chemical Engineering (miscellaneous) (Q1); Computer Science (miscellaneous) (Q1); Energy Engineering and Power Technology (Q1); Engineering (miscellaneous) (Q1); Environmental Engineering (Q1); Materials Science (miscellaneous) (Q1),"4,023",7.553,0.00715,"Intelligent sensing, mechanism understanding, and the deterioration forecasting based on spatio–temporal big data not only promote the safety of the infrastructure but also indicate the basic theory and key technology for the infrastructure construction to turn to intelligentization. The advancement of underground space utilization has led to the development of three characteristics (deep, big, and clustered) that help shape a tridimensional urban layout. However, compared to buildings and bridges overground, the diseases and degradation that occur underground are more insidious and difficult to identify. Numerous challenges during the construction and service periods remain. To address this gap, this paper summarizes the existing methods and evaluates their strong points and weak points based on real-world space safety management. The key scientific issues, as well as solutions, are discussed in a unified intelligent monitoring system.",https://doi.org/10.1016/j.eng.2022.07.016,2022,Bowen Du and Junchen Ye and Hehua Zhu and Leilei Sun and Yanliang Du,INTELLIGENT MONITORING SYSTEM BASED ON SPATIO–TEMPORAL DATA FOR UNDERGROUND SPACE INFRASTRUCTURE,article
446,17366,IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES,journal,15579670,"1,372",Q1,190,468,1553,14440,6839,1514,"4,30","30,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Condensed Matter Physics (Q1); Electrical and Electronic Engineering (Q1); Radiation (Q1),"26,865",3.599,0.02547,"A novel concept and approach for integration of a three-state diplexer (TSD) by utilizing the triple-mode cavity resonators is proposed in this paper. The proposed TSD has the inherent nature of three frequency channels, two of which can be utilized for duplexing channels by exciting one port as the input in each state. Meanwhile, three fundamental modes, namely, TE011, TE101, and TM110, are excited in the triple-mode resonators (TMRs) to control these three frequency channels. Without utilizing any junction networks for impedance matching, the required values of the external quality factors and coupling coefficients can be extracted to meet the relevant Chebyshev responses in the three bands of the TSD, simultaneously. Owing to the modal orthogonality among the three fundamental modes, high isolation among these three frequency channels can be effectively achieved. For proof of concept, two design examples of the TSD structures are presented with different topologies. For both examples, four and six TMRs are adopted, respectively, where the predicted three frequency channels of the TSD can be successfully excited with excellent channel isolations. The fabricated prototype shows good agreement between the simulated and measured results verifying the feasibility of the proposed design methodology.",10.1109/TMTT.2018.2866858,2018,,A NEW CONCEPT AND APPROACH FOR INTEGRATION OF THREE-STATE CAVITY DIPLEXER BASED ON TRIPLE-MODE RESONATORS,
447,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"Today’s largest and fastest growing companies’ assets are no longer physical, but rather digital (software, algorithms...). This is all the more true in the manufacturing, and particularly in the maintenance sector where quality of enterprise maintenance services are closely linked to the quality of maintenance data reporting procedures. If quality of the reported data is too low, it can results in wrong decision-making and loss of money. Furthermore, various maintenance experts are involved and directly concerned about the quality of enterprises’ daily maintenance data reporting (e.g., maintenance planners, plant managers...), each one having specific needs and responsibilities. To address this Multi-Criteria Decision Making (MCDM) problem, and since data quality is hardly considered in existing expert maintenance systems, this paper develops a maintenance reporting quality assessment (MRQA) dashboard that enables any company stakeholder to easily – and in real-time – assess/rank company branch offices in terms of maintenance reporting quality. From a theoretical standpoint, AHP is used to integrate various data quality dimensions as well as expert preferences. A use case describes how the proposed MRQA dashboard is being used by a Finnish multinational equipment manufacturer to assess and enhance reporting practices in a specific or a group of branch offices.",https://doi.org/10.1016/j.eswa.2016.06.043,2016,Manik Madhikermi and Sylvain Kubler and Jérémy Robert and Andrea Buda and Kary Främling,DATA QUALITY ASSESSMENT OF MAINTENANCE REPORTING PROCEDURES,article
448,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"With the unprecedented increase in data all over the world, financial sector such as companies and industries try to remain competitive by transforming themselves into data-driven organizations. By analyzing a huge amount of financial data, companies are able to obtain valuable information to determine their strategic plans such as risk control, crisis management, or growth management. However, as the amount of data increase dramatically, traditional data analytic platforms confront with storing, managing, and analyzing difficulties. Emerging Big Data Analytics (BDA) overcome these problems by providing decentralized and distributed processing. In this study, we propose two new models for default prediction. In the first model, called DPModel-1, statistical (logistic regression), and machine learning methods (decision tree, random forest, gradient boosting) are employed to predict company default. Derived from the first model, we propose DPModel-2 based on graph theory. DPModel-2 also comprises new variables obtained from the trading interactions of companies. In both models, grid search optimization and SHapley Additive exPlanations (SHAP) value are utilized in order to determine the best hyperparameters and make the models interpretable, respectively. By leveraging balance sheet, credit, and invoice datasets, default prediction is realized for about one million companies in Turkey between the years 2010–2018. The default rates of companies range between 3%-6% by year. The experimental results are conducted on a BDA platform. According to the DPModel-1 results, the highest AUC score is ensured by random forest with 0.87. In addition, the results are improved for each technique separately by adjusting new variables with graph theory. According to DPModel-2 results, the best AUC score is achieved by random forest with 0.89.",https://doi.org/10.1016/j.eswa.2021.114840,2021,Mustafa Yıldırım and Feyza Yıldırım Okay and Suat Özdemir,BIG DATA ANALYTICS FOR DEFAULT PREDICTION USING GRAPH THEORY,article
449,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"Combining query processing techniques with data quality management approaches enables enforcement of quality constraints, such as timeliness, accuracy and completeness, as part of ad-hoc query specification and execution, improving the quality of query results. Despite the emergence of novel data quality processing tools, there is a dearth of studies assessing performance and scalability in the execution of data quality assessment tasks during query processing. This paper reports on an empirical study aiming to investigate the extent to which a big data computing framework (Spark) can offer significant gains in performance and scalability when executing data quality querying tasks over a range of computational platforms including a single commodity multi-core machine and a cluster-based platform for a wide range of workloads. Our results show that substantial performance and scalability gains can be obtained by using optimized data science libraries combined with the parallel and distributed capabilities of big data computing. We also provide guidelines on choosing the appropriate computational infrastructure for executing DQ-aware queries.",https://doi.org/10.1016/j.eswa.2021.114858,2021,Sonia Cisneros-Cabrera and Anna-Valentini Michailidou and Sandra Sampaio and Pedro Sampaio and Anastasios Gounaris,EXPERIMENTING WITH BIG DATA COMPUTING FOR SCALING DATA QUALITY-AWARE QUERY PROCESSING,article
450,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"In this study, a data driven predictive maintenance system was developed for production lines in manufacturing. By utilizing the data generated from IoT sensors in real-time, the system aims to detect signals for potential failures before they occur by using machine learning methods. Consequently, it helps address the issues by notifying operators early such that preventive actions can be taken prior to a production stop. In current study, the effectiveness of the system was also assessed using real-world manufacturing system IoT data. The evaluation results indicated that the predictive maintenance system was successful in identifying the indicators of potential failures and it can help prevent some production stops from happening. The findings of comparative evaluations of machine learning algorithms indicated that models of Random Forest, a bagging ensemble algorithm, and XGBoost, a boosting method, appeared to outperform the individual algorithms in the assessment. The best performing machine learning models in this study have been integrated into the production system in the factory.",https://doi.org/10.1016/j.eswa.2021.114598,2021,Serkan Ayvaz and Koray Alpay,PREDICTIVE MAINTENANCE SYSTEM FOR PRODUCTION LINES IN MANUFACTURING: A MACHINE LEARNING APPROACH USING IOT DATA IN REAL-TIME,article
451,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"The entity reconciliation (ER) problem aroused much interest as a research topic in today's Big Data era, full of big and open heterogeneous data sources. This problem poses when relevant information on a topic needs to be obtained using methods based on: (i) identifying records that represent the same real world entity, and (ii) identifying those records that are similar but do not correspond to the same real-world entity. ER is an operational intelligence process, whereby organizations can unify different and heterogeneous data sources in order to relate possible matches of non-obvious entities. Besides, the complexity that the heterogeneity of data sources involves, the large number of records and differences among languages, for instance, must be added. This paper describes a Systematic Mapping Study (SMS) of journal articles, conferences and workshops published from 2010 to 2017 to solve the problem described before, first trying to understand the state-of-the-art, and then identifying any gaps in current research. Eleven digital libraries were analyzed following a systematic, semiautomatic and rigorous process that has resulted in 61 primary studies. They represent a great variety of intelligent proposals that aim to solve ER. The conclusion obtained is that most of the research is based on the operational phase as opposed to the design phase, and most studies have been tested on real-world data sources, where a lot of them are heterogeneous, but just a few apply to industry. There is a clear trend in research techniques based on clustering/blocking and graphs, although the level of automation of the proposals is hardly ever mentioned in the research work.",https://doi.org/10.1016/j.eswa.2017.03.010,2017,J.G. Enríquez and F.J. Domínguez-Mayo and M.J. Escalona and M. Ross and G. Staples,ENTITY RECONCILIATION IN BIG DATA SOURCES: A SYSTEMATIC MAPPING STUDY,article
452,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"This paper describes the design and implementation of the Data Quality Query System (DQ2S), a query processing framework and tool incorporating data quality profiling functionality in the processing of queries involving quality-aware query language extensions. DQ2S supports the combination of performance and quality-oriented query optimizations, and a query processing platform that enables advanced data profiling queries to be formulated based on well established query language constructs, often used to interact with relational database management systems. DQ2S encompasses a declarative query language and a data model that provides users with the capability to express constraints on the quality of query results as well as query quality-related information; a set of algebraic operators for manipulating data quality-related information, and optimization heuristics. The proposed query language and algebra represent seamless extensions to SQL and relational database engines, respectively. The constructs of the proposed data model are implemented at the user’s view level and are internally mapped into relational model constructs. The quality-aware extensions and features are extremely useful when users need to assess the quality of relational data sets and define quality constraints for acceptable data prior to using candidate data sources in decision support systems and conducting big data analytical tasks.",https://doi.org/10.1016/j.eswa.2015.06.050,2015,Sandra de F. {Mendes Sampaio} and Chao Dong and Pedro Sampaio,DQ2S – A FRAMEWORK FOR DATA QUALITY-AWARE INFORMATION MANAGEMENT,article
453,24201,EXPERT SYSTEMS WITH APPLICATIONS,journal,09574174,"1,368",Q1,207,770,1945,42314,17345,1943,"8,67","54,95",United Kingdom,Western Europe,Elsevier Ltd.,1990-2021,Artificial Intelligence (Q1); Computer Science Applications (Q1); Engineering (miscellaneous) (Q1),"55,444",6.954,0.04053,"In recent years, the growing availability of huge amounts of information, generated in every sector at high speed and in a wide variety of forms and formats, is unprecedented. The ability to harness big data is an opportunity to obtain more accurate analyses and to improve decision-making in industry, government and many other organizations. However, handling big data may be challenging and proper data integration is a key dimension in achieving high information quality. In this paper, we propose a novel approach to data integration that calibrates online generated big data with interview based customer survey data. A common issue of customer surveys is that responses are often overly positive, making it difficult to identify areas of weaknesses in organizations. On the other hand, online reviews are often overly negative, hampering an accurate evaluation of areas of excellence. The proposed methodology calibrates the levels of unbalanced responses in different data sources via resampling and performs data integration using Bayesian Networks to propagate the new re-balanced information. In this paper we show, with a case study example, how the novel data integration approach allows businesses and organizations to get a bias corrected appraisal of the level of satisfaction of their customers. The application is based on the integration of online data of review blogs and customer satisfaction surveys from the San Francisco airport. We illustrate how this integration enhances the information quality of the data analytic work in four of InfoQ dimensions, namely, Data Structure, Data Integration, Temporal Relevance and Chronology of Data and Goal.",https://doi.org/10.1016/j.eswa.2017.12.044,2018,Luciana {Dalla Valle} and Ron Kenett,SOCIAL MEDIA BIG DATA INTEGRATION: A NEW APPROACH BASED ON CALIBRATION,article
454,22491,EUROPEAN MANAGEMENT JOURNAL,journal,02632373,"1,365",Q1,102,103,215,9317,1147,208,"5,72","90,46",United Kingdom,Western Europe,Elsevier Ltd.,1982-2020,Strategy and Management (Q1),"5,790",5.075,0.00371,"Focus
The transformative power of today's big data (BD) has allowed many companies, i.e., decision-makers, to evolve at an unprecedented pace. With regard to decision-making, artificial intelligence (AI) takes task delegation to a new level, and by employing AI-assisted tools, companies can provide their HR departments with the means to manage the existing data and HR altogether.
Objectives
To determine how HR managers assess whether BD management is facilitated by AI, and how they frame the changes necessary to meet the trends related to AI and its implementation, namely their willingness to master its implementation and to meet the possible challenges.
Methodology
Content analysis was conducted on interviews held with a sample of 16 HR practitioners from a spectrum of areas, and the findings were analysed using the big data maturity model (BDMM) framework. Domains covered by this model allow the study of decision-making trends, in terms of preparedness and willingness to tackle disruptive technology with the aim of improving and gaining the competitive edge in decision-making.
Findings
The central potential of AI lies in faster data storage and processing power, thereby leading to more insightful and effective decision-making. This article contains closer insights into the challenges underlying the implementation of AI in decision-making processes, specifically in terms of strategic alignment, governance, and implementation. The results reflect the notions regarding the nature of AI – in assisting HR – and lay out the path that precedes the extraction of BD, through the delivery of advantageous intelligence, to augment decision-making in HR.",https://doi.org/10.1016/j.emj.2022.07.001,2022,Aleksandar Radonjić and Henrique Duarte and Nádia Pereira,ARTIFICIAL INTELLIGENCE AND HRM: HR MANAGERS’ PERSPECTIVE ON DECISIVENESS AND CHALLENGES,article
455,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Todays' Intelligent Transportation System (ITS) applications majorly depend on either limited neighbouring traffic data or crowd sourced stale traffic data. Enabling big traffic data analytics in ITS environments is a step closer towards utilizing significant traffic patterns and trends for making more precise and intelligent decisions particularly in connected autonomous vehicular environments. Towards this end, this paper presents a Traffic Aware Data Offloading (TRADING) approach for big traffic data centric ITS applications in connected autonomous vehicular environments. Specifically, TRADING balances offloading data traffic among gateways focusing on vehicular traffic and network status in the vicinity of gateways. In addition, TRADING mitigates the effect of gateway advertisement overhead to liberate the transmission channels for traffic big data transmission. The performance of TRADING is comparatively evaluated in a realistic simulation environment by considering gateway access overhead, load distribution among gateways, data offloading delay, and data offloading success ratio. The comparative performance evaluation results show some significant developments towards enabling big traffic data centric ITS.",10.1109/TVT.2020.2991372,2020,,TRADING: TRAFFIC AWARE DATA OFFLOADING FOR BIG DATA ENABLED INTELLIGENT TRANSPORTATION SYSTEM,
456,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Appropriate navigation strategies should be developed to overcome the current shipping industrial challenges under emission-control-based energy efficiency measures. Effective navigation strategies should be based on accurate ship performance and navigation information; therefore, various onboard data handling systems are installed on ships to collect large-scale datasets. Ship performance and navigation data that are collected to develop such navigation strategies can be an integrated part of the ship energy efficiency management plan (SEEMP). Hence, the SEEMP with various navigation strategies can play an important part of e-navigation under modern integrated bridge systems. This study proposes a machine-intelligence-based data handling framework for ship performance and navigation data to improve the quality of the respective navigation strategies. The prosed framework is divided into two main sections of pre and post processing. The data pre-processing is an onboard application that consists of sensor faults detection, data classification, and data compression steps. The data post processing is a shore-based application (i.e., in data centers) and that consists of data expansion, integrity verification, and data regression steps. Finally, a ship performance and navigation dataset of a selected vessel is analyzed through the proposed framework and successful results are presented in this study.",10.1109/TVT.2017.2701501,2017,,MACHINE INTELLIGENCE BASED DATA HANDLING FRAMEWORK FOR SHIP ENERGY EFFICIENCY,
457,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"The growth in mobile devices results in constant generation and consumption of a large amount of data by mobile users on the go which is unbearable by the current mobile networks in terms of cost and bandwidth. At the same time, the technological advancements in modern vehicles allow us to harness their computing, caching, and communication capabilities to support various smart city applications. It is now possible to recruit a set of connected vehicles to collect, store, and share heterogeneous information regarding urban streets and facilitate citizens with different location-aware services. However, for a user to find and retrieve relevant content among the fleet of hundreds of vehicles on urban roads is challenging due to high mobility and intermittent connectivity. To address this, in this paper we propose ROVERS for a service provider to recruit the best set of vehicles to facilitate users on urban streets with different location-based applications. To identify the best vehicles, we first use a distributed ranking scheme CarRank, where the vehicle autonomously classifies itself as important with respect to urban users' interest. Then, we present a centralized recruitment scheme, exploiting game-theory for the service provider to fairly and optimally select the best vehicles under desired coverage, redundancy, and quality requirements. Comparative analysis after in-depth simulations using realistic mobility traces of 2986 vehicles shows that the set of vehicles selected using ROVERS yield better results compared to other selection approaches.",10.1109/TVT.2019.2910568,2019,,ROVERS: INCENTIVE-BASED RECRUITMENT OF CONNECTED VEHICLES FOR URBAN BIG DATA COLLECTION,
458,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Radio resource slicing is critical to customize service provisioning in fifth-generation (5G) uplink radio access networks (RANs). Using drone-small-cells (DSCs) as aerial support for terrestrial base stations can enhance the flexibility for resource provisioning in response to traffic distribution variations. In this paper, we study a multi-DSC-assisted radio resource slicing problem for 5G uplink RANs, with the objective of minimizing the total uplink resource consumption under differentiated quality-of-service (QoS) constraints for both human-type and machine-type communication services. We begin with an interference-aware graph model to formulate the joint DSC three-dimension (3D) placement and device-DSC association problem for uplink radio resource slicing and prove that the proposed problem is NP-hard. A complexity-adjustable problem approximation is presented via screening candidate DSC deployment positions, which incorporates flight height adaptation to balance the uplink communication coverage and resource utilization. A lightweight approximation using a fixed DSC flight altitude is also provided with reduced complexity. For mathematical traceability, the DSC placement and device-DSC associations in each approximation are transformed as a special weight clique problem. An upgraded clique algorithm is then developed to determine how to deploy DSCs for a given number of DSCs. Simulation results demonstrate the proposed scheme's effectiveness in terms of resource utilization, network coverage, and drone dispatching cost.",10.1109/TVT.2021.3083255,2021,,DRONE-SMALL-CELL-ASSISTED RESOURCE SLICING FOR 5G UPLINK RADIO ACCESS NETWORKS,
459,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"The ever-increasing amount of data in cellular networks poses challenges for network operators to monitor the quality of experience (QoE). Traditional key quality indicators (KQIs)-based hard decision methods are difficult to undertake the task of QoE anomaly detection in the case of big data. To solve this problem, in this paper, we propose a KQIs-based QoE anomaly detection framework using semi-supervised machine learning algorithm, i.e., iterative positive sample aided one-class support vector machine (IPS-OCSVM). There are four steps for realizing the proposed method while the key step is combining machine learning with the network operator's expert knowledge using OCSVM. Our proposed IPS-OCSVM framework realizes QoE anomaly detection through soft decision and can easily fine-tune the anomaly detection ability on demand. Moreover, we prove that the fluctuation of KQIs thresholds based on expert knowledge has a limited impact on the result of anomaly detection. Finally, experiment results are given to confirm the proposed IPS-OCSVM framework for QoE anomaly detection in cellular networks.",10.1109/TVT.2020.2995160,2020,,SEMI-SUPERVISED MACHINE LEARNING AIDED ANOMALY DETECTION METHOD IN CELLULAR NETWORKS,
460,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Multicasting is emerging as an efficient method to deliver the same data to a group of users, thereby saving network resources. The fairness between different multicast groups is an important quality-of-service (QoS) indication, but it has not been given significant attention. In this paper, we propose a normalized signal-to-noise ratio (SNR)-based fair scheduling for multiple multicast groups in multicast systems. The system fairness and capacity are then analyzed and compared for both fair scheduling and greedy scheduling over independent but non-identically distributed (i.n.d.) fading channels. Closed-form expressions in terms of the system spectral efficiency, outage probability, system fairness, and average bit error rate (BER) are derived in an uncoded/coded M-ary quadrature amplitude modulation based adaptive transmission multicast system over i.n.d. Rayleigh fading channels. Numerical results show that compared with greedy scheduling, fair scheduling achieves considerably high fairness at the cost of slight system capacity loss, regardless of the number of multicast groups. Our focus is on the physical layer without rate loss, but we also briefly discuss applications of the proposed scheduling in a cross-layer design subject to the loss rate QoS constraint.",10.1109/TVT.2017.2698064,2017,,MULTICAST SYSTEMS WITH FAIR SCHEDULING IN NON-IDENTICALLY DISTRIBUTED FADING CHANNELS,
461,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. Aiming at provisioning flexible on-demand mobile-edge cloud service, in this paper we propose a comprehensive framework consisting of a resource-efficient computation offloading mechanism for users and a joint communication and computation (JCC) resource allocation mechanism for network operator. Specifically, we first study the resource-efficient computation offloading problem for a user, in order to reduce user's resource occupation by determining its optimal communication and computation resource profile with minimum resource occupation and meanwhile satisfying the QoS constraint. We then tackle the critical problem of user admission control for JCC resource allocation, in order to properly select the set of users for resource demand satisfaction. We show the admission control problem is NP-hard, and hence develop an efficient approximation solution of a low complexity by carefully designing the user ranking criteria and rigourously derive its performance guarantee. To prevent the manipulation that some users may untruthfully report their valuations in acquiring mobile-edge cloud service, we further resort to the powerful tool of critical value approach to design truthful pricing scheme for JCC resource allocation. Extensive performance evaluation demonstrates that the proposed schemes can achieve superior performance for on-demand mobile-edge cloud computing.",10.1109/TVT.2018.2846232,2018,,EFFICIENT RESOURCE ALLOCATION FOR ON-DEMAND MOBILE-EDGE CLOUD COMPUTING,
462,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Mobile edge computing (MEC) can provide computing and storage services to user equipments (UEs) by utilizing edge nodes known as the small base stations (SBS’s) deployed at the edge of the network. The short-distance transmission nature between SBS’s and UEs makes the millimeter-wave (mmWave) communication empowered with multiple-input multiple-output (MIMO) hybrid precoding techniques particularly attractive for MEC. In this work, we consider the UE-SBS association, precoding design and power allocation for MEC networks endowed with mmWave MIMO. More specifically, the user association problem is first formulated as a max-k-cut (M $k$ C) problem and then, solved by a distributed local-search algorithm. Next, the joint optimization of precoding and power allocation is cast into the difference of two convex functions (D.C.) programming framework before an iterative rank-constrained D.C. programming algorithm is developed to maximize the weighted sum-rate (WSR) of all UEs while taking into account the quality of service (QoS) requirement of each UE. Furthermore, the monotonic convergence of the proposed iterative algorithm is analytically proven. Finally, extensive computer simulation is conducted to demonstrate the effectiveness of the proposed iterative algorithm.",10.1109/TVT.2021.3076353,2021,,"QOS-AWARE RESOURCE ALLOCATION FOR MOBILE EDGE NETWORKS: USER ASSOCIATION, PRECODING AND POWER ALLOCATION",
463,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"In this paper, we study the network average power consumption minimization problem in a two-tier heterogeneous network by optimally tuning the activation ratio of micro base stations (BSs) under the quality of service (QoS) constraints of the network mean queueing delay and the network signal-to-interference ratio (SIR) coverage. With the consideration of dynamic packets arrivals, each BS can either be busy or be idle depending on its queueing status. The network performance is thus critically determined by the traffic intensity of each BS. With the assumption of universal frequency reuse, the average traffic intensity of each tier is characterized by a set of fixed-point equations, which can be solved by a proposed iterative method. By using the approximation that BSs of the same tier have the same SIR coverage, the cumulative distribution function of the traffic intensity of each tier is further obtained. On that basis, the network average power consumption per area, the network mean queueing delay, and the network SIR coverage are characterized. Numerical results demonstrate that if the idle power coefficient is below a certain threshold, then the optimal activation ratio equals the one to minimize the network average power consumption per area; otherwise, the optimal activation ratio can be obtained according to the QoS constraints. It is further shown that universal frequency reuse outperforms spectrum partitioning in terms of both the network average power consumption and the network SIR coverage in the considered scenario.",10.1109/TVT.2018.2852065,2018,,QUEUE-AWARE POWER CONSUMPTION MINIMIZATION IN TWO-TIER HETEROGENEOUS NETWORKS,
464,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"The rapid expansion of urbanization and the fast pace of life result in abundant choices with little time for people to manage routes. A proper planning route enables us to enjoy life better with fewer time and energy costs. Therefore, route planning becomes too valuable to be ignored. At the same time, with the popularity of mobile devices, location sensing, and Web 2.0 technologies, location-based social networks (e.g., Facebook Palaces and Foursquare) have attracted millions of users to share their visited locations and other information, which generates large amounts of user check-in data. These data can be used to mine users' preferences and time information for recommending routes. In this paper, we propose FineRoute, a personalized and time-sensitive route recommendation system. We take three factors that user' preferences, proper visiting time, and transition time into consideration for the route generation. First, we infer users' preferences by constructing a three-dimensional tensor, with three dimensions representing users, locations, and time, respectively. Second, we obtain the proper visiting time for certain locations, as well as the transition time between two locations from the check-in dataset. Moreover, we adopt Kullback-Leibler divergence in order to measure the quality of a route in terms of the proper visiting month and the proper visiting hour. Finally, we propose a route generation algorithm by extending the classic longest path algorithm. We conduct experiments on a real-world check-in dataset and the results demonstrate the effectiveness of our scheme.",10.1109/TVT.2017.2764999,2017,,FINEROUTE: PERSONALIZED AND TIME-AWARE ROUTE RECOMMENDATION BASED ON CHECK-INS,
465,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"With the advancement of mobile crowd sensing systems and vehicular ad hoc networks, the human-carried mobile devices (e.g., smartphones, smart navigators, and smart tablets) equipped with a variety of sensors (such as GPS, accelerometer, and compass) can work together to collect sensory data consequently delivered to the cloud for processing purposes, which supports a wide range of promising applications such as traffic monitoring, path planning, and real-time navigation. To ensure the authenticity and privacy of data, privacy-preserving truth discovery has attracted much attention since it can find reliable information among uneven quality of data collected from mobile users, while protecting both the confidentiality of users' raw sensory data and reliability. However, these methods always incur tremendous overhead and require all participants to keep online for interacting frequently with the cloud server. In this paper, we design an efficient and privacy-preserving truth discovery (EPTD) approach in mobile crowd sensing systems, which can tolerate users offline at any stage, while guaranteeing practical efficiency and accuracy under working process. More notably, our EPTD is the first solution to resolve the problem that users must be online all times during the truth discovery under a single cloud server setting. Moreover, we design a double-masking protocol to ensure the strong security of users' privacy even if the cloud server colludes with multiple users. Extensive experiments conducted on real-world mobile crowd sensing systems also demonstrate the high performance of our proposed scheme compared with existing models.",10.1109/TVT.2019.2895834,2019,,EFFICIENT AND PRIVACY-PRESERVING TRUTH DISCOVERY IN MOBILE CROWD SENSING SYSTEMS,
466,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"While achieving promising performance, there are still many challenges for the long term evolution advanced networks to offer support for the evolving multimedia services, especially in current big multimedia data era. The conventional multimedia communication schemes tend to serve all group members with the data rate supported by the receiver under the worst channel condition, which, however, may not provide satisfactory quality of service (QoS) for all receivers. In this paper, we propose a cluster-oriented device-to-device (D2D) multimedia communication scheme for multimedia services, which extends the conventional scheme with additional D2D communication to increase the total system data rate and thus provide satisfactory QoS for all receivers. In the proposed scheme, we jointly consider the power, bandwidth, and link selection optimization. To derive the optimal solution, we decompose the whole optimization problem into three subproblems. Specifically, we first formulate the power allocation problem as a Stackelberg game by fixing the bandwidth and D2D links as parameters, where the players are the multimedia server (MS) and the candidate D2D transmitter. The MS is the buyer who buys the power from the candidate D2D transmitter for D2D transmission and the candidate D2D transmitter is the seller who earns reward by helping the MS with the D2D transmission. Through analyzing the game, we derive the Stackelberg equilibrium as the optimal power allocation. Then, with the optimal power allocation, we optimize the bandwidth allocation and link selection by maximizing the MS's utility function. Finally, simulations are conducted to validate the proposed scheme.",10.1109/TVT.2017.2762745,2018,,"CLUSTER-ORIENTED DEVICE-TO-DEVICE MULTIMEDIA COMMUNICATIONS: JOINT POWER, BANDWIDTH, AND LINK SELECTION OPTIMIZATION",
467,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"In traditional networks, routing table is essential for packet transmission due to the lack of the direction information about destination in the head of packet. However, it is feasible to make the address of device encode the routing information with the application of data technology. In this article, we propose new identities for networking routers -vectors, and a new routing principle based on these vectors is designed accordingly. These vectors encode the device distance information and serve as a pattern of the network topology. Then, routing decisions could be made by these vector calculations and only requirement of table query on the destination vector following the proposed routing principle. The proposed method is not limited in calculating the shortest path routing, but extend to solve the constrain routing problem. Besides, multi-paths routing is also available as long as multi-paths exist between the origin-destination pairs. The simulation results show that our proposed method works reliable and stable in routing tasks, and can achieve a remarkable performance when compared with the state-of-the-art work on the delay constrained least cost path (DCLC) problem.",10.1109/TVT.2020.2986769,2020,,A LEARNING-BASED APPROACH TO INTRA-DOMAIN QOS ROUTING,
468,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"In Intelligent Transportation Systems (ITS), vehicular networks are enabling technologies for onboard data services such as traffic safety, user infotainment, etc. Vehicular networks face many challenges when it comes to providing satisfactory quality of service, mainly because of issues that arise from unreliable communication in unfavorable propagation conditions. One prime example is Vehicle-to-Vehicle (V2V) communication in the presence of big vehicles that present obstacles in the communication path of smaller vehicles, where the signal strength decays drastically due to the big vehicle shadowing. As a result, the communication range is shortened, and the safety message dissemination capability is reduced. In this paper, we analyze the impact of big vehicle shadowing on V2V communications, taking into account Cellular Vehicle-to-Everything (C-V2X) networks. A geometric as well as a stochastic approach is employed to analyze the length of shadow regions for conventional cars and big vehicles on the road in different scenarios. This paper analyses the effect of large vehicles shadowing on a V2V communication link as a function of the shadow region length. A beamforming-based signal reception technique is proposed in order to mitigate packet collisions caused by hidden nodes. Considering relaying operation by big vehicles, three relaying schemes are proposed to improve the V2V message dissemination performance. Extensive simulations are conducted to demonstrate the effectiveness of the proposed schemes.",10.1109/TVT.2022.3212704,2022,,CELLULAR V2X COMMUNICATIONS IN THE PRESENCE OF BIG VEHICLE SHADOWING: PERFORMANCE ANALYSIS AND MITIGATION,
469,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Unmanned aerial vehicle (UAV) swarm has emerged as a promising novel paradigm to achieve better coverage and higher capacity for future wireless network by exploiting the more favorable line-of-sight (LoS) propagation. To reap the potential gains of UAV swarm, the remote control signal sent by ground control unit (GCU) is essential, whereas the control signal quality are susceptible in practice due to the effect of the adjacent channel interference (ACI) and the external interference (EI) from radiation sources distributed across the region. To tackle these challenges, this paper considers priority-aware resource coordination in a multi-UAV communication system, where multiple UAVs are controlled by a GCU to perform certain tasks with a pre-defined trajectory. Specifically, we maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the UAVs by jointly optimizing channel assignment and power allocation strategy under stringent resource availability constraints. According to the intensity of ACI, we consider the corresponding problem in two scenarios, i.e., Null-ACI and ACI systems. By virtue of the particular problem structure in Null-ACI case, we first recast the formulation into an equivalent yet more tractable form and obtain the global optimal solution via Hungarian algorithm. For general ACI systems, we develop an efficient iterative algorithm for its solution based on the alternating optimization methods. Extensive simulation results demonstrate that the proposed algorithms can significantly enhance the minimum SINR among all the UAVs and adapt the allocation of communication resources to diverse mission priority.",10.1109/TVT.2021.3104279,2021,,EFFICIENT RESOURCE ALLOCATION FOR MULTI-UAV COMMUNICATION AGAINST ADJACENT AND CO-CHANNEL INTERFERENCE,
470,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"With the popularity of versatile mobile multimedia applications and the pressing need to reduce energy consumption in future wireless networks, new challenges have been posed to maintain adequate coverage, quality of service, and reliability for big-scale multimedia traffic. Specifically, in this paper we introduce a cooperative multimedia relay framework and investigate premium-regular-diversity-based multimedia resource allocation treatment approaches. We also comparatively study five generic wireless multimedia relay scenarios including direct transmission, single relay, multiple pure relays, relay cooperation with space-time coding, and relay coordination with distributed beamforming. The key contribution of the new relay resource allocation framework is that packet importance priority diversity at the application layer is jointly considered with spatial diversity and relay coordination protocols at lower layers. Premium packets and regular packets of multimedia streams are adaptively allocated to relay nodes, and transmission resources are optimally allocated with regards to energy budget. Extensive simulation results demonstrate that the proposed resource allocation paradigm using multirelay coordination has significant video quality enhancement and energy saving potentials to support future big-data wireless multimedia traffic.",10.1109/TVT.2017.2744600,2017,,MULTIMEDIA RELAY RESOURCE ALLOCATION FOR ENERGY EFFICIENT WIRELESS NETWORKS: HIGH-LAYER CONTENT PRIORITIZATION WITH LOW-LAYER DIVERSITY COOPERATION,
471,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"The ongoing increasing traffic in the era of big data yields unprecedented demands in user experience and network capacity expansion. The users of next generation mobile networks (5 G) should be able to use 3GPP, IEEE, and other technologies simultaneously. The integration of multiple radio access technologies (RATs) of licensed or unlicensed bands has been widely deemed as a cost-efficient way to greatly increase the network capacity. In this paper, we propose a smart aggregated RAT access (SARA) strategy with aim of maximizing the long-term network throughput while meeting diverse traffic quality of service (QoS) requirements. We consider the scenario that users with different QoS requirements access to a heterogeneous network with coexisting cellular-WiFi. In order to maximize system throughput while meeting diverse traffic QoS requirements in such a complex and dynamic environment, we exploit multiagent reinforcement learning to perform RAT selection in conjunction with resource allocation for individual user access requests, through sensing dynamic channel states and traffic QoS requirements. In SARA, we first use Nash Q-learning to provide a set of feasible RAT selection strategies while decreasing the strategy space in learning process, and then employ Monte Carlo tree search (MCTS) based Q-learning to perform resource allocation. Numerical results reveal that the network throughput can be maximized while meeting various traffic QoS requirements with limited number of searches by using our proposed SARA algorithm. For bulk arrival access requests, a suboptimal solution can be obtained as high computational complexity is incurred for achieving global optimality. Another attractive feature of SARA is that a tradeoff between the solution optimality and learning time can be readily made by terminating the search of MCTS according to the time constraint. Compared with traditional WiFi offloading schemes, SARA can significantly improve network throughput while guaranteeing traffic QoS requirements.",10.1109/TVT.2018.2793186,2018,,SMART MULTI-RAT ACCESS BASED ON MULTIAGENT REINFORCEMENT LEARNING,
472,17393,IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY,journal,19399359,"1,365",Q1,178,1427,3074,49867,23276,3060,"7,80","34,95",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1967-2020,Aerospace Engineering (Q1); Applied Mathematics (Q1); Automotive Engineering (Q1); Computer Networks and Communications (Q1); Electrical and Electronic Engineering (Q1),"36,492",5.978,0.05223,"Cellular networks are among the biggest energy hogs of communication networks, and their contributions to the global energy consumption rapidly increase due to the surge of data traffic. With the development of green energy technologies, base stations (BSs) can be powered by green energy to reduce on-grid energy consumption and subsequently reduce carbon footprints. However, equipping a BS with a green energy system incurs additional capital expenditure (CAPEX) that is determined by the size of the green energy generator, the battery capacity, and other installation expenses. In this paper, we introduce and investigate the green energy provisioning (GEP) problem, which aims to minimize the CAPEX of deploying green energy systems in BSs while satisfying the quality-of-service (QoS) requirements of cellular networks. The GEP problem is challenging because it involves optimization over multiple time slots and across multiple BSs. We decompose the GEP problem into the weighted energy minimization problem and the green energy system sizing problem and propose a GEP solution consisting of the provision-cost-aware traffic load balancing algorithm and the binary energy system sizing algorithm to solve the subproblems and subsequently solve the GEP problem. We validate the performance and the viability of the proposed GEP solution through extensive simulations, which also conform to our analytical results.",10.1109/TVT.2015.2466101,2016,,PROVISIONING GREEN ENERGY FOR BASE STATIONS IN HETEROGENEOUS NETWORKS,
473,20566,CHINA ECONOMIC REVIEW,journal,1043951X,"1,361",Q1,76,184,319,8316,1318,311,"3,96","45,20",Netherlands,Western Europe,Elsevier,1989-2020,Economics and Econometrics (Q1); Finance (Q1),"5,722",4.227,0.00605,"Based on mobile internet user data, we construct an “Internet population” measure and reexamine spatial population distribution in China. The location based service (LBS) data of mobile internet uses is able to capture the accurate location of users' residence and solve the underestimation problem of missing migrants. We have three main findings. First, contrary to previous studies based on traditional population statistics, city size distribution of Internet population fits well into Zipf's law with a R2 of 90.7%. Second, the Internet population indicator is superior to traditional population statistics in explaining inelastic household consumption such as water consumption, electricity consumption, and garbage disposal. It suggests that the “Internet population” is a better proxy of actual city population. Third, the traditional population statistics systematically overestimate population in small cities and underestimate population in large cities. It indicates that the public resource distortions will continue to exist or even worsen off in China if the allocation process relies greatly on traditional population statistics. Although no measures are perfect, our new population measure provides important incremental information for future discussion.",https://doi.org/10.1016/j.chieco.2022.101808,2022,Huixuan Li and Jing Chen and Zihao Chen and Jianguo Xu,URBAN POPULATION DISTRIBUTION IN CHINA: EVIDENCE FROM INTERNET POPULATION,article
474,12178,JOURNAL OF LIGHTWAVE TECHNOLOGY,journal,15582213,"1,346",Q1,200,843,2094,25682,11223,2075,"5,45","30,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1983-2020,"Atomic and Molecular Physics, and Optics (Q1)","26,555",4.142,0.03062,"Network slicing is a key concept in 5G networking. It enables an infrastructure provider (InP) to support heterogeneous services over a common platform by creating a customized slice for each one of them. Once in operation, the slices can be dynamically scaled up/down to match the variation of service requirements. Although an InP generates revenue by accepting a slice request, however it might need to pay a penalty (proportional to the level of service degradation) if a slice cannot be scaled up when required. Hence, it becomes crucial to decide which slice requests should be accepted in order to maximize the net profit of an InP. This paper presents a slice admission strategy based on big data analytics (BDA) predictions. The intuition is to accept a slice request only when it is estimated that no service degradation will take place for both the incoming slice request and the slices already in operation. In this way, the penalty paid by an InP is contained, with beneficial effects on the overall net profit. Apart from simulations, the performance of the proposed admission policy has also been evaluated using emulation. Simulation results show that, in the presence of a high penalty due to service degradation, using BDA predictions brings up to 50.7% increase in profit, as compared to a slice admission policy without BDA. Emulation results for a small network scenario show a profit increase of up to 38.3% with only a small impact on the slice provisioning time (i.e., due to the processing of BDA predictions).",10.1109/JLT.2019.2896138,2019,,A SLICE ADMISSION POLICY BASED ON BIG DATA ANALYTICS FOR MULTI-TENANT 5G NETWORKS,
475,27660,MATURITAS,journal,03785122,"1,346",Q1,105,146,527,5638,2319,475,"3,97","38,62",Ireland,Western Europe,Elsevier Ireland Ltd,1978-2021,"Biochemistry, Genetics and Molecular Biology (miscellaneous) (Q1); Obstetrics and Gynecology (Q1)","9,715",4.342,0.01085,"The increasingly aging population in Europe and worldwide brings up the need for the restructuring of healthcare. Technological advancements in electronic health can be a driving force for new health management models, especially in chronic care. In a patient-centered e-health management model, communication and coordination between patient, healthcare professionals in primary care and hospitals can be facilitated, and medical decisions can be made timely and easily communicated. Bringing the right information to the right person at the right time is what connected health aims at, and this may set the basis for the investigation and deployment of the integrated care models. In this framework, an overview of the main technological axes and challenges around connected health technologies in chronic disease management are presented and discussed. A central concept is personal health system for the patient/citizen and three main application areas are identified. The connected health ecosystem is making progress, already shows benefits in (a) new biosensors, (b) data management, (c) data analytics, integration and feedback. Examples are illustrated in each case, while open issues and challenges for further research and development are pinpointed.",https://doi.org/10.1016/j.maturitas.2015.03.015,2015,Ioanna G. Chouvarda and Dimitrios G. Goulis and Irene Lambrinoudaki and Nicos Maglaveras,CONNECTED HEALTH AND INTEGRATED CARE: TOWARD NEW MODELS FOR CHRONIC DISEASE MANAGEMENT,article
476,15139,REGIONAL SCIENCE AND URBAN ECONOMICS,journal,01660462,"1,343",Q1,79,84,236,3483,606,235,"2,36","41,46",Netherlands,Western Europe,Elsevier,1973-2020,Economics and Econometrics (Q1); Urban Studies (Q1),"4,552",2.613,0.00472,"We use a new property-level data set and an innovative methodology to estimate the price of land from 2000 to 2013 for nearly the universe of detached single-family homes in the Washington, DC metro area and to characterize the boom-bust cycle in land and house prices at a fine geography. The results show that land prices were more volatile than house prices everywhere, but especially so in the areas where land was inexpensive in 2000. We demonstrate that the change in the land share of house value during the boom was a significant predictor of the decline in house prices during the bust, highlighting the value of focusing on land in assessing house-price risk.",https://doi.org/10.1016/j.regsciurbeco.2017.06.006,2017,Morris A. Davis and Stephen D. Oliner and Edward J. Pinto and Sankar Bokka,"RESIDENTIAL LAND VALUES IN THE WASHINGTON, DC METRO AREA: NEW INSIGHTS FROM BIG DATA",article
477,16759,ADVANCES IN CLINICAL CHEMISTRY,journal,00652423,"1,330",Q1,46,59,118,10307,495,18,"4,45","174,69",United States,Northern America,Academic Press Inc.,"1958-1973, 1975-1978, 1980-1981, 1983, 1985-1987, 1989-1990, 1992-1994, 1996, 1998-2001, 2003-2020",Chemistry (miscellaneous) (Q1); Clinical Biochemistry (Q1),"1,701",5.394,0.00219,"In this chapter we discuss the past, present and future of clinical biomarker development. We explore the advent of new technologies, paving the way in which health, medicine and disease is understood. This review includes the identification of physicochemical assays, current regulations, the development and reproducibility of clinical trials, as well as, the revolution of omics technologies and state-of-the-art integration and analysis approaches.",https://doi.org/10.1016/bs.acc.2020.08.002,2021,Laura Bravo-Merodio and Animesh Acharjee and Dominic Russ and Vartika Bisht and John A. Williams and Loukia G. Tsaprouni and Georgios V. Gkoutos,CHAPTER FOUR - TRANSLATIONAL BIOMARKERS IN THE ERA OF PRECISION MEDICINE,incollection
478,28339,OCEAN ENGINEERING,journal,00298018,"1,321",Q1,100,1216,2475,51177,10979,2469,"4,31","42,09",United Kingdom,Western Europe,Elsevier BV,1968-2020,Environmental Engineering (Q1); Ocean Engineering (Q1),"23,463",3.795,0.0247,"Improving the operational energy efficiency of existing ships is attracting considerable interests to reduce the environmental footprint due to air emissions. As the shipping industry is entering into Shipping 4.0 with digitalization as a disruptive force, an intriguing area in the field of ship’s operational energy efficiency is big data analytics. This paper proposes a big data analytics framework for ship performance monitoring under localized operational conditions with the help of appropriate data analytics together with domain knowledge. The proposed framework is showcased through a data set obtained from a bulk carrier pertaining the detection of data anomalies, the investigation of the ship’s localized operational conditions, the identification of the relative correlations among parameters and the quantification of the ship’s performance in each of the respective conditions. The novelty of this study is to provide a KPI (i.e. key performance indicator) for ship performance quantification in order to identify the best performance trim-draft mode under the engine modes of the case study ship. The proposed framework has the features to serve as an operational energy efficiency measure to provide data quality evaluation and decision support for ship performance monitoring that is of value for both ship operators and decision-makers.",https://doi.org/10.1016/j.oceaneng.2021.109392,2021,Khanh Q. Bui and Lokukaluge P. Perera,ADVANCED DATA ANALYTICS FOR SHIP PERFORMANCE MONITORING UNDER LOCALIZED OPERATIONAL CONDITIONS,article
479,28339,OCEAN ENGINEERING,journal,00298018,"1,321",Q1,100,1216,2475,51177,10979,2469,"4,31","42,09",United Kingdom,Western Europe,Elsevier BV,1968-2020,Environmental Engineering (Q1); Ocean Engineering (Q1),"23,463",3.795,0.0247,"Energy efficiency of inland ships is significantly influenced by navigational environment, including wind speed and direction as well as water depth and speed. The complexity of the inland navigational environment makes it rather difficult to determine the optimal speeds under different environmental conditions to achieve the best energy efficiency. Route division according to the characteristics of these environmental factors could provide a good solution for the optimization of ship engine speed under different navigational environments. In this paper, the distributed parallel k-means clustering algorithm is adopted to achieve an elaborate route division by analyzing the corresponding environmental factors based on a self-developed big data analytics platform. Subsequently, a ship energy efficiency optimization model considering multiple environmental factors is established through analyzing the energy transfer among hull, propeller and main engine. Then, decisions are made concerning the optimal engine speeds in different segments along the path. Finally, a case study on the Yangtze River is performed to validate the present optimization method. The results show that the proposed method can effectively reduce energy consumption and CO2 emissions of ships.",https://doi.org/10.1016/j.oceaneng.2018.08.050,2018,Xinping Yan and Kai Wang and Yupeng Yuan and Xiaoli Jiang and Rudy R. Negenborn,ENERGY-EFFICIENT SHIPPING: AN APPLICATION OF BIG DATA ANALYSIS FOR OPTIMIZING ENGINE SPEED OF INLAND SHIPS CONSIDERING MULTIPLE ENVIRONMENTAL FACTORS,article
480,28339,OCEAN ENGINEERING,journal,00298018,"1,321",Q1,100,1216,2475,51177,10979,2469,"4,31","42,09",United Kingdom,Western Europe,Elsevier BV,1968-2020,Environmental Engineering (Q1); Ocean Engineering (Q1),"23,463",3.795,0.0247,"This study analyzes the energy efficiency of ships based on ISO 19030, which is a standard for the measurement of changes in hull and propeller performance. The goal is to provide energy efficiency management with digital indicators that have not been easily provided. The ship navigation information platform (SNIP) is developed to determine the dynamic information of each ship, including the fuel consumption, ship speed, horsepower of the engine, rotation speed of the engine, wind direction, and wind speed. In addition, model test data and computational fluid dynamics (CFD) calculation data are applied to calculate the energy efficiency performance indicators. Finally, the relationship of the speed through water and the speed over ground enables us to modify the effects of the ocean currents. The results verify that these indicators can be used as a reference for performance monitoring and maintenance prediction of international maritime affairs.",https://doi.org/10.1016/j.oceaneng.2021.108953,2021,Heiu-Jou Shaw and Cheng-Kuan Lin,MARINE BIG DATA ANALYSIS OF SHIPS FOR THE ENERGY EFFICIENCY CHANGES OF THE HULL AND MAINTENANCE EVALUATION BASED ON THE ISO 19030 STANDARD,article
481,23393,JOURNAL OF ENVIRONMENTAL SCIENCES,journal,10010742,"1,316",Q1,99,329,1018,17571,5975,1001,"5,83","53,41",China,Asiatic Region,Chinese Academy of Sciences,"1970, 1972-1973, 1978-1985, 1993, 1995-2021",Environmental Chemistry (Q1); Environmental Engineering (Q1); Environmental Science (miscellaneous) (Q1); Medicine (miscellaneous) (Q1),"17,274",5.565,0.01334,"Traditional air quality data have a spatial resolution of 1 km or above, making it challenging to resolve detailed air pollution exposure in complex urban areas. Combining urban morphology, dynamic traffic emission, regional and local meteorology, physicochemical transformations in air quality models using big data fusion technology, an ultra-fine resolution modeling system was developed to provide air quality data down to street level. Based on one-year ultra-fine resolution data, this study investigated the effects of pollution heterogeneity on the individual and population exposure to particulate matter (PM2.5 and PM10), nitrogen dioxide (NO2), and ozone (O3) in Hong Kong, one of the most densely populated and urbanized cities. Sharp fine-scale variabilities in air pollution were revealed within individual city blocks. Using traditional 1 km average to represent individual exposure resulted in a positively skewed deviation of up to 200% for high-end exposure individuals. Citizens were disproportionally affected by air pollution, with annual pollutant concentrations varied by factors of 2 to 5 among 452 District Council Constituency Areas (DCCAs) in Hong Kong, indicating great environmental inequities among the population. Unfavorable city planning resulted in a positive spatial coincidence between pollution and population, which increased public exposure to air pollutants by as large as 46% among districts in Hong Kong. Our results highlight the importance of ultra-fine pollutant data in quantifying the heterogeneity in pollution exposure in the dense urban area and the critical role of smart urban planning in reducing exposure inequities.",https://doi.org/10.1016/j.jes.2022.02.041,2023,Wenwei Che and Yumiao Zhang and Changqing Lin and Yik Him Fung and Jimmy C.H. Fung and Alexis K.H. Lau,IMPACTS OF POLLUTION HETEROGENEITY ON POPULATION EXPOSURE IN DENSE URBAN AREAS USING ULTRA-FINE RESOLUTION AIR QUALITY DATA,article
482,130156,INTERNATIONAL JOURNAL OF SURGERY,journal,17439191,"1,315",Q1,61,698,1214,12301,4685,959,"4,38","17,62",Netherlands,Western Europe,Elsevier BV,2003-2020,Medicine (miscellaneous) (Q1); Surgery (Q1),"16,011",6.071,0.01876,"Staggering statistics regarding the global burden of disease due to lack of surgical care worldwide has been gaining attention in the global health literature over the last 10 years. The Lancet Commission on Global Surgery reported that 16.9 million lives were lost due to an absence of surgical care in 2010, equivalent to 33% of all deaths worldwide. Although data from low- and middle-income countries (LMICs) are limited, recent investigations, such as the African Surgical Outcomes Study, highlight that despite operating on low risk patients, there is increased postoperative mortality in LMICs versus higher-resource settings, a majority of which occur secondary to seemingly preventable complications like surgical site infections. We propose that implementing creative, low-cost surgical outcomes monitoring and select quality improvement systems proven effective in high-income countries, such as surgical infection prevention programs and safety checklists, can enhance the delivery of safe surgical care in existing LMIC surgical systems. While efforts to initiate and expand surgical access and capacity continues to deserve attention in the global health community, here we advocate for creative modifications to current service structures, such as promoting a culture of safety, employing technology and mobile health (mHealth) for patient data collection and follow-up, and harnessing partnerships for information sharing, to create a framework for improving morbidity and mortality in responsible, scalable, and sustainable ways.",https://doi.org/10.1016/j.ijsu.2019.07.036,2019,Belain Eyob and Marissa A. Boeck and Patrick FaSiOen and Shamir Cawich and Michael D. Kluger,ENSURING SAFE SURGICAL CARE ACROSS RESOURCE SETTINGS VIA SURGICAL OUTCOMES DATA & QUALITY IMPROVEMENT INITIATIVES,article
483,21100255484,JOURNAL OF HOSPITALITY AND TOURISM MANAGEMENT,journal,14476770,"1,310",Q1,34,153,194,12127,1119,190,"5,44","79,26",United Kingdom,Western Europe,Elsevier BV,2006-2020,"Tourism, Leisure and Hospitality Management (Q1)","2,467",5.959,0.00232,"To address the unsolved problem of the mechanism underlying the effect of big data analytics capabilities on competitive advantage and performance, this study combined quantitative and qualitative methods to test the examined framework. The results of 257 questionnaires from hotel marketing managers and 19 semistructured interviews, confirm that big data analytics capabilities develop from big data strategies and knowledge management and enhance competitive advantage and performance through sustainability marketing. Moreover, social media enhance sustainability marketing and competitive advantage and performance. The original findings of the current research contribute to the development of big data, sustainability marketing, and social media.",https://doi.org/10.1016/j.jhtm.2022.02.026,2022,Jeou-Shyan Horng and Chih-Hsing Liu and Sheng-Fang Chou and Tai-Yi Yu and Da-Chian Hu,ROLE OF BIG DATA CAPABILITIES IN ENHANCING COMPETITIVE ADVANTAGE AND PERFORMANCE IN THE HOSPITALITY SECTOR: KNOWLEDGE-BASED DYNAMIC CAPABILITIES VIEW,article
484,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"We present a newly developed approach of combining controlled-source seismology (CSS) and local earthquake tomography (LET) data to obtain a new 3-D crustal model of the western Alpine region. Our approach combines either data by taking into account the strengths of the individual seismic methods. Our western Alpine 3-D model is primarily based on a well-defined Moho, constrained by CSS and LET data, and includes smooth lateral variations in seismic velocities mainly constrained by LET data, but locally also by CSS data. The consistent combination of results from the two different seismic methods is feasible due to LET Moho elements, as defined by characteristic P-wave velocities and their uncertainty estimates. These uncertainty estimates are based on values of the diagonal element of the resolution matrix, absolute P-wave velocities that are typical for crust and mantle and a specific velocity gradient across the Moho discontinuity. Finally, our definition of LET Moho elements and their uncertainties is validated by comparisons of highest quality Moho results from both methods coinciding in 353 localities. Our model clearly shows three Moho surfaces, being Europe, Adria and Liguria as well as major tectonic structures like suture zones and the high-velocity Ivrea body. In general, it is in a good agreement with previous studies. The biggest differences occur along plate boundaries, where the strong lateral velocity variations are best resolved by LET. Due to the larger number of available Moho reflector elements a more accurate definition of plate boundaries at Moho level is possible and, therefore, new insights in deep lithosphere structures of the Alpine collision zone can be expected. Furthermore, our new 3-D crustal model directly includes a 3-D migrated image of the Ivrea body.",10.1111/j.1365-246X.2012.05655.x,2012,,COMBINING CONTROLLED-SOURCE SEISMOLOGY AND LOCAL EARTHQUAKE TOMOGRAPHY TO DERIVE A 3-D CRUSTAL MODEL OF THE WESTERN ALPINE REGION,
485,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"Seismic tomography has arrived at the threshold of the era of big data. However, how to extract information optimally from every available time-series remains a challenge; one that is directly related to the objective function chosen as a distance metric between observed and synthetic data. Time-domain cross-correlation and frequency-dependent multitaper traveltime measurements are generally tied to window selection algorithms in order to balance the amplitude differences between seismic phases. Even then, such measurements naturally favour the dominant signals within the chosen windows. Hence, it is difficult to select all usable portions of seismograms with any sort of optimality. As a consequence, information ends up being lost, in particular from scattered waves. In contrast, measurements based on instantaneous phase allow extracting information uniformly over the seismic records without requiring their segmentation. And yet, measuring instantaneous phase, like any other phase measurement, is impeded by phase wrapping. In this paper, we address this limitation by using a complex-valued phase representation that we call ‘exponentiated phase’. We demonstrate that the exponentiated phase is a good substitute for instantaneous-phase measurements. To assimilate as much information as possible from every seismogram while tackling the non-linearity of inversion problems, we discuss a flexible hybrid approach to combine various objective functions in adjoint seismic tomography. We focus on those based on the exponentiated phase, to take into account relatively small-magnitude scattered waves; on multitaper measurements of selected surface waves; and on cross-correlation measurements on specific windows to select distinct body-wave arrivals. Guided by synthetic experiments, we discuss how exponentiated-phase, multitaper and cross-correlation measurements, and their hybridization, affect tomographic results. Despite their use of multiple measurements, the computational cost to evaluate gradient kernels for the objective functions is scarcely affected, allowing for issues with data quality and measurement challenges to be simultaneously addressed efficiently.",10.1093/gji/ggaa063,2019,,"THE EXPONENTIATED PHASE MEASUREMENT, AND OBJECTIVE-FUNCTION HYBRIDIZATION FOR ADJOINT WAVEFORM TOMOGRAPHY",
486,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"The temporal evolution of the complete source moment tensor is investigated for 28 earthquakes that occurred at Mt Etna in the period August 1990–December 1991 preceding the biggest eruption of the last three centuries.We perform several tests to check the robustness of the results of inversion considering different frequency ranges and different groups of stations. As well as the selection of good-quality data, the error analysis, statistically significant at the 95 per cent confidence level, is employed to validate the findings of the inversion and to distinguish between physical solutions and artefacts of modelling.For events between 0.3 and 10 km depth, strike-slip mechanisms prevail on normal, inverse and dip-slip mechanisms; this is possibly due to the dyke-induced stress dominating the overall stress field at the surface, producing a continuous switch of the tensile and compressive axes. The regional E–W tension prevails at depth, as indicated by the prevalence of normal mechanisms. An increment of the non-double-couple components is observed immediately before the eruption and can be related to movements of fluids, even though, for some events, the complex interaction between tectonic stress and volcanic activity cannot be excluded. The source time functions retrieved are in general simple and short but some show complexities, as one would expect in volcanic seismicity. From the seismic scalar moment found, we extrapolate an empirical moment–magnitude relation that we compare with other relations proposed for the same area and computed for the duration magnitude and the equivalent Wood–Anderson magnitude.",10.1046/j.1365-246x.2001.01375.x,2001,,NON-DOUBLE-COUPLE MECHANISMS IN THE SEISMICITY PRECEDING THE 1991–1993 ETNA VOLCANO ERUPTION,
487,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"We present the first high-resolution Rayleigh-wave phase-velocity azimuthal anisotropy tomography of the Japan subduction zone at periods of 20–150s, which is determined using a large number of high-quality amplitude and phase data of teleseismic fundamental-mode Rayleigh waves. The obtained 2-D anisotropic phase-velocity models are then inverted for a 3-D shear-wave velocity azimuthal anisotropy tomography down to a depth of ∼300km beneath Japan. The subducting Pacific slab is imaged as a dipping high-velocity zone with trench-parallel fast-velocity directions (FVDs) which may indicate the anisotropy arising from the normal faults produced at the outer-rise area near the Japan trench axis, overprinting the slab fossil fabric, whereas the mantle wedge generally exhibits lower velocities with trench-normal FVDs which reflect subduction-driven corner flow and anisotropy. Depth variations of azimuthal anisotropy are revealed in the big mantle wedge beneath the Japan Sea, which may reflect past deformations in the Eurasian lithosphere related to backarc spreading during 21 to 15 Ma and complex current convection in the asthenosphere induced by active subductions of both the Pacific and Philippine Sea plates.",10.1093/gji/ggw288,2016,,BACKARC SPREADING AND MANTLE WEDGE FLOW BENEATH THE JAPAN SEA: INSIGHT FROM RAYLEIGH-WAVE ANISOTROPIC TOMOGRAPHY,
488,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"We determined the first 3-D P-wave anisotropic tomography beneath the North China Craton (NCC) using a large number of high-quality arrival-time data from local earthquakes and teleseismic events, which reveals depth-dependent azimuthal anisotropy in the crust and upper mantle down to 600 km depth. In the NCC western block, the fast velocity direction (FVD) varies from east–west in the southern part to northeast–southwest in the northern part, which may reflect either the interaction between the Yangtze block and NCC or fossil lithospheric fabrics in the craton. Under the NCC eastern block, a uniform northwest–southeast FVD is revealed in the lower part of the upper mantle (300–410 km depths) and the mantle transition zone (410–660 km depths), which may reflect horizontal and upwelling flows in the big mantle wedge (BMW) above the stagnant Pacific slab in the mantle transition zone. The NCC central block exhibits a northeast–southwest FVD, consistent with the surface tectonic orientation there, suggesting that the cold and thick (>300 km) cratonic root of the NCC western block may obstruct the northwest–southeast trending mantle flow induced by the Pacific Plate subduction, resulting in a northeast–southwest trending mantle flow under the central block. Our present results indicate that the corner flow in the BMW associated with the deep subduction of the Pacific Plate is the main cause of NCC reactivation and mantle dynamics under East China.",10.1093/gji/ggt333,2013,,REACTIVATION AND MANTLE DYNAMICS OF NORTH CHINA CRATON: INSIGHT FROM P-WAVE ANISOTROPY TOMOGRAPHY,
489,27947,GEOPHYSICAL JOURNAL INTERNATIONAL,journal,1365246X,"1,302",Q1,168,531,1529,30241,4356,1517,"2,77","56,95",United Kingdom,Western Europe,Oxford University Press,"1922-1943, 1945, 1947-1957, 1988-2020",Geochemistry and Petrology (Q1); Geophysics (Q1),"32,388",2.934,0.03134,"We used strong-motion records from the 2012 May 20 and 29 Emilia-Romagna earthquakes (Mw 6.1 and 5.9, respectively) and four aftershocks with magnitudes ranging between 4.9 and 5.5 to analyse the S-wave spectral amplitude decay with distance and estimate acceleration source functions and site effects. The data set consists of six earthquakes, 44 stations and 248 records with hypocentral distances in the range 10 < r < 100 km. We rotated the accelerograms to calculate transverse and radial components of the acceleration spectrum. We found non-parametric attenuation functions that describe the spectral amplitude decay of SH and SV waves with distance at 60 different frequencies between 0.1 and 40 Hz. These attenuation functions provide an estimate of the quality factor Q at each frequency analysed. Assuming that geometrical spreading is 1/r for r ≤ rx and 1/(rx r)0.5 for r > rx with rx = 60 km and normalizing at 15 km (the recording distance where the attenuation functions start to decay), we find that the average Q for SH waves can be approximated by QSH = 82 ± 1 f 1.2±0.02 and by QSV = 79 ± 1 f  1.24±0.03 for SV waves in the frequency range 0.10 ≤ f ≤ 10.7 Hz. At higher frequencies, 11.8 ≤ f ≤ 40 Hz, the frequency dependence of Q weakens and is approximated by QSH = 301 ± 1 f 0.36±0.04 and QSV = 384 ± 1 f 0.28±0.04. These results indicate that the S-wave attenuation is radially isotropic at local distances in the epicentral area. Nevertheless, we used these attenuation parameters separately to correct the radial (with QSV) and transverse (with QSH) components of the acceleration spectra and to separate source and site effects using a non-parametric spectral inversion scheme. We found that the source function of the main event and the bigger aftershocks show enhanced low frequency radiation between 0.4 and 3.0 Hz. We converted the source functions into far-field source acceleration spectra and interpreted the resulting source spectra in terms of Brune's model. The stress drops obtained range between approximately 0.9 and 2.9 MPa. Although all the recording stations used are located in the Po Plain, the site functions obtained from the spectral inversion show important amplification variability between the sites. We compared these site functions with the average horizontal to vertical spectral ratios calculated for each station, and we found consistent results for most stations.",10.1093/gji/ggt245,2013,,"THE 2012 MAY 20 AND 29, EMILIA EARTHQUAKES (NORTHERN ITALY) AND THE MAIN AFTERSHOCKS: S-WAVE ATTENUATION, ACCELERATION SOURCE FUNCTIONS AND SITE EFFECTS",
490,21100370190,CURRENT OPINION IN FOOD SCIENCE,journal,22147993,"1,297",Q1,38,89,318,5095,1714,286,"5,16","57,25",Netherlands,Western Europe,Elsevier BV,2015-2021,Applied Microbiology and Biotechnology (Q1); Food Science (Q1),"3,298",6.031,0.00491,"The massive rise of Big Data generated from smartphones, social media, Internet of Things (IoT), and multimedia, has produced an overwhelming flow of data in either structured or unstructured format. Big Data technologies are being developed and implemented in the food supply chain that gather and analyse these data. Such technologies demand new approaches in data collection, storage, processing and knowledge extraction. In this article, an overview of the recent developments in Big Data applications in food safety are presented. This review shows that the use of Big Data in food safety remains in its infancy but it is influencing the entire food supply chain. Big Data analysis is used to provide predictive insights in several steps in the food supply chain, support supply chain actors in taking real time decisions, and design the monitoring and sampling strategies. Lastly, the main research challenges that require research efforts are introduced.",https://doi.org/10.1016/j.cofs.2020.11.006,2020,Cangyu Jin and Yamine Bouzembrak and Jiehong Zhou and Qiao Liang and Leonieke M. {van den Bulk} and Anand Gavai and Ningjing Liu and Lukas J. {van den Heuvel} and Wouter Hoenderdaal and Hans J.P. Marvin,BIG DATA IN FOOD SAFETY- A REVIEW,article
491,17973,NEUROMODULATION,journal,10947159,"1,296",Q1,60,253,378,9647,1477,335,"3,56","38,13",United Kingdom,Western Europe,Wiley-Blackwell Publishing Ltd,1998-2020,Anesthesiology and Pain Medicine (Q1); Medicine (miscellaneous) (Q1); Neurology (clinical) (Q1); Neurology (Q2),"4,447",4.722,0.00554,,https://doi.org/10.1016/j.neurom.2022.08.222,2022,Mark Plazier and Vincent Raymaekers and Wim Duyvendak and Sacha Meeuws and Maarten Wissels and Steven Vanvolsem and Gert Roosen and Sven Bamps and Salah-Edine Achabar and Stefan Schu and Anna Keil and Björn Carsten Schultheis and Philipp Slotty and Dirk {De Ridder} and Jan Vesper,PO048 / #665 THE BIG CHANGE IS COMMING: BIG DATA: E-POSTER VIEWING,article
492,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"We consider the problem in precision health of grouping people into subpopulations based on their degree of vulnerability to a risk factor. These subpopulations cannot be discovered with traditional clustering techniques because their quality is evaluated with a supervised metric: The ease of modeling a response variable for observations within them. Instead, we apply the more appropriate supervised cadre model (SCM). We extend the SCM formalism so that it may be applied to multivariate regression and binary classification problems and develop a way to use conditional entropy to assess the confidence in the process by which a subject is assigned their cadre. Using the SCM, we generalize the environment-wide association study (EWAS) to be able to model heterogeneity in population risk. In our EWAS, we consider more than 200 environmental exposure factors and find their association with diastolic blood pressure, systolic blood pressure, and hypertension. This requires adapting the SCM to be applicable to data generated by a complex survey design. After correcting for false positives, we found 25 exposure variables that had a significant association with at least one of our response variables. Eight of these were significant for a discovered subpopulation but not for the overall population. Some of these associations have been identified by previous researchers, whereas others appear to be novel. We examine discovered subpopulations in detail, finding that they are interpretable and suggestive of further research questions.",10.1109/JBHI.2019.2918070,2020,,A PRECISION ENVIRONMENT-WIDE ASSOCIATION STUDY OF HYPERTENSION VIA SUPERVISED CADRE MODELS,
493,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"The current development of cloud computing is completely changing the paradigm of data knowledge extraction in huge databases. An example of this technology in the cardiac arrhythmia field is the SCOOP platform, a national-level scientific cloud-based big data service for implantable cardioverter defibrillators. In this scenario, we here propose a new methodology for automatic classification of intracardiac electrograms (EGMs) in a cloud computing system, designed for minimal signal preprocessing. A new compression-based similarity measure (CSM) is created for low computational burden, so-called weighted fast compression distance, which provides better performance when compared with other CSMs in the literature. Using simple machine learning techniques, a set of 6848 EGMs extracted from SCOOP platform were classified into seven cardiac arrhythmia classes and one noise class, reaching near to 90% accuracy when previous patient arrhythmia information was available and 63% otherwise, hence overcoming in all cases the classification provided by the majority class. Results show that this methodology can be used as a high-quality service of cloud computing, providing support to physicians for improving the knowledge on patient diagnosis.",10.1109/JBHI.2015.2412175,2015,,SYMMETRICAL COMPRESSION DISTANCE FOR ARRHYTHMIA DISCRIMINATION IN CLOUD-BASED BIG-DATA SERVICES,
494,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Benefiting from non-invasive sensing tech- nologies, heartbeat detection from ballistocardiogram (BCG) signals is of great significance for home-care applications, such as risk prediction of cardiovascular disease (CVD) and sleep staging, etc. In this paper, we propose an effective deep learning model for automatic heartbeat detection from BCG signals based on UNet and bidirectional long short-term memory (Bi-LSTM). The developed deep learning model provides an effective solution to the existing challenges in BCG-aided heartbeat detection, especially for BCG in low signal-to-noise ratio, in which the waveforms in BCG signals are irregular due to measured postures, rhythm and artifact motion. For validations, performance of the proposed detection is evaluated by BCG recordings from 43 subjects with different measured postures and heart rate ranges. The accuracy of the detected heartbeat intervals measured in different postures and signal qualities, in comparison with the R-R interval of ECG, is promising in terms of mean absolute error and mean relative error, respectively, which is superior to the state-of-the-art methods. Numerical results demonstrate that the proposed UNet-BiLSTM model performs robust to noise and perturbations (e.g. respiratory effort and artifact motion) in BCG signals, and provides a reliable solution to long term heart rate monitoring.",10.1109/JBHI.2022.3162396,2022,,NON-CONTACT HEARTBEAT DETECTION BASED ON BALLISTOCARDIOGRAM USING UNET AND BIDIRECTIONAL LONG SHORT-TERM MEMORY,
495,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Red blood cell (RBC) segmentation and classification from microscopic images is a crucial step for the diagnosis of sickle cell disease (SCD). In this work, we adopt a deep learning based semantic segmentation framework to solve the RBC classification task. A major challenge for robust segmentation and classification is the large variations on the size, shape and viewpoint of the cells, combining with the low image quality caused by noise and artifacts. To address these challenges, we apply deformable convolution layers to the classic U-Net structure and implement the deformable U-Net (dU-Net). U-Net architecture has been shown to offer accurate localization for image semantic segmentation. Moreover, deformable convolution enables free-form deformation of the feature learning process, thus making the network more robust to various cell morphologies and image settings. dU-Net is tested on microscopic red blood cell images from patients with sickle cell disease. Results show that dU-Net can achieve highest accuracy for both binary segmentation and multi-class semantic segmentation tasks, comparing with both unsupervised and state-of-the-art deep learning based supervised segmentation methods. Through detailed investigation of the segmentation results, we further conclude that the performance improvement is mainly caused by the deformable convolution layer, which has better ability to separate the touching cells, discriminate the background noise and predict correct cell shapes without any shape priors.",10.1109/JBHI.2020.3000484,2020,,AUTOMATED SEMANTIC SEGMENTATION OF RED BLOOD CELLS FOR SICKLE CELL DISEASE,
496,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Health-care administrators worldwide are striving to lower the cost of care while improving the quality of care given. Hospitalization is the largest component of health expenditure. Therefore, earlier identification of those at higher risk of being hospitalized would help health-care administrators and health insurers to develop better plans and strategies. In this paper, a method was developed, using large-scale health insurance claims data, to predict the number of hospitalization days in a population. We utilized a regression decision tree algorithm, along with insurance claim data from 242 075 individuals over three years, to provide predictions of number of days in hospital in the third year, based on hospital admissions and procedure claims data. The proposed method performs well in the general population as well as in subpopulations. Results indicate that the proposed model significantly improves predictions over two established baseline methods (predicting a constant number of days for each customer and using the number of days in hospital of the previous year as the forecast for the following year). A reasonable predictive accuracy (AUC $=0.843$) was achieved for the whole population. Analysis of two subpopulations-namely elderly persons aged 63 years or older in 2011 and patients hospitalized for at least one day in the previous year-revealed that the medical information (e.g., diagnosis codes) contributed more to predictions for these two subpopulations, in comparison to the population as a whole.",10.1109/JBHI.2015.2402692,2015,,PREDICTING DAYS IN HOSPITAL USING HEALTH INSURANCE CLAIMS,
497,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Diffuse low-grade gliomas (DLGG) are brain tumors of young adults. They affect the quality of life of the inflicted patients and, if untreated, they evolve into higher grade tumors where the patient's life is at risk. Therapeutic management of DLGGs includes chemotherapy, and tumor diameter is particularly important for the follow-up of DLGG evolution. In fact, the main clinical basis for deciding whether to continue chemotherapy is tumor diameter growth rate. In order to reliably assist the doctors in selecting the most appropriate time to stop treatment, we propose a novel clinical decision support system. Based on two mathematical models, one linear and one exponential, we are able to predict the evolution of tumor diameter under Temozolomide chemotherapy as a first treatment and thus offer a prognosis on when to end it. We present the results of an implementation of these models on a database of 42 patients from Nancy and Montpellier University Hospitals. In this database, 38 patients followed the linear model and four patients followed the exponential model. From a training data set of a minimal size of five, we are able to predict the next tumor diameter with high accuracy. Thanks to the corresponding prediction interval, it is possible to check if the new observation corresponds to the predicted diameter. If the observed diameter is within the prediction interval, the clinician is notified that the trend is within a normal range. Otherwise, the practitioner is alerted of a significant change in tumor diameter.",10.1109/JBHI.2018.2834159,2019,,DATA-DRIVEN PREDICTIVE MODELS OF DIFFUSE LOW-GRADE GLIOMAS UNDER CHEMOTHERAPY,
498,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"The object detection, which has been widely applied in the biomedical field already, is of real significance but technically challenging. In practice, the object detection accuracy is vulnerable to labeling quality, which is usually not a big headache for simple algorithm or model verification since there are a bunch of ideal public available datasets whose classes and tags are all well-marked. However, in real scenarios, image data is often partially or even incorrectly labeled. Particularly, in cell detection, this becomes a thorny issue since the labelling of the dataset is incomplete and inaccurate. To address this issue, we propose a data-augmentation algorithm that can generate full labeled cell image data from incomplete labeled ones. First of all, we randomly extract the labeled objects from raw cell images, and meanwhile, keep their corresponding position information. Next, we employ the framework of cycle-consistent adversarial network, but significantly distinguished from the original one, to generate fully labeled data including both objects and backgrounds. We conduct extensive experiments on a blood cell classification dataset called BCCD to evaluate our model, and experimental results show that our proposed method can successfully address the weak annotation problem and improve the performance of object detection.",10.1109/JBHI.2020.2970091,2020,,CYCLEGAN WITH AN IMPROVED LOSS FUNCTION FOR CELL DETECTION USING PARTLY LABELED IMAGES,
499,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"The novel Coronavirus disease (COVID-19) is a highly contagious virus and has spread all over the world, posing an extremely serious threat to all countries. Automatic lung infection segmentation from computed tomography (CT) plays an important role in the quantitative analysis of COVID-19. However, the major challenge lies in the inadequacy of annotated COVID-19 datasets. Currently, there are several public non-COVID lung lesion segmentation datasets, providing the potential for generalizing useful information to the related COVID-19 segmentation task. In this paper, we propose a novel relation-driven collaborative learning model to exploit shared knowledge from non-COVID lesions for annotation-efficient COVID-19 CT lung infection segmentation. The model consists of a general encoder to capture general lung lesion features based on multiple non-COVID lesions, and a target encoder to focus on task-specific features based on COVID-19 infections. We develop a collaborative learning scheme to regularize feature-level relation consistency of given input and encourage the model to learn more general and discriminative representation of COVID-19 infections. Extensive experiments demonstrate that trained with limited COVID-19 data, exploiting shared knowledge from non-COVID lesions can further improve state-of-the-art performance with up to 3.0% in dice similarity coefficient and 4.2% in normalized surface dice. In addition, experimental results on large scale 2D dataset with CT slices show that our method significantly outperforms cutting-edge segmentation methods metrics. Our method promotes new insights into annotation-efficient deep learning and illustrates strong potential for real-world applications in the global fight against COVID-19 in the absence of sufficient high-quality annotations.",10.1109/JBHI.2021.3106341,2021,,EXPLOITING SHARED KNOWLEDGE FROM NON-COVID LESIONS FOR ANNOTATION-EFFICIENT COVID-19 CT LUNG INFECTION SEGMENTATION,
500,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"The evolving disease spectrum poses significant challenges to the asthma management, thus worsening health quality and increased financial burden on patients. However, potential dependency pattern in comorbidity spectrum remains unclear. We built comorbidity networks based on Bayesian networks utilizing 19604 asthma-patient hospitalization data to investigate dependency patterns among asthma comorbidities. We analyze static properties and trajectory behaviors of gender- and age-stratified asthmatic comorbidity networks. Results suggest that chronic obstructive pulmonary disease, respiratory failure, hypertension, atherosclerosis, and gastritis and duodenitis are the hubs of the asthma comorbidity network. They have a strong dependency pattern, while most of the associations among other comorbidities are sparse and weak. The strength of association between comorbidities is higher in female asthmatics than in males. Although the comorbidity network in children with asthma is simple and stable, the onset of common comorbidities as they age will enhance the association between comorbidities and thus increase the risk of developing other comorbidities. Furthermore, the more attributes of comorbidities, the stronger association with each other, and the greater risk of causing high treatment costs. Our study will help to dissect the asthma co-morbidity network and provide a basis for improving asthma management and cost control.",10.1109/JBHI.2022.3182368,2022,,BAYESIAN COMORBIDITY NETWORK AND COST ANALYSIS FOR ASTHMA,
501,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Spectral-domain optical coherence tomography (SD-OCT) images inevitably suffer from multiplicative speckle noise caused by random interference. This study proposes an unsupervised domain adaptation approach for noise reduction by translating the SD-OCT to the corresponding high-quality enhanced depth imaging (EDI)-OCT. We propose a structure-persevered cycle-consistent generative adversarial network for unpaired image-to-image translation, which can be applied to imbalanced unpaired data, and can effectively preserve retinal details based on a structure-specific cross-domain description. It also imposes smoothness by penalizing the intensity variation of the low reflective region between consecutive slices. Our approach was tested on a local data set that consisted of 268 SD-OCT volumes and two public independent validation datasets including 20 SD-OCT volumes and 17 B-scans, respectively. Experimental results show that our method can effectively suppress noise and maintain the retinal structure, compared with other traditional approaches and deep learning methods in terms of qualitative and quantitative assessments. Our proposed method shows good performance for speckle noise reduction and can assist downstream tasks of OCT analysis.",10.1109/JBHI.2021.3071421,2021,,NOISE REDUCTION FOR SD-OCT USING A STRUCTURE-PRESERVING DOMAIN TRANSFER APPROACH,
502,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Automatic segmentation of COVID-19 pneumonia lesions is critical for quantitative measurement for diagnosis and treatment management. For this task, deep learning is the state-of-the-art method while requires a large set of accurately annotated images for training, which is difficult to obtain due to limited access to experts and the time-consuming annotation process. To address this problem, we aim to train the segmentation network from imperfect annotations, where the training set consists of a small clean set of accurately annotated images by experts and a large noisy set of inaccurate annotations by non-experts. To avoid the labels with different qualities corrupting the segmentation model, we propose a new approach to train segmentation networks to deal with noisy labels. We introduce a dual-branch network to separately learn from the accurate and noisy annotations. To fully exploit the imperfect annotations as well as suppressing the noise, we design a Divergence-Aware Selective Training (DAST) strategy, where a divergence-aware noisiness score is used to identify severely noisy annotations and slightly noisy annotations. For severely noisy samples we use an regularization through dual-branch consistency between predictions from the two branches. We also refine slightly noisy samples and use them as supplementary data for the clean branch to avoid overfitting. Experimental results show that our method achieves a higher performance than standard training process for COVID-19 pneumonia lesion segmentation when learning from imperfect labels, and our framework outperforms the state-of-the-art noise-tolerate methods significantly with various clean label percentages.",10.1109/JBHI.2022.3172978,2022,,LEARNING COVID-19 PNEUMONIA LESION SEGMENTATION FROM IMPERFECT ANNOTATIONS VIA DIVERGENCE-AWARE SELECTIVE TRAINING,
503,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Objective: This paper presents a deep learning method of predicting where in a hospital emergency patients will be admitted after being triaged in the Emergency Department (ED). Such a prediction will allow for the preparation of bed space in the hospital for timely care and admission of the patient as well as allocation of resource to the relevant departments, including during periods of increased demand arising from seasonal peaks in infections. Methods: The problem is posed as a multi-class classification into seven separate ward types. A novel deep learning training strategy was created that combines learning via curriculum and a multi-armed bandit to exploit this curriculum post-initial training. Results: We successfully predict the initial hospital admission location with area-under-receiver-operating-curve (AUROC) ranging between 0.60 to 0.78 for the individual wards and an overall maximum accuracy of 52% where chance corresponds to 14% for this seven-class setting. Our proposed network was able to interpret which features drove the predictions using a `network saliency' term added to the network loss function. Conclusion: We have proven that prediction of location of admission in hospital for emergency patients is possible using information from triage in ED. We have also shown that there are certain tell-tale tests which indicate what space of the hospital a patient will use. Significance: It is hoped that this predictor will be of value to healthcare institutions by allowing for the planning of resource and bed space ahead of the need for it. This in turn should speed up the provision of care for the patient and allow flow of patients out of the ED thereby improving patient flow and the quality of care for the remaining patients within the ED.",10.1109/JBHI.2020.2990309,2021,,HOSPITAL ADMISSION LOCATION PREDICTION VIA DEEP INTERPRETABLE NETWORKS FOR THE YEAR-ROUND IMPROVEMENT OF EMERGENCY PATIENT CARE,
504,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"Recent advances in deep learning have produced encouraging results for biomedical image segmentation; however, outcomes rely heavily on comprehensive annotation. In this paper, we propose a neural network architecture and a new algorithm, known as overlapped region forecast, for the automatic segmentation of gastric cancer images. To the best of our knowledge, this report for the first time describes that deep learning has been applied to the segmentation of gastric cancer images. Moreover, a reiterative learning framework that achieves superior performance without pretraining or further manual annotation is presented to train a simple network on weakly annotated biomedical images. We customize the loss function to make the model converge faster while avoiding becoming trapped in local minima. Patch boundary errors were eliminated by our overlapped region forecast algorithm. By studying the characteristics of the model trained using two different patch extraction methods, we train iteratively and integrate predictions and weak annotations to improve the quality of the training data. Using these methods, a mean Intersection over Union coefficient of 0.883 and a mean accuracy of 91.09% were achieved on the partially labeled dataset, thereby securing a win in the 2017 China Big Data and Artificial Intelligence Innovation and Entrepreneurship Competition.",10.1109/JBHI.2018.2850040,2019,,WEAKLY SUPERVISED BIOMEDICAL IMAGE SEGMENTATION BY REITERATIVE LEARNING,
505,21100256982,IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS,journal,21682208,"1,293",Q1,125,417,655,15291,5019,638,"6,98","36,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Biotechnology (Q1); Computer Science Applications (Q1); Electrical and Electronic Engineering (Q1); Health Information Management (Q1),"7,850",5.772,0.01284,"The papers in this special focus on enabling technologies for next generation telehealthcare applications. The use of Information and Communication Technology (ICT) for health and well-being is rapidly increasing in the majority of high-income countries. The interest about telehealthcare allows the provisioning of various kinds of health-related services and applications over the Internet. There are several benefits associated with tele-healthcare, including: the reduction of infection risk due to optimized patients access to clinical centers; optimized healthcare workflows; containment of hospital costs; increased patient safety; improves in the quality of life of both patients and their families. Common telehealthcare applications include tele-nursing, tele-rehabilitation, tele-dialog, tele-monitoring, tele-analysis, tele-pharmacy, tele-care, tele-psychiatry, tele-radiology, tele-pathology, teledermatology, tele-dentistry, tele-audiology, tele-ophthalmology, etc. In the past ten years, key enabling technologies (KETs) such as Internet of Things (IoT), tools for big data management and processing, Cloud/Edge/Fog computing, Artificial Intelligence (AI), Blockchain reached an advanced maturity, and therefore the potential for revolutionizing the whole tele-healthcare sector.",10.1109/JBHI.2021.3126034,2021,,GUEST EDITORIAL ENABLING TECHNOLOGIES FOR NEXT GENERATION TELEHEALTHCARE,
506,22706,INTERNATIONAL JOURNAL OF FORECASTING,journal,01692070,"1,268",Q1,96,142,277,5578,1254,261,"4,50","39,28",Netherlands,Western Europe,Elsevier,1985-2020,Business and International Management (Q1),"7,207",3.779,0.00612,,https://doi.org/10.1016/j.ijforecast.2019.05.004,2019,Tao Hong and Pierre Pinson,ENERGY FORECASTING IN THE BIG DATA WORLD,article
507,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"With the advent of new remote sensors, the number and volume of remote-sensing data and its derived products, which are regarded as typical “big data,” have grown exponentially. However, it remains a significant challenge to evaluate the quality of these big remote-sensing data and their derived products. Spatial sampling is necessary for the quality assessment of remote-sensing data and the derived products. This paper proposes an approach of multilevel stratified spatial sampling for the quality assessment of remote-sensing-derived products, with the aim of resolving the issue of the quality inspection of remote sensing big data and the derived products. The proposed multilevel stratified strategy: 1) makes full use of the prior knowledge of the data set; 2) selects a sample subset to get an unbiased estimator for the quality; 3) aims to acquire knowledge about the entire product; and 4) makes an evaluation based on statistical inference. The proposed method improves the sampling accuracy without increasing the inspection cost, and the whole procedure is repeatable and easily adopted for the quality inspection of remote-sensing-derived products and other geospatial data.",10.1109/JSTARS.2015.2437371,2015,,A MULTILEVEL STRATIFIED SPATIAL SAMPLING APPROACH FOR THE QUALITY ASSESSMENT OF REMOTE-SENSING-DERIVED PRODUCTS,
508,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Chlorophyll-a (Chl-a), an important indicator of phytoplankton biomass and eutrophication, is sensitive to water constitutes and optical characteristics. An integrated machine learning method of genetic algorithm and artificial neural networks (GA–ANN) was developed to retrieve the concentration of Chl-a. In situ spectra and simultaneous water quality parameters of 107 samples from two reservoirs (Res) and coastal waters (CW) were used to calibrate GA–ANN and three-band models (TBM) for comparison of Chl-a estimation. Both GA–ANN and TBM methods perform well for the joint dataset (WGD) of Res and CW with the R2 exceeding 0.90, and the root mean square error (RMSE) of corresponding validation (N = 35) are 4.40 and 5.23 μg/L, respectively. Similarly, for independent dataset of Res (N = 45), GA–ANN and TBM methods show robust performance: the R2 values are 0.87 and 0.80, respectively; and the corresponding RMSE values are 7.79 and 7.73 μg/L, respectively. For CW dataset (N = 62), the R2 values of two methods are 0.81 and 0.62, respectively; and the corresponding RMSE values are 0.79 and 1.32 μg/L, respectively. When the GA–ANN and TBM models were applied to retrieve Chl-a concentration from the calibrated Sentinel 2 MSI reflectance data in two Res on October 20, 2019, however, the validated results of MSI-derived Chl-a concentrations using quasi-synchronous in situ data (N = 36) indicated that the GA–ANN model outperforms TBM with higher R2 value (0.91 vs. 0.26) and smaller RMSE (4.41 vs. 13.85 μg/L) and mean absolute errors (3.40 vs. 11.87 μg/L) values. Although TBM has obvious overestimation of Chl-a concentration when applied to remote sensing image, we still thought that both GA–ANN and TBM are useful methods for Chl-a estimation in case-II waters, and GA–ANN performs marginally better with less deviation to measured Chl-a for multispectral remote sensing data. The ratio of TSS to Chl-a, experimental measurements, abundance of sampling points, and Chl-a concentration range are several important factors affecting the accuracy and robustness of GA–ANN and TBM methods.",10.1109/JSTARS.2021.3066697,2021,,REMOTE SENSING ESTIMATION OF CHLOROPHYLL-A IN CASE-II WATERS OF COASTAL AREAS: THREE-BAND MODEL VERSUS GENETIC ALGORITHM–ARTIFICIAL NEURAL NETWORKS MODEL,
509,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"The Urban Agglomerations of Middle and Lower Reaches of the Yangtze River Economic Belt (UAMLYREB) have experienced rapid and intense urbanization over the past decades with natural ecosystems being converted to impervious surfaces. Thus, impervious surfaces are recognized as critical parameters when considering the effect of urbanization on water quality. While understanding how the threshold of impervious surfaces affects water quality has been a hot topic, there has been little quantitative analysis on how such thresholds change during rapid urbanization periods across large urban areas. To remedy this deficiency, this article made use of remotely-sensed impervious surface area data and in situ water quality monitoring observations for the period 2000 to 2018 to quantitively derive the temporal variation in the thresholds of the percentage of the impervious surface area (PISA) when inferring the relationship between PISA and a set of water quality indicators for a selection of watersheds within the UAMLYREB. We employed segmented regression model to derive the nonlinear relationship between PISA, the water quality indicators, and the PISA-related thresholds. Our results indicate that PISA may be considered a useful water quality indicator over watershed spatial scales. We also found that the threshold effects differed between water quality indicators (DO, CODMn, NH3-N), where, except for NH3-N, the indicators showed a PISA threshold of 30.08 to 42.34%, with slight variations over the study period. These results imply that maintaining PISA to be around 30% in watershed areas may be sufficient to mitigate against water quality degradation during the urbanization process.",10.1109/JSTARS.2021.3106038,2021,,THE IMPACTS OF IMPERVIOUS SURFACE ON WATER QUALITY IN THE URBAN AGGLOMERATIONS OF MIDDLE AND LOWER REACHES OF THE YANGTZE RIVER ECONOMIC BELT FROM REMOTELY SENSED DATA,
510,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"With the initial establishment of global earth observation system in various countries, more and more high-resolution remote sensing data of multisource, multitemporal, multiscale, and different types of satellites are obtained. It is urgent to explore the advanced basic theory of remote sensing information science, design high-performance generic key technologies of remote sensing information system and global positioning system, and study complex engineering system of remote sensing applications and geographic information system. In this article, the basic theory exploration, inversion technology research, and engineering application design and development of generic optical remote sensing product (ORSP) are systematically reviewed. We classify the ORSP scientifically, review the main algorithms and application scope of 16 kinds of generic ORSP, and expound the validation and quality evaluation methods of ORSP in engineering application. Furthermore, we analyze the current core problems and solutions, and prospects for the state-of-the-art research and the future development trend of generic ORSP. This will provide valuable reference for scientific research and construction of high-resolution earth observation system.",10.1109/JSTARS.2021.3062411,2021,,"RESEARCH ON GENERIC OPTICAL REMOTE SENSING PRODUCTS: A REVIEW OF SCIENTIFIC EXPLORATION, TECHNOLOGY RESEARCH, AND ENGINEERING APPLICATION",
511,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"With the exponential growth of the Internet of things (IoT) in remote sensing image applications, network resource orchestration and data privacy are significant aspects to handle in bigdata cellular networks. The image data sharing procedure toward central cloud servers in order to perform real-time classifications has leaked client personalization and heavily burdened the communication networks. Thus, the deployment of IoT image sensors in privacy-constrained sectors requires an optimized federated learning (FL) scheme to efficiently consider both aspects of securing data privacy and maximizing the model accuracy with sufficient communication and computation resources. In this article, an adaptive model communication scheme with virtual resource optimization for edge FL is proposed by converging a deep q-learning algorithm to enforce a self-learning agent interacting with network functions virtualization orchestrator and software-defined networking based architecture. The agent targets to optimize the resource control policy of virtual multi-access edge computing entities in virtualized infrastructure manager. The proposed scheme trains the learning model and weighs the optimal actions for particular network states by using an epsilon-greedy strategy. In the exploitation phase, the scheme considers multiple spatial-resolution sensing conditions and allocates computation offloading resources for global multiconvolutional neural networks model aggregation based on the congestion states. In the simulation results, the quality of service and global collaborative model performance metrics were evaluated in terms of delay, packet drop ratios, packet delivery ratios, loss values, and overall accuracy.",10.1109/JSTARS.2021.3120724,2021,,ADAPTIVE RESOURCE OPTIMIZED EDGE FEDERATED LEARNING IN REAL-TIME IMAGE SENSING CLASSIFICATIONS,
512,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"This article proposes a technique named Printgrammetry, a structured workflow that allows the extraction of 3-D models from Google Earth platform through the combination of image captures from the screen monitor with structure from motion algorithms. This technique was developed to help geologists and other geoscientists in acquiring 3-D photo-realistic models of outcrops and natural landscapes of big proportions without the need of field mapping and expensive equipment. The methodology is detailed aiming to permit easy reproducibility and focused on achieving the highest resolution possible by working with the best images that the platform can provide. The results have shown that it is possible to obtain visually high-quality models from natural landscapes from Google Earth by acquiring images at high level of detail regions of the software, using a 4K monitor, multidirectional screenshots, and by marking homogeneously spaced targets for georeferencing and scaling. The geometric quality assessment performed using light detection and ranging ground truth data as comparison shows that the Printgrammetry dense point clouds have reached 98.1% of the total covered area under 5 m of distance for the Half Dome case study and 96.7% for the Raplee Ridge case study. The generated 3-D models were then visualized and interacted through an immersive virtual reality software that allowed geologists to manipulate this virtual field environment in different scales. This technique is considered by the authors to have a promising potential for research, industrial, and educational projects that do not require high-precision models.",10.1109/JSTARS.2020.2997239,2020,,PRINTGRAMMETRY—3-D MODEL ACQUISITION METHODOLOGY FROM GOOGLE EARTH IMAGERY DATA,
513,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Compared with color or grayscale images, hyperspectral images deliver more informative representation of ground objects and enhance the performance of many recognition and classification applications. However, hyperspectral images are normally corrupted by various types of noises, which have a serious impact on the subsequent image processing tasks. In this paper, we propose a novel hyperspectral image denoising method based on tucker decomposition to model the nonlocal similarity across the spatial domain and global similarity along the spectral domain. In this method, 3-D full band patches extracted from a hyperspectral image are grouped to form a third-order tensor by utilizing the nonlocal similarity in a proper window size. In this way, the task of image denoising is transformed into a high-order tensor approximation problem, which can be solved by nonnegative tucker decomposition. Instead of a traditional alternative least square based tucker decomposition, we propose a hierarchical least square based nonnegative tucker decomposition method to reduce the computational cost and improve the denoising effect. In addition, an iterative denoising strategy is adopted to achieve better denoising outcome in practice. Experimental results on three datasets show that the proposed method outperforms several state-of-the-art methods and significantly enhances the quality of the corrupted hyperspectral image.",10.1109/JSTARS.2018.2791718,2018,,NONLOCAL SIMILARITY BASED NONNEGATIVE TUCKER DECOMPOSITION FOR HYPERSPECTRAL IMAGE DENOISING,
514,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Since 2010, TanDEM-X and its twin satellite TerraSAR-X fly in a close orbit formation and form a single-pass synthetic aperture radar (SAR) interferometer. The formation was established to acquire a global high-precision digital elevation model (DEM) using SAR interferometry (InSAR). In order to achieve the required height accuracy of the TanDEM-X DEM, at least two global coverages have to be acquired. However, in difficult and mountainous terrain, up to five coverages are present. Here, acquisitions from ascending and descending orbits are needed to fill gaps and to overcome geometric limitations. Therefore, a strategy to properly combine the available height estimates is mandatory. The objective of this paper is the presentation of the operational TanDEM-X DEM mosaicking approach. In general, multiple InSAR DEM heights are combined by means of a weighted average with the height error as weight. Apart from this widely used mosaicking approach, one big challenge remains with the handling of larger height discrepancies between the input data, which are mainly caused by phase unwrapping errors, but also by temporal changes between acquisitions. In the case of inconsistencies, the TanDEM-X mosaicking approach performs a grouping into height levels. A priority concept is set up to evaluate the different groups of heights considering the number of DEMs and several InSAR quality parameters: the height error, the phase unwrapping method, and the height of ambiguity. This allows the identification of the most reliable height level for mosaicking. This fusion concept is verified on different test areas affected by phase unwrapping errors in flat and mountainous terrain as well as by height discrepancies in forests. The results show that the quality of the final TanDEM-X DEM mosaic benefits a lot from this mosaicking approach.",10.1109/JSTARS.2015.2421879,2016,,THE TANDEM-X DEM MOSAICKING: FUSION OF MULTIPLE ACQUISITIONS USING INSAR QUALITY PARAMETERS,
515,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"The quality and accuracy of remote sensing instruments continue to increase, allowing geoscientists to perform various quantitative retrieval applications to observe the geophysical variables of land, atmosphere, ocean, etc. The explosive growth of time-series remote sensing (RS) data over large-scales poses great challenges on managing, processing, and interpreting RS ``Big Data.'' To explore these time-series RS data efficiently, in this paper, we design and implement a high-performance framework to address the time-consuming time-series quantitative retrieval issue on a graphics processing unit cluster, taking the aerosol optical depth (AOD) retrieval from satellite images as a study case. The presented framework exploits the multilevel parallelism for time-series quantitative RS retrieval to promote efficiency. At the coarse-grained level of parallelism, the AOD time-series retrieval is represented as multidirected acyclic graph workflows and scheduled based on a list-based heuristic algorithm, heterogeneous earliest finish time, taking the idle slot and priorities of retrieval jobs into account. At the fine-grained level, the parallel strategies for the major remote sensing image processing algorithms divided into three categories, i.e., the point or pixel-based operations, the local operations, and the global or irregular operations have been summarized. The parallel framework was implemented with message passing interface and compute unified device architecture, and experimental results with the AOD retrieval case verify the effectiveness of the presented framework.",10.1109/JSTARS.2019.2920077,2019,,HIGH-PERFORMANCE TIME-SERIES QUANTITATIVE RETRIEVAL FROM SATELLITE IMAGES ON A GPU CLUSTER,
516,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Hyperspectral image classification is an important topic for hyperspectral remote sensing with various applications. Hyperspectral image classification accuracy. It has been greatly improved with the introduction of deep neural networks, while the idea of transfer learning provides an opportunity to solve the problem even with the lack of training samples. In this article, we propose an effective transfer learning approach for hyperspectral images, projecting hyperspectral images with different sensors and different number of bands into a general spectral space, preserving the relative positions of each band for spectral alignment, and designing a hierarchical depth neural network for shallow feature transfer and deep feature classification. The experiments show that the proposed method can effectively preserve the source domain features, especially for the scenarios with very few samples in the target domain, which can significantly improve the classification accuracy and reduce the risk of model overfitting. Meanwhile, this strategy greatly reduces the requirement of source domain data, using multisensor data to jointly train a more robust general feature model. The proposed method can achieve high accuracies even with few training samples compared to currently many state-of-the-art classification methods.",10.1109/JSTARS.2022.3173676,2022,,MULTISOURCE DOMAIN TRANSFER LEARNING BASED ON SPECTRAL PROJECTIONS FOR HYPERSPECTRAL IMAGE CLASSIFICATION,
517,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Optical remote sensing imagery plays an important role in observing the Earth's surface today. However, it is not easy to obtain complete multitemporal optical remote sensing images because of the cloud cover, how reconstructing cloud-free optical images has become a big challenge task in recent years. Inspired by the remote sensing fusion methods based on the convolutional neural network model, we propose a two-flow network to remove clouds from optical images. In the proposed method, synthetic aperture radar images are used as auxiliary data to guide optical image reconstruction, which is not influenced by cloud cover. In addition, a novel loss function called content loss is introduced to improve image quality. The ablation experiment of the loss function also proves that content loss is indeed effective. To be more in line with a real situation, the network is trained, tested, and validated on the SEN12MS-CR dataset, which is a global real cloud-removal dataset. The experimental results show that the proposed method is better than other state-of-the-art methods in many indicators (RMSE, SSIM, SAM, and PSNR).",10.1109/JSTARS.2022.3203508,2022,,CLOUD REMOVAL BASED ON SAR-OPTICAL REMOTE SENSING DATA FUSION VIA A TWO-FLOW NETWORK,
518,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Individual tree detection from airborne laser scanning (ALS) point clouds is the basis for forestry inventory and further applications. In the past decade, many methods have been developed to localize tree instances in ALS point clouds. These methods rely on empirical rules and field measurements that may change from plot to plot. Besides, most existing methods cannot consider multiple clues (e.g., shape priors and neighboring trees) under the same framework, which makes them not flexible and extensible. In this letter, we devise a new point-based and model-driven framework named “crown guess and selection”. This framework first generates crown candidates automatically, and then the qualities of candidates and their neighboring information are both considered. Finally, expected crowns are selected from candidates simultaneously. The proposed framework is tested and evaluated in a benchmark dataset. We also compare the new framework with several existing methods, and it turns out that the proposed framework outperforms others in terms of model flexibility and detection accuracy.",10.1109/JSTARS.2022.3171771,2022,,A CROWN GUESS AND SELECTION FRAMEWORK FOR INDIVIDUAL TREE DETECTION FROM ALS POINT CLOUDS,
519,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"The first Canadian wetland inventory (CWI) map, which was based on Landsat data, was produced in 2019 using the Google Earth Engine (GEE) big data processing platform. The proposed GEE-based method to create the preliminary CWI map proved to be a cost, time, and computationally efficient approach. Although the initial effort to produce the CWI map was valuable with a 71% overall accuracy (OA), there were several inevitable limitations (e.g., low-quality samples for the training and validation of the map). Therefore, it was important to comprehensively investigate those limitations and develop effective solutions to improve the accuracy of the Landsat-based CWI (L-CWI) map. Over the past year, the L-CWI map was shared with several governmental, academic, environmental nonprofit, and industrial organizations. Subsequently, valuable feedback was received on the accuracy of this product by comparing it with various in situ data, photo-interpreted reference samples, land cover/land use maps, and high-resolution aerial images. It was generally observed that the accuracy of the L-CWI map was lower relative to the other available products. For example, the average OA in four Canadian provinces using in situ data was 60%. Moreover, including reliable in situ data, using an object-based classification method, and adding more optical and synthetic aperture radar datasets were identified as the main practical solutions to improve the CWI map in the future. Finally, limitations and solutions discussed in this study are applicable to any large-scale wetland mapping using remote sensing methods, especially to CWI generation using optical satellite data in GEE.",10.1109/JSTARS.2020.3036802,2021,,EVALUATION OF THE LANDSAT-BASED CANADIAN WETLAND INVENTORY MAP USING MULTIPLE SOURCES: CHALLENGES OF LARGE-SCALE WETLAND CLASSIFICATION USING REMOTE SENSING,
520,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Ground-penetrating radar (GPR) profiling is the primary tool to provide detail information of the internal structure and characteristics inside a sand dune in the desert area. However, with the severe elevation change in a short horizontal distance and on the rugged and complex surface topography of the sand dunes, getting clear imaging of the internal structure of sand dunes from the GPR profiling is still a big challenge. The classic imaging technique such as the Kirchhoff migration has been applied to process GPR data on sand dunes, with limited success. The reverse-time migration (RTM) technique is the most advanced imaging technique that can handles GPR data acquired on rugged surface with severe topographic relief to generate subsurface structural images with high fidelity and has been tried to process GPR data on sand dunes. The results are encouraging, and the imaging quality is significantly improved. The finite-difference time-domain (FDTD) method is the major numerical tool for forward and backward continuations of the wave field during the RTM process. There are two aspects for using FDTD in RTM of GPR data on sand dunes still need improvement: the numerical scattering caused by the staircase approximation of the ground surface by using gridding in the Cartesian coordinate, and the negligence of the possible anisotropy of the electromagnetic material properties due to the calcareous cementation bedding inside a sand dune. In this paper, we develop the RTM algorithm based on the staggered grid FDTD that handles the rugged topographic surface by using the curvilinear coordinate, and the possible anisotropic radar wave velocity of the sand dune media. We first demonstrate the equivalency of the nonuniform, isotropic medium and the uniform, anisotropic medium for justifying using the uniform, anisotropic velocity in the RTM by synthetic modeling. Next, we validate our approach of using the synthetic data with the comparison of using the Cartesian coordinate and the curvilinear coordinate in an isotropic medium. The results indicate that the RTM algorithm using the curvilinear coordinate can efficiently eliminate the adverse effect of the staircase approximated boundary of the topography surface. Finally, we processed the real GPR data collected on a sand dune in the Badain Jaran desert by using the curvilinear coordinate and the uniform, anisotropic velocity in FDTD forward and backward wave field continuation. Comparison of the results indicates that the RTM imaging using the boundary-conforming curvilinear coordinate and anisotropic velocity gains more coherent and higher resolution images for the calcareous cementation layers and the water table.",10.1109/JSTARS.2017.2787671,2018,,ANISOTROPIC REVERSE-TIME MIGRATION OF GROUND-PENETRATING RADAR DATA COLLECTED ON THE SAND DUNES IN THE BADAIN JARAN DESERT,
521,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Urban thermal condition has seriously affected the quality of residents’ daily life and triggered some environmental issues. Understanding spatial patterns of land surface temperature (LST) and its driving mechanism is important for the sustainable development of cities. Taking Beijing as an example, this study employed spatial econometric models to investigate spatial and temporal heterogeneity of LST from 2014 to 2018 based on multisource remote sensing and statistical data. The global autocorrelation Moran's I index showed the existence of significant positive correlations of LST among regions, indicating the regions with high thermal environments are spatially adjacent. The temperature of a region would increase by more than 0.6% for every 1% increase in LST of surrounding areas based on the spatial Durbin model. In terms of spatial interactions of influencing factors, elevation, normalized difference vegetation index, modified normalized difference water index, nighttime light, and fossil energy consumption of neighbors exhibited significantly positive spatial agglomeration effects on local LST, whereas albedo, GDP, and population density of adjacent areas had negative effects on LST in local areas. Particularly, the indirect effects of drivers were greater than their direct effects, indicating urban thermal condition was an interregional issue and joint control measures should be adopted to mitigate the urban heat island effects as a whole.",10.1109/JSTARS.2021.3129842,2021,,UNDERSTANDING THE DRIVERS OF LAND SURFACE TEMPERATURE BASED ON MULTISOURCE DATA: A SPATIAL ECONOMETRIC PERSPECTIVE,
522,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"China is the world’s most populous country with only 7% of the world’s arable land. Accurate assessment of the effect that future climate change may pose on grain production is essential to the sustainability of agriculture. Model variations plus uncertainties in the future climate change scenarios create a big challenge for such evaluation. In this work, we developed the statistical models for six different regions in China, using the historical yield data between 1981 and 2010 from the National Bureau of Statistics combined with meteorological station observations and analyzed the impact of climate variation (i.e., temperature and precipitation changes) on the grain yields into the 2030s, based on 28 ensemble climate predictions from six state-of-the-art Coupled Model Intercomparison Project Phase 5 (CMIP5) model outputs. Our results indicate that the four crops (i.e., rice, maize, wheat, and soybean) respond similarly to the climate variation in different regions of China, with the sensitivity to warming increasing from north to south and from inner land to coast regions. In addition, the yields of all the four crops in East and Central-South China are also positively correlated with precipitation change. Future projections with a medium greenhouse gas mitigation scenario (RCP4.5) showed that the yield of the four crops in six regions of China would increase ranging from 0.02 to 1.19 hundred ton/ha, in 2030s with respect to the 2000s. Nevertheless, adaptive implementations such as appropriately improve the irrigation infrastructure in East and Central-South China could mitigate the adverse impact from future climate change.",10.1109/JSTARS.2014.2357584,2014,,REGIONAL GRAIN YIELD RESPONSE TO CLIMATE CHANGE IN CHINA: A STATISTIC MODELING APPROACH,
523,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Cloud computing has become a promising solution to efficient processing of remotely sensed big data, due to its high-performance and scalable computing capabilities. However, existing cloud solutions generally involve the problems of low resource utilization and high energy consumption when processing large-scale remote sensing datasets, affecting the quality-of-service of the cloud system. Aiming at hyperspectral image classification applications, this article proposes an energy-efficient cloud implementation by employing a multiobjective task scheduling algorithm. We first present a parallel computing mechanism for a fusion-based classification method based on Apache Spark. With the general classification flow represented by a workflow model, we formulate a multiobjective scheduling framework that jointly minimizes the total execution time as well as energy consumption. We further develop an effective scheduling algorithm to solve the multiobjective optimization problem and produce a set of Pareto-optimal solutions, providing the tradeoff between computational efficiency and energy efficiency. Experimental results demonstrate that the multiobjective scheduling approach proposed in this work can substantially reduce the execution time and energy consumption for performing large-scale hyperspectral image classification on Spark. In addition, our proposed algorithm can generate better tradeoff solutions to the multiobjective scheduling problem as compared to competing scheduling algorithms.",10.1109/JSTARS.2020.3036896,2021,,MULTIOBJECTIVE TASK SCHEDULING FOR ENERGY-EFFICIENT CLOUD IMPLEMENTATION OF HYPERSPECTRAL IMAGE CLASSIFICATION,
524,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Pansharpening is also known as the fusion of a low-resolution (LR) multispectral (MS) image and a high-resolution (HR) panchromatic (Pan) image of the same scene, which is an effective way to improve the spatial resolution of the LR MS image so as to obtain an HR MS image (i.e., pansharpened MS image). In this article, we propose a novel multicomponent consistency priors driven variational model for simultaneous decomposition and pansharpening (SDP) in a unified optimization framework. Specifically, the proposed SDP model particularly decomposes the Pan and MS images into cartoon, structure and texture components, and fully exploits the multicomponent consistency priors on these cartoon, structure and texture components of the Pan and MS images. Thus, the proposed SDP model can suitably characterize the different properties of these multicomponents so that these multicomponents can be well preserved. Moreover, the proposed SDP model is actually a band-coupled model, which can fully preserve the intrinsic structural correlation among the MS bands, because the MS image is actually a spatial-spectral strongly correlated cube. Then, an efficient iterative algorithm based on the forward-backward splitting technique is designed to solve the proposed SDP model. Finally, we compare the proposed SDP method with some state-of-the-art methods on various satellite datasets, and the experimental results demonstrate the effectiveness of the proposed method, which can perform higher spectral and spatial qualities than the other methods.",10.1109/JSTARS.2019.2953140,2019,,MULTICOMPONENT DRIVEN CONSISTENCY PRIORS FOR SIMULTANEOUS DECOMPOSITION AND PANSHARPENING,
525,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Large-scale building extraction is an essential work in the field of a remote sensing image analysis. The high-resolution image extraction methods based on deep learning have achieved state-of-the-art performance. However, most of the previous work has focused on region accuracy rather than boundary quality. Aiming at the low-accuracy problems and incomplete boundary of the building extraction method, we propose a predictive optimization architecture, BAPANet. Notably, the architecture consists of an encoder–decoder network, and residual refinement modules responsible for prediction, and refinement. The objective function optimizes the network in the form of three levels (pixel, feature map, and patch) by fusing three loss functions: binary cross-entropy, intersection over-union, and structural similarity. The five public datasets’ experimental results show that the extraction method in this article has high region accuracy, and the boundary of buildings is clear and complete.",10.1109/JSTARS.2020.3017934,2021,,ARBITRARY-SHAPED BUILDING BOUNDARY-AWARE DETECTION WITH PIXEL AGGREGATION NETWORK,
526,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Landslide inventory mapping (LIM) plays an important role in hazard assessment and hazard relief. Even though much research has taken place in past decades, there is space for improvements in accuracy and the usability of mapping systems. In this paper, a new landslide inventory mapping framework is proposed based on the integration of the majority voting method and the multiscale segmentation of a postevent images, making use of spatial feature of landslide. Compared with some similar state-of-the-art methods, the proposed framework has three advantages: 1) the generation of LIM is almost automatic; 2) the framework can achieve more accurate results because it takes into account the landslide spatial information in an irregular manner through multisegmentation of the postevent image and object-based majority voting (MV); and 3) it needs less parameter tuning. The proposed framework was applied to four landslide sites on Lantau Island, Hong Kong. Compared with existing methods, including region level set evolution (RLSE), edge level set evolution (ELSE) and change detection Markov random field (CDMRF) methods, quantitative evaluation shows the proposed framework is competitive in terms of Completeness. The framework outperformed RLSE, ELSE, and CDMRF for the four experiments by more than 9% in Correctness and by 8% in Quality. To the authors' knowledge, this is the first-time that landslide spatial information has been utilized through the integration of multiscale segmentation of postevent image with the MV approach to obtain LIM using high spatial resolution remote sensing images. The approach is also of wide generality and applicable to other kinds of land cover change detection using remote sensing images.",10.1109/JSTARS.2018.2803784,2018,,LANDSLIDE INVENTORY MAPPING FROM BITEMPORAL HIGH-RESOLUTION REMOTE SENSING IMAGES USING CHANGE DETECTION AND MULTISCALE SEGMENTATION,
527,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"The environment and climate significantly affect the land surface temperature (LST) of a city. Previous studies have revealed that LST exhibits significant spatial heterogeneity primarily caused by a combination of natural factors and human activities. Based on this, the introduction of point of interest data of the “production-living-ecological space” divides the influencing pattern into a comprehensive description of human activities supplemented by natural factors, resulting in the precise influencing factors of spatial heterogeneity of LST. Taking Nanjing (Jiangsu Province, China) as a case study, this study uses Landsat-8 remote sensing images, point of interest data, and other data to establish a geographically weighted regression model that combines natural factors and human activities. The main research results are as follows: First, the LST of Nanjing ranged from 19.9 °C to 47.6 °C, whereas the distribution trend was “low at both ends and high in the middle.” Second, there is no multicollinearity of the influencing factors, the fitting degree of LST and each influencing factor reached 0.87. The regression coefficients were high and exhibited both positive and negative values, implying that spatial heterogeneity exists among the influencing factors and LST. Finally, the ranking of how all factors influence the LST followed the order of water area > forest and grassland > ecological space > slope > production space > elevation > living space. The research results have practical significance for improving the quality of life of urban residents and providing a critical theoretical basis for optimizing urban human settlements.",10.1109/JSTARS.2021.3105582,2021,,"INFLUENCING FACTORS OF SPATIAL HETEROGENEITY OF LAND SURFACE TEMPERATURE IN NANJING, CHINA",
528,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Recently, agricultural remote sensing community has endeavored to utilize the power of artificial intelligence (AI). One important topic is using AI to make the mapping of crops more accurate, automatic, and rapid. This article proposed a classification workflow using deep neural network (DNN) to produce high-quality in-season crop maps from Landsat imageries for North Dakota. We use historical crop maps from the agricultural department and North Dakota ground measurements as training datasets. Processing workflows are created to automate the tedious preprocessing, training, testing, and postprocessing workflows. We tested this hybrid solution on new images and received accurate results on major crops such as corn, soybean, barley, spring wheat, dry beans, sugar beets, and alfalfa. The pixelwise overall accuracy in all three test regions is over 82% for all land types (including noncrop land), which is the same level of accuracy as the U.S. Department of Agriculture Cropland Data Layer. The texture of DNN maps is more consistent with fewer noises, which is more comfortable to read. We find DNN is better on recognizing big farmlands than recognizing the scattered wetlands and suburban regions in North Dakota. The model trained on multiple scenes of multiple years and months yields higher accuracy than any of the models trained only on a single scene, a single month, or a single year. These results reflect that DNN can produce reliable in-season maps for major crops in North Dakota big farms and could provide a relatively accurate reference for the minor crops in scattered wetland fields.",10.1109/JSTARS.2020.2990104,2020,,DEEP LEARNING CLASSIFICATION FOR CROP TYPES IN NORTH DAKOTA,
529,17700155033,IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING,journal,21511535,"1,246",Q1,88,521,1344,24726,6143,1323,"4,54","47,46",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2008-2020,Computers in Earth Sciences (Q1); Atmospheric Science (Q2),"13,046",3.784,0.02119,"Intelligent matching of heterogeneous remote sensing images is a common basic problem in the field of intelligent remote sensing image processing. Aiming at the difficulty of matching satellite-aerial remote sensing images, this article proposes an intelligent matching method for heterogeneous remote sensing images based on style transfer. First, based on the idea of image style transfer of a generative adversarial networks, this method improves the conversion effect of the model on heterogeneous images by constructing a new generative network loss function and converts satellite images into aerial images. Then, the advanced deep learning-based matching algorithms D2-Net and LoFTR are used to achieve matching between the generated aerial image and the original aerial image. Finally, this transformation relationship is mapped to the corresponding satellite–aerial image pair to obtain the final matching result. The image style transfer experiments and the matching experiments we carry out under different test datasets show that the smooth cycle-consistent generative adversarial networks proposed in this article can effectively reduce the complexity of the algorithm and improve the quality of image generation. In addition, combining it with deep learning-based feature-matching methods can effectively improve the accuracy and robustness of the matching algorithm. Our code and data can be found at: https://gitee.com/AZQZ/intelligent-matching.",10.1109/JSTARS.2022.3197748,2022,,INTELLIGENT MATCHING METHOD FOR HETEROGENEOUS REMOTE SENSING IMAGES BASED ON STYLE TRANSFER,
530,15220,ANNALS OF EMERGENCY MEDICINE,journal,01960644,"1,241",Q1,153,392,1312,6283,2154,703,"1,47","16,03",United States,Northern America,Mosby Inc.,1980-2020,Emergency Medicine (Q1),"14,808",5.721,0.01573,"Clinical research often focuses on resource-intensive causal inference, whereas the potential of predictive analytics with constantly increasing big data sources remains largely unexplored. Basic prediction, divorced from causal inference, is much easier with big data. Emergency care may benefit from this simpler application of big data. Historically, predictive analytics have played an important role in emergency care as simple heuristics for risk stratification. These tools generally follow a standard approach: parsimonious criteria, easy computability, and independent validation with distinct populations. Simplicity in a prediction tool is valuable, but technological advances make it no longer a necessity. Emergency care could benefit from clinical predictions built using data science tools with abundant potential input variables available in electronic medical records. Patients’ risks could be stratified more precisely with large pools of data and lower resource requirements for comparing each clinical encounter to those that came before it, benefiting clinical decisionmaking and health systems operations. The largest value of predictive analytics comes early in the clinical encounter, in which diagnostic and prognostic uncertainty are high and resource-committing decisions need to be made. We propose an agenda for widening the application of predictive analytics in emergency care. Throughout, we express cautious optimism because there are myriad challenges related to database infrastructure, practitioner uptake, and patient acceptance. The quality of routinely compiled clinical data will remain an important limitation. Complementing big data sources with prospective data may be necessary if predictive analytics are to achieve their full potential to improve care quality in the emergency department.",https://doi.org/10.1016/j.annemergmed.2015.06.024,2016,Alexander T. Janke and Daniel L. Overbeek and Keith E. Kocher and Phillip D. Levy,EXPLORING THE POTENTIAL OF PREDICTIVE ANALYTICS AND BIG DATA IN EMERGENCY CARE,article
531,23080,ADVANCES IN COMPUTERS,book series,00652458,"1,236",Q1,33,36,79,1113,290,3,"4,58","30,92",United States,Northern America,Academic Press Inc.,"1960-1962, 1964, 1966-1967, 1969-1973, 1975-2000, 2002-2020",Computer Science (miscellaneous) (Q1),598,2.655,0.00052,"With the explosion of social media, the Web, Internet of Things, and the proliferation of smart devices, large amounts of data are being generated each day. However, traditional data management technologies are increasingly inadequate to cope with this growth in data. NoSQL has become increasingly popular as this technology can provide consistent, scalable and available solutions for the ever-growing heterogeneous data. Recent years have seen growing applications shifting from traditional data management systems to NoSQL solutions. However, there is limited in-depth literature reporting on NoSQL storage technologies for big graph and their applications in various fields. This chapter fills this gap by conducting a comprehensive study of 80 state-of-the-art NoSQL technologies. In this chapter, we first present a feature analysis of the NoSQL solutions and then generate a data set of the investigated solutions for further analysis in order to better understand and select the technologies. We perform a clustering analysis to segment the NoSQL solutions, compare the classified solutions based on their storage data models and Brewer's CAP theorem, and examine big graph applications in six specific domains. To help users select appropriate NoSQL solutions, we have developed a decision tree model and a web-based user interface to facilitate this process. In addition, the significance, challenges, applications and categories of storage technologies are discussed as well.",https://doi.org/10.1016/bs.adcom.2021.09.006,2022,Samiya Khan and Xiufeng Liu and Syed Arshad Ali and Mansaf Alam,"BIVARIATE, CLUSTER, AND SUITABILITY ANALYSIS OF NOSQL SOLUTIONS FOR BIG GRAPH APPLICATIONS",incollection
532,21100203111,IEEE WIRELESS COMMUNICATIONS LETTERS,journal,21622345,"1,230",Q1,72,522,900,6907,6003,900,"6,73","13,23",United States,Northern America,IEEE Communications Society,2012-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Physics and Astronomy (miscellaneous) (Q1),"6,558",4.348,0.01251,"Aerial-ground cooperative vehicular networks are envisioned as a novel paradigm in B5G/6G visions. In this letter, the challenge of optimizing the global energy-efficiency (EE) of multi-UAV-aided vehicular networks in the presence of uncertain air-to-ground (A2G) channels is addressed. Specifically, we propose a maximin paradigm to characterize the system, which aims to maximize its global EE meanwhile satisfying Quality-of-Service (QoS)-oriented data rate requirements in the worst-case situation. We theoretically derive a closed-form optimal solution for an embedded minimization subproblem under a parametric channel uncertainty set and thus develop a computationally tractable robust counterpart, which leads to a robust EE optimization design. Simulation results show that the proposed method significantly outperforms conventional EE schemes in terms of achieving higher global system performance and better robustness under random uncertain environments.",10.1109/LWC.2020.3043365,2021,,ROBUST COOPERATIVE COMMUNICATION OPTIMIZATION FOR MULTI-UAV-AIDED VEHICULAR NETWORKS,
533,21100203111,IEEE WIRELESS COMMUNICATIONS LETTERS,journal,21622345,"1,230",Q1,72,522,900,6907,6003,900,"6,73","13,23",United States,Northern America,IEEE Communications Society,2012-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Physics and Astronomy (miscellaneous) (Q1),"6,558",4.348,0.01251,"The coupled stochastic channel interferences can lead to intermittent connectivity and invalid fragment transmissions, which pose a significant challenge to guarantee the reliability of computation offloading. A wide variety of conventional approaches to making offloading decisions are based on the fundamental condition that channels are sufficiently reliable for completing each transmission session. However, the reliability that a user can successfully offload a computation task before a restricted deadline remains unexplored under the interference channels. In this letter, we focus on the Nakagami- ${m}$  fading channel and propose an analytical framework to characterize the reliability of computation offloading with the restrictions of application deadline and offloading data size in the presence of coupled stochastic interferences. A lower-bound offloading reliability capturing coupled randomness is theoretically derived. Based on the analytical framework, we further propose an admission control method for users to make computation offloading decisions. Simulation results verify our theoretical framework and show the superior performance of the proposed method over other benchmark schemes in terms of guaranteeing reliability.",10.1109/LWC.2021.3096381,2021,,RELIABILITY-GUARANTEED ADMISSION CONTROL FOR MOBILE COMPUTATION OFFLOADING UNDER NAKAGAMI FADING CHANNEL,
534,21100203111,IEEE WIRELESS COMMUNICATIONS LETTERS,journal,21622345,"1,230",Q1,72,522,900,6907,6003,900,"6,73","13,23",United States,Northern America,IEEE Communications Society,2012-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Physics and Astronomy (miscellaneous) (Q1),"6,558",4.348,0.01251,"Licensed-assisted-access (LAA) is used to extend the LTE link into the unlicensed band. How to guarantee the quality-of-service (QoS) for LTE devices in the unlicensed band is a challenging problem due to the listen-before-talk contention access in 5-GHz unlicensed bands. In this letter, we quantitatively analyze the medium access control delay for tagged LAA eNBs and propose a delay-guaranteed admission control scheme. We consider the freezing time of busy slots caused by collision or successful transmission, and introduce the exponential backoff mechanism for delay analysis. Validated by simulation results, our method provides important insights into the system admission performance and fairness of access.",10.1109/LWC.2019.2905206,2019,,DELAY-GUARANTEED ADMISSION CONTROL FOR LAA COEXISTING WITH WIFI,
535,21100203111,IEEE WIRELESS COMMUNICATIONS LETTERS,journal,21622345,"1,230",Q1,72,522,900,6907,6003,900,"6,73","13,23",United States,Northern America,IEEE Communications Society,2012-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Physics and Astronomy (miscellaneous) (Q1),"6,558",4.348,0.01251,"Handoff decision making is critical for mobile users to reap potential benefits from heterogeneous wireless networks. This letter proposes a biologically inspired handoff decision-making method by mimicking the dynamics which govern the adaptive behavior of an Escherichia coli cell in a time-varying environment. With the goal of guaranteeing the quality of service (QoS), we formulate a utility function that covers the demands of a user's diverse applications and the time-varying network conditions. With this utility function, we map the dynamic heterogeneous environment to a cellular decision-making space, such that the user is induced by a cellular attractor selection mechanism to make distributed and robust handoff decisions. Furthermore, we also present a multi-attribute decision-making network selection algorithm for any user to determine an access network, which is integrated with the proposed bio-inspired decision-making mechanism. Simulation results are supplemented to show that the proposed method can achieve better QoS and fairness when it is compared with conventional methods.",10.1109/LWC.2017.2748947,2018,,FROM CELLULAR DECISION MAKING TO ADAPTIVE HANDOFF IN HETEROGENEOUS WIRELESS NETWORKS,
536,28634,BRITISH ACCOUNTING REVIEW,journal,08908389,"1,223",Q1,67,44,118,3565,648,112,"5,16","81,02",United States,Northern America,Academic Press Inc.,1988-2020,Accounting (Q1),"2,836",5.577,0.00189,"This paper reviews the accounting literature that focuses on four Internet-related technologies that have the potential to dramatically change and disrupt the work of accountants and accounting researchers in the near future. These include cloud, big data, blockchain, and artificial intelligence (AI). For instance, access to distributed ledgers (blockchain) and big data supported by cloud-based analytics tools and AI will automate decision making to a large extent. These technologies may significantly improve financial visibility and allow more timely intervention due to the perpetual nature of accounting. However, given the number of tasks technology has relieved of accountants, these technologies may also lead to concerns about the profession's legitimacy. The findings suggest that scholars have not given sufficient attention to these technologies and how these technologies affect the everyday work of accountants. Research is urgently needed to understand the new kinds of accounting required to manage firms in the changing digital economy and to determine the new skills and competencies accountants may need to master to remain relevant and add value. The paper outlines a set of questions to guide future research.",https://doi.org/10.1016/j.bar.2019.04.002,2019,Jodie Moll and Ogan Yigitbasioglu,THE ROLE OF INTERNET-RELATED TECHNOLOGIES IN SHAPING THE WORK OF ACCOUNTANTS: NEW DIRECTIONS FOR ACCOUNTING RESEARCH,article
537,20532,JOURNAL OF AIR TRANSPORT MANAGEMENT,journal,09696997,"1,220",Q1,75,142,356,7377,1612,349,"4,68","51,95",United Kingdom,Western Europe,Elsevier Ltd.,"1994-1995, 1997-2020","Law (Q1); Management, Monitoring, Policy and Law (Q1); Strategy and Management (Q1); Transportation (Q1)","4,929",4.134,0.00394,"The evaluation, acquisition and use of newly available big data sources has become a major strategic and organizational challenge for airline network planners. We address this challenge by developing a maturity model for big data readiness for airline network planning. The development of the maturity model is grounded in literature, expert interviews and case study research involving nine airlines. Four airline business models are represented, namely full-service carriers, low-cost airlines, scheduled charter airlines and cargo airlines. The maturity model has been well received with seven change requests in the model development phase. The revised version has been evaluated as exhaustive and useful by airline network planners. The self-assessment of airlines revealed low to medium maturity for most domains. Organizational factors show the lowest average maturity, IT architecture the highest. Full-service carriers seem to be more mature than airlines with different business models.",https://doi.org/10.1016/j.jairtraman.2019.101721,2020,Iris Hausladen and Maximilian Schosser,TOWARDS A MATURITY MODEL FOR BIG DATA ANALYTICS IN AIRLINE NETWORK PLANNING,article
538,30441,COMPUTERS AND ELECTRONICS IN AGRICULTURE,journal,01681699,"1,208",Q1,115,648,1300,28725,9479,1298,"7,27","44,33",Netherlands,Western Europe,Elsevier,1985-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Computer Science Applications (Q1); Forestry (Q1); Horticulture (Q1),"17,657",5.565,0.01646,"With the rapid developments in ICT, the current agriculture businesses have become increasingly data-driven and are supported by advanced data analytics techniques. In this context, several studies have investigated the adopted data analytics platforms in the agricultural sector. However, the main characteristics and overall findings on these platforms are scattered over the various studies, and to the best of our knowledge, there has been no attempt yet to systematically synthesize the features and obstacles of the adopted data analytics platforms. This article presents the results of an in-depth systematic literature review (SLR) that has explicitly focused on the domains of the platforms, the stakeholders, the objectives, the adopted technologies, the data properties and the obstacles. According to the year-wise analysis, it is found that no relevant primary study between 2010 and 2013 was found. This implies that the research of data analytics in agricultural sectors is a popular topic from recent years, so the results from before 2010 are likely less relevant. In total, 535 papers published from 2010 to 2020 were retrieved using both automatic and manual search strategies, among which 45 journal articles were selected for further analysis. From these primary studies, 33 features and 34 different obstacles were identified. The identified features and obstacles help characterize the different data analytics platforms and pave the way for further research.",https://doi.org/10.1016/j.compag.2022.106813,2022,Ngakan {Nyoman Kutha Krisnawijaya} and Bedir Tekinerdogan and Cagatay Catal and Rik van der Tol,DATA ANALYTICS PLATFORMS FOR AGRICULTURAL SYSTEMS: A SYSTEMATIC LITERATURE REVIEW,article
539,30441,COMPUTERS AND ELECTRONICS IN AGRICULTURE,journal,01681699,"1,208",Q1,115,648,1300,28725,9479,1298,"7,27","44,33",Netherlands,Western Europe,Elsevier,1985-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Computer Science Applications (Q1); Forestry (Q1); Horticulture (Q1),"17,657",5.565,0.01646,"The world population is estimated to reach nine billion by 2050. Many challenges are adding pressure on the current agriculture supply chains that include shrinking land sizes, ever increasing demand for natural resources and environmental issues. The agriculture systems need a major transformation from the traditional practices to precision agriculture or smart farming practices to overcome these challenges. Geographic information system (GIS) is one such technology that pushes the current methods to precision agriculture. In this paper, we present a systematic literature review (SLR) of 120 research papers on various applications of big GIS analytics (BGA) in agriculture. The selected papers are classified into two broad categories; the level of analytics and GIS applications in agriculture. The GIS applications viz., land suitability, site search and selection, resource allocation, impact assessment, land allocation, and knowledge-based systems are considered in this study. The outcome of this study is a proposed BGA framework for agriculture supply chain. This framework identifies big data analytics to play a significant role in improving the quality of GIS application in agriculture and provides the researchers, practitioners, and policymakers with guidelines on the successful management of big GIS data for improved agricultural productivity.",https://doi.org/10.1016/j.compag.2018.10.001,2018,Rohit Sharma and Sachin S. Kamble and Angappa Gunasekaran,BIG GIS ANALYTICS FRAMEWORK FOR AGRICULTURE SUPPLY CHAINS: A LITERATURE REVIEW IDENTIFYING THE CURRENT TRENDS AND FUTURE PERSPECTIVES,article
540,30441,COMPUTERS AND ELECTRONICS IN AGRICULTURE,journal,01681699,"1,208",Q1,115,648,1300,28725,9479,1298,"7,27","44,33",Netherlands,Western Europe,Elsevier,1985-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Computer Science Applications (Q1); Forestry (Q1); Horticulture (Q1),"17,657",5.565,0.01646,"With increasing population, the demand for agricultural productivity is rising to meet the goal of “Zero Hunger”. Consequently, farmers have optimized the agricultural activities in a sustainable way with the modern technologies. This integration has boosted the agriculture production due to high potentiality in assisting the farmers. The impulse towards the technological advancement has revived the traditional agriculture methods and resulted in eco-friendly, sustainable, and efficient farming. This has revolutionized the era of smart farming which primarily alliance with modern technologies like, big data, machine learning, deep learning, swarm intelligence, internet-of-things, block chain, robotics and autonomous system, cloud-fog-edge computing, cyber physical systems, and generative adversarial networks (GAN). To cater the same, a detailed survey on ten hot-spots of smart farming is presented in this paper. The survey covers the technology-wise state-of-the-art methods along with their application domains. Moreover, the publicly available data sets with existing research challenges are investigated. Lastly, the paper concludes with suggestions to the identified problems and possible future research directions.",https://doi.org/10.1016/j.compag.2022.107217,2022,Vivek Sharma and Ashish Kumar Tripathi and Himanshu Mittal,"TECHNOLOGICAL REVOLUTIONS IN SMART FARMING: CURRENT TRENDS, CHALLENGES & FUTURE DIRECTIONS",article
541,30441,COMPUTERS AND ELECTRONICS IN AGRICULTURE,journal,01681699,"1,208",Q1,115,648,1300,28725,9479,1298,"7,27","44,33",Netherlands,Western Europe,Elsevier,1985-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Computer Science Applications (Q1); Forestry (Q1); Horticulture (Q1),"17,657",5.565,0.01646,"Crowdsourcing, understood as outsourcing tasks or data collection by a large group of non-professionals, is increasingly used in scientific research and operational applications. In this paper, we reviewed crowdsourcing initiatives in agricultural science and farming activities and further discussed the particular characteristics of this approach in the field of agriculture. On-going crowdsourcing initiatives in agriculture were analysed and categorised according to their crowdsourcing component. We identified eight types of agricultural data and information that can be generated from crowdsourcing initiatives. Subsequently we described existing methods of quality control of the crowdsourced data. We analysed the profiles of potential contributors in crowdsourcing initiatives in agriculture, suggested ways for increasing farmers’ participation, and discussed the on-going initiatives in the light of their target beneficiaries. While crowdsourcing is reported to be an efficient way of collecting observations relevant to environmental monitoring and contributing to science in general, we pointed out that crowdsourcing applications in agriculture may be hampered by privacy issues and other barriers to participation. Close connections with the farming sector, including extension services and farm advisory companies, could leverage the potential of crowdsourcing for both agricultural research and farming applications. This paper coins the term of farmsourcing asa professional crowdsourcing strategy in farming activities and provides a source of recommendations and inspirations for future collaborative actions in agricultural crowdsourcing.",https://doi.org/10.1016/j.compag.2017.08.026,2017,Julien Minet and Yannick Curnel and Anne Gobin and Jean-Pierre Goffart and François Mélard and Bernard Tychon and Joost Wellens and Pierre Defourny,CROWDSOURCING FOR AGRICULTURAL APPLICATIONS: A REVIEW OF USES AND OPPORTUNITIES FOR A FARMSOURCING APPROACH,article
542,30441,COMPUTERS AND ELECTRONICS IN AGRICULTURE,journal,01681699,"1,208",Q1,115,648,1300,28725,9479,1298,"7,27","44,33",Netherlands,Western Europe,Elsevier,1985-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Computer Science Applications (Q1); Forestry (Q1); Horticulture (Q1),"17,657",5.565,0.01646,"As the volume of data collected by various IoT sensors used in smart farm applications increases, the storing and processing of big data for agricultural applications become a huge challenge. The insight of this paper is that lossy compression can unleash the power of compression to IoT because, as compared with its counterpart (a lossless one), it can significantly reduce the data volume when the spatiotemporal characteristics of IoT sensor data are properly exploited. However, lossy compression faces the challenge of compressing too much data thus losing data fidelity, which might affect the quality of the data and potential analytics outcomes. To understand the impact of lossy compression on IoT data management and analytics, we evaluated four classification algorithms with reconstructed agricultural sensor data based on various energy concentration. Specifically, we applied three transformation-based lossy compression mechanisms to five real-world weather datasets collected at different sampling granularities from IoT weather stations. Our experimental results indicate that there is a strong positive correlation between the concentrated energy of the transformed coefficients and the compression ratio as well as the data quality. While we observed a general trend where much higher compression ratios can be achieved at the cost of a decrease in quality, we also observed that the impact on the classification accuracy varies among the data sets and algorithms we evaluated. Lastly, we show that the sampling granularity also influences the data fidelity in terms of the prediction performance and compression ratio.",https://doi.org/10.1016/j.compag.2018.08.045,2018,Aekyeung Moon and Jaeyoung Kim and Jialing Zhang and Seung Woo Son,EVALUATING FIDELITY OF LOSSY COMPRESSION ON SPATIOTEMPORAL DATA FROM AN IOT ENABLED SMART FARM,article
543,21100389511,ENERGY REPORTS,journal,23524847,"1,199",Q1,33,983,239,28463,1788,239,"7,37","28,96",United Kingdom,Western Europe,Elsevier Ltd.,2015-2020,Energy (miscellaneous) (Q1),"2,964",6.870,0.00318,"With the development of big data technology, power system has entered the era of data analysis. With the help of the massive data provided by the wide area measurement system, the power system can be easily evaluated, and the abnormal operation status can be detected and positioned. As the increase of renewable energy permeability, more new abnormal operating status have appeared in the system. Aimed at the abnormal operation state in the development of new energy, this paper proposes an oscillation location scheme based on evidence theory and support vector machine, which makes up for the limitation of single oscillation location method. The result of location analysis of oscillation energy method, oscillation phase difference method and forced oscillation phase difference location method is fused by evidence theory.",https://doi.org/10.1016/j.egyr.2022.02.022,2022,Jian Wang,A NOVEL OSCILLATION IDENTIFICATION METHOD FOR GRID-CONNECTED RENEWABLE ENERGY BASED ON BIG DATA TECHNOLOGY,article
544,21100389511,ENERGY REPORTS,journal,23524847,"1,199",Q1,33,983,239,28463,1788,239,"7,37","28,96",United Kingdom,Western Europe,Elsevier Ltd.,2015-2020,Energy (miscellaneous) (Q1),"2,964",6.870,0.00318,"Electric power systems are taking drastic advances in deployment of information and communication technologies; numerous new measurement devices are installed in forms of advanced metering infrastructure, distributed energy resources (DER) monitoring systems, high frequency synchronized wide-area awareness systems that with great speed are generating immense volume of energy data. However, it is still questioned that whether the today’s power system data, the structures and the tools being developed are indeed aligned with the pillars of the big data science. Further, several requirements and especial features of power systems and energy big data call for customized methods and platforms. This paper provides an assessment of the distinguished aspects in big data analytics developments in the domain of power systems. We perform several taxonomy of the existing and the missing elements in the structures and methods associated with big data analytics in power systems. We also provide a holistic outline, classifications, and concise discussions on the technical approaches, research opportunities, and application areas for energy big data analytics.",https://doi.org/10.1016/j.egyr.2017.11.002,2018,Hossein Akhavan-Hejazi and Hamed Mohsenian-Rad,POWER SYSTEMS BIG DATA ANALYTICS: AN ASSESSMENT OF PARADIGM SHIFT BARRIERS AND PROSPECTS,article
545,21100389511,ENERGY REPORTS,journal,23524847,"1,199",Q1,33,983,239,28463,1788,239,"7,37","28,96",United Kingdom,Western Europe,Elsevier Ltd.,2015-2020,Energy (miscellaneous) (Q1),"2,964",6.870,0.00318,"The operation control of power units is usually carried out by the control personnel with the help of distributed control system. Although it can ensure the safety of unit operation and meet the requirements of power generation loads, the economy of unit operation and the accuracy of control process still need to be further improved. Therefore, by designing multiple view mapping and association, it provides interactive visualization support for relevant experts in the key links of model establishment and evaluation. In the exploration stage of estimating model parameter, the user can get the delay range by line chart and focus + context technology, while in the model screening stage, the user can provide the combination of screening views, selecting the model by its accuracy on different data sets, and finding the model anomalies by the model structure view. Besides, in the model evaluation stage, the user can get the delay range by predicting line chart and model accuracy radar chart. In addition, the method in this paper keeps between 4.2–7.2 in most distributions, and the maximum value is 18. The time series trend of the data segment is consistent, and the absolute value of the weight coefficient is basically 0 after being superimposed, which has great advantages compared with other methods, proving the effective results of the research content in this paper.",https://doi.org/10.1016/j.egyr.2021.09.205,2021,Jianguo Qian and Bingquan Zhu and Ying Li and Zhengchai Shi,VISUAL RECOGNITION PROCESSING OF POWER MONITORING DATA BASED ON BIG DATA COMPUTING,article
546,17361,IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS,journal,19399367,"1,190",Q1,195,680,1970,19879,10265,1963,"4,98","29,23",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1970-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Industrial and Manufacturing Engineering (Q1),"25,984",3.654,0.02947,"The smart grid is a fully automatic delivery grid for electricity power with a two-way reliable flow of electricity and information among different equipment on the grid. Smart meters and sensors monitoring the system provide a huge amount of data in various part of smart grid. To logically manage this trouble, a new lossy data compression approach for big data compression is proposed. The optimal singular value decomposition (SVD) is applied to a matrix that achieves the optimal number of singular values to the sending process, and the other ones will be neglected. This goal is done due to the quality of retrieved data and the compression ratio. In the presented scheme, to implement the optimization framework, various intelligent optimization methods are used to determine the number of optimal values in the elimination stage. The efficiency and capabilities of the proposed method are examined using a wide range of data types, from electricity market data to image processing benchmarks. The comparisons show that the compression level obtained by the proposed method can dominate the points given by the existing SVD rank reduction methods. Also, as the other finding of this article, the performance of the rank reduction methods depends on the application and data types. It means that a rank reduction method can reveal a good performance in one application and performs unacceptably for another purpose. So, the optimized rank reduction can pave the way toward a robust and reliable performance.",10.1109/TIA.2021.3073640,2021,,OPTIMAL SINGULAR VALUE DECOMPOSITION BASED BIG DATA COMPRESSION APPROACH IN SMART GRIDS,
547,17361,IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS,journal,19399367,"1,190",Q1,195,680,1970,19879,10265,1963,"4,98","29,23",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1970-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Industrial and Manufacturing Engineering (Q1),"25,984",3.654,0.02947,"In the North American energy market, natural gas (NG) prices have been gradually decreasing during the past several years, primarily due to advances in shale gas extraction techniques. The availability of cheaper NG, while seen as an attractive short-term fuel switching option, is viewed with caution by most cement plants due to long-term procurement concerns. Also, due to traditionally higher NG prices, cement plants have invested heavily into solid fuels, including storage, grinding, handling, and dosing systems-often achieving high thermal substitution rates (TSRs) of solid alternative fuels and raw materials (AFRs). As a result, a wealth of knowledge has been acquired on firing solid fuels, including some of the more difficult ones, e.g., higher sulfur petcoke and bigger size AFRs, where operational issues such as build-ups, emissions, and production losses have been and are being minimized. Switching to gas firing, however, requires readaptation of combustion and process guidelines for a fuel which, although in principal, is easier to burn, but has relatively lower radiative heat transfer and sharper burning characteristics than coal. As such, the plants, which have switched to NG firing, have observed inconsistent trends in production, energy, and emission performance, mainly due to the lack of sufficient information on combustion/process interactions of the two fuel types required for cost-effective optimization. An NG flame ignites earlier, releases intense heat but lacks dissipation of heat as compared with a solid fuel flame, thereby requires plant specific adjustments. This paper presents actual results of NG firing trials at selected cement plants along with mineral interactive computational fluid dynamics (MI-CFD) predictions, subsequent to validation from the plant data, on four kiln and four calciners. Recommendations are also made to improve and optimize NG firing by taking into considerations of the combustion and mineral interactions.",10.1109/TIA.2015.2504554,2016,,"FROM COAL TO NATURAL GAS: ITS IMPACT ON KILN PRODUCTION, CLINKER QUALITY, AND EMISSIONS",
548,17361,IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS,journal,19399367,"1,190",Q1,195,680,1970,19879,10265,1963,"4,98","29,23",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1970-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Industrial and Manufacturing Engineering (Q1),"25,984",3.654,0.02947,"Electrical plug loads and appliances have evolved over time to provide sophisticated functions to occupants in a building, and they account for a big share of building's energy consumption. Despite their evolution, they are still unmanageable in commercial and industrial buildings, unlike lighting or air conditioning that are fixed infrastructures managed by an intelligent software layer, such as a building management system. The qualities of heterogeneity, numerosity, spatial irregularity, and displaceability have impeded efficient management of plug loads, unless they are appropriately identified in real time. Decades of efforts in both intrusive and nonintrusive load monitoring have not yielded any sufficiently reliable universal mechanism to identify plug loads. In this article, a practical method of uniquely identifying plug loads using a novel socket cyber-physical system is proposed. This socket/receptacle can access the metadata and operational data of plug loads in an automated fashion, thus yielding a live digital profile of plug loads connected to sockets. Based on acquired intelligence, a supervisory control system can contextually identify the plug loads to provide several digitalized services. Various benefits and use cases of the proposed smart cyber-physical system are explained, inclusive of improvement in operational energy efficiency of plug loads.",10.1109/TIA.2020.3016621,2020,,CONTEXT-AWARE PLUG-LOAD IDENTIFICATION TOWARD ENHANCED ENERGY EFFICIENCY IN THE BUILT ENVIRONMENT,
549,17361,IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS,journal,19399367,"1,190",Q1,195,680,1970,19879,10265,1963,"4,98","29,23",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1970-2020,Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Industrial and Manufacturing Engineering (Q1),"25,984",3.654,0.02947,"The power systems are transitioning to renewables. The power system infrastructure digitalization is the next stage in this evolution. A digitalized future distribution network (DN) has an opportunity to evolve into real-time analysis based on a huge volume of data. Such real-time analysis will be feasible through the integration of the theoretical background of fault analysis and machine learning techniques. Fault location is one of the major issues to improve reliability indices. The voltage sags characterization is used to locate faults in the DN. This article presents a methodology to characterize voltage sags using fault analysis and deep convolutional neural networks. The voltage divider model allows the characterization and the discrete wavelet transform is used in signal processing. The machine learning and deep learning models used allow estimating the sag magnitude, fault location, phases involved, duration, and impact of distributed generation (DG) in each event. The IEEE 13-node test feeder including DG was used to validate the effectiveness of the proposed methodology. This paper provides a way to handle a Big Data stream in the DN control center and to efficiently locate faults in several operational scenarios.",10.1109/TIA.2022.3162569,2022,,VOLTAGE SAGS CHARACTERIZATION USING FAULT ANALYSIS AND DEEP CONVOLUTIONAL NEURAL NETWORKS,
550,15057,ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS,journal,15674223,"1,184",Q1,74,108,188,6016,1347,188,"7,27","55,70",Netherlands,Western Europe,Elsevier,2002-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Management of Technology and Innovation (Q1); Marketing (Q1),"4,026",6.014,0.00318,"Big data has increasingly appeared as a frontier of opportunity in enhancing firm performance. However, it still is in early stages of introduction and many enterprises are still un-decisive in its adoption. The aim of this study is to propose a theoretical model based on integration of Human-Organization-Technology fit and Technology-Organization-Environment frameworks to identify the key factors affecting big data adoption and its consequent impact on the firm performance. The significant factors are gained from the literature and the research model is developed. Data was collected from top managers and/or owners of SMEs hotels in Malaysia using online survey questionnaire. Structural Equation Modelling (SEM) is used to assess the developed model and Adaptive Neuro-Fuzzy Inference Systems (ANFIS) technique is used to prioritize adoption factors based on their importance levels. The results showed that relative advantage, management support, IT expertise, and external pressure are the most important factors in the technological, organizational, human, and environmental dimensions. The results further revealed that technology is the most important influential dimension. The outcomes of this study can assist the policy makers, businesses and governments to make well-informed decisions in adopting big data.",https://doi.org/10.1016/j.elerap.2019.100921,2020,Elaheh Yadegaridehkordi and Mehrbakhsh Nilashi and Liyana Shuib and Mohd {Hairul Nizam Bin Md Nasir} and Shahla Asadi and Sarminah Samad and Nor {Fatimah Awang},THE IMPACT OF BIG DATA ON FIRM PERFORMANCE IN HOTEL INDUSTRY,article
551,12332,SAFETY SCIENCE,journal,09257535,"1,178",Q1,111,451,1047,26276,5909,1020,"5,49","58,26",Netherlands,Western Europe,Elsevier,1991-2020,"Public Health, Environmental and Occupational Health (Q1); Safety Research (Q1); Safety, Risk, Reliability and Quality (Q1)","17,184",4.877,0.01488,"Big data and analytics have shown promise in predicting safety incidents and identifying preventative measures directed towards specific risk variables. However, the safety industry is lagging in big data utilization due to various obstacles, which may include lack of data readiness (e.g., disparate databases, missing data, low validity) and personnel competencies. This paper provides a primer on the application of big data to safety. We then describe a safety analytics readiness assessment framework that highlights system requirements and the challenges that safety professionals may encounter in meeting these requirements. The proposed framework suggests that safety analytics readiness depends on (a) the quality of the data available, (b) organizational norms around data collection, scaling, and nomenclature, (c) foundational infrastructure, including technological platforms and skills required for data collection, storage, and analysis of health and safety metrics, and (d) measurement culture, or the emergent social patterns between employees, data acquisition, and analytic processes. A safety-analytics readiness assessment can assist organizations with understanding current capabilities so measurement systems can be matured to accommodate more advanced analytics for the ultimate purpose of improving decisions that mitigate injury and incidents.",https://doi.org/10.1016/j.ssci.2021.105569,2022,Maira E. Ezerins and Timothy D. Ludwig and Tara O'Neil and Anne M. Foreman and Yalçın Açıkgöz,ADVANCING SAFETY ANALYTICS: A DIAGNOSTIC FRAMEWORK FOR ASSESSING SYSTEM READINESS WITHIN OCCUPATIONAL SAFETY AND HEALTH,article
552,12332,SAFETY SCIENCE,journal,09257535,"1,178",Q1,111,451,1047,26276,5909,1020,"5,49","58,26",Netherlands,Western Europe,Elsevier,1991-2020,"Public Health, Environmental and Occupational Health (Q1); Safety Research (Q1); Safety, Risk, Reliability and Quality (Q1)","17,184",4.877,0.01488,"The paper at hand motivates, proposes, demonstrates, and evaluates a novel systematic approach to discovering causal dependencies between events encoded in large arrays of data, called causality mining. The approach has emerged in the discussions with our project partner, an Australian public energy company. It was successfully evaluated in a case study with the project partner to extract valuable, and otherwise unknown, information on the causal dependencies between observations reported by the company’s employees as part of the organizational health and safety management practices and incidents that had occurred at the organization’s sites. The dependencies were derived based on the notion of proximity of the observations and incidents. The setup and results of the evaluation are reported in this paper. The new approach and the delivered insights aim at improving the overall health and safety culture of the project partner practices, as they can be applied to caution and, thus, prevent future incidents.",https://doi.org/10.1016/j.ssci.2019.04.045,2019,Artem Polyvyanyy and Anastasiia Pika and Moe T. Wynn and Arthur H.M. {ter Hofstede},A SYSTEMATIC APPROACH FOR DISCOVERING CAUSAL DEPENDENCIES BETWEEN OBSERVATIONS AND INCIDENTS IN THE HEALTH AND SAFETY DOMAIN,article
553,12332,SAFETY SCIENCE,journal,09257535,"1,178",Q1,111,451,1047,26276,5909,1020,"5,49","58,26",Netherlands,Western Europe,Elsevier,1991-2020,"Public Health, Environmental and Occupational Health (Q1); Safety Research (Q1); Safety, Risk, Reliability and Quality (Q1)","17,184",4.877,0.01488,"It is clear that big data has numerous potential impacts in many fields. However, few papers discussed its applications in the field of safety science research. Additionally, there exist many problems that cannot be ignored when big data is applied to safety science, most outstanding of which is lack of universal supporting theory that guides how to apply big data to safety science research like methods, principles and approaches, etc. In other terms, it is not enough for big data to be viewed asa strong enabler for safety science applications mainly due to lack of universal and basic theory from the perspective of safety science. Considering the above analyzes, the two key objectives of this paper are: (1) to propose the connotation of safety big data (SBD) and its applying rules, methods and principles, and (2) to put forward some application prospects and challenges of big data to safety science research seen from theoretical research. First, by comparing SBD and traditional safety small data (SSD) from four aspects including theoretical research, typical research method, specific analysis method and processing mode, this paper puts forward the definition and connotation of SBD. Subsequently this paper further summarizes and extracts the application rules and methods of SBD. And then nine principles of SBD are explored and their relationship and application are addressed from the view of theory architecture and working framework in data processing flow. At last, this paper also discusses the potential applications and some hot issues of SBD. Overall, this paper will play an essential role in supporting the application of SBD. In addition, it will fill in the theory gaps in the field of SBD beyond traditional safety statistics, and further enriches the contents of safety science.",https://doi.org/10.1016/j.ssci.2017.08.012,2018,Qiumei Ouyang and Chao Wu and Lang Huang,"METHODOLOGIES, PRINCIPLES AND PROSPECTS OF APPLYING BIG DATA IN SAFETY SCIENCE RESEARCH",article
554,12332,SAFETY SCIENCE,journal,09257535,"1,178",Q1,111,451,1047,26276,5909,1020,"5,49","58,26",Netherlands,Western Europe,Elsevier,1991-2020,"Public Health, Environmental and Occupational Health (Q1); Safety Research (Q1); Safety, Risk, Reliability and Quality (Q1)","17,184",4.877,0.01488,"Safety data and information are the most valuable assets for organizations’ safety decision-making (SDM), especially in the era of big data (BD). In this study, a conceptual framework for SDM based on BD, known as BD-driven SDM, was developed and its detailed structure and elements as well as strategies were presented. Other theoretical and practical contributions include: (a) the description of the meta-process and interdisciplinary research area of BD-driven SDM, (b) the design of six types of general analytics and five types of special analytics for SBD mining according to different requirements of safety management applications, (c) the analysis of influencing factors of BD-driven SDM, and (d) the discussion of advantages and limitations in this research as well as suggestions for future research. The results obtained from this study are of important implications for research and practice on BD-driven SDM.",https://doi.org/10.1016/j.ssci.2018.05.012,2018,Lang Huang and Chao Wu and Bing Wang and Qiumei Ouyang,BIG-DATA-DRIVEN SAFETY DECISION-MAKING: A CONCEPTUAL FRAMEWORK AND ITS INFLUENCING FACTORS,article
555,12469,ORTHOPEDIC CLINICS OF NORTH AMERICA,journal,00305898,"1,177",Q1,86,61,186,2288,437,153,"2,01","37,51",United Kingdom,Western Europe,W.B. Saunders Ltd,1970-2020,Orthopedics and Sports Medicine (Q1),"3,693",2.472,0.00273,,https://doi.org/10.1016/j.ocl.2016.05.009,2016,Steven H. Shaha and Zain Sayeed and Afshin A. Anoushiravani and Mouhanad M. El-Othmani and Khaled J. Saleh,"BIG DATA, BIG PROBLEMS: INCORPORATING MISSION, VALUES, AND CULTURE IN PROVIDER AFFILIATIONS",article
556,18174,CONTROL ENGINEERING PRACTICE,journal,09670661,"1,175",Q1,119,196,615,8010,2779,611,"4,42","40,87",United Kingdom,Western Europe,Elsevier Ltd.,1993-2020,Applied Mathematics (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1),"8,368",3.475,0.00717,"In this paper, a novel robust Bayesian network is proposed for process modeling with low-quality data. Since unreliable data can cause model parameters to deviate from the real distributions and make network structures unable to characterize the true causalities, data quality feature is utilized to improve the process modeling and monitoring performance. With a predetermined trustworthy center, the data quality measurement results can be evaluated through an exponential function with Mahalanobis distances. The conventional Bayesian network learning algorithms including structure learning and parameter learning are modified by the quality feature in a weighting form, intending to extract useful information and make a reasonable model. The effectiveness of the proposed method is demonstrated through TE benchmark process and a real industrial process.",https://doi.org/10.1016/j.conengprac.2020.104344,2020,Guangjie Chen and Zhiqiang Ge,ROBUST BAYESIAN NETWORKS FOR LOW-QUALITY DATA MODELING AND PROCESS MONITORING APPLICATIONS,article
557,13754,PROCESS SAFETY AND ENVIRONMENTAL PROTECTION,journal,09575820,"1,173",Q1,76,417,1079,20761,6888,1071,"6,41","49,79",United Kingdom,Western Europe,Institution of Chemical Engineers,1990-2021,"Chemical Engineering (miscellaneous) (Q1); Environmental Engineering (Q1); Safety, Risk, Reliability and Quality (Q1); Environmental Chemistry (Q2)","12,452",6.158,0.01335,"In the age of big data, intelligence, and Industry 4.0, intelligence plays an increasingly significant role in management or, more specifically, decision making; thus, it becomes a popular topic and is recognised as an important discipline. Hence, safety intelligence (SI) as a new safety concept and term was proposed. SI aims to transform raw safety data and information into meaningful and actionable information for safety management; it is considered an essential perspective for safety management in the era of Safety 4.0 (computational safety science—a new paradigm for safety science in the age of big data, intelligence, and Industry 4.0). However, thus far, no existing research provides a framework that comprehensively describes SI and guides the implementation of SI practices in organisations. To address this research gap and to provide a framework for SI and its practice in the context of safety management, based on a systematic and comprehensive explanation on SI from different perspectives, this study attempts to propose a theoretical framework for SI from a safety management perspective and then presents an SI practice model aimed at supporting safety management in organisations.",https://doi.org/10.1016/j.psep.2020.10.008,2021,Bing Wang,SAFETY INTELLIGENCE AS AN ESSENTIAL PERSPECTIVE FOR SAFETY MANAGEMENT IN THE ERA OF SAFETY 4.0: FROM A THEORETICAL TO A PRACTICAL FRAMEWORK,article
558,21100228018,INTERNATIONAL JOURNAL OF DISASTER RISK REDUCTION,journal,22124209,"1,161",Q1,45,562,856,35838,4363,844,"4,78","63,77",United Kingdom,Western Europe,Elsevier Ltd.,2012-2020,Geology (Q1); Geotechnical Engineering and Engineering Geology (Q1); Safety Research (Q1),"6,931",4.320,0.01003,"The effects of data governance (as a means to maximize big data value creation in fire risk management) performance on fire risk was analyzed based on multi-source statistical data of 105 cities in China from 2016 to 2018. Specifically, data governance was first quantified with ten detailed indicators, which were then selected for explaining urban fire risk through correlation analysis. Next, the sample cities were clustered in terms of major socio-economic characteristics, and then the effects of data governance were examined by constructing multivariate regression models for each city cluster with ordinary least squares (OLS). The results showed that the constructed regression models produced good interpretation of fire risk in different types of cities, with coefficient of determination (R2) in each model exceeding 0.65. Among the indicators, the development of infrastructures (e.g. data collection devices and data analysis platforms), the level of data use, and the updating of fire risk related data were proved to produce significant effects on the reduction of fire frequency and fire consequence. Moreover, the organizational maturity of data governance was proved to be helpful in reducing fire frequency. For the cities with large population, the cross-department sharing of high-value data was found to be another important determinant of urban fire frequency. In comparison with existing statistical models which interpreted fire risk with general social factors (with the highest R2 = 0.60), these new regression models presented a better statistical performance (with the average R2 = 0.72). These findings are expected to provide decision support for the local governments of China and other jurisdictions to facilitate big data projects in improving fire risk management.",https://doi.org/10.1016/j.ijdrr.2022.103138,2022,Zhao-Ge Liu and Xiang-Yang Li and Grunde Jomaas,EFFECTS OF GOVERNMENTAL DATA GOVERNANCE ON URBAN FIRE RISK: A CITY-WIDE ANALYSIS IN CHINA,article
559,12212,JOURNAL OF CRITICAL CARE,journal,08839441,"1,149",Q1,83,300,1095,9042,2889,847,"2,53","30,14",Netherlands,Western Europe,Elsevier BV,1986-2020,Critical Care and Intensive Care Medicine (Q1),"9,746",3.425,0.01662,"The digitalization of the Intensive Care Unit (ICU) led to an increasing amount of clinical data being collected at the bedside. The term “Big Data” can be used to refer to the analysis of these datasets that collect enormous amount of data of different origin and format. Complexity and variety define the value of Big Data. In fact, the retrospective analysis of these datasets allows to generate new knowledge, with consequent potential improvements in the clinical practice. Despite the promising start of Big Data analysis in medical research, which has seen a rising number of peer-reviewed articles, very limited applications have been used in ICU clinical practice. A close future effort should be done to validate the knowledge extracted from clinical Big Data and implement it in the clinic. In this article, we provide an introduction to Big Data in the ICU, from data collection and data analysis, to the main successful examples of prognostic, predictive and classification models based on ICU data. In addition, we focus on the main challenges that these models face to reach the bedside and effectively improve ICU care.",https://doi.org/10.1016/j.jcrc.2020.09.002,2020,Giorgia Carra and Jorge I.F. Salluh and Fernando José {da Silva Ramos} and Geert Meyfroidt,DATA-DRIVEN ICU MANAGEMENT: USING BIG DATA AND ALGORITHMS TO IMPROVE OUTCOMES,article
560,12212,JOURNAL OF CRITICAL CARE,journal,08839441,"1,149",Q1,83,300,1095,9042,2889,847,"2,53","30,14",Netherlands,Western Europe,Elsevier BV,1986-2020,Critical Care and Intensive Care Medicine (Q1),"9,746",3.425,0.01662,,https://doi.org/10.1016/j.jcrc.2019.09.005,2019,Walter Verbrugghe and Kirsten Colpaert,"THE ELECTRONIC MEDICAL RECORD: BIG DATA, LITTLE INFORMATION?",article
561,16318,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,journal,15582531,"1,148",Q1,200,389,929,14641,5464,915,"5,20","37,64",United States,Northern America,IEEE Computer Society,1963-2020,Biomedical Engineering (Q1),"27,406",4.538,0.01971,"Objective: Rapid advances of high-throughput technologies and wide adoption of electronic health records (EHRs) have led to fast accumulation of -omic and EHR data. These voluminous complex data contain abundant information for precision medicine, and big data analytics can extract such knowledge to improve the quality of healthcare. Methods: In this paper, we present -omic and EHR data characteristics, associated challenges, and data analytics including data preprocessing, mining, and modeling. Results: To demonstrate how big data analytics enables precision medicine, we provide two case studies, including identifying disease biomarkers from multi-omic data and incorporating -omic information into EHR. Conclusion: Big data analytics is able to address -omic and EHR data challenges for paradigm shift toward precision medicine. Significance: Big data analytics makes sense of -omic and EHR data to improve healthcare outcome. It has long lasting societal impact.",10.1109/TBME.2016.2573285,2017,,–OMIC AND ELECTRONIC HEALTH RECORD BIG DATA ANALYTICS FOR PRECISION MEDICINE,
562,16318,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,journal,15582531,"1,148",Q1,200,389,929,14641,5464,915,"5,20","37,64",United States,Northern America,IEEE Computer Society,1963-2020,Biomedical Engineering (Q1),"27,406",4.538,0.01971,"Recent developments in laser scanning microscopy have greatly extended its applicability in cancer imaging beyond the visualization of complex biology, and opened up the possibility of quantitative analysis of inherently dynamic biological processes. However, the physics of image acquisition intrinsically means that image quality is subject to a tradeoff between a number of imaging parameters, including resolution, signal-to-noise ratio, and acquisition speed. We address the problem of geometric distortion, in particular, jaggedness artefacts that are caused by the variable motion of the microscope laser, by using a combination of image processing techniques. Image restoration methods have already shown great potential for post-acquisition image analysis. The performance of our proposed image restoration technique was first quantitatively evaluated using phantom data with different textures, and then qualitatively assessed using in vivo biological imaging data. In both cases, the presented method, comprising a combination of image registration and filtering, is demonstrated to have substantial improvement over state-of-the-art microscopy acquisition methods.",10.1109/TBME.2019.2908345,2020,,IMAGE-BASED ARTEFACT REMOVAL IN LASER SCANNING MICROSCOPY,
563,16318,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,journal,15582531,"1,148",Q1,200,389,929,14641,5464,915,"5,20","37,64",United States,Northern America,IEEE Computer Society,1963-2020,Biomedical Engineering (Q1),"27,406",4.538,0.01971,"Objective: To facilitate the analysis and diagnosis of X-ray coronary angiography in interventional surgery, it is necessary to extract vessel from X-ray coronary angiography. However, vessel images of angiography suffer from low quality with large artefacts, which challenges the existing vascular technology. Methods: In this paper, we propose a ávessel framework to detect vessels and segment vessels in angiographic vessel data. In this framework, we develop a new matrix decomposition model with gradient sparse in the tensor representation. Then, the energy function with the input of the hierarchical vessel is used in vessel detection and vessel segmentation. Results: Through experiments conducted on angiographic data, we have demonstrated the good performance of the proposed method in removing background structure. Conclusion: We evaluated our method for vessel detection and segmentation in different clinical settings, including LAO/RAO with cranial and caudal angulation, and showed its competitive results compared with eight state-of-the-art methods in terms of extensive qualitative and quantitative evaluation. Significance: Our method can remove a large number of background artefacts and obtain a better vascular structure, which has contributed to the clinical diagnosis of coronary artery diseases.",10.1109/TBME.2019.2936460,2020,,VESSEL SEGMENTATION OF X-RAY CORONARY ANGIOGRAPHIC IMAGE SEQUENCE,
564,16318,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,journal,15582531,"1,148",Q1,200,389,929,14641,5464,915,"5,20","37,64",United States,Northern America,IEEE Computer Society,1963-2020,Biomedical Engineering (Q1),"27,406",4.538,0.01971,"Background: Despite recent significant progress in the development of automatic sleep staging methods, building a good model still remains a big challenge for sleep studies with a small cohort due to the data-variability and data-inefficiency issues. This work presents a deep transfer learning approach to overcome these issues and enable transferring knowledge from a large dataset to a small cohort for automatic sleep staging. Methods: We start from a generic end-to-end deep learning framework for sequence-to-sequence sleep staging and derive two networks as the means for transfer learning. The networks are first trained in the source domain (i.e. the large database). The pretrained networks are then finetuned in the target domain (i.e. the small cohort) to complete knowledge transfer. We employ the Montreal Archive of Sleep Studies (MASS) database consisting of 200 subjects as the source domain and study deep transfer learning on three different target domains: the Sleep Cassette subset and the Sleep Telemetry subset of the Sleep-EDF Expanded database, and the Surrey-cEEGrid database. The target domains are purposely adopted to cover different degrees of data mismatch to the source domains. Results: Our experimental results show significant performance improvement on automatic sleep staging on the target domains achieved with the proposed deep transfer learning approach. Conclusions: These results suggest the efficacy of the proposed approach in addressing the above-mentioned data-variability and data-inefficiency issues. Significance: As a consequence, it would enable one to improve the quality of automatic sleep staging models when the amount of data is relatively small.11The source code and the pretrained models are published at https://github.com/pquochuy/sleep_transfer_learning.",10.1109/TBME.2020.3020381,2021,,TOWARDS MORE ACCURATE AUTOMATIC SLEEP STAGING VIA DEEP TRANSFER LEARNING,
565,16318,IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING,journal,15582531,"1,148",Q1,200,389,929,14641,5464,915,"5,20","37,64",United States,Northern America,IEEE Computer Society,1963-2020,Biomedical Engineering (Q1),"27,406",4.538,0.01971,"Objective: Stimulated Raman projection tomography (SRPT), a recently developed label-free volumetric chemical imaging technology, has been reported to quantitatively reconstruct the distribution of chemicals in a three-dimensional (3D) complex system. The current image reconstruction scheme used in SRPT is based on a filtered back projection (FBP) algorithm that requires at least 180 angular-dependent projections to rebuild a reasonable SRPT image, resulting in a long total acquisition time. This is a big limitation for longitudinal studies on live systems. Methods: We present a sparse-view data-based sparse reconstruction scheme, in which sparsely sampled projections at 180 degrees were used to reconstruct the volumetric information. In the scheme, the simultaneous algebra reconstruction technique (SART), combined with total variation regularization, was used for iterative reconstruction. To better describe the projection process, a pixel vertex driven model (PVDM) was developed to act as projectors, whose performance was compared with those of the distance driven model (DDM). Results: We evaluated our scheme with numerical simulations and validated it for SRPT by mapping lipid contents in adipose cells. Simulation results showed that the PVDM performed better than the DDM in the case of using sparse-view data. Our scheme could maintain the quality of the reconstructed images even when the projection number was reduced to 15. The cell-based experimental results demonstrated that the proposed scheme can improve the imaging speed of the current FBP-based SRPT scheme by a factor of 9-12 without sacrificing discernible imaging details. Conclusion: Our proposed scheme significantly reduces the total acquisition time required for SRPT at a speed of one order of magnitude faster than the currently used scheme. This significant improvement in imaging speed would potentially promote the applicability of SRPT for imaging living organisms.",10.1109/TBME.2019.2935301,2020,,ACCELERATED STIMULATED RAMAN PROJECTION TOMOGRAPHY BY SPARSE RECONSTRUCTION FROM SPARSE-VIEW DATA,
566,29805,ISA TRANSACTIONS,journal,00190578,"1,147",Q1,79,559,892,22562,5669,884,"6,08","40,36",United States,Northern America,"ISA - Instrumentation, Systems, and Automation Society",1968-2020,Applied Mathematics (Q1); Computer Science Applications (Q1); Control and Systems Engineering (Q1); Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"10,483",5.468,0.01283,"The data of the power Internet of Things (IOT) system is transferred from the IaaS layer to the SaaS layer. The general data preprocessing method mainly solves the problem of big data anomalies and missing at the PaaS layer, but it still lacks the ability to judge the high error data that meets the timing characteristics, making it difficult to deal with heterogeneous power inconsistent issues. This paper shows this phenomenon and its physical mechanism, showing the difficulty of building a quantitative model forward. A data-driven method is needed to form a hybrid model to correct the data. The research object is the electricity meter data on both sides of a commercial building transformer, which comes from different power IOT systems. The low-voltage side was revised based on the high-voltage side. Compared with the correction method based on purely using neural networks, the combined method, Linear Regression (LS) + Differential Evolution (DE) + Extreme Learning Machine (ELM), further reduces the deviation from approximately 4% to 1%.",https://doi.org/10.1016/j.isatra.2021.01.056,2021,Haoyu Jiang and Kai Chen and Quanbo Ge and Jinqiang Xu and Yingying Fu and Chunxi Li,DATA CONSISTENCY METHOD OF HETEROGENEOUS POWER IOT BASED ON HYBRID MODEL,article
567,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"In the Internet of Things (IoT), data gathered from a global-scale deployment of smart-things, are the base for making intelligent decisions and providing services. If data are of poor quality, decisions are likely to be unsound. Data quality (DQ) is crucial to gain user engagement and acceptance of the IoT paradigm and services. This paper aims at enhancing DQ in IoT by providing an overview of its state-of-the-art. Data properties and their new lifecycle in IoT are surveyed. The concept of DQ is defined and a set of generic and domain-specific DQ dimensions, fit for use in assessing IoT's DQ, are selected. IoT-related factors endangering the DQ and their impact on various DQ dimensions and on the overall DQ are exhaustively analyzed. DQ problems manifestations are discussed and their symptoms identified. Data outliers, as a major DQ problem manifestation, their underlying knowledge and their impact in the context of IoT and its applications are studied. Techniques for enhancing DQ are presented with a special focus on data cleaning techniques which are reviewed and compared using an extended taxonomy to outline their characteristics and their fitness for use for IoT. Finally, open challenges and possible future research directions are discussed.",https://doi.org/10.1016/j.jnca.2016.08.002,2016,Aimad Karkouch and Hajar Mousannif and Hassan {Al Moatassime} and Thomas Noel,DATA QUALITY IN INTERNET OF THINGS: A STATE-OF-THE-ART SURVEY,article
568,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"Over the last years, big data has emerged as a new paradigm for the processing and analysis of massive volumes of data. Big data processing has been combined with service and cloud computing, leading to a new class of services called “Big Services”. In this new model, services can be seen as an abstract layer that hides the complexity of the processed big data. To meet users' complex and heterogeneous needs in the era of big data, service reuse is a natural and efficient means that helps orchestrating available services' operations, to provide customer on-demand big services. However different from traditional Web service composition, composing big services refers to the reuse of, not only existing high-quality services, but also high-quality data sources, while taking into account their security constraints (e.g., data provenance, threat level and data leakage). Moreover, composing heterogeneous and large-scale data-centric services faces several challenges, apart from security risks, such as the big services' high execution time and the incompatibility between providers' policies across multiple domains and clouds. Aiming to solve the above issues, we propose a scalable approach for big service composition, which considers not only the quality of reused services (QoS), but also the quality of their consumed data sources (QoD). Since the correct representation of big services requirements is the first step towards an effective composition, we first propose a quality model for big services and we quantify the data breaches using L-Severity metrics. Then to facilitate processing and mining big services' related information during composition, we exploit the strong mathematical foundation of fuzzy Relational Concept Analysis (fuzzy RCA) to build the big services' repository as a lattice family. We also used fuzzy RCA to cluster services and data sources based on various criteria, including their quality levels, their domains, and the relationships between them. Finally, we define algorithms that parse the lattice family to select and compose high-quality and secure big services in a parallel fashion. The proposed method, which is implemented on top of Spark big data framework, is compared with two existing approaches, and experimental studies proved the effectiveness of our big service composition approach in terms of QoD-aware composition, scalability, and security breaches.",https://doi.org/10.1016/j.jnca.2020.102732,2020,Mokhtar Sellami and Haithem Mezni and Mohand Said Hacid,ON THE USE OF BIG DATA FRAMEWORKS FOR BIG SERVICE COMPOSITION,article
569,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"Big Data Cyber Security Analytics (BDCA) systems use big data technologies (e.g., Apache Spark) to collect, store, and analyse a large volume of security event data for detecting cyber-attacks. The volume of digital data in general and security event data in specific is increasing exponentially. The velocity with which security event data is generated and fed into a BDCA system is unpredictable. Therefore, a BDCA system should be highly scalable to deal with the unpredictable increase/decrease in the velocity of security event data. However, there has been little effort to investigate the scalability of BDCA systems to identify and exploit the sources of scalability improvement. In this paper, we first investigate the scalability of a Spark-based BDCA system with default Spark settings. We then identify Spark configuration parameters (e.g., execution memory) that can significantly impact the scalability of a BDCA system. Based on the identified parameters, we finally propose a parameter-driven adaptation approach, SCALER, for optimizing a system's scalability. We have conducted a set of experiments by implementing a Spark-based BDCA system on a large-scale OpenStack cluster. We ran our experiments with four security datasets. We have found that (i) a BDCA system with default settings of Spark configuration parameters deviates from ideal scalability by 59.5% (ii) 9 out of 11 studied Spark configuration parameters significantly impact scalability and (iii) SCALER improves the BDCA system's scalability by 20.8% compared to the scalability with default Spark parameter setting. The findings of our study highlight the importance of exploring the parameter space of the underlying big data framework (e.g., Apache Spark) for scalable cyber security analytics.",https://doi.org/10.1016/j.jnca.2021.103294,2022,Faheem Ullah and M. Ali Babar,ON THE SCALABILITY OF BIG DATA CYBER SECURITY ANALYTICS SYSTEMS,article
570,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"The crowd's power, combined with the sensing capabilities of smart mobile de-vices, has resulted in the emergence of a revolutionary data acquisition paradigm known as Mobile Crowdsensing. In exchange for rewards, mobile users collect and share location-specific data values. However, most existing crowdsensing systems built on traditional centralized architectures are highly prone to attacks, intrusions, single point of failure, manipulations, and low reliability. Recently, decentralized blockchain technologies are being applied in mobile crowdsensing systems to ensure workers' privacy, data privacy, and the quality of sensed data at a low service fee. By leveraging blockchain technology, this paper inherits the advantages of the public blockchain without the need for any trusted third-parties. We propose a smart contract-based privacy-preserving data aggregation and quality assessment protocol to infer reliable aggregated results and estimate data quality, wherein, we design a fair quality-driven incentive mechanism to distribute rewards based on the data quality. The protocol ensures a secure, cost-optimal, and reliable aggregation and estimation of the sensed data quality on the public blockchain without disclosing the sensed data's and participants' privacy. We adopt Interplanetary File Systems to offset the blockchain's expensive storage costs. Experiments were conducted using real-world datasets which were implemented on a full-stack on-chain and off-chain decentralized application on the Ethereum blockchain. The experimental results demonstrate our design is highly efficient in achieving privacy-preserving data aggregation and significantly reduces on-chain computation costs.",https://doi.org/10.1016/j.jnca.2022.103483,2022,Ruiyun Yu and Ann Move Oguti and Dennis Reagan Ochora and Shuchen Li,TOWARDS A PRIVACY-PRESERVING SMART CONTRACT-BASED DATA AGGREGATION AND QUALITY-DRIVEN INCENTIVE MECHANISM FOR MOBILE CROWDSENSING,article
571,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"There is a rapid increase in the adoption of emerging technologies like the Internet of Things (IoT), Unmanned Aerial Vehicles (UAV), Internet of Underground Things (IoUT), Data analytics in the agriculture domain to meet the increased food demand to cater to the increasing population. Agriculture 4.0 is set to revolutionize agriculture productivity by using Precision Agriculture (PA), IoT, UAVs, IoUT, and other technologies to increase agriculture produce for growing demographics while addressing various farm-related issues. This survey provides a comprehensive overview of how multiple technologies such as IoT, UAVs, IoUT, Big Data Analytics, Deep Learning Techniques, and Machine Learning methods can be used to manage various farm-related operations. For each of these technologies, a detailed review is done on how the technology is being used in Agriculture 4.0. These discussions include an overview of relevant technologies, their use cases, existing case studies, and research works that demonstrate the use of these technologies in Agriculture 4.0. This paper also highlights the various future research gaps in the adoption of these technologies in Agriculture 4.0.",https://doi.org/10.1016/j.jnca.2021.103107,2021,Meghna Raj and Shashank Gupta and Vinay Chamola and Anubhav Elhence and Tanya Garg and Mohammed Atiquzzaman and Dusit Niyato,A SURVEY ON THE ROLE OF INTERNET OF THINGS FOR ADOPTING AND PROMOTING AGRICULTURE 4.0,article
572,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"The rapid growth of emerging applications and the evolution of cloud computing technologies have significantly enhanced the capability to generate vast amounts of data. Thus, it has become a great challenge in this big data era to manage such voluminous amount of data. The recent advancements in big data techniques and technologies have enabled many enterprises to handle big data efficiently. However, these advances in techniques and technologies have not yet been studied in detail and a comprehensive survey of this domain is still lacking. With focus on big data management, this survey aims to investigate feasible techniques of managing big data by emphasizing on storage, pre-processing, processing and security. Moreover, the critical aspects of these techniques are analyzed by devising a taxonomy in order to identify the problems and proposals made to alleviate these problems. Furthermore, big data management techniques are also summarized. Finally, several future research directions are presented.",https://doi.org/10.1016/j.jnca.2016.04.008,2016,Aisha Siddiqa and Ibrahim Abaker Targio Hashem and Ibrar Yaqoob and Mohsen Marjani and Shahabuddin Shamshirband and Abdullah Gani and Fariza Nasaruddin,A SURVEY OF BIG DATA MANAGEMENT: TAXONOMY AND STATE-OF-THE-ART,article
573,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"Affective computing is an emerging multidisciplinary research field that is increasingly drawing the attention of researchers and practitioners in various fields, including artificial intelligence, natural language processing, cognitive and social sciences. Research in affective computing includes areas such as sentiment, emotion, and opinion modelling. The internet is an excellent source of data required for sentiment analysis, such as customer reviews of products, social media, forums, blogs, etc. Most of these data, called big data, are unstructured and unorganized. Hence there is a strong demand for developing suitable data processing techniques to process these rich and valuable data to produce useful information. Early surveys on sentiment and emotion recognition in the literature have been limited to discussions using text, audio, and visual modalities. So far, to the author's knowledge, a comprehensive survey combining physiological modalities with these other modalities for affective computing has yet to be reported. The objective of this paper is to fill the gap in this surveyed area. The usage of physiological modalities for affective computing brings several benefits in that the signals can be used in different environmental conditions, more robust systems can be constructed in combination with other modalities, and it has increased anti-spoofing characteristics. The paper includes extensive reviews on different frameworks and categories for state-of-the-art techniques, critical analysis of their performances, and discussions of their applications, trends and future directions to serve as guidelines for readers towards this emerging research area.",https://doi.org/10.1016/j.jnca.2019.102447,2020,Nusrat J. Shoumy and Li-Minn Ang and Kah Phooi Seng and D.M.Motiur Rahaman and Tanveer Zia,"MULTIMODAL BIG DATA AFFECTIVE ANALYTICS: A COMPREHENSIVE SURVEY USING TEXT, AUDIO, VISUAL AND PHYSIOLOGICAL SIGNALS",article
574,27277,JOURNAL OF NETWORK AND COMPUTER APPLICATIONS,journal,10848045,"1,145",Q1,105,187,713,13916,5998,701,"8,17","74,42",United States,Northern America,Academic Press Inc.,1996-2020,Computer Networks and Communications (Q1); Computer Science Applications (Q1); Hardware and Architecture (Q1),"9,700",6.281,0.0115,"With an exponential increase in the provisioning of multimedia devices over the Internet of Things (IoT), a significant amount of multimedia data (also referred to as multimedia big data – MMBD) is being generated. Current research and development activities focus on scalar sensor data based IoT or general MMBD and overlook the complexity of facilitating MMBD over IoT. This paper examines the unique nature and complexity of MMBD computing for IoT applications and develops a comprehensive taxonomy for MMBD abstracted into a novel process model reflecting MMBD over IoT. This process model addresses a number of research challenges associated with MMBD, such as scalability, accessibility, reliability, heterogeneity, and Quality of Service (QoS) requirements. A case study is presented to demonstrate the process model.",https://doi.org/10.1016/j.jnca.2018.09.014,2018,Aparna Kumari and Sudeep Tanwar and Sudhanshu Tyagi and Neeraj Kumar and Michele Maasberg and Kim-Kwang Raymond Choo,MULTIMEDIA BIG DATA COMPUTING AND INTERNET OF THINGS APPLICATIONS: A TAXONOMY AND PROCESS MODEL,article
575,23161,FOOD QUALITY AND PREFERENCE,journal,09503293,"1,135",Q1,120,227,558,12290,3000,548,"5,43","54,14",United Kingdom,Western Europe,Elsevier Ltd.,"1988-1991, 1993-2021",Food Science (Q1); Nutrition and Dietetics (Q1),"13,058",5.565,0.00829,"As sensory evaluation relies upon humans accurately communicating their sensory experience, the diverse and overlapping vocabulary of flavor descriptors remains a major challenge. The lexicon generation protocols used in methods like Descriptive Analysis are expensive and time-consuming, while the post-facto analyses of natural vocabulary in “quick and dirty” methods like Free Choice or Flash Profiling require considerable subjective decision-making on the part of the analyst. A potential alternative for producing lexicons and analyzing the sensory attributes of products in nonstandardized text can be found in Natural Language Processing (NLP). NLP tools allow for the analysis of larger volumes of free text with fewer subjective decisions. This paper describes the steps necessary to automatically collect, clean, and analyze existing product descriptions from the web. As a case study, online reviews of international whiskies from two prominent websites (2309 reviews from WhiskyCast and 4289 reviews from WhiskyAdvocate) were collected, preprocessed to only retain potentially-descriptive nouns, adjectives, and verbs, and then the final term list was grouped into a flavor wheel using Correspondence Analysis and Agglomerative Hierarchical Clustering. The wheel is compared to an existing Scotch flavor wheel. The ease of collecting nonstandardized descriptions of products and the improved speed of automated methods can facilitate collection of descriptive sensory data for products where no lexicon exists. This has the potential to speed up and standardize many of the bottlenecks in rapid descriptive methods and facilitate the collection and use of very large datasets of product descriptions.",https://doi.org/10.1016/j.foodqual.2020.103926,2020,Leah M. Hamilton and Jacob Lahne,FAST AND AUTOMATED SENSORY ANALYSIS: USING NATURAL LANGUAGE PROCESSING FOR DESCRIPTIVE LEXICON DEVELOPMENT,article
576,23689,INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,journal,13865056,"1,124",Q1,106,210,579,9073,3102,572,"4,82","43,20",Ireland,Western Europe,Elsevier Ireland Ltd,1996-2020,Health Informatics (Q1),"7,651",4.046,0.01044,"Background
Big data analytics promise insights into healthcare processes and management, improving outcomes while reducing costs. However, data quality is a major challenge for reliable results. Business process discovery techniques and an associated data model were used to develop data management tool, ICU-DaMa, for extracting variables essential for overseeing the quality of care in the intensive care unit (ICU).
Objective
To determine the feasibility of using ICU-DaMa to automatically extract variables for the minimum dataset and ICU quality indicators from the clinical information system (CIS).
Methods
The Wilcoxon signed-rank test and Fisher’s exact test were used to compare the values extracted from the CIS with ICU-DaMa for 25 variables from all patients attended in a polyvalent ICU during a two-month period against the gold standard of values manually extracted by two trained physicians. Discrepancies with the gold standard were classified into plausibility, conformance, and completeness errors.
Results
Data from 149 patients were included. Although there were no significant differences between the automatic method and the manual method, we detected differences in values for five variables, including one plausibility error and two conformance and completeness errors. Plausibility: 1) Sex, ICU-DaMa incorrectly classified one male patient as female (error generated by the Hospital’s Admissions Department). Conformance: 2) Reason for isolation, ICU-DaMa failed to detect a human error in which a professional misclassified a patient’s isolation. 3) Brain death, ICU-DaMa failed to detect another human error in which a professional likely entered two mutually exclusive values related to the death of the patient (brain death and controlled donation after circulatory death). Completeness: 4) Destination at ICU discharge, ICU-DaMa incorrectly classified two patients due to a professional failing to fill out the patient discharge form when thepatients died. 5) Length of continuous renal replacement therapy, data were missing for one patient because the CRRT device was not connected to the CIS.
Conclusions
Automatic generation of minimum dataset and ICU quality indicators using ICU-DaMa is feasible. The discrepancies were identified and can be corrected by improving CIS ergonomics, training healthcare professionals in the culture of the quality of information, and using tools for detecting and correcting data errors.",https://doi.org/10.1016/j.ijmedinf.2018.02.007,2018,Gonzalo Sirgo and Federico Esteban and Josep Gómez and Gerard Moreno and Alejandro Rodríguez and Lluis Blanch and Juan José Guardiola and Rafael Gracia and Lluis {De Haro} and María Bodí,VALIDATION OF THE ICU-DAMA TOOL FOR AUTOMATICALLY EXTRACTING VARIABLES FOR MINIMUM DATASET AND QUALITY INDICATORS: THE IMPORTANCE OF DATA QUALITY ASSESSMENT,article
577,23689,INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,journal,13865056,"1,124",Q1,106,210,579,9073,3102,572,"4,82","43,20",Ireland,Western Europe,Elsevier Ireland Ltd,1996-2020,Health Informatics (Q1),"7,651",4.046,0.01044,"Background
The application of Big Data analytics in healthcare has immense potential for improving the quality of care, reducing waste and error, and reducing the cost of care.
Purpose
This systematic review of literature aims to determine the scope of Big Data analytics in healthcare including its applications and challenges in its adoption in healthcare. It also intends to identify the strategies to overcome the challenges.
Data sources
A systematic search of the articles was carried out on five major scientific databases: ScienceDirect, PubMed, Emerald, IEEE Xplore and Taylor & Francis. The articles on Big Data analytics in healthcare published in English language literature from January 2013 to January 2018 were considered.
Study selection
Descriptive articles and usability studies of Big Data analytics in healthcare and medicine were selected.
Data extraction
Two reviewers independently extracted information on definitions of Big Data analytics; sources and applications of Big Data analytics in healthcare; challenges and strategies to overcome the challenges in healthcare.
Results
A total of 58 articles were selected as per the inclusion criteria and analyzed. The analyses of these articles found that: (1) researchers lack consensus about the operational definition of Big Data in healthcare; (2) Big Data in healthcare comes from the internal sources within the hospitals or clinics as well external sources including government, laboratories, pharma companies, data aggregators, medical journals etc.; (3) natural language processing (NLP) is most widely used Big Data analytical technique for healthcare and most of the processing tools used for analytics are based on Hadoop; (4) Big Data analytics finds its application for clinical decision support; optimization of clinical operations and reduction of cost of care (5) major challenge in adoption of Big Data analytics is non-availability of evidence of its practical benefits in healthcare.
Conclusion
This review study unveils that there is a paucity of information on evidence of real-world use of Big Data analytics in healthcare. This is because, the usability studies have considered only qualitative approach which describes potential benefits but does not take into account the quantitative study. Also, majority of the studies were from developed countries which brings out the need for promotion of research on Healthcare Big Data analytics in developing countries.",https://doi.org/10.1016/j.ijmedinf.2018.03.013,2018,Nishita Mehta and Anil Pandit,CONCURRENCE OF BIG DATA ANALYTICS AND HEALTHCARE: A SYSTEMATIC REVIEW,article
578,23689,INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS,journal,13865056,"1,124",Q1,106,210,579,9073,3102,572,"4,82","43,20",Ireland,Western Europe,Elsevier Ireland Ltd,1996-2020,Health Informatics (Q1),"7,651",4.046,0.01044,"Background
In recent years, the literature associated with healthcare big data has grown rapidly, but few studies have used bibliometrics and a visualization approach to conduct deep mining and reveal a panorama of the healthcare big data field.
Methods
To explore the foundational knowledge and research hotspots of big data research in the field of healthcare informatics, this study conducted a series of bibliometric analyses on the related literature, including papers’ production trends in the field and the trend of each paper’s co-author number, the distribution of core institutions and countries, the core literature distribution, the related information of prolific authors and innovation paths in the field, a keyword co-occurrence analysis, and research hotspots and trends for the future.
Results
By conducting a literature content analysis and structure analysis, we found the following: (a) In the early stage, researchers from the United States, the People’s Republic of China, the United Kingdom, and Germany made the most contributions to the literature associated with healthcare big data research and the innovation path in this field. (b) The innovation path in healthcare big data consists of three stages: the disease early detection, diagnosis, treatment, and prognosis phase, the life and health promotion phase, and the nursing phase. (c) Research hotspots are mainly concentrated in three dimensions: the disease dimension (e.g., epidemiology, breast cancer, obesity, and diabetes), the technical dimension (e.g., data mining and machine learning), and the health service dimension (e.g., customized service and elderly nursing).
Conclusion
This study will provide scholars in the healthcare informatics community with panoramic knowledge of healthcare big data research, as well as research hotspots and future research directions.",https://doi.org/10.1016/j.ijmedinf.2016.11.006,2017,Dongxiao Gu and Jingjing Li and Xingguo Li and Changyong Liang,VISUALIZING THE KNOWLEDGE STRUCTURE AND EVOLUTION OF BIG DATA RESEARCH IN HEALTHCARE INFORMATICS,article
579,23640,ADVANCED ENGINEERING INFORMATICS,journal,14740346,"1,107",Q1,81,146,295,8184,1973,289,"6,41","56,05",United Kingdom,Western Europe,Elsevier Ltd.,2002-2020,Artificial Intelligence (Q1); Information Systems (Q1),"4,432",5.603,0.00428,"The prospering Big data era is emerging in the power grid. Multiple world-wide studies are emphasizing the big data applications in the microgrid due to the huge amount of produced data. Big data analytics can impact the design and applications towards safer, better, more profitable, and effective power grid. This paper presents the recognition and challenges of the big data and the microgrid. The construction of big data analytics is introduced. The data sources, big data opportunities, and enhancement areas in the microgrid like stability improvement, asset management, renewable energy prediction, and decision-making support are summarized. Diverse case studies are presented including different planning, operation control, decision making, load forecasting, data attacks detection, and maintenance aspects of the microgrid. Finally, the open challenges of big data in the microgrid are discussed.",https://doi.org/10.1016/j.aei.2019.100945,2019,Karim Moharm,STATE OF THE ART IN BIG DATA APPLICATIONS IN MICROGRID: A REVIEW,article
580,23640,ADVANCED ENGINEERING INFORMATICS,journal,14740346,"1,107",Q1,81,146,295,8184,1973,289,"6,41","56,05",United Kingdom,Western Europe,Elsevier Ltd.,2002-2020,Artificial Intelligence (Q1); Information Systems (Q1),"4,432",5.603,0.00428,"Pipelines carrying energy products play vital roles in economic wealth and public safety, but incidents continue occurring. Condition assessment of pipelines is essential to identify anomalies timely. Advanced sensing technologies obtain informative data for condition assessment, while data analysis by human has limited efficiency, accuracy, and reliability. Advances in machine learning offer exciting opportunities for automated condition assessment with minimum human intervention. This paper reviews machine learning approaches to detect, classify, locate, and quantify pipeline anomalies based on intelligent interpretation of routine operation data, nondestructive testing data, and computer vision data. Statistics and uncertainties of performance metrics of machine learning approaches are discussed. An analysis on strengths, weaknesses, opportunities, and threats (SWOT) is performed. Guides for practitioners to perform automated pipeline condition assessment are recommended. This review provide insights into the machine learning approaches for automated pipeline condition assessment. The SWOT analysis will support decision making in the pipeline industry.",https://doi.org/10.1016/j.aei.2022.101687,2022,Yiming Liu and Yi Bao,REVIEW ON AUTOMATED CONDITION ASSESSMENT OF PIPELINES WITH MACHINE LEARNING,article
581,23640,ADVANCED ENGINEERING INFORMATICS,journal,14740346,"1,107",Q1,81,146,295,8184,1973,289,"6,41","56,05",United Kingdom,Western Europe,Elsevier Ltd.,2002-2020,Artificial Intelligence (Q1); Information Systems (Q1),"4,432",5.603,0.00428,"The aerospace sector is one of the many sectors in which large amounts of data are generated. Thanks to the evolution of technology, these data can be exploited in several ways to improve the operation and management of industrial processes. However, to achieve this goal, it is necessary to define architectures and data models that allow to manage and homogenise the heterogeneous data collected. In this paper, we present an Airport Digital Twin Reference Conceptualisation’s and data model based on FIWARE Generic Enablers and the Next Generation Service Interfaces-Linked Data standard. Concretely, we particularise the Airport Digital Twin to improve the efficiency of flight turnaround events. The architecture proposed is validated in the Aberdeen International Airport with the aim of reducing delays in commercial flights. The implementation includes an application that shows the real state of the airport, combining two-dimensional and three-dimensional virtual reality representations of the stands, and a mobile application that helps ground operators to schedule departure and arrival flights.",https://doi.org/10.1016/j.aei.2022.101723,2022,Javier Conde and Andres Munoz-Arcentales and Mario Romero and Javier Rojo and Joaquín Salvachúa and Gabriel Huecas and Álvaro Alonso,APPLYING DIGITAL TWINS FOR THE MANAGEMENT OF INFORMATION IN TURNAROUND EVENT OPERATIONS IN COMMERCIAL AIRPORTS,article
582,23640,ADVANCED ENGINEERING INFORMATICS,journal,14740346,"1,107",Q1,81,146,295,8184,1973,289,"6,41","56,05",United Kingdom,Western Europe,Elsevier Ltd.,2002-2020,Artificial Intelligence (Q1); Information Systems (Q1),"4,432",5.603,0.00428,"The ability to process large amounts of data and to extract useful insights from data has revolutionised society. This phenomenon—dubbed as Big Data—has applications for a wide assortment of industries, including the construction industry. The construction industry already deals with large volumes of heterogeneous data; which is expected to increase exponentially as technologies such as sensor networks and the Internet of Things are commoditised. In this paper, we present a detailed survey of the literature, investigating the application of Big Data techniques in the construction industry. We reviewed related works published in the databases of American Association of Civil Engineers (ASCE), Institute of Electrical and Electronics Engineers (IEEE), Association of Computing Machinery (ACM), and Elsevier Science Direct Digital Library. While the application of data analytics in the construction industry is not new, the adoption of Big Data technologies in this industry remains at a nascent stage and lags the broad uptake of these technologies in other fields. To the best of our knowledge, there is currently no comprehensive survey of Big Data techniques in the context of the construction industry. This paper fills the void and presents a wide-ranging interdisciplinary review of literature of fields such as statistics, data mining and warehousing, machine learning, and Big Data Analytics in the context of the construction industry. We discuss the current state of adoption of Big Data in the construction industry and discuss the future potential of such technologies across the multiple domain-specific sub-areas of the construction industry. We also propose open issues and directions for future work along with potential pitfalls associated with Big Data adoption in the industry.",https://doi.org/10.1016/j.aei.2016.07.001,2016,Muhammad Bilal and Lukumon O. Oyedele and Junaid Qadir and Kamran Munir and Saheed O. Ajayi and Olugbenga O. Akinade and Hakeem A. Owolabi and Hafiz A. Alaka and Maruf Pasha,"BIG DATA IN THE CONSTRUCTION INDUSTRY: A REVIEW OF PRESENT STATUS, OPPORTUNITIES, AND FUTURE TRENDS",article
583,14414,JOURNAL OF PROCESS CONTROL,journal,09591524,"1,102",Q1,114,136,413,5639,1820,408,"4,39","41,46",United Kingdom,Western Europe,Elsevier Ltd.,1991-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Modeling and Simulation (Q1),"7,446",3.666,0.00525,"With the ever increasing data collected from the process, the era of big data has arrived in the process industry. Therefore, the computational effort for data modeling and analytics in standalone modes has become increasingly demanding, particularly for large-scale processes. In this paper, a distributed parallel process modeling approach is presented based on a MapReduce framework for big data quality prediction. Firstly, the architecture for distributed parallel data modeling is formulated under the MapReduce framework. Secondly, a big data quality prediction scheme is developed based on the distributed parallel data modeling approach. As an example, the basic Semi-Supervised Probabilistic Principal Component Regression (SSPPCR) model is deployed to concurrently train a set of local models with split datasets. Meanwhile, Bayesian rule is utilized in a MapReduce way to integrate local models based on their predictive abilities. Two case studies demonstrate the effectiveness of the proposed method for big data quality prediction.",https://doi.org/10.1016/j.jprocont.2018.04.004,2018,Le Yao and Zhiqiang Ge,BIG DATA QUALITY PREDICTION IN THE PROCESS INDUSTRY: A DISTRIBUTED PARALLEL MODELING FRAMEWORK,article
584,14414,JOURNAL OF PROCESS CONTROL,journal,09591524,"1,102",Q1,114,136,413,5639,1820,408,"4,39","41,46",United Kingdom,Western Europe,Elsevier Ltd.,1991-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Modeling and Simulation (Q1),"7,446",3.666,0.00525,"In the big data era, small data problems still exist in many industrial sectors. Taking the high-value process industries as an example, a large number of materials and processing methods are often tested at the design stage. However, only a small amount of data can be collected for each material-process combination, which poses a serious challenge to data-driven process modeling. There is a great necessity to integrate the small data measured in different tasks and build the process model by sharing the information. In this work, a deep embedding neural network is proposed to extract the qualitative task information for process modeling. Specifically, an autoencoder is used to learn embeddings which are combined with the quantitative process conditions as the inputs of a feed-forward neural network to produce the final predictions. The feasibility, including interpretability and prediction accuracy, of the developed method is illustrated with an extrusion process.",https://doi.org/10.1016/j.jprocont.2022.04.018,2022,Haibin Wu and Yu-Han Lo and Le Zhou and Yuan Yao,PROCESS MODELING BY INTEGRATING QUANTITATIVE AND QUALITATIVE INFORMATION USING A DEEP EMBEDDING NETWORK AND ITS APPLICATION TO AN EXTRUSION PROCESS,article
585,14414,JOURNAL OF PROCESS CONTROL,journal,09591524,"1,102",Q1,114,136,413,5639,1820,408,"4,39","41,46",United Kingdom,Western Europe,Elsevier Ltd.,1991-2020,Computer Science Applications (Q1); Control and Systems Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Modeling and Simulation (Q1),"7,446",3.666,0.00525,"With ever-accelerating advancement of information, communication, sensing and characterization technologies, such as industrial Internet of Things (IoT) and high-throughput instruments, it is expected that the data generated from manufacturing will grow exponentially, generating so called ‘big data’. One of the focuses of smart manufacturing is to create manufacturing intelligence from real-time data to support accurate and timely decision-making. Therefore, big data analytics is expected to contribute significantly to the advancement of smart manufacturing. In this work, a roadmap of statistical process monitoring (SPM) is presented. Most recent developments in SPM are briefly reviewed and summarized. Specific challenges and potential solutions in handling manufacturing big data are discussed. We suggest that process characteristics or feature based SPM, instead of process variable based SPM, is a promising route for next generation SPM and could play a significant role in smart manufacturing. The advantages of feature based SPM are discussed to support the suggestion and future directions in SPM are discussed in the context of smart manufacturing.",https://doi.org/10.1016/j.jprocont.2017.06.012,2018,Q. Peter He and Jin Wang,STATISTICAL PROCESS MONITORING AS A BIG DATA ANALYTICS TOOL FOR SMART MANUFACTURING,article
586,13929,APPLIED ERGONOMICS,journal,00036870,"1,093",Q1,98,232,682,11314,2995,675,"4,17","48,77",United Kingdom,Western Europe,Elsevier Ltd.,1969-2021,"Engineering (miscellaneous) (Q1); Human Factors and Ergonomics (Q1); Physical Therapy, Sports Therapy and Rehabilitation (Q1); Safety, Risk, Reliability and Quality (Q1)","9,523",3.661,0.00851,"Human reliability analysis plays an important role in the safety assessment and management of rail operations. This paper discusses how the increasing availability of operational data can be used to develop an understanding of train driver reliability. The paper derives human reliability data for two driving tasks, stopping at red signals and controlling speed on approach to buffer stops. In the first of these cases, a tool has been developed that can estimate the number of times a signal is approached at red by trains on the Great Britain (GB) rail network. The tool has been developed using big data techniques and ideas, recording and analysing millions of pieces of data from live operational feeds to update and summarise statistics from thousands of signal locations in GB on a daily basis. The resulting driver reliability data are compared to similar analyses of other train driving tasks. This shows human reliability approaching the currently accepted limits of human performance. It also shows higher error rates amongst freight train drivers than passenger train drivers for these tasks. The paper highlights the importance of understanding the task specific performance limits if further improvements in human reliability are sought. It also provides a practical example of how big data could play an increasingly important role in system error management, whether from the perspective of understanding normal performance and the limits of performance for specific tasks or as the basis for dynamic safety indicators which, if not leading, could at least become closer to real time.",https://doi.org/10.1016/j.apergo.2022.103795,2022,Chris Harrison and Julian Stow and Xiaocheng Ge and Jonathan Gregory and Huw Gibson and Alice Monk,AT THE LIMIT? USING OPERATIONAL DATA TO ESTIMATE TRAIN DRIVER HUMAN RELIABILITY,article
587,16321,IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,journal,15580210,"1,093",Q1,140,326,742,14338,4245,730,"4,92","43,98",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2001-2020,Biomedical Engineering (Q1); Computer Science Applications (Q1); Internal Medicine (Q1); Medicine (miscellaneous) (Q1); Rehabilitation (Q1); Neuroscience (miscellaneous) (Q2),"9,404",3.802,0.00984,"Fall detection systems are designed in view to reduce the serious consequences of falls thanks to the early automatic detection that enables a timely medical intervention. The majority of the state-of-the-art fall detection systems are based on machine learning (ML). For training and performance evaluation, they use some datasets that are collected following predefined simulation protocols i.e. subjects are asked to perform different types of activities and to repeat them several times. Apart from the quality of simulating the activities, protocol-based data collection results in big differences between the distribution of the activities of daily living (ADLs) in these datasets in comparison with the actual distribution in real life. In this work, we first show the effects of this problem on the sensitivity of the ML algorithms and on the interpretability of the reported specificity. Then, we propose a reliable design of an ML-based fall detection system that aims at discriminating falls from the ambiguous ADLs. The latter are extracted from 400 days of recorded activities of older adults experiencing their daily life. The proposed system can be used in neck- and wrist-worn fall detectors. In addition, it is invariant to the rotation of the wearable device. The proposed system shows 100% of sensitivity while it generates an average of one false positive every 25 days for the neck-worn device and an average of one false positive every 3 days for the wrist-worn device.",10.1109/TNSRE.2021.3133616,2021,,A RELIABLE FALL DETECTION SYSTEM BASED ON ANALYZING THE PHYSICAL ACTIVITIES OF OLDER ADULTS LIVING IN LONG-TERM CARE FACILITIES,
588,21100400826,JOURNAL OF ENERGY STORAGE,journal,2352152X,"1,088",Q1,42,860,831,44642,5383,828,"6,87","51,91",Netherlands,Western Europe,Elsevier BV,2015-2020,"Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","7,765",6.583,0.00926,"The establishment of an accurate battery model is of great significance to improve the reliability of electric vehicles (EVs). However, the battery is a complex electrochemical system with hardly observable and simulatable internal chemical reactions, and it is challenging to estimate the state of battery accurately. This paper proposes a novel flexible and reliable battery management method based on the battery big data platform and Cyber-Physical System (CPS) technology. First of all, to integrate the battery big data resources in the cloud, a Cyber-physical battery management framework is defined and served as the basic data platform for battery modeling issues. And to improve the quality of the collected battery data in the database, this work reports the first attempt to develop an adaptive data cleaning method for the cloud battery management issue. Furthermore, a deep learning algorithm-based feature extraction model, as well as a feature-oriented battery modeling method, is developed to mitigate the under-fitting problem and improve the accuracy of the cloud-based battery model. The actual operation data of electric buses is used to validate the proposed methodologies. The maximum data restoring error can be limited within 1.3% in the experiments, which indicates that the proposed data cleaning method is able to improve the cloud battery data quality effectively. Meanwhile, the maximum SoC estimation error in the proposed feature-oriented battery modeling method is within 2.47%, which highlights the effectiveness of the proposed method.",https://doi.org/10.1016/j.est.2020.102064,2021,Shuangqi Li and Pengfei Zhao,BIG DATA DRIVEN VEHICLE BATTERY MANAGEMENT METHOD: A NOVEL CYBER-PHYSICAL SYSTEM PERSPECTIVE,article
589,21100400826,JOURNAL OF ENERGY STORAGE,journal,2352152X,"1,088",Q1,42,860,831,44642,5383,828,"6,87","51,91",Netherlands,Western Europe,Elsevier BV,2015-2020,"Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","7,765",6.583,0.00926,"State of health (SOH) of lithium-ion battery pack directly determines the driving mileage and output power of the electric vehicle. With the development of big data storage and analysis technology, using big data to off-line estimate battery pack SOH is more feasible than before. This paper proposes a SOH estimation method based on real data of electric vehicles concerning user behavior. The charging capacity is calculated by historical charging data, and locally weighted linear regression (LWLR) algorithm is used to qualitatively characterize the capacity decline trend. The health features are extracted from historical operating data, maximal information coefficient (MIC) algorithm is used to measure the correlation between health features and capacity. Then, long and short-term memory (LSTM)-based neural network will further learn the nonlinear degradation relationship between capacity and health features. Bayesian optimization algorithm is used to ensure the generalization of the model when different electric vehicles produce different user behaviors. The estimation method is validated by the 300 days historical dataset from 100 vehicles with different driving behavior. The results indicates that the maximum relative error of estimating SOH is 0.2%.",https://doi.org/10.1016/j.est.2021.102867,2021,Zhigang He and Xiaoyu Shen and Yanyan Sun and Shichao Zhao and Bin Fan and Chaofeng Pan,STATE-OF-HEALTH ESTIMATION BASED ON REAL DATA OF ELECTRIC VEHICLES CONCERNING USER BEHAVIOR,article
590,21100400826,JOURNAL OF ENERGY STORAGE,journal,2352152X,"1,088",Q1,42,860,831,44642,5383,828,"6,87","51,91",Netherlands,Western Europe,Elsevier BV,2015-2020,"Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","7,765",6.583,0.00926,"This paper proposes the architecture of the combination of the battery management system (BMS) and the cloud big data platform. Firstly, BMS measures and extracts the mean voltage falloff (MVF). A regression model of capacity and MVF based on historical data is established with generalized Box-Cox Transformation and least squares. The capacity and MVF are uploaded to the cloud big data platform, and then the mean and variance of the MVF is predicted based on the relevance vector machine, thereby realizing the 2σ range prediction of the lithium battery's state of health and the probability density function prediction of the remaining useful life. This paper makes two contributions to the data-driven prediction method. First, the edge-cloud collaborative computing architecture combining BMS and cloud is proposed, which effectively utilizes the advantages of BMS data quality and cloud computing power. Second, through the combination of relevance vector machine with particle swarm optimization and horizontal parameter transfer, the number of samples required for model learning is reduced to 30% and has better accuracy and robustness. Through the verification of NASA data, the results show that the average error is less than 2.18%.",https://doi.org/10.1016/j.est.2021.103342,2021,Yong Zhou and Huanghui Gu and Teng Su and Xuebing Han and Languang Lu and Yuejiu Zheng,REMAINING USEFUL LIFE PREDICTION WITH PROBABILITY DISTRIBUTION FOR LITHIUM-ION BATTERIES BASED ON EDGE AND CLOUD COLLABORATIVE COMPUTATION,article
591,24807,NEUROCOMPUTING,journal,09252312,"1,085",Q1,143,1653,3586,78823,25554,3535,"7,08","47,68",Netherlands,Western Europe,Elsevier,1989-2020,Artificial Intelligence (Q1); Computer Science Applications (Q1); Cognitive Neuroscience (Q2),"46,751",5.719,0.06669,"The task of choosing the appropriate classifier for a given scenario is not an easy-to-solve question. First, there is an increasingly high number of algorithms available belonging to different families. And also there is a lack of methodologies that can help on recommending in advance a given family of algorithms for a certain type of datasets. Besides, most of these classification algorithms exhibit a degradation in the performance when faced with datasets containing irrelevant and/or redundant features. In this work we analyze the impact of feature selection in classification over several synthetic and real datasets. The experimental results obtained show that the significance of selecting a classifier decreases after applying an appropriate preprocessing step and, not only this alleviates the choice, but it also improves the results in almost all the datasets tested.",https://doi.org/10.1016/j.neucom.2021.05.107,2022,Laura Morán-Fernández and Verónica Bólon-Canedo and Amparo Alonso-Betanzos,HOW IMPORTANT IS DATA QUALITY? BEST CLASSIFIERS VS BEST FEATURES,article
592,24807,NEUROCOMPUTING,journal,09252312,"1,085",Q1,143,1653,3586,78823,25554,3535,"7,08","47,68",Netherlands,Western Europe,Elsevier,1989-2020,Artificial Intelligence (Q1); Computer Science Applications (Q1); Cognitive Neuroscience (Q2),"46,751",5.719,0.06669,"Machine-to-Machine (M2M) communication relies on the physical objects (e.g., satellites, sensors, and so forth) interconnected with each other, creating mesh of machines producing massive volume of data about large geographical area (e.g., living and non-living environment). Thus, the M2M is an ideal example of Big Data. On the contrary, the M2M platforms that handle Big Data might perform poorly or not according to the goals of their operator (in term of cost, database utilization, data quality, processing and computational efficiency, analysis and feature extraction applications). Therefore, to address the aforementioned needs, we propose a new effective, memory and processing efficient system architecture for Big Data in M2M, which, unlike other previous proposals, does not require whole set of data to be processed (including raw data sets), and to be kept in the main memory. Our designed system architecture exploits divide-and-conquer approach and data block-wise vertical representation of the database follows a particular petitionary strategy, which formalizes the problem of feature extraction applications. The architecture goes from physical objects to the processing servers, where Big Data set is first transformed into a several data blocks that can be quickly processed, then it classifies and reorganizes these data blocks from the same source. In addition, the data blocks are aggregated in a sequential manner based on a machine ID, and equally partitions the data using fusion algorithm. Finally, the results are stored in a server that helps the users in making decision. The feasibility and efficiency of the proposed system architecture are implemented on Hadoop single node setup on UBUNTU 14.04 LTS core™i5 machine with 3.2GHz processor and 4GB memory. The results show that the proposed system architecture efficiently extract various features (such as River) from the massive volume of satellite data.",https://doi.org/10.1016/j.neucom.2015.04.109,2016,Awais Ahmad and Anand Paul and M. Mazhar Rathore,AN EFFICIENT DIVIDE-AND-CONQUER APPROACH FOR BIG DATA ANALYTICS IN MACHINE-TO-MACHINE COMMUNICATION,article
593,21100823476,DIGITAL COMMUNICATIONS AND NETWORKS,journal,23528648,"1,082",Q1,26,77,105,3226,881,96,"8,81","41,90",China,Asiatic Region,Chongqing University of Posts and Telecommunications,2015-2020,Communication (Q1); Computer Networks and Communications (Q1); Hardware and Architecture (Q1),823,6.797,0.00138,"Rapid developments in hardware, software, and communication technologies have facilitated the emergence of Internet-connected sensory devices that provide observations and data measurements from the physical world. By 2020, it is estimated that the total number of Internet-connected devices being used will be between 25 and 50 billion. As these numbers grow and technologies become more mature, the volume of data being published will increase. The technology of Internet-connected devices, referred to as Internet of Things (IoT), continues to extend the current Internet by providing connectivity and interactions between the physical and cyber worlds. In addition to an increased volume, the IoT generates big data characterized by its velocity in terms of time and location dependency, with a variety of multiple modalities and varying data quality. Intelligent processing and analysis of this big data are the key to developing smart IoT applications. This article assesses the various machine learning methods that deal with the challenges presented by IoT data by considering smart cities as the main use case. The key contribution of this study is the presentation of a taxonomy of machine learning algorithms explaining how different techniques are applied to the data in order to extract higher level information. The potential and challenges of machine learning for IoT data analytics will also be discussed. A use case of applying a Support Vector Machine (SVM) to Aarhus smart city traffic data is presented for a more detailed exploration.",https://doi.org/10.1016/j.dcan.2017.10.002,2018,Mohammad Saeid Mahdavinejad and Mohammadreza Rezvan and Mohammadamin Barekatain and Peyman Adibi and Payam Barnaghi and Amit P. Sheth,MACHINE LEARNING FOR INTERNET OF THINGS DATA ANALYSIS: A SURVEY,article
594,21100823476,DIGITAL COMMUNICATIONS AND NETWORKS,journal,23528648,"1,082",Q1,26,77,105,3226,881,96,"8,81","41,90",China,Asiatic Region,Chongqing University of Posts and Telecommunications,2015-2020,Communication (Q1); Computer Networks and Communications (Q1); Hardware and Architecture (Q1),823,6.797,0.00138,"The development of data-driven artificial intelligence technology has given birth to a variety of big data applications. Data has become an essential factor to improve these applications. Federated learning, a privacy-preserving machine learning method, is proposed to leverage data from different data owners. It is typically used in conjunction with cryptographic methods, in which data owners train the global model by sharing encrypted model updates. However, data encryption makes it difficult to identify the quality of these model updates. Malicious data owners may launch attacks such as data poisoning and free-riding. To defend against such attacks, it is necessary to find an approach to audit encrypted model updates. In this paper, we propose a blockchain-based audit approach for encrypted gradients. It uses a behavior chain to record the encrypted gradients from data owners, and an audit chain to evaluate the gradients’ quality. Specifically, we propose a privacy-preserving homomorphic noise mechanism in which the noise of each gradient sums to zero after aggregation, ensuring the availability of aggregated gradient. In addition, we design a joint audit algorithm that can locate malicious data owners without decrypting individual gradients. Through security analysis and experimental evaluation, we demonstrate that our approach can defend against malicious gradient attacks in federated learning.",https://doi.org/10.1016/j.dcan.2022.05.006,2022,Zhe Sun and Junping Wan and Lihua Yin and Zhiqiang Cao and Tianjie Luo and Bin Wang,A BLOCKCHAIN-BASED AUDIT APPROACH FOR ENCRYPTED DATA IN FEDERATED LEARNING,article
595,21100823476,DIGITAL COMMUNICATIONS AND NETWORKS,journal,23528648,"1,082",Q1,26,77,105,3226,881,96,"8,81","41,90",China,Asiatic Region,Chongqing University of Posts and Telecommunications,2015-2020,Communication (Q1); Computer Networks and Communications (Q1); Hardware and Architecture (Q1),823,6.797,0.00138,"Advanced technologies are required in future mobile wireless networks to support services with highly diverse requirements in terms of high data rate and reliability, low latency, and massive access. Deep Learning (DL), one of the most exciting developments in machine learning and big data, has recently shown great potential in the study of wireless communications. In this article, we provide a literature review on the applications of DL in the physical layer. First, we analyze the limitations of existing signal processing techniques in terms of model accuracy, global optimality, and computational scalability. Next, we provide a brief review of classical DL frameworks. Subsequently, we discuss recent DL-based physical layer technologies, including both DL-based signal processing modules and end-to-end systems. Deep neural networks are used to replace a single or several conventional functional modules, whereas the objective of the latter is to replace the entire transceiver structure. Lastly, we discuss the open issues and research directions of the DL-based physical layer in terms of model complexity, data quality, data representation, and algorithm reliability.",https://doi.org/10.1016/j.dcan.2021.09.014,2021,Siqi Liu and Tianyu Wang and Shaowei Wang,TOWARD INTELLIGENT WIRELESS COMMUNICATIONS: DEEP LEARNING - BASED PHYSICAL LAYER TECHNOLOGIES,article
596,21100420330,JOURNAL OF MODERN POWER SYSTEMS AND CLEAN ENERGY,journal,21965420,"1,078",Q1,40,126,350,4408,1848,346,"4,87","34,98",Germany,Western Europe,Springer Verlag,2013-2020,"Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","1,955",3.265,0.00366,"The high penetration of distributed generation (DG) has set up a challenge for energy management and consequently for the monitoring and assessment of power quality (PQ). Besides, there are new types of disturbances owing to the uncontrolled connections of non-linear loads. The stochastic behaviour triggers the need for new holistic indicators which also deal with big data of PQ in terms of compression and scalability so as to extract the useful information regarding different network states and the prevailing PQ disturbances for future risk assessment and energy management systems. Permanent and continuous monitoring would guarantee the report to claim for damages and to assess the risk of PQ distortions. In this context, we propose a measurement method that postulates the use of two-dimensional (2D) diagrams based on higher-order statistics (HOSs) and a previous voltage quality index that assesses the voltage supply waveform in a continous monitoring campaign. Being suitable for both PQ and reliability applications, the results conclude that the inclusion of HOS measurements in the industrial metrological reports helps characterize the deviations of the voltage supply waveform, extracting the individual customers&#x0027; pattern fingerprint, and compressing the data from both time and spatial aspects. The method allows a continuous and robust performance needed in the SG framework. Consequently, the method can be used by an average consumer as a probabilistic method to assess the risk of PQ deviations in site characterization.",10.35833/MPCE.2020.000041,2022,,SITE CHARACTERIZATION INDEX FOR CONTINUOUS POWER QUALITY MONITORING BASED ON HIGHER-ORDER STATISTICS,
597,23706,JOURNAL OF BIOMEDICAL INFORMATICS,journal,15320464,"1,057",Q1,103,203,591,9904,3884,527,"7,05","48,79",United States,Northern America,Academic Press Inc.,2001-2020,Computer Science Applications (Q1); Health Informatics (Q1),"12,255",6.317,0.01469,"The construction of medical big data includes several problems that need to be solved, such as integration and data sharing of many heterogeneous information systems, efficient processing and analysis of large-scale medical data with complex structure or low degree of structure, and narrow application range of medical data. Therefore, medical big data construction is not only a simple collection and application of medical data but also a complex systematic project. This paper introduces China's experience in the construction of a regional medical big data ecosystem, including the overall goal of the project; establishment of policies to encourage data sharing; handling the relationship between personal privacy, information security, and information availability; establishing a cooperation mechanism between agencies; designing a polycentric medical data acquisition system; and establishing a large data centre. From the experience gained from one of China's earliest established medical big data projects, we outline the challenges encountered during its development and recommend approaches to overcome these challenges to design medical big data projects in China more rationally. Clear and complete top-level design of a project requires to be planned in advance and considered carefully. It is essential to provide a culture of information sharing and to facilitate the opening of data, and changes in ideas and policies need the guidance of the government. The contradiction between data sharing and data security must be handled carefully, that is not to say data openness could be abandoned. The construction of medical big data involves many institutions, and high-level management and cooperation can significantly improve efficiency and promote innovation. Compared with infrastructure construction, it is more challenging and time-consuming to develop appropriate data standards, data integration tools and data mining tools.",https://doi.org/10.1016/j.jbi.2019.103149,2019,Bei Li and Jianbin Li and Yuqiao Jiang and Xiaoyun Lan,EXPERIENCE AND REFLECTION FROM CHINA’S XIANGYA MEDICAL BIG DATA PROJECT,article
598,23706,JOURNAL OF BIOMEDICAL INFORMATICS,journal,15320464,"1,057",Q1,103,203,591,9904,3884,527,"7,05","48,79",United States,Northern America,Academic Press Inc.,2001-2020,Computer Science Applications (Q1); Health Informatics (Q1),"12,255",6.317,0.01469,"Significant technological advances made in recent years have shepherded a dramatic increase in utilization of digital technologies for biomedicine– everything from the widespread use of electronic health records to improved medical imaging capabilities and the rising ubiquity of genomic sequencing contribute to a “digitization” of biomedical research and clinical care. With this shift toward computerized tools comes a dramatic increase in the amount of available data, and current tools for data analysis capable of extracting meaningful knowledge from this wealth of information have yet to catch up. This article seeks to provide an overview of emerging mathematical methods with the potential to improve the abilities of clinicians and researchers to analyze biomedical data, but may be hindered from doing so by a lack of conceptual accessibility and awareness in the life sciences research community. In particular, we focus on topological data analysis (TDA), a set of methods grounded in the mathematical field of algebraic topology that seeks to describe and harness features related to the “shape” of data. We aim to make such techniques more approachable to non-mathematicians by providing a conceptual discussion of their theoretical foundations followed by a survey of their published applications to scientific research. Finally, we discuss the limitations of these methods and suggest potential avenues for future work integrating mathematical tools into clinical care and biomedical informatics.",https://doi.org/10.1016/j.jbi.2022.104082,2022,Yara Skaf and Reinhard Laubenbacher,TOPOLOGICAL DATA ANALYSIS IN BIOMEDICINE: A REVIEW,article
599,26441,SOCIAL SCIENCE RESEARCH,journal,0049089X,"1,042",Q1,89,80,398,5842,1123,398,"2,28","73,03",United States,Northern America,Academic Press Inc.,1972-2020,Education (Q1); Sociology and Political Science (Q1),"6,976",2.322,0.00899,"The term big data is currently a buzzword in social science, however its precise meaning is ambiguous. In this paper we focus on administrative data which is a distinctive form of big data. Exciting new opportunities for social science research will be afforded by new administrative data resources, but these are currently under appreciated by the research community. The central aim of this paper is to discuss the challenges associated with administrative data. We emphasise that it is critical for researchers to carefully consider how administrative data has been produced. We conclude that administrative datasets have the potential to contribute to the development of high-quality and impactful social science research, and should not be overlooked in the emerging field of big data.",https://doi.org/10.1016/j.ssresearch.2016.04.015,2016,Roxanne Connelly and Christopher J. Playford and Vernon Gayle and Chris Dibben,THE ROLE OF ADMINISTRATIVE DATA IN THE BIG DATA REVOLUTION IN SOCIAL SCIENCE RESEARCH,article
600,21100239262,SUSTAINABLE ENERGY TECHNOLOGIES AND ASSESSMENTS,journal,22131388,"1,040",Q1,39,270,333,13311,1833,331,"5,73","49,30",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","3,234",5.353,0.00348,"Angelica sinensis is a kind of traditional Chinese medicine with very good blood nourishing effect, and it is cultivated in many regions of China. But with the increasingly severe climate, angelica cultivation has become a big problem. Therefore, this paper starts from the soil microorganisms of angelica planting, and studies the influence of soil biodiversity and angelica planting in the context of big data. This paper proposes a Hadoop system for big data analysis, combining the biocommunity characteristics and metagenomes of soil microorganisms. It then calculates the distance between samples and generates a dissimilarity matrix. Finally, this paper proposes a soil optimization method for angelica planting based on big data analysis of soil microorganisms. In order to optimize the Angelica planting soil designed in this paper, a soil microbial genome comparison experiment and a big data concurrent control test experiment were designed in this paper. It then analyzes the data obtained from the experiment, and the results of the analysis are used to optimize the soil for angelica planting. It finally compares the soil method of Angelica planting designed in this paper with the traditional Angelica planting method. The experimental results show that the survival rate of Angelica sinensis planted by the soil optimization method based on big data analysis of soil microorganisms has increased by 16.09% compared with the traditional Angelica sinensis planting site. The growth rate of Angelica sinensis planted by the soil optimization method based on big data analysis of soil microorganisms increased by 9.64% compared with the traditional Angelica sinensis planting area.",https://doi.org/10.1016/j.seta.2022.102674,2022,Yinan Peng and Ze Ye and Peng Xi and Hongshan Qi and Bin Ji and Zhiye Wang,THE RELATIONSHIP BETWEEN SOIL MICROBIAL DIVERSITY AND ANGELICA PLANTING BASED ON NETWORK BIG DATA,article
601,21100239262,SUSTAINABLE ENERGY TECHNOLOGIES AND ASSESSMENTS,journal,22131388,"1,040",Q1,39,270,333,13311,1833,331,"5,73","49,30",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","3,234",5.353,0.00348,"The use of Internet of Things (IoT) networks offers great advantages over wired networks, especially due to their simple installation, low maintenance costs, and automatic configuration. IoT facilitates the integration of sensing and communication for various industries, including smart farming and precision agriculture. For several years, many researchers have strived to find new sources of energy that are always “cleaner” and more environmentally friendly. Energy harvesting technology is one of the most promising environment-friendly solutions that extend the lifetime of these IoT devices. In this paper, the state-of-art of IoT energy harvesting capabilities and communication technologies in smart agriculture is presented. In addition, this work proposes a comprehensive architecture that includes big data technologies, IoT components, and knowledge-based systems for innovative farm architecture. The solution answers some of the biggest challenges the agriculture industry faces, especially when handling small files in a big data environment without impacting the computation performance. The solution is built on top of a pre-defined big data architecture that includes an abstraction layer of the data lake that handles data quality following a data migration strategy to ensure the data's insights. Furthermore, in this paper, we compared several machine learning algorithms to find the most suitable smart farming analytics tools in terms of forecasting and predictions.",https://doi.org/10.1016/j.seta.2022.102093,2022,El Mehdi Ouafiq and Rachid Saadane and Abdellah Chehri and Seunggil Jeon,AI-BASED MODELING AND DATA-DRIVEN EVALUATION FOR SMART FARMING-ORIENTED BIG DATA ARCHITECTURE USING IOT WITH ENERGY HARVESTING CAPABILITIES,article
602,21100239262,SUSTAINABLE ENERGY TECHNOLOGIES AND ASSESSMENTS,journal,22131388,"1,040",Q1,39,270,333,13311,1833,331,"5,73","49,30",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","3,234",5.353,0.00348,"Solar power is expected to play a substantial role globally, due to it being one of the leading renewable electricity sources for future use. Even though the use of solar irradiation to generate electricity is currently at a fast deployment pace and technological evolution, its natural variability still presents an important barrier to overcome. Machine learning and data mining techniques arise as alternatives to aid solar electricity generation forecast reducing the impacts of its natural inconstant power supply. This paper presents a literature review on big data models for solar photovoltaic electricity generation forecasts, aiming to evaluate the most applicable and accurate state-of-art techniques to the problem, including the motivation behind each project proposal, the characteristics and quality of data used to address the problem, among other issues. A Systematic Literature Review (SLR) method was used, in which research questions were defined and translated into search strings. The search returned 38 papers for final evaluation, affirming that the use of these models to predict solar electricity generation is currently an ongoing academic research question. Machine learning is widely used, and neural networks is considered the most accurate algorithm. Extreme learning machine learning has reduced time and raised precision.",https://doi.org/10.1016/j.seta.2018.11.008,2019,Gabriel {de Freitas Viscondi} and Solange N. Alves-Souza,A SYSTEMATIC LITERATURE REVIEW ON BIG DATA FOR SOLAR PHOTOVOLTAIC ELECTRICITY GENERATION FORECASTING,article
603,21100239262,SUSTAINABLE ENERGY TECHNOLOGIES AND ASSESSMENTS,journal,22131388,"1,040",Q1,39,270,333,13311,1833,331,"5,73","49,30",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Energy Engineering and Power Technology (Q1); Renewable Energy, Sustainability and the Environment (Q2)","3,234",5.353,0.00348,"Because of big data on energy consumption, there is a lack of research on the discrete manufacturing system. The discrete manufacturing system has plenty of multi-source and heterogeneous data; it was challenging to collect real-time data. Recently, low carbon and green manufacturing is a hot field; especially, it can save electrical energy. This paper proposes a significant energy consumption data of a data-driven analysis framework, which promoting the energy efficiency of discrete manufacturing plant, equipment, and workshop production process. Firstly, put forward the evaluation standards of energy efficiency for discrete manufacturing shops. Then make energy-consumption data preprocessing. Efficiency optimization of big data mining method is put forward based on grid computing function. Design the discrete manufacturing system energy-consumption parameter values, then summarizes prediction algorithms and models in order to predict the results and the trends. Finally, introduce the application of a mobile phone shell manufacturing shop to verify the proposed framework. Further research will focus on energy-consumption data mining processing.",https://doi.org/10.1016/j.seta.2021.101336,2021,Tao Zhang and Weixi Ji and Yongtao Qiu,A FRAMEWORK OF ENERGY-CONSUMPTION DRIVEN DISCRETE MANUFACTURING SYSTEM,article
604,24286,INTERNATIONAL JOURNAL OF APPROXIMATE REASONING,journal,0888613X,"1,039",Q1,97,129,496,6026,2071,475,"4,55","46,71",United States,Northern America,Elsevier Inc.,"1974, 1987-2020",Applied Mathematics (Q1); Artificial Intelligence (Q1); Software (Q1); Theoretical Computer Science (Q1),"4,819",3.816,0.00487,"Recently, a fundamental study on measurement of data quality introduced an ordinal-scaled procedure of measurement. Besides the pure ordinal information about the level of quality, numerical information is induced when considering uncertainty involved during measurement. In the case where uncertainty is modelled as probability, this numerical information is ratio-scaled. An essential property of the mentioned approach is that the application of a measure on a large collection of data can be represented efficiently in the sense that (i) the representation has a low storage complexity and (ii) it can be updated incrementally when new data are observed. However, this property only holds when the evaluation of predicates is clear and does not deal with uncertainty. For some dimensions of quality, this assumption is far too strong and uncertainty comes into play almost naturally. In this paper, we investigate how the presence of uncertainty influences the efficiency of a measurement procedure. Hereby, we focus specifically on the case where uncertainty is caused by insufficient information and is thus modelled by means of possibility theory. It is shown that the amount of data that reaches a certain level of quality, can be summarized as a possibility distribution over the set of natural numbers. We investigate an approximation of this distribution that has a controllable loss of information, allows for incremental updates and exhibits a low space complexity.",https://doi.org/10.1016/j.ijar.2018.03.007,2018,A. Bronselaer and J. Nielandt and G. {De Tré},AN INCREMENTAL APPROACH FOR DATA QUALITY MEASUREMENT WITH INSUFFICIENT INFORMATION,article
605,29271,CLINICAL ONCOLOGY,journal,09366555,"1,037",Q1,76,180,455,5806,1127,304,"2,47","32,26",United Kingdom,Western Europe,W.B. Saunders Ltd,"1975, 1984-1985, 1989-2020","Radiology, Nuclear Medicine and Imaging (Q1); Oncology (Q2)","4,553",4.126,0.00538,"Modern artificial intelligence techniques have solved some previously intractable problems and produced impressive results in selected medical domains. One of their drawbacks is that they often need very large amounts of data. Pre-existing datasets in the form of national cancer registries, image/genetic depositories and clinical datasets already exist and have been used for research. In theory, the combination of healthcare Big Data with modern, data-hungry artificial intelligence techniques should offer significant opportunities for artificial intelligence development, but this has not yet happened. Here we discuss some of the structural reasons for this, barriers preventing artificial intelligence from making full use of existing datasets, and make suggestions as to enable progress. To do this, we use the framework of the 6Vs of Big Data and the FAIR criteria for data sharing and availability (Findability, Accessibility, Interoperability, and Reuse). We share our experience in navigating these barriers through The Brain Tumour Data Accelerator, a Brain Tumour Charity-supported initiative to integrate fragmented patient data into an enriched dataset. We conclude with some comments as to the limits of such approaches.",https://doi.org/10.1016/j.clon.2021.11.040,2022,J.W. Wang and M. Williams,"REGISTRIES, DATABASES AND REPOSITORIES FOR DEVELOPING ARTIFICIAL INTELLIGENCE IN CANCER CARE",article
606,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Smart contracts are commonly deployed for safety-critical applications, the quality assurance of which has been a vital factor. Test cases are standard means to ensure the correctness of data flows in smart contracts. To more efficiently generate test cases with high coverage, we propose an improved genetic algorithm-based test-case generation approach for smart contract data flow testing. Our approach introduces the theory of particle swarm optimization into the genetic algorithm, which reduces the influence brought by the randomness of genetic operations and enhances its capability to find global optima. A set of 30 real smart contracts deployed on Ethereum and GitHub is collected to perform the experimental study, on which our approach is compared with three baseline approaches. The experimental results show that, in most cases, the coverage of the test cases generated by our approach is significantly higher than the baseline approaches with relatively lower numbers of iterations and lower execution time.",10.1109/TR.2022.3173025,2022,,TEST-CASE GENERATION FOR DATA FLOW TESTING OF SMART CONTRACTS BASED ON IMPROVED GENETIC ALGORITHM,
607,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Just-in-time (JIT) bug prediction is an effective quality assurance activity that identifies whether a code commit will introduce bugs into the mobile app, aiming to provide prompt feedback to practitioners for priority review. Since collecting sufficient labeled bug data is not always feasible for some mobile apps, one possible approach is to leverage cross-app models. In this work, we propose a new cross-triplet deep feature embedding method, called CDFE, for cross-app JIT bug prediction task. The CDFE method incorporates a state-of-the-art cross-triplet loss function into a deep neural network to learn high-level feature representation for the cross-app data. This loss function adapts to the cross-app feature learning task and aims to learn a new feature space to shorten the distance of commit instances with the same label and enlarge the distance of commit instances with different labels. In addition, this loss function assigns higher weights to losses caused by cross-app instance pairs than that by intra-app instance pairs, aiming to narrow the discrepancy of cross-app bug data. We evaluate our CDFE method on a benchmark bug dataset from 19 mobile apps with two effort-aware indicators. The experimental results on 342 cross-app pairs show that our proposed CDFE method performs better than 14 baseline methods.",10.1109/TR.2021.3066170,2022,,EFFORT-AWARE JUST-IN-TIME BUG PREDICTION FOR MOBILE APPS VIA CROSS-TRIPLET DEEP FEATURE EMBEDDING,
608,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Entity reconciliation (ER) aims to combine data from different sources for a unified vision. The management of large volumes of data has given rise to significant challenges to the ER problem due to facts such as data becoming more unstructured, unclean, and incomplete or the existence of many datasets that store information about the same topic. Testing the applications that implement the ER problem is crucial to ensure both the correctness of the reconciliation process and the quality of the reconciled data. This paper presents an approach based on model-driven engineering that allows the creation of test models for the early integration testing of ER applications, contributing in three main aspects: the description of the elements of the proposed framework, the definition of the testing model, and the validation of the proposal through two real-world case studies. This validation verifies that the early integration testing of the ER application is capable of detecting a series of deficiencies, which a priori are not known and that will help to improve the final result that the ER application offers.",10.1109/TR.2018.2809866,2018,,EARLY INTEGRATION TESTING FOR ENTITY RECONCILIATION IN THE CONTEXT OF HETEROGENEOUS DATA SOURCES,
609,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Machine learning has made significant progress in image recognition, natural language processing, and autonomous driving. However, the generation of adversarial examples has proved that the machine learning system is unreliable. By adding imperceptible perturbations to clean images can fool the well-trained machine learning systems. To solve this problem, we propose an adaptive image denoising framework Adaptive Scalar Quantization (ASQ-FastBM3D). The ASQ-FastBM3D framework combines the ASQ method with the FastBM3D algorithm. The adaptive scalar quantization is the improvement of scalar quantization, which is used to eliminate most of the perturbations. FastBM3D is proposed to improve the quality of the quantified image. The running time of FastBM3D is 50&#x0025; less than that of BM3D. Compared with some traditional filter methods and some state-of-the-art neural network methods for recovering the adversarial examples, the accuracy rate of our ASQ-FastBM3D method is 99.73&#x0025; and the F1 score is 98.01&#x0025;, which is the highest.",10.1109/TR.2022.3171420,2022,,ASQ-FASTBM3D: AN ADAPTIVE DENOISING FRAMEWORK FOR DEFENDING ADVERSARIAL ATTACKS IN MACHINE LEARNING ENABLED SYSTEMS,
610,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"The popularity of mobile devices has led to an explosive growth in the number of mobile apps in which Android mobile apps are the mainstream. Android mobile apps usually undergo frequent update due to new requirements proposed by users. Just-in-time (JIT) defect prediction is appropriate for this scenario for quality assurance because it can provide timely feedback by determining whether a new code commit will introduce defects into the apps. As defect-prediction performance usually relies on the quality of the data representation and the used classification model, in this work, we propose a model, called Simplified Deep Forest (SDF), to conduct JIT defect prediction for Android mobile apps. SDF modifies a state-of-the-art deep forest model by removing the multigrained scanning operation that is designed for data with a high-dimensional feature space. It uses a cascade structure with ensemble forests for representation learning and classification. We conduct experiments on 10 Android mobile apps and experimental results show that SDF performs significantly better than comparative methods in terms of 3 performance indicators.",10.1109/TR.2021.3060937,2021,,SIMPLIFIED DEEP FOREST MODEL BASED JUST-IN-TIME DEFECT PREDICTION FOR ANDROID MOBILE APPS,
611,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. In our developer survey, commenting has become an important, yet often-neglected activity when programming. Moreover, there is a lack of formal and automatic way in current practice to remind developers where to comment in the source code. To provide informative guidance on commenting during development, we propose a novel method CommentSuggester to recommend developers regarding appropriate commenting locations in the source code. Because commenting is closely related to the context information of source code, we identify this important factor to determine comment positions and extract it as structural context features, syntactic context features, and semantic context features. Subsequently, machine learning techniques are applied to identify possible commenting locations in the source code. We evaluated CommentSuggester using large datasets from dozens of open-source software systems in GitHub. The encouraging experimental results and user study demonstrated the feasibility and effectiveness of our commenting suggestion method.",10.1109/TR.2019.2931725,2020,,LEARNING CODE CONTEXT INFORMATION TO PREDICT COMMENT LOCATIONS,
612,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Recently, just-in-time (JIT) defect prediction technique attracted a lot of attention. In JIT defect prediction, all branches and omitting changes outside the main branch should be considered which can significantly affect the performance of JIT defect prediction. However, there are many duplicate changes among all the branches, which are referred to as a pair of changes with identical implementation in different branches. Such changes can influence the calculation of developer experience metrics and are considered as the noisy data for JIT defect prediction. In this article, the impact of duplicate changes on JIT defect prediction is explored. An empirical study on a total of 105 828 changes from eight Apache open-source projects is given. We find that 13% of changes from different branches are duplicate among the studied projects. The duplicate changes have a great influence on the model metrics for JIT defect prediction. For 50% of the changes, removing duplicate changes decreases the experience metrics with an average of 6–55. In addition, the duplicate changes have a significant impact on the evaluation and interpretation of JIT defect prediction models. Removing duplicate changes among the studied projects can significantly improve the performance of JIT defect prediction models ranging from 1 to 125% concerning various performance measures (i.e., area under the curve, Matthews correlation coefficient, and F1). Given the impact of duplicate changes, we suggest that researchers should remove duplicate changes from the original historical changes of software repository when evaluating the performance of JIT defect prediction models in future work.",10.1109/TR.2021.3061618,2022,,THE IMPACT OF DUPLICATE CHANGES ON JUST-IN-TIME DEFECT PREDICTION,
613,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"Software is currently a key part of many safety-critical and life-critical application systems. People always need easy- and instinctive-to-use software, but the biggest challenge for software engineers is how to develop software with high reliability in a timely manner. To assure quality, and to assess the reliability of software products, many software reliability growth models (SRGMs) have been proposed in the past three decades. The practical problem is that sometimes these selected SRGMs by companies or software practitioners disagree in their reliability predictions, while no single model can be trusted to provide consistently accurate results across various applications. Consequently, some researchers have proposed to use combinational models for improving the prediction capability of software reliability. In this paper, three enhanced weighted-combinations, namely weighted arithmetic, weighted geometric, and weighted harmonic combinations, are proposed. To solve the problem of determining proper weights for model combinations, we further study how to incorporate enhanced genetic algorithms (EGAs) with several efficient operators into weighted assignments. Experiments are performed based on real software failure data, and numerical results show that our proposed models are flexible enough to depict various software development environments. Finally, some management metrics are presented to both assure software quality and determine the optimal release strategy of software products under development.",10.1109/TR.2014.2315966,2014,,OPTIMAL WEIGHTED COMBINATIONAL MODELS FOR SOFTWARE RELIABILITY ESTIMATION AND ANALYSIS,
614,17387,IEEE TRANSACTIONS ON RELIABILITY,journal,15581721,"1,032",Q1,102,114,293,4569,1485,279,"5,11","40,08",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,"Electrical and Electronic Engineering (Q1); Safety, Risk, Reliability and Quality (Q1)","7,371",4.424,0.00623,"This paper studies a consecutive- k-within- m-out- of- n:F system with Markov-dependent components; that is, the reliability of a component depends on its neighbors. Using probability generating functions, the closed-form formula for reliability of the consecutive- k-within- m-out-of- n:F system with Markov-dependent components and a closed-form formula for joint reliability importance (JRI) of two components in such a system are derived. The JRI of two components evaluates the interaction effect between the components on contributing to system reliability. A formula of the JRI of more than two components are also derived and presented. Many real systems and procedures, such as radar detection systems, pipeline systems, quality inspection procedures, and so on, can be modeled as a consecutive- k-within- m-out-of- n:F system, in which components are Markov-dependent. The present results can evaluate the reliability of these systems or the accuracy of the procedures as well as the contributions of components to the system reliability or the accuracy of the procedures. The applications of the present formulas are demonstrated through the numerical examples. The examples show the changes of system radiabilities and the changes among the JRI values of different pairs of components in consecutive- k-within- m-out-of- n:F systems. The JRI values of Markov-dependent components are also compared to the JRI values of s-independent components.",10.1109/TR.2015.2484079,2016,,RELIABILITY AND JOINT RELIABILITY IMPORTANCE IN A CONSECUTIVE-$K$-WITHIN-$M$-OUT-OF- $N$:F SYSTEM WITH MARKOV-DEPENDENT COMPONENTS,
615,19678,DIAGNOSTIC MICROBIOLOGY AND INFECTIOUS DISEASE,journal,07328893,"1,027",Q1,95,192,693,4910,1788,677,"2,63","25,57",United States,Northern America,Elsevier Inc.,1983-2020,Medicine (miscellaneous) (Q1); Infectious Diseases (Q2); Microbiology (medical) (Q2),"8,091",2.803,0.00954,,https://doi.org/10.1016/j.diagmicrobio.2018.12.006,2019,Susanna K.P. Lau and Patrick C.Y. Woo,"PITFALLS IN BIG DATA ANALYSIS: NEXT-GENERATION TECHNOLOGIES, LAST-GENERATION DATA",article
616,4100151536,RESEARCH IN TRANSPORTATION ECONOMICS,journal,07398859,"1,019",Q1,46,160,220,7437,694,205,"2,79","46,48",United States,Northern America,JAI Press,"1994, 1996, 1999, 2001, 2004-2020","Economics, Econometrics and Finance (miscellaneous) (Q1); Transportation (Q1)","2,095",2.627,0.00218,"A group of researchers, consultants, software developers, and transit agencies convened in Santiago, Chile over 3 days as part of the Thredbo workshop titled “Harnessing Big Data”, to present their recent research and discuss the state of practice, state of the art, and future directions of big data in public transportation. This report documents their discussion. The key conclusion of the workshop is that, although much progress has been made in utilizing big data to improve transportation planning and operations, much remains to be done, both in terms of developing further analysis tools and use cases of big data, and of disseminating best practices so that they are adopted across the industry.",https://doi.org/10.1016/j.retrec.2016.10.008,2016,Gabriel E. Sánchez-Martínez and Marcela Munizaga,WORKSHOP 5 REPORT: HARNESSING BIG DATA,article
617,21100416081,SUSTAINABLE PRODUCTION AND CONSUMPTION,journal,23525509,"1,019",Q1,26,91,198,6098,1058,194,"5,34","67,01",Netherlands,Western Europe,Elsevier BV,2015-2021,"Environmental Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Environmental Chemistry (Q2); Renewable Energy, Sustainability and the Environment (Q2)","1,403",5.032,0.00196,"The generation of reliable life cycle inventories is essential towards Life Cycle Assessment (LCA) development, and the use of literature inventories as data sources can serve as a driving force for emerging LCA databases. The aim of this paper was to propose a method to select and rank scientific publications to be used as possible data sources for supplying LCA databases with new datasets. A case study was designed to identify eligible datasets to compose the emergent Brazilian Life Cycle Inventory Database System – the “SICV Brasil” launched in 2016. The methodology used was based on an exploratory research composed of three steps: i) a bibliographic survey on the scientific productions of Life Cycle Inventories (LCI) in Brazil from 2000 to 2017; ii) a cross-check of LCI data and information based on the 40 selected requirements used in order to analyze the quality of LCI datasets in terms of mandatory, recommended and optional requirements; and iii) an analysis of the data quality requirements for those datasets with support of principles of Analytical Hierarchy Process (AHP) to elect possible datasets to be included in the SICV Brasil database. In total, 57 publications were analyzed and the results indicated that mandatory requirements had under 50% acceptance and only 10 requirements (less than 25%) were fully met. The best LCI dataset received 73 points (90%) with the scoring method, while 16 datasets were given less than 40 points (50%). Therefore, it is necessary to improve data quality of LCI datasets found in literature before using them to integrate LCA databases. In this regard, this study proposed a guide with short, medium, and long-term measures to mitigate this problem. The idea is to put an action plan into practice to gather more LCI datasets from literature which may be eligible for publication to SICV Brasil to improve this national database with more and relevant high-quality datasets.",https://doi.org/10.1016/j.spc.2020.09.021,2021,Luri {Shirosaki Marçal de Souza} and Andréa Oliveira Nunes and Gabriela Giusti and Yovana M.B. Saavedra and Thiago Oliveira Rodrigues and Tiago E. {Nunes Braga} and Diogo A. {Lopes Silva},EVALUATING AND RANKING SECONDARY DATA SOURCES TO BE USED IN THE BRAZILIAN LCA DATABASE – “SICV BRASIL”,article
618,25240,TOXICOLOGY LETTERS,journal,03784274,"1,007",Q1,145,303,840,14151,3425,821,"3,93","46,70",Netherlands,Western Europe,Elsevier BV,1977-2020,Medicine (miscellaneous) (Q1); Toxicology (Q1),"18,729",4.372,0.01073,,https://doi.org/10.1016/j.toxlet.2015.08.097,2015,T. Gant,THE IMPORTANCE OF DATA QUALITY TO ENHANCE THE IMPACT OF OMICS SCIENCES,article
619,24140,ARTIFICIAL INTELLIGENCE IN MEDICINE,journal,09333657,"0,980",Q1,87,165,245,9065,1746,237,"6,69","54,94",Netherlands,Western Europe,Elsevier,1989-2020,Artificial Intelligence (Q1); Medicine (miscellaneous) (Q1),"4,245",5.326,0.00422,"Introduction
Machine learning capability holds promise to inform disease models, the discovery and development of novel disease modifying therapeutics and prevention strategies in psychiatry. Herein, we provide an introduction on how machine learning/Artificial Intelligence (AI) may instantiate such capabilities, as well as provide rationale for its application to psychiatry in both research and clinical ecosystems.
Methods
Databases PubMed and PsycINFO were searched from 1966 to June 2016 for keywords:Big Data, Machine Learning, Precision Medicine, Artificial Intelligence, Mental Health, Mental Disease, Psychiatry, Data Mining, RDoC, and Research Domain Criteria. Articles selected for review were those that were determined to be aligned with the objective of this particular paper.
Results
Results indicate that AI is a viable option to build useful predictors of outcome while offering objective and comparable accuracy metrics, a unique opportunity, particularly in mental health research. The approach has also consistently brought notable insight into disease models through processing the vast amount of already available multi-domain, semi-structured medical data. The opportunity for AI in psychiatry, in addition to disease-model refinement, is in characterizing those at risk, and it is likely also relevant to personalizing and discovering therapeutics.
Conclusions
Machine learning currently provides an opportunity to parse disease models in complex, multi-factorial disease states (e.g. mental disorders) and could possibly inform treatment selection with existing therapies and provide bases for domain-based therapeutic discovery.",https://doi.org/10.1016/j.artmed.2019.101704,2019,Andy M.Y. Tai and Alcides Albuquerque and Nicole E. Carmona and Mehala Subramanieapillai and Danielle S. Cha and Margarita Sheko and Yena Lee and Rodrigo Mansur and Roger S. McIntyre,MACHINE LEARNING AND BIG DATA: IMPLICATIONS FOR DISEASE MODELING AND THERAPEUTIC DISCOVERY IN PSYCHIATRY,article
620,17243,JOURNAL OF VASCULAR AND INTERVENTIONAL RADIOLOGY,journal,10510443,"0,979",Q1,133,401,1086,6771,2111,715,"1,86","16,89",United States,Northern America,Elsevier Inc.,1990-2020,"Medicine (miscellaneous) (Q1); Radiology, Nuclear Medicine and Imaging (Q1); Cardiology and Cardiovascular Medicine (Q2)","11,063",3.464,0.01078,"Observational data research studying access, utilization, cost, and outcomes of image-guided interventions using publicly available “big data” sets is growing in the interventional radiology (IR) literature. Publicly available data sets offer insight into real-world care and represent an important pillar of IR research moving forward. They offer insights into how IR procedures are being used nationally and whether they are working as intended. On the other hand, large data sources are aggregated using complex sampling frames, and their strengths and weaknesses only become apparent after extensive use. Unintentional misuse of large data sets can result in misleading or sometimes erroneous conclusions. This review introduces the most commonly used databases relevant to IR research, highlights their strengths and limitations, and provides recommendations for use. In addition, it summarizes methodologic best practices pertinent to all data sets for planning and executing scientifically rigorous and clinically relevant observational research.",https://doi.org/10.1016/j.jvir.2022.08.003,2022,Premal S. Trivedi and Vincent M. Timpone and Rustain L. Morgan and Alexandria M. Jensen and Margaret Reid and P. Michael Ho and Osman Ahmed,A PRACTICAL GUIDE TO USE OF PUBLICLY AVAILABLE DATA SETS FOR OBSERVATIONAL RESEARCH IN INTERVENTIONAL RADIOLOGY,article
621,17013,JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,journal,09204105,"0,975",Q1,111,1174,2764,59146,13310,2752,"4,78","50,38",Netherlands,Western Europe,Elsevier,1987-2021,Fuel Technology (Q1); Geotechnical Engineering and Engineering Geology (Q1),"25,616",4.346,0.02651,"Pressure transient analysis provides essential information to evaluate the dimensions of injection induced fractures, permeability damage near the wellbore, and pressure elevation in the injection horizon. For injection wells, shut-in data can be collected and analyzed after each injection cycle to evaluate the well injectivity and predict the well longevity. However, any interactive analysis of the pressure data could be subjective and time-consuming. In this study a novel cloud-based approach to automatically analyzing pressure data is presented, which aims to improve the reliability and efficiency of pressure transient analysis. There are two fundamental requirements for automated pressure transient analysis: 1) Pressure data needs to be automatically retrieved from field sites and fed to the analyzer; 2) The engineer can automatically select instantaneous shut-in pressure (ISIP), identify flow regimes, and determine the fracture closure point if any. To meet these requirements as well as to take advantage of cloud storage and computing technologies, a web-based application has been developed to pull real time injection data from any field sites and push it to a cloud database. A built-in pressure transient workflow has been also proposed to detect any stored or real-time pressure data and perform pressure analysis automatically if the required data is available. The automated pressure transient analysis technology has been applied to multiple injection projects. In general, the analysis results including formation and fracture properties (i.e. permeability, fracture half length, skin factor, and fracture closure pressure) are comparable to results from interactive analysis. Any discrepancies are mainly caused by poor data quality. Issues such as inconsistent selections of ISIP and different slopes defined for pre and after closure analyses also contribute to the divergence. Overall, the automated pressure transient analysis provides consistent results as the exact same criteria are applied to the pressure data, and analysis results are independent of the analyzer's experience and knowledge. As data from oil/gas industry increases exponentially over time, automated data transmission, storage, analysis and access are becoming necessary to maximize the value of the data and reduce operation cost. The automated pressure transient analysis presented here demonstrates that cloud storage and computing combined with automated analysis tools is a viable way to overcome big data challenges faced by oil/gas industry professionals.",https://doi.org/10.1016/j.petrol.2020.107627,2021,Yonggui Guo and Ibrahim Mohamed and Ali Zidane and Yashesh Panchal and Omar Abou-Sayed and Ahmed Abou-Sayed,AUTOMATED PRESSURE TRANSIENT ANALYSIS: A CLOUD-BASED APPROACH,article
622,17013,JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING,journal,09204105,"0,975",Q1,111,1174,2764,59146,13310,2752,"4,78","50,38",Netherlands,Western Europe,Elsevier,1987-2021,Fuel Technology (Q1); Geotechnical Engineering and Engineering Geology (Q1),"25,616",4.346,0.02651,"In recent years, machine learning has been adopted in the Oil and Gas industry as a promising technology for solutions to the most demanding problems like downhole parameters estimations and incidents detection. A big amount of available data makes this technology an attractive option for solving a wide variety of drilling problems, as well as a reliable candidate for performing big-data analysis and interpretation. Nevertheless, this approach may cause, in some cases, that petroleum engineering concepts are disregarded in favor of more data-intensive approaches. This study aims to evaluate the impact of drilling data measurement correction on data-driven model performance. In our study, besides using the standard data processing technologies, like gap filling, outlier removal, noise reduction etc., the physics-based drilling models are also implemented for data quality improvement and data correction in consideration of the measurement physics, rarely mentioned in most of publications. In our case study, recurrent neural networks (RNN) that are able to capture temporal natures of a signal are employed for the rate of penetration (ROP) estimation with an adjustable predictive window. The results show that the RNN model produces the best results when using the drilling data recovered through analytical methods. Moreover, the comprehensive data-driven model evaluation and engineering interpretation are conducted to facilitate better understanding of the data-driven models and their applications.",https://doi.org/10.1016/j.petrol.2021.109904,2022,Mauro A. Encinas and Andrzej T. Tunkiel and Dan Sui,DOWNHOLE DATA CORRECTION FOR DATA-DRIVEN RATE OF PENETRATION PREDICTION MODELING,article
623,21100389518,JOURNAL OF BUILDING ENGINEERING,journal,23527102,"0,974",Q1,39,777,721,38204,4094,720,"5,70","49,17",Netherlands,Western Europe,Elsevier BV,2015-2021,"Architecture (Q1); Building and Construction (Q1); Civil and Structural Engineering (Q1); Mechanics of Materials (Q1); Safety, Risk, Reliability and Quality (Q1)","5,990",5.318,0.00753,"With the increase in the energy consumption of air-conditioning (AC) systems in Chinese residential buildings, the realization of energy savings in AC systems has attracted increasing attention. The variable refrigerant flow (VRF) system is a common AC system for residential buildings in China. In most previous studies on VRF systems, onsite measurements or surveys were conducted to collect operational data. These traditional methods may face various data issues, such as limited sample sizes and invalid data, making them unable to capture the spatial and temporal performance features of VRF systems in residential buildings on a large scale. To fill this gap, with advances in data storage and transmission technology, Big Data methods have been widely used for data collection. In the present study, researchers adopted 16,985 sets of VRF system operation data from China as the database and conducted data analysis for both the spatial and temporal dimensions. Several key indicators were proposed from the two perspectives (spatial and temporal), including the part-space index (PSI), load ratio (LR), use duration (UD), and cooling energy consumption. The main findings were as follows: (1) The “part-time part-space” operation mode of residential VRF systems can be analyzed according to the statistical results of the UD and PSI. (2) An LR of <30% is the main operating condition for VRF systems in residential buildings. (3) Extracted typical LR patterns can reflect different user behavior. The statistical results obtained in this study provide a basis for VRF engineering projects.",https://doi.org/10.1016/j.jobe.2022.105219,2022,Hua Liu and Yi Wu and Da Yan and Shan Hu and Mingyang Qian,INVESTIGATION OF VRF SYSTEM COOLING OPERATION AND PERFORMANCE IN RESIDENTIAL BUILDINGS BASED ON LARGE-SCALE DATASET,article
624,11300153406,DISABILITY AND HEALTH JOURNAL,journal,19366574,"0,967",Q1,36,132,307,4567,796,278,"2,29","34,60",United States,Northern America,Elsevier Inc.,2008-2020,"Medicine (miscellaneous) (Q1); Public Health, Environmental and Occupational Health (Q1)","2,139",2.554,0.00403,,https://doi.org/10.1016/j.dhjo.2015.04.003,2015,Suzanne McDermott and Margaret A. Turk,WHAT ARE THE IMPLICATIONS OF THE BIG DATA PARADIGM SHIFT FOR DISABILITY AND HEALTH?,article
625,28249,JOURNAL OF PROFESSIONAL NURSING,journal,87557223,"0,960",Q1,53,137,229,4125,508,205,"1,74","30,11",United Kingdom,Western Europe,W.B. Saunders Ltd,1985-2020,Medicine (miscellaneous) (Q1); Nursing (miscellaneous) (Q1),"2,171",2.104,0.00228,,https://doi.org/10.1016/j.profnurs.2017.10.005,2018,Betty Rambur and Therese Fitzpatrick,A PLEA TO NURSE EDUCATORS: INCORPORATE BIG DATA USE AS A FOUNDATIONAL SKILL FOR UNDERGRADUATE AND GRADUATE NURSES,article
626,28425,FIRE SAFETY JOURNAL,journal,03797112,"0,958",Q1,78,260,442,8386,1566,437,"3,13","32,25",United Kingdom,Western Europe,Elsevier Ltd.,1977-2020,"Chemistry (miscellaneous) (Q1); Materials Science (miscellaneous) (Q1); Physics and Astronomy (miscellaneous) (Q1); Safety, Risk, Reliability and Quality (Q1)","5,861",2.764,0.00398,"Wildfires, whether natural or caused by humans, are considered among the most dangerous and devastating disasters around the world. Their complexity comes from the fact that they are hard to predict, hard to extinguish and cause enormous financial losses. To address this issue, many research efforts have been conducted in order to monitor, predict and prevent wildfires using several Artificial Intelligence techniques and strategies such as Big Data, Machine Learning, and Remote Sensing. The latter offers a rich source of satellite images, from which we can retrieve a huge amount of data that can be used to monitor wildfires. The method used in this paper combines Big Data, Remote Sensing and Data Mining algorithms (Artificial Neural Network and SVM) to process data collected from satellite images over large areas and extract insights from them to predict the occurrence of wildfires and avoid such disasters. For this reason, we implemented a methodology that serves this purpose by building a dataset based on Remote Sensing data related to the state of the crops (NDVI), meteorological conditions (LST), as well as the fire indicator “Thermal Anomalies”, these data, were acquired from “MODIS” (Moderate Resolution Imaging Spectroradiometer), a key instrument aboard the Terra and Aqua satellites. This dataset is available on GitHub via this link (https://github.com/ouladsayadyounes/Wildfires). Experiments were made using the big data platform “Databricks”. Experimental results gave high prediction accuracy (98.32%). These results were assessed using several validation strategies (e.g., classification metrics, cross-validation, and regularization) as well as a comparison with some wildfire early warning systems.",https://doi.org/10.1016/j.firesaf.2019.01.006,2019,Younes Oulad Sayad and Hajar Mousannif and Hassan {Al Moatassime},PREDICTIVE MODELING OF WILDFIRES: A NEW DATASET AND MACHINE LEARNING APPROACH,article
627,29253,NURSING OUTLOOK,journal,00296554,"0,953",Q1,57,119,315,4073,747,240,"2,37","34,23",United States,Northern America,Mosby Inc.,1953-2020,Nursing (miscellaneous) (Q1),"2,751",3.250,0.00323,"Background
Chronic diseases, such as opioid use disorder (OUD) require a multifaceted scientific approach to address their evolving complexity. The Council for the Advancement of Nursing Science's (Council) four nursing science priority areas (precision health; global health, determinants of health, and big data/data analytics) were established to provide a framework to address current complex health problems.
Purpose
To examine OUD research through the nursing science priority areas and evaluate the appropriateness of the priority areas as a framework for research on complex health conditions.
Method
OUD was used as an exemplar to explore the relevance of the nursing science priorities for future research.
Findings
Research in the four priority areas is advancing knowledge in OUD identification, prevention, and treatment. Intersection of OUD research population focus and methodological approach was identified among the priority areas.
Discussion
The Council priorities provide a relevant framework for nurse scientists to address complex health problems like OUD.",https://doi.org/10.1016/j.outlook.2020.02.001,2020,Patricia Eckardt and Donald Bailey and Holli A. DeVon and Cynthia Dougherty and Pamela Ginex and Cheryl A. Krause-Parello and Rita H. Pickler and Therese S. Richmond and Eleanor Rivera and Carol F. Roye and Nancy Redeker,OPIOID USE DISORDER RESEARCH AND THE COUNCIL FOR THE ADVANCEMENT OF NURSING SCIENCE PRIORITY AREAS,article
628,29253,NURSING OUTLOOK,journal,00296554,"0,953",Q1,57,119,315,4073,747,240,"2,37","34,23",United States,Northern America,Mosby Inc.,1953-2020,Nursing (miscellaneous) (Q1),"2,751",3.250,0.00323,"Background
Big data and cutting-edge analytic methods in nursing research challenge nurse scientists to extend the data sources and analytic methods used for discovering and translating knowledge.
Purpose
The purpose of this study was to identify, analyze, and synthesize exemplars of big data nursing research applied to practice and disseminated in key nursing informatics, general biomedical informatics, and nursing research journals.
Methods
A literature review of studies published between 2009 and 2015. There were 650 journal articles identified in 17 key nursing informatics, general biomedical informatics, and nursing research journals in the Web of Science database. After screening for inclusion and exclusion criteria, 17 studies published in 18 articles were identified as big data nursing research applied to practice.
Discussion
Nurses clearly are beginning to conduct big data research applied to practice. These studies represent multiple data sources and settings. Although numerous analytic methods were used, the fundamental issue remains to define the types of analyses consistent with big data analytic methods.
Conclusion
There are needs to increase the visibility of big data and data science research conducted by nurse scientists, further examine the use of state of the science in data analytics, and continue to expand the availability and use of a variety of scientific, governmental, and industry data resources. A major implication of this literature review is whether nursing faculty and preparation of future scientists (PhD programs) are prepared for big data and data science.",https://doi.org/10.1016/j.outlook.2016.11.021,2017,Bonnie L. Westra and Martha Sylvia and Elizabeth F. Weinfurter and Lisiane Pruinelli and Jung In Park and Dianna Dodd and Gail M. Keenan and Patricia Senk and Rachel L. Richesson and Vicki Baukner and Christopher Cruz and Grace Gao and Luann Whittenburg and Connie W. Delaney,BIG DATA SCIENCE: A LITERATURE REVIEW OF NURSING RESEARCH EXEMPLARS,article
629,29712,CLINICAL THERAPEUTICS,journal,01492918,"0,925",Q2,134,223,672,9030,1766,587,"2,33","40,49",United States,Northern America,Elsevier Inc.,1977-2020,Pharmacology (Q2); Pharmacology (medical) (Q2),"9,397",3.393,0.00964,"Purpose
Interest in leveraging real-world evidence (RWE) to support regulatory decision making for product effectiveness has been increasing globally as evident by the increasing number of regulatory frameworks and guidance documents. However, acceptance of RWE, especially before marketing for regulatory approval, differs across countries. In addition, guidance on the design and conduct of innovative clinical trials, such as randomized controlled registry studies, pragmatic trials, and other hybrid studies, is lacking.
Methods
We assessed the global regulatory environment with regard to RWE based on regional availability of the following 3 key regulatory elements: (1) RWE regulatory framework, (2) data quality and standards guidance. and (3) study methods guidance.
Findings
This article reviews the available frameworks and existing guidance from across the globe and discusses the observed gaps and opportunities for further development and harmonization.
Implications
Cross-country collaborations are encouraged to further shape and align RWE policies and help establish frameworks in countries without current policies with the goal of creating efficiencies when considering RWE to support regulatory decision-making globally.",https://doi.org/10.1016/j.clinthera.2022.01.012,2022,Leah Burns and Nadege Le Roux and Robert Kalesnik-Orszulak and Jennifer Christian and Mathias Hukkelhoven and Frank Rockhold and John O'Donnell,REAL-WORLD EVIDENCE FOR REGULATORY DECISION-MAKING: GUIDANCE FROM AROUND THE WORLD,article
630,29286,CLINICA CHIMICA ACTA,journal,00098981,"0,924",Q2,142,555,1269,26479,4130,1202,"3,35","47,71",Netherlands,Western Europe,Elsevier,1956-2020,Biochemistry (Q2); Biochemistry (medical) (Q2); Clinical Biochemistry (Q2); Medicine (miscellaneous) (Q2),"22,229",3.786,0.01641,"Although reference intervals (RIs) play an important role in clinical diagnosis, there remain significant differences with respect to race, gender, age and geographic location. Accordingly, the Clinical Laboratory Standards Institute (CLSI) EP28-A3c has recommended that clinical laboratories establish RIs appropriate to their subject population. Unfortunately, the traditional and direct approach to establish RIs relies on the recruitment of a sufficient number of healthy individuals of various age groups, collection and testing of large numbers of specimens and accurate data interpretation. The advent of the big data era has, however, created a unique opportunity to “mine” laboratory information. Unfortunately, this indirect method lacks standardization, consensus support and CLSI guidance. In this review we provide a historical perspective, comprehensively assess data processing and statistical methods, and post-verification analysis to validate this big data approach in establishing laboratory specific RIs.",https://doi.org/10.1016/j.cca.2022.01.001,2022,Dan Yang and Zihan Su and Min Zhao,BIG DATA AND REFERENCE INTERVALS,article
631,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"ABSTRACT
Introduction. With biomedical imaging research increasingly using large datasets, it becomes critical to find operator-free methods to quality control the data collected and the associated analysis. Attempts to use artificial intelligence (AI) to perform automated quality control (QC) for both single-site and multi-site datasets have been explored in some neuroimaging techniques (e.g. EEG or MRI), although these methods struggle to find replication in other domains. The aim of this study is to test the feasibility of an automated QC pipeline for brain [18F]-FDOPA PET imaging as a biomarker for the dopamine system. Methods. Two different Convolutional Neural Networks (CNNs) were used and combined to assess spatial misalignment to a standard template and the signal-to-noise ratio (SNR) relative to 200 static [18F]-FDOPA PET images that had been manually quality controlled from three different PET/CT scanners. The scans were combined with an additional 400 scans, in which misalignment (200 scans) and low SNR (200 scans) were simulated. A cross-validation was performed, where 80% of the data were used for training and 20% for validation. Two additional datasets of [18F]-FDOPA PET images (50 and 100 scans respectively with at least 80% of good quality images) were used for out-of-sample validation. Results. The CNN performance was excellent in the training dataset (accuracy for motion: 0.86 ± 0.01, accuracy for SNR: 0.69 ± 0.01), leading to 100% accurate QC classification when applied to the two out-of-sample datasets. Data dimensionality reduction affected the generalizability of the CNNs, especially when the classifiers were applied to the out-of-sample data from 3D to 1D datasets. Conclusions. This feasibility study shows that it is possible to perform automatic QC of [18F]-FDOPA PET imaging with CNNs. The approach has the potential to be extended to other PET tracers in both brain and non-brain applications, but it is dependent on the availability of large datasets necessary for the algorithm training.",https://doi.org/10.1016/j.cmpb.2021.106239,2021,Antonella D. Pontoriero and Giovanna Nordio and Rubaida Easmin and Alessio Giacomel and Barbara Santangelo and Sameer Jahuar and Ilaria Bonoldi and Maria Rogdaki and Federico Turkheimer and Oliver Howes and Mattia Veronese,AUTOMATED DATA QUALITY CONTROL IN FDOPA BRAIN PET IMAGING USING DEEP LEARNING,article
632,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Background and Objectives
Data Quality (DQ) programs are recognized as a critical aspect of new-generation research platforms using electronic health record (EHR) data for building Learning Healthcare Systems. The AP-HP Clinical Data Repository aggregates EHR data from 37 hospitals to enable large-scale research and secondary data analysis. This paper describes the DQ program currently in place at AP-HP and the lessons learned from two DQ campaigns initiated in 2017.
Materials and Methods
As part of the AP-HP DQ program, two domains - patient identification (PI) and healthcare services (HS) - were selected for conducting DQ campaigns consisting of 5 phases: defining the scope, measuring, analyzing, improving and controlling DQ. Semi-automated DQ profiling was conducted in two data sets – the PI data set containing 8.8 M patients and the HS data set containing 13,099 consultation agendas and 2122 care units. Seventeen DQ measures were defined and DQ issues were classified using a unified DQ reporting framework. For each domain, actions plans were defined for improving and monitoring prioritized DQ issues.
Results
Eleven identified DQ issues (8 for the PI data set and 3 for the HS data set) were categorized into completeness (n = 6), conformance (n = 3) and plausibility (n = 2) DQ issues. DQ issues were caused by errors from data originators, ETL issues or limitations of the EHR data entry tool. The action plans included sixteen actions (9 for the PI domain and 7 for the HS domain). Though only partial implementation, the DQ campaigns already resulted in significant improvement of DQ measures.
Conclusion
DQ assessments of hospital information systems are largely unpublished. The preliminary results of two DQ campaigns conducted at AP-HP illustrate the benefit of the engagement into a DQ program. The adoption of a unified DQ reporting framework enables the communication of DQ findings in a well-defined manner with a shared vocabulary. Dedicated tooling is needed to automate and extend the scope of the generic DQ program. Specific DQ checks will be additionally defined on a per-study basis to evaluate whether EHR data fits for specific uses.",https://doi.org/10.1016/j.cmpb.2018.10.016,2019,Christel Daniel and Patricia Serre and Nina Orlova and Stéphane Bréant and Nicolas Paris and Nicolas Griffon,INITIALIZING A HOSPITAL-WIDE DATA QUALITY PROGRAM. THE AP-HP EXPERIENCE.,article
633,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Background and Objectives
Data curation is a tedious task but of paramount relevance for data analytics and more specially in the health context where data-driven decisions must be extremely accurate. The ambition of TAQIH is to support non-technical users on 1) the exploratory data analysis (EDA) process of tabular health data, and 2) the assessment and improvement of its quality.
Methods
A web-based tool has been implemented with a simple yet powerful visual interface. First, it provides interfaces to understand the dataset, to gain the understanding of the content, structure and distribution. Then, it provides data visualization and improvement utilities for the data quality dimensions of completeness, accuracy, redundancy and readability.
Results
It has been applied in two different scenarios. (1) The Northern Ireland General Practitioners (GPs) Prescription Data, an open data set containing drug prescriptions. (2) A glucose monitoring tele health system dataset. Findings on (1) include: Features that had significant amount of missing values (e.g. AMP_NM variable 53.39%); instances that have high percentage of variable values missing (e.g. 0.21% of the instances with > 75% of missing values); highly correlated variables (e.g. Gross and Actual cost almost completely correlated (∼ + 1.0)). Findings on (2) include: Features that had significant amount of missing values (e.g. patient height, weight and body mass index (BMI) (> 70%), date of diagnosis 13%)); highly correlated variables (e.g. height, weight and BMI). Full detail of the testing and insights related to findings are reported.
Conclusions
TAQIH enables and supports users to carry out EDA on tabular health data and to assess and improve its quality. Having the layout of the application menu arranged sequentially as the conventional EDA pipeline helps following a consistent analysis process. The general description of the dataset and features section is very useful for the first overview of the dataset. The missing value heatmap is also very helpful in visually identifying correlations among missing values. The correlations section has proved to be supportive as a preliminary step before further data analysis pipelines, as well as the outliers section. Finally, the data quality section provides a quantitative value to the dataset improvements.",https://doi.org/10.1016/j.cmpb.2018.12.029,2019,Roberto {Álvarez Sánchez} and Andoni {Beristain Iraola} and Gorka {Epelde Unanue} and Paul Carlin,"TAQIH, A TOOL FOR TABULAR DATA QUALITY ASSESSMENT AND IMPROVEMENT IN THE CONTEXT OF HEALTH DATA",article
634,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Objective
To identify common temporal evolution profiles in biological data and propose a semi-automated method to these patterns in a clinical data warehouse (CDW).
Materials and Methods
We leveraged the CDW of the European Hospital Georges Pompidou and tracked the evolution of 192 biological parameters over a period of 17 years (for 445,000 + patients, and 131 million laboratory test results).
Results
We identified three common profiles of evolution: discretization, breakpoints, and trends. We developed computational and statistical methods to identify these profiles in the CDW. Overall, of the 192 observed biological parameters (87,814,136 values), 135 presented at least one evolution. We identified breakpoints in 30 distinct parameters, discretizations in 32, and trends in 79.
Discussion and conclusion
our method allowed the identification of several temporal events in the data. Considering the distribution over time of these events, we identified probable causes for the observed profiles: instruments or software upgrades and changes in computation formulas. We evaluated the potential impact for data reuse. Finally, we formulated recommendations to enable safe use and sharing of biological data collection to limit the impact of data evolution in retrospective and federated studies (e.g. the annotation of laboratory parameters presenting breakpoints or trends).",https://doi.org/10.1016/j.cmpb.2018.12.030,2019,Vincent Looten and Liliane {Kong Win Chang} and Antoine Neuraz and Marie-Anne Landau-Loriot and Benoit Vedie and Jean-Louis Paul and Laëtitia Mauge and Nadia Rivet and Angela Bonifati and Gilles Chatellier and Anita Burgun and Bastien Rance,WHAT CAN MILLIONS OF LABORATORY TEST RESULTS TELL US ABOUT THE TEMPORAL ASPECT OF DATA QUALITY? STUDY OF DATA SPANNING 17 YEARS IN A CLINICAL DATA WAREHOUSE,article
635,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,,https://doi.org/10.1016/j.cmpb.2019.06.013,2019,Carlos Sáez and Siaw-Teng Liaw and Eizen Kimura and Pascal Coorevits and Juan M Garcia-Gomez,GUEST EDITORIAL: SPECIAL ISSUE IN BIOMEDICAL DATA QUALITY ASSESSMENT METHODS,article
636,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Purpose
We present a Health Care System (HCS) based on integrated learning to achieve high-efficiency and high-precision integration of medical and health big data, and compared it with an internet-based integrated system.
Method
The method proposed in this paper adopts the Bagging integrated learning method and the Extreme Learning Machine (ELM) prediction model to obtain a high-precision strong learning model. In order to verify the integration efficiency of the system, we compare it with the Internet-based health big data integration system in terms of integration volume, integration efficiency, and storage space capacity.
Results
The HCS based on integrated learning relies on the Internet in terms of integration volume, integration efficiency, and storage space capacity. The amount of integration is proportional to the time and the integration time is between 170-450 ms, which is only half of the comparison system; whereby the storage space capacity reaches 8.3×28TB.
Conclusion
The experimental results show that the integrated learning-based HCS integrates medical and health big data with high integration volume and integration efficiency, and has high space storage capacity and concurrent data processing performance.",https://doi.org/10.1016/j.cmpb.2021.106293,2021,Yuguang Ye and Jianshe Shi and Daxin Zhu and Lianta Su and Jianlong Huang and Yifeng Huang,MANAGEMENT OF MEDICAL AND HEALTH BIG DATA BASED ON INTEGRATED LEARNING-BASED HEALTH CARE SYSTEM: A REVIEW AND COMPARATIVE ANALYSIS,article
637,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Background
In the age of information superhighway, big data play a significant role in information processing, extractions, retrieving and management. In computational biology, the continuous challenge is to manage the biological data. Data mining techniques are sometimes imperfect for new space and time requirements. Thus, it is critical to process massive amounts of data to retrieve knowledge. The existing software and automated tools to handle big data sets are not sufficient. As a result, an expandable mining technique that enfolds the large storage and processing capability of distributed or parallel processing platforms is essential.
Method
In this analysis, a contemporary distributed clustering methodology for imbalance data reduction using k-nearest neighbor (K-NN) classification approach has been introduced. The pivotal objective of this work is to illustrate real training data sets with reduced amount of elements or instances. These reduced amounts of data sets will ensure faster data classification and standard storage management with less sensitivity. However, general data reduction methods cannot manage very big data sets. To minimize these difficulties, a MapReduce-oriented framework is designed using various clusters of automated contents, comprising multiple algorithmic approaches.
Results
To test the proposed approach, a real DNA (deoxyribonucleic acid) dataset that consists of 90 million pairs has been used. The proposed model reduces the imbalance data sets from large-scale data sets without loss of its accuracy.
Conclusions
The obtained results depict that MapReduce based K-NN classifier provided accurate results for big data of DNA.",https://doi.org/10.1016/j.cmpb.2016.04.005,2016,Sarwar Kamal and Shamim Hasnat Ripon and Nilanjan Dey and Amira S. Ashour and V. Santhi,A MAPREDUCE APPROACH TO DIMINISH IMBALANCE PARAMETERS FOR BIG DEOXYRIBONUCLEIC ACID DATASET,article
638,23604,COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE,journal,01692607,"0,924",Q1,102,538,789,23721,4743,753,"6,27","44,09",Ireland,Western Europe,Elsevier Ireland Ltd,1985-2020,Computer Science Applications (Q1); Software (Q1); Health Informatics (Q2),"12,277",5.428,0.01119,"Background and objective
In recent years, several data quality conceptual frameworks have been proposed across the Data Quality and Information Quality domains towards assessment of quality of data. These frameworks are diverse, varying from simple lists of concepts to complex ontological and taxonomical representations of data quality concepts. The goal of this study is to design, develop and implement a platform agnostic computable data quality knowledge repository for data quality assessments.
Methods
We identified computable data quality concepts by performing a comprehensive literature review of articles indexed in three major bibliographic data sources. From this corpus, we extracted data quality concepts, their definitions, applicable measures, their computability and identified conceptual relationships. We used these relationships to design and develop a data quality meta-model and implemented it in a quality knowledge repository.
Results
We identified three primitives for programmatically performing data quality assessments: data quality concept, its definition, its measure or rule for data quality assessment, and their associations. We modeled a computable data quality meta-data repository and extended this framework to adapt, store, retrieve and automate assessment of other existing data quality assessment models.
Conclusion
We identified research gaps in data quality literature towards automating data quality assessments methods. In this process, we designed, developed and implemented a computable data quality knowledge repository for assessing quality and characterizing data in health data repositories. We leverage this knowledge repository in a service-oriented architecture to perform scalable and reproducible framework for data quality assessments in disparate biomedical data sources.",https://doi.org/10.1016/j.cmpb.2019.05.017,2019,Naresh Sundar Rajan and Ramkiran Gouripeddi and Peter Mo and Randy K. Madsen and Julio C. Facelli,TOWARDS A CONTENT AGNOSTIC COMPUTABLE KNOWLEDGE REPOSITORY FOR DATA QUALITY ASSESSMENT,article
639,28805,NURSE EDUCATION IN PRACTICE,journal,14715953,"0,924",Q1,47,193,486,6984,1193,433,"2,24","36,19",United Kingdom,Western Europe,Churchill Livingstone,2001-2020,Education (Q1); Nursing (miscellaneous) (Q1); Medicine (miscellaneous) (Q2),"3,334",2.281,0.00456,"The pace of technological evolution in healthcare is advancing. In this article key technology trends are identified that are likely to influence nursing practice and education over the next decade. The complexity of curricular revision can create challenges in the face of rapid practice change. Nurse educators are encouraged to consider the role of electronic health records (EHRs), wearable technologies, big data and data analytics, and increased patient engagement as key areas for curriculum development. Student nurses, and those already in practice, should be offered ongoing educational opportunities to enhance a wide spectrum of professional informatics skills. The nurses of 2025 will most certainly inhabit a very different practice environment than what exists today and technology will be key in this transformation. Nurse educators must prepare now to lead these practitioners into the future.",https://doi.org/10.1016/j.nepr.2016.12.007,2017,Tracie Risling,EDUCATING THE NURSES OF 2025: TECHNOLOGY TRENDS OF THE NEXT DECADE,article
640,26529,FUZZY SETS AND SYSTEMS,journal,01650114,"0,902",Q1,169,333,570,11642,2262,560,"3,72","34,96",Netherlands,Western Europe,Elsevier,1978-2020,Artificial Intelligence (Q1); Logic (Q1),"17,883",3.343,0.00737,,https://doi.org/10.1016/j.fss.2018.05.022,2018,Sadok Ben Yahia and Anne Laurent and Gabriella Pasi,PREFACE: SPECIAL ISSUE ON BIG DATA,article
641,29806,INTERNATIONAL JOURNAL OF ACCOUNTING INFORMATION SYSTEMS,journal,14670895,"0,897",Q1,53,21,51,1375,290,50,"5,56","65,48",United States,Northern America,Elsevier Inc.,2000-2020,Finance (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Accounting (Q2),"1,009",4.400,0.00056,"Given exponential growth in the size of big data, its multi-channel sources and variability in quality that create challenges concerning cost-effective use, firms have invested significantly in databases and analytical tools to inform decision-making. In this regard, one means to avoid the costs associated with producing less than insightful reports and negative effects on performance through wasted resources is prioritizing data in terms of relevance and quality. The aim of this study is to investigate this approach by developing and testing a scale to evaluate Big Data Availability and the role of Big Data Prioritization for more effective use of big data in decision-making and performance. Focusing on the context of supply chain management (SCM), we validate this scale through a survey involving 84 managers. Findings support a positive association between Big Data Availability and its use in SCM decision-making, and suggest that Big Data Prioritization, as conceptualized in the study, has a positive impact on the use of big data in SCM decision-making and SCM performance. Through developing a scale to evaluate association between Big Data Availability and use in SCM decision-making, we make an empirical contribution to value generation from big data.",https://doi.org/10.1016/j.accinf.2020.100470,2020,Carla Wilkin and Aldónio Ferreira and Kristian Rotaru and Luigi Red Gaerlan,BIG DATA PRIORITIZATION IN SCM DECISION-MAKING: ITS ROLE AND PERFORMANCE IMPLICATIONS,article
642,29806,INTERNATIONAL JOURNAL OF ACCOUNTING INFORMATION SYSTEMS,journal,14670895,"0,897",Q1,53,21,51,1375,290,50,"5,56","65,48",United States,Northern America,Elsevier Inc.,2000-2020,Finance (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Accounting (Q2),"1,009",4.400,0.00056,"With corporate investment in Big Data of $34 billion in 2013 growing to $232 billion through 2016 (Gartner 2012), the Big 4 accounting firms are aiming to be at the forefront of Big Data implementations. Notably, they see Big Data as an increasingly essential part of their assurance practice. We argue that while there is a place for Big Data in auditing, its application to auditing is less clear than it is in the other fields, such as marketing and medical research. The objectives of this paper are to: (1) provide a discussion of both the inhibitors of incorporating Big Data into financial statement audits; and (3) present a research agenda to identify approaches to ameliorate those inhibitors.",https://doi.org/10.1016/j.accinf.2016.07.004,2016,Michael Alles and Glen L. Gray,INCORPORATING BIG DATA IN AUDITS: IDENTIFYING INHIBITORS AND A RESEARCH AGENDA TO ADDRESS THOSE INHIBITORS,article
643,29806,INTERNATIONAL JOURNAL OF ACCOUNTING INFORMATION SYSTEMS,journal,14670895,"0,897",Q1,53,21,51,1375,290,50,"5,56","65,48",United States,Northern America,Elsevier Inc.,2000-2020,Finance (Q1); Information Systems and Management (Q1); Management Information Systems (Q1); Accounting (Q2),"1,009",4.400,0.00056,"The nature of management accountants' responsibility is evolving from merely reporting aggregated historical value to also including organizational performance measurement and providing management with decision related information. Corporate information systems such as enterprise resource planning (ERP) systems have provided management accountants with both expanded data storage power and enhanced computational power. With big data extracted from both internal and external data sources, management accountants now could utilize data analytics techniques to answer the questions including: what has happened (descriptive analytics), what will happen (predictive analytics), and what is the optimized solution (prescriptive analytics). However, research shows that the nature and scope of managerial accounting has barely changed and that management accountants employ mostly descriptive analytics, some predictive analytics, and a bare minimum of prescriptive analytics. This paper proposes a Managerial Accounting Data Analytics (MADA) framework based on the balanced scorecard theory in a business intelligence context. MADA provides management accountants the ability to utilize comprehensive business analytics to conduct performance measurement and provide decision related information. With MADA, three types of business analytics (descriptive, predictive, and prescriptive) are implemented into four corporate performance measurement perspectives (financial, customer, internal process, and learning and growth) in an enterprise system environment. Other related issues that affect the successful utilization of business analytics within a corporate-wide business intelligence (BI) system, such as data quality and data integrity, are also discussed. This paper contributes to the literature by discussing the impact of business analytics on managerial accounting from an enterprise systems and BI perspective and by providing the Managerial Accounting Data Analytics (MADA) framework that incorporates balanced scorecard methodology.",https://doi.org/10.1016/j.accinf.2017.03.003,2017,Deniz Appelbaum and Alexander Kogan and Miklos Vasarhelyi and Zhaokai Yan,IMPACT OF BUSINESS ANALYTICS AND ENTERPRISE SYSTEMS ON MANAGERIAL ACCOUNTING,article
644,61490,BIOSYSTEMS ENGINEERING,journal,15375110,"0,894",Q1,110,236,588,9794,3137,581,"5,07","41,50",United States,Northern America,Academic Press Inc.,2002-2020,Agronomy and Crop Science (Q1); Animal Science and Zoology (Q1); Control and Systems Engineering (Q1); Food Science (Q1); Soil Science (Q1),"9,924",4.123,0.00737,"The Internet of Things is allowing agriculture, here specifically arable farming, to become data-driven, leading to more timely and cost-effective production and management of farms, and at the same time reducing their environmental impact. This review is addressing an analytical survey of the current and potential application of Internet of Things in arable farming, where spatial data, highly varying environments, task diversity and mobile devices pose unique challenges to be overcome compared to other agricultural systems. The review contributes an overview of the state of the art of technologies deployed. It provides an outline of the current and potential applications, and discusses the challenges and possible solutions and implementations. Lastly, it presents some future directions for the Internet of Things in arable farming. Current issues such as smart phones, intelligent management of Wireless Sensor Networks, middleware platforms, integrated Farm Management Information Systems across the supply chain, or autonomous vehicles and robotics stand out because of their potential to lead arable farming to smart arable farming. During the implementation, different challenges are encountered, and here interoperability is a key major hurdle throughout all the layers in the architecture of an Internet of Things system, which can be addressed by shared standards and protocols. Challenges such as affordability, device power consumption, network latency, Big Data analysis, data privacy and security, among others, have been identified by the articles reviewed and are discussed in detail. Different solutions to all identified challenges are presented addressing technologies such as machine learning, middleware platforms, or intelligent data management.",https://doi.org/10.1016/j.biosystemseng.2019.12.013,2020,Andrés Villa-Henriksen and Gareth T.C. Edwards and Liisa A. Pesonen and Ole Green and Claus Aage Grøn Sørensen,"INTERNET OF THINGS IN ARABLE FARMING: IMPLEMENTATION, APPLICATIONS, CHALLENGES AND POTENTIAL",article
645,26617,EUROPEAN JOURNAL OF INTERNAL MEDICINE,journal,09536205,"0,894",Q2,71,384,907,8947,1904,557,"2,14","23,30",Netherlands,Western Europe,Elsevier,1989-2020,Internal Medicine (Q2),"7,083",4.487,0.00933,"The big data approach offers a powerful alternative to Evidence-based medicine. This approach could guide cancer management thanks to machine learning application to large-scale data. Aim of the Thyroid CoBRA (Consortium for Brachytherapy Data Analysis) project is to develop a standardized web data collection system, focused on thyroid cancer. The Metabolic Radiotherapy Working Group of Italian Association of Radiation Oncology (AIRO) endorsed the implementation of a consortium directed to thyroid cancer management and data collection. The agreement conditions, the ontology of the collected data and the related software services were defined by a multicentre ad hoc working-group (WG). Six Italian cancer centres were firstly started the project, defined and signed the Thyroid COBRA consortium agreement. Three data set tiers were identified: Registry, Procedures and Research. The COBRA-Storage System (C-SS) appeared to be not time-consuming and to be privacy respecting, as data can be extracted directly from the single centre's storage platforms through a secured connection that ensures reliable encryption of sensible data. Automatic data archiving could be directly performed from Image Hospital Storage System or the Radiotherapy Treatment Planning Systems. The C-SS architecture will allow “Cloud storage way” or “distributed learning” approaches for predictive model definition and further clinical decision support tools development. The development of the Thyroid COBRA data Storage System C-SS through a multicentre consortium approach appeared to be a feasible tool in the setup of complex and privacy saving data sharing system oriented to the management of thyroid cancer and in the near future every cancer type.",https://doi.org/10.1016/j.ejim.2018.02.012,2018,Luca Tagliaferri and Carlo Gobitti and Giuseppe Ferdinando Colloca and Luca Boldrini and Eleonora Farina and Carlo Furlan and Fabiola Paiar and Federica Vianello and Michela Basso and Lorenzo Cerizza and Fabio Monari and Gabriele Simontacchi and Maria Antonietta Gambacorta and Jacopo Lenkowicz and Nicola Dinapoli and Vito Lanzotti and Renzo Mazzarotto and Elvio Russi and Monica Mangoni,A NEW STANDARDIZED DATA COLLECTION SYSTEM FOR INTERDISCIPLINARY THYROID CANCER MANAGEMENT: THYROID COBRA,article
646,26617,EUROPEAN JOURNAL OF INTERNAL MEDICINE,journal,09536205,"0,894",Q2,71,384,907,8947,1904,557,"2,14","23,30",Netherlands,Western Europe,Elsevier,1989-2020,Internal Medicine (Q2),"7,083",4.487,0.00933,,https://doi.org/10.1016/j.ejim.2018.05.019,2018,Andrea Damiani and Graziano Onder and Vincenzo Valentini,LARGE DATABASES (BIG DATA) AND EVIDENCE-BASED MEDICINE,article
647,17957,COMPUTERS IN BIOLOGY AND MEDICINE,journal,00104825,"0,884",Q1,94,383,936,19977,5223,923,"5,59","52,16",United Kingdom,Western Europe,Elsevier Ltd.,1970-2020,Computer Science Applications (Q1); Health Informatics (Q2),"9,751",4.589,0.01186,"Background
Clinical notes are ubiquitous resources offering potential value in optimizing critical care via data mining technologies.
Objective
To determine the predictive value of clinical notes as prognostic markers of 1-year all-cause mortality among people with diabetes following critical care.
Materials and methods
Mortality of diabetes patients were predicted using three cohorts of clinical text in a critical care database, written by physicians (n = 45253), nurses (159027), and both (n = 204280). Natural language processing was used to pre-process text documents and LASSO-regularized logistic regression models were trained and tested. Confusion matrix metrics of each model were calculated and AUROC estimates between models were compared. All predictive words and corresponding coefficients were extracted. Outcome probability associated with each text document was estimated.
Results
Models built on clinical text of physicians, nurses, and the combined cohort predicted mortality with AUROC of 0.996, 0.893, and 0.922, respectively. Predictive performance of the models significantly differed from one another whereas inter-rater reliability ranged from substantial to almost perfect across them. Number of predictive words with non-zero coefficients were 3994, 8159, and 10579, respectively, in the models of physicians, nurses, and the combined cohort. Physicians’ and nursing notes, both individually and when combined, strongly predicted 1-year all-cause mortality among people with diabetes following critical care.
Conclusion
Clinical notes of physicians and nurses are strong and novel prognostic markers of diabetes-associated mortality in critical care, offering potentially generalizable and scalable applications. Clinical text-derived personalized risk estimates of prognostic outcomes such as mortality could be used to optimize patient care.",https://doi.org/10.1016/j.compbiomed.2021.104305,2021,Kushan {De Silva} and Noel Mathews and Helena Teede and Andrew Forbes and Daniel Jönsson and Ryan T. Demmer and Joanne Enticott,CLINICAL NOTES AS PROGNOSTIC MARKERS OF MORTALITY ASSOCIATED WITH DIABETES MELLITUS FOLLOWING CRITICAL CARE: A RETROSPECTIVE COHORT ANALYSIS USING MACHINE LEARNING AND UNSTRUCTURED BIG DATA,article
648,17957,COMPUTERS IN BIOLOGY AND MEDICINE,journal,00104825,"0,884",Q1,94,383,936,19977,5223,923,"5,59","52,16",United Kingdom,Western Europe,Elsevier Ltd.,1970-2020,Computer Science Applications (Q1); Health Informatics (Q2),"9,751",4.589,0.01186,"Background
Building cancer risk models from real-world data requires overcoming challenges in data preprocessing, efficient representation, and computational performance. We present a case study of a cloud-based approach to learning from de-identified electronic health record data and demonstrate its effectiveness for melanoma risk prediction.
Methods
We used a hybrid distributed and non-distributed approach to computing in the cloud: distributed processing with Apache Spark for data preprocessing and labeling, and non-distributed processing for machine learning model training with scikit-learn. Moreover, we explored the effects of sampling the training dataset to improve computational performance. Risk factors were evaluated using regression weights as well as tree SHAP values.
Results
Among 4,061,172 patients who did not have melanoma through the 2016 calendar year, 10,129 were diagnosed with melanoma within one year. A gradient-boosted classifier achieved the best predictive performance with cross-validation (AUC = 0.799, Sensitivity = 0.753, Specificity = 0.688). Compared to a model built on the original data, a dataset two orders of magnitude smaller could achieve statistically similar or better performance with less than 1% of the training time and cost.
Conclusions
We produced a model that can effectively predict melanoma risk for a diverse dermatology population in the U.S. by using hybrid computing infrastructure and data sampling. For this de-identified clinical dataset, sampling approaches significantly shortened the time for model building while retaining predictive accuracy, allowing for more rapid machine learning model experimentation on familiar computing machinery. A large number of risk factors (>300) were required to produce the best model.",https://doi.org/10.1016/j.compbiomed.2019.04.039,2019,Aaron N. Richter and Taghi M. Khoshgoftaar,EFFICIENT LEARNING FROM BIG DATA FOR CANCER RISK MODELING: A CASE STUDY WITH MELANOMA,article
649,16044,ELECTRIC POWER SYSTEMS RESEARCH,journal,03787796,"0,845",Q1,122,643,1165,20949,5369,1158,"4,25","32,58",Netherlands,Western Europe,Elsevier BV,1977-2021,Electrical and Electronic Engineering (Q1); Energy Engineering and Power Technology (Q1),"13,115",3.414,0.01287,"This paper provides a survey of big data analytics applications and associated implementation issues. The emphasis is placed on applications that are novel and have demonstrated value to the industry, as illustrated using field data and practical applications. The paper reflects on the lessons learned from initial implementations, as well as ideas that are yet to be explored. The various data science trends treated in the literature are outlined, while experiences from applying them in the electricity grid setting are emphasized to pave the way for future applications. The paper ends with opportunities and challenges, as well as implementation goals and strategies for achieving impactful outcomes.",https://doi.org/10.1016/j.epsr.2020.106788,2020,Mladen Kezunovic and Pierre Pinson and Zoran Obradovic and Santiago Grijalva and Tao Hong and Ricardo Bessa,BIG DATA ANALYTICS FOR FUTURE ELECTRICITY GRIDS,article
650,20870,TELECOMMUNICATIONS POLICY,journal,03085961,"0,840",Q1,69,87,224,5352,831,212,"3,51","61,52",United Kingdom,Western Europe,Elsevier Ltd.,1976-2020,Electrical and Electronic Engineering (Q1); Human Factors and Ergonomics (Q1); Information Systems (Q1),"2,745",3.036,0.00269,"This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users׳ adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design.",https://doi.org/10.1016/j.telpol.2015.03.007,2016,Dong-Hee Shin,DEMYSTIFYING BIG DATA: ANATOMY OF BIG DATA DEVELOPMENTAL PROCESS,article
651,17697,PUBLIC HEALTH,journal,00333506,"0,826",Q2,75,433,874,11891,2120,788,"2,10","27,46",Netherlands,Western Europe,Elsevier,"1888-1913, 1915-2020","Medicine (miscellaneous) (Q2); Public Health, Environmental and Occupational Health (Q2)","7,603",2.427,0.01222,,https://doi.org/10.1016/j.puhe.2015.02.013,2015,P. Mackie and F. Sim and C. Johnman,BIG DATA! BIG DEAL?,article
652,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Quality-related process monitoring is an important tool to ensure process safety and product quality. However, the existence of process dynamics and multi-rate sampling makes it difficult to construct an efficient monitoring model. In order to handle process dynamics and multi-rate sampling, a multi-rate process monitoring method based on a dynamic dual-latent variable model is proposed. The model involves two sets of latent variables modelled as first-order Markov chains, which are used to capture both quality-related and quality-unrelated dynamic information. In addition, to deal with multiple sampling rates in the process data, the proposed model is combined with a multi-rate Kalman filtering technique. An expectation maximization(EM) algorithm is used to estimate the unknown parameters and a fault detection strategy is developed. The higher fault detection rate of the proposed method is verified by two application studies including a real industrial experiment and the Tennessee Eastman(TE) process.",10.1109/TIM.2022.3180436,2022,,ENHANCED DYNAMIC DUAL-LATENT VARIABLE MODEL FOR MULTI-RATE PROCESS MONITORING AND ITS INDUSTRIAL APPLICATION,
653,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"In this article, a fuzzy adaptive Kalman filter (FAKaF)-based method was proposed for image reconstruction in electrical capacitance tomography (ECT). When the Kalman filter (KF) is applied for image reconstruction in ECT, two key parameters need to be predetermined, i.e., the observation noise covariance ( ${R}$ ) and the initial estimation error covariance ( ${P}_{0}$ ). These two parameters play significant roles in image reconstruction. For instance, a larger  ${R}$  may lead to a blurrier image. A larger  ${P}_{0}$  can cause increasing artifacts or even heavier distortion of the reconstructed image. In this work, a FAKaF was established to adjust  ${P}_{0}$  using  ${R}$  calculated from the measured capacitances so as to improve the quality of the reconstructed image. The implementation of the FAKaF-based reconstruction method was divided into offline and online parts. In the offline part, the Kalman gain and the corresponding fuzzy control table were precalculated, aiming to save resource consumption and improve imaging speed. Simulations and experiments were carried out to evaluate the image quality and computational cost of the proposed method. Comparisons were made with three widely-used algorithms. Results show that the proposed FAKaF-based method yields good quality images and few artifacts, needs few iterations and consumes less computational cost.",10.1109/TIM.2021.3099563,2021,,IMAGE RECONSTRUCTION BASED ON FUZZY ADAPTIVE KALMAN FILTER IN ELECTRICAL CAPACITANCE TOMOGRAPHY,
654,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"To address the problem that the high dimensionality, time series, coupling, and multiple timescales of production data in the process industry lead to the low accuracy of traditional prediction models, we propose a multitimescale data enhancement and cement clinker free calcium oxide (f-CaO) prediction method based on the regression-Wasserstein generative adversarial net (R-WGAN) model. The model is built using a combination of WGAN and regression prediction networks. First, the data are extracted according to the principle of sliding window to eliminate the effect of time-varying delay between data in data enhancement and prediction, and a dual data pathway is used for data stitching so that data of different timescales can be enhanced at the same time. We then augment the data with a generator network, use a discriminator network to judge the goodness of the generated data, and propose an auxiliary evaluation strategy to evaluate whether the high-dimensional generated data conform to the actual laws, expand the training set of the regression prediction network with the generated data that conform to the laws, and finally achieve the prediction of cement clinker f-CaO. The model was applied in the quality management system of a cement company for simulation, and experiments showed that the model with data enhancement has the advantages of high accuracy, robustness, and good generalization in cement clinker f-CaO prediction.",10.1109/TIM.2021.3126832,2022,,R-WGAN-BASED MULTITIMESCALE ENHANCEMENT METHOD FOR PREDICTING F-CAO CEMENT CLINKER,
655,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Electrical capacitance tomography (ECT) is a technique to visualize the permittivity distribution inside a domain from the interelectrode mutual capacitances on the domain boundary. The potential applications of ECT in nondestructive testing (NDT) depend on accurate and stable image reconstruction. To improve image quality, this article presents a reconstruction framework with the sparse representation of phase boundaries in two-phase distributions. By adopting a sparsity-promoting basis, i.e., radial basis functions, the reconstruction problem is transformed into searching for the optimal phase boundaries and real-permittivity values of inclusions by formulating an optimization problem accordingly. This can reduce the number of unknowns significantly and has a strong ability to accommodate to the topology changes of inclusion geometries, which can improve the reconstruction accuracy and robustness. Both simulation and phantom experiments are performed to investigate the reconstruction performance, especially regarding the antinoise ability and robustness against choices of model parameters. Compared with typical conventional methods, our method can not only provide significantly improved image quality but also accurately estimate the real-permittivity values of inclusions. This would enable ECT to be applied in challenging NDT applications.",10.1109/TIM.2020.3007908,2021,,SIMULTANEOUS SHAPE AND PERMITTIVITY RECONSTRUCTION IN ECT WITH SPARSE REPRESENTATION: TWO-PHASE DISTRIBUTION IMAGING,
656,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Usually, the sensitivity matrix-based algorithms are used for image reconstruction in electrical tomography. These algorithms assume that the inverse problem is like that in the well-established medical CT and find successful applications. In the medical CT, rather than using the matrix-based algorithms, the inverse Radon transform and its derivatives dominate. However, these inverse transforms have not been introduced to electrical tomography due to a lack of the link between the parallel projections and electrical distributions. This article presents a map from electrical field lines to parallel lines in the inverse Radon transform and a novel image reconstruction algorithm by using the transform for dual-modality electrical tomography. The transform is realized through mapping the coordinates in electric field to the assumed parallel projections. The points of intersections between electrical field lines from different exciting electrodes are mapped to those of parallel lines from the related projections in a typical inverse Radon transform. Unlike the medical CT, different excitation schemes are related to distinct equivalent projections, and iterative scanning is used to apply all available projected data. Simulated and experimental data are implemented to validate the feasibility and effectiveness of the proposed algorithm, and performance comparisons are made with three algorithms, such as Calderon’s method, iterative method based on electrical field lines, and typical Landweber method. The proposed method yields good quality images in the least time and dynamic flames are monitored. Dual-modality images of material distributions are obtained to capture the ignition and blowout of the flame evolution in a Bunsen burner.",10.1109/TIM.2020.2990262,2020,,INVERSE RADON METHOD BASED ON ELECTRICAL FIELD LINES FOR DUAL-MODALITY ELECTRICAL TOMOGRAPHY,
657,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"This article introduces a general-purpose framework aimed at capturing the elusive concept of quality of measurement information (MI), a critical issue for both researchers and practitioners when dealing with MI-enabled decision-making. The framework is a blueprint for the definition, assessment, communication, and improvement of MI quality, as analyzed through a set of general criteria, classified according to the syntactic, semantic, and pragmatic layers of semiotics, as suggested in the ISO 8000-8:2015 technical standard. The top-down analysis, where each criterion is specified in terms of characteristics and each characteristic in terms of domain-related indicators, is complemented with a bottom-up synthesis and operationalized by means of a flowchart. An application example, about the quality of information provided by the networks of measurement instruments reporting pollutants in the air, is presented to test the usefulness and the limitations of the framework.",10.1109/TIM.2020.3047954,2021,,QUALITY OF MEASUREMENT INFORMATION IN DECISION-MAKING,
658,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"The wavelength modulation spectroscopy (WMS) method is typically used in the tunable diode laser absorption spectroscopy (TDLAS) for spectrum extraction in a noisy background. Usually, two entire absorption spectra for target species are scanned in a cascade way in the WMS method, and it limits the temporal response of the TDLAS sensor. In this article, the frequency-division multiplexing and main peak scanning method were introduced to the WMS method and enabled a high frame rate six times that in the classical TDLAS sensor at the same scanning speed. For the first time, two wavelengths modulated at different frequencies were used to extract the absorptions in parallel along various laser paths and implemented successfully on a TDLAS tomography hardware, to reconstruct the distributions of both temperature and species concentrations, at a frame rate up to 10 kHz. A five-view fan-beam tomographic sensor was utilized in the tomographic imaging. In each view, lasers at two wavelengths were selected and modulated at different sinusoidal frequencies on the same sawtooth signal. Numerical simulations varied the high-quality tomographic imaging of both temperature and H2O molar concentration distributions for different phantoms. Experiments were also carried out on dynamic flames, which were generated by exciting a Bunsen burner acoustically. The acoustic excitation frequency varied from 40 to 750 Hz, and the results of the tomographic images agreed well with the flame evolutions.",10.1109/TIM.2020.2998935,2020,,FREQUENCY-DIVISION MULTIPLEXING AND MAIN PEAK SCANNING WMS METHOD FOR TDLAS TOMOGRAPHY IN FLAME MONITORING,
659,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Radio tomographic imaging (RTI) is a technology to locate the target by using an attenuation image. The attenuation image can be reconstructed from the shadowing received signal strength (RSS) measurements in a wireless network. However, due to multi-path interference and the limited measuring capability in hardware, not all the RSS measurements in a wireless network are informative shadowing measurements. Some measurements may increase or remain unchanged when the target shadows some links in the wireless network, which means that this part of RSS measurements is polluted. If the polluted RSS measurements are used to reconstruct the attenuation image, the image quality and the localization accuracy will deteriorate. To alleviate the effect of polluted RSS measurements, a dual-RTI approach with shadowing-measurement awareness is developed in this article. The proposed dual-RTI consists of two steps: 1) signal reconstruction step in dual space and 2) a backprojection step to obtain the attenuation image. The reconstruction in dual space can select the informative shadowing measurements automatically and allocate superior weights to them. Then, the backprojection step just utilizes the measurement vectors from the shadowing links to obtain the attenuation image. These two steps allow the dual-RTI to achieve better image quality and localization accuracy. Furthermore, the dual-RTI reduces the time consumption of the localization system, which facilitates the practical engineering applications. Finally, experiments from three different scenarios are conducted to validate the advantages of the dual-RTI approach.",10.1109/TIM.2019.2942171,2020,,DUAL-RADIO TOMOGRAPHIC IMAGING WITH SHADOWING-MEASUREMENT AWARENESS,
660,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"In this article, an annular electrical capacitance tomography (ECT) sensor was designed, and a revised Calderon image reconstruction method was proposed for monitoring the flashback flame of a bluff-body burner. The central support of the bluff-body was used as the internal electrode of the sensor, and the external electrode array was fixed on the outer surface of the burner. The capacitance values of all pairs of electrodes, including the internal and external, composed a boundary capacitance matrix of the annular sensing field. The revised Calderon method was compared with the commonly used sensitivity matrix-based methods including the linear back projection (LBP) and Landweber methods for imaging the cross-sectional distribution of permittivity which is continuous in value. Simulation results show that the revised Calderon method is of higher image reconstruction quality than the LBP and Landweber methods. In the experiment, the designed annular ECT sensor and revised Calderon method were used to monitor the flame flashback phenomenon of the bluff-body burner. The experiment results not only monitored the occurrence of flame flashback, revealed the variations of flame flashback intensity and time with the fuel:air equivalent ratio, but also determined the boundary condition of flame flashback of the bluff-body burner. The proposed method provides a new approach for experimental study on the influencing factors of flame flashback, and thus can be applied to research on combustion stability and high-performance burner design.",10.1109/TIM.2021.3094989,2021,,REVISED CALDERON METHOD OF ANNULAR ECT FOR IMAGING FLASHBACK FLAME OF A BLUFF-BODY BURNER,
661,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Light detection and ranging (LiDAR) provides a 3-D understanding of environment and plays an important role in autonomous driving. To study the influence of 3-D data quality on the environment perception and provide a theoretical basis for optimizing system design, a multi-beam LiDAR perception assessment model has been established to reveal the relationship between data quality and multi-parameters, including system and motion parameters. A novel ground segmentation algorithm was proposed with a combination of the grid elevation and the neighbor relationship, which was used to validate how the data quality influences the results of environment perception. By the way of down-sampling based on the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) dataset, the experimental results showed that the proposed ground segmentation with combination of grid-elevation and neighbor-relationship (GSCGN) method was superior than other general ground segmentation methods in terms of accuracy and efficiency. It should be noted that the mean vertical angular resolution (MVAR), laser repetition frequency, and beam numbers were the dominant influencing parameters on the point density and the accuracy of ground segmentation. Based on the experimental results, the lower limits of system parameters were determined as 16-beam and 4-kHz repetition frequency, with the acceptable recall of 92.2% for ground and 93.5% for object, the accuracy of 92.9% and the runtime of 0.036 s, which can not only provide a reliable environment perception effect, but also reducing the computational burden to satisfy the real-time autonomous driving. This study offers a meaningful investigation to guide LiDAR system design with balancing the contradiction between the optimized system design and the high-degree environment perception.",10.1109/TIM.2021.3094230,2021,,STUDY OF A MULTI-BEAM LIDAR PERCEPTION ASSESSMENT MODEL FOR REAL-TIME AUTONOMOUS DRIVING,
662,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"This paper is devoted to the design and implementation of a multipurpose platform (MPP) for power system monitoring and analysis. This MPP is a novel device, which combines the abilities of a power quality (PQ) analyzer, an event logger, a synchronized phasor measurement unit, and an interarea oscillation identifier, all in one device. The multiple functions of the proposed MPP can serve the needs of the power system operators (SOs) as a wide-area monitoring system to observe the states and stability of the power system, and as a PQ analyzer to monitor the PQ events and parameters, permanently. Furthermore, the algorithms of flicker and harmonic current contributions at a point of common coupling can be embedded on this MPP, to determine the individual contributions of different loads supplied from the same bus. The operational features of the developed MPP have been tested on the Turkish electricity transmission system and its interfaces with the distribution system by installing 450 MPPs and integrating them with a monitoring and control center. The proposed all-in-one MPP can therefore meet the multiple requirements of the power SOs to serve the needs of modern electricity markets and convert an ordinary electricity system to a smart grid.",10.1109/TIM.2013.2281556,2014,,MULTIPURPOSE PLATFORM FOR POWER SYSTEM MONITORING AND ANALYSIS WITH SAMPLE GRID APPLICATIONS,
663,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Optical coherence tomography (OCT) images are widely used for clinical examination of the retina. Automatic deep learning-based methods have been developed to classify normal and pathological OCT images. However, lack of the big enough training data reduces the performance of these models. A synthesis of data using generative adversarial networks (GANs) is already known as an efficient alternative to increase the amount of the training data. However, the recent works show that despite high structural similarity between the synthetic data and the real images, a considerable distortion is observed in frequency domain. Here, we propose a dual-discriminator Fourier acquisitive GAN (DDFA-GAN) to generate more realistic OCT images with considering the Fourier domain similarity in structural design of the GAN. By applying two discriminators, the proposed DDFA-GAN is jointly trained with the Fourier and spatial details of the images and is proven to be feasible with a limited number of training data. Results are compared with popular GANs, namely, deep convolutional GAN (DCGAN), Wasserstein GAN with gradient penalized (WGAN-GP), and least square GAN (LS-GAN). In comparison, a Fréchet inception distance (FID) score of 51.30 and a multiscale structural similarity index measure (MS-SSIM) of 0.19 indicate the superiority of the proposed method in producing images resembling the same quality, discriminative features, and diversity, as the real normal and diabetic macular edema (DME) OCT images. The statistical comparison illustrates this similarity in the spatial and frequency domains, as well. Overall, DDFA-GAN generates realistic OCT images to meet requirements of the training data in automatic deep learning-based methods, used for clinical examination of the retina, and to improve the accuracy of the subsequent measurements.",10.1109/TIM.2022.3189735,2022,,A DUAL-DISCRIMINATOR FOURIER ACQUISITIVE GAN FOR GENERATING RETINAL OPTICAL COHERENCE TOMOGRAPHY IMAGES,
664,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"The hearth temperature is the main factor to affect the performance of a blast furnace (BF) such as heat transfer, mass transfer and reduction, desulfurization, and pig iron composition. Therefore, the hearth temperature must be monitored and controlled to assure the quality and throughput of iron products. However, the hearth temperature can only be determined indirectly by measuring the temperature of the tuyere raceway of BF. To predict the temperature in a BF hearth promptly and reliably, a collaborative multiple rank regression (CMRR) method is proposed to predict the temperature based on the obtained images and physical variables. The proposed method is innovative in the sense that: 1) images and physical variables are classified into corresponding labels to explore their correspondences; 2) design constraints are imposed on regression coefficients to avoid overfitting; and 3) the locality preserving projection is adopted to tackle with diversity of big data by unifying physical variables and images in light of their similarity. The effectiveness of the proposed method is validated by the comparative studies of the CMRR with other eight existing models using the real-world data collected from an industrial BF with a volume of 2500 m3.",10.1109/TIM.2022.3180408,2022,,COLLABORATIVE MULTIPLE RANK REGRESSION FOR TEMPERATURE PREDICTION OF BLAST FURNACE,
665,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Monitoring respiratory rate (RR) is crucial for helping identify respiratory disorders. Devices for conventional respiratory monitoring are inconvenient and scarcely available. Recent research has demonstrated the ability of noncontact technologies, such as photoplethysmography and infrared thermography, to gather respiratory signals from the face and monitor breathing. However, current noncontact respiratory monitoring techniques have poor accuracy because they are sensitive to environmental influences like lighting and motion artifacts. Furthermore, frequent contact between users and the cloud in real-world medical application settings might cause service request delays and potentially the loss of personal data. We proposed a noncontact RR monitoring system with a cooperative three-layer design to increase the precision of respiratory monitoring and decrease data transmission latency. To reduce data transmission and network latency, our three-tier architecture layer-by-layer decomposes the computing tasks of respiration monitoring. Moreover, we improved the accuracy of respiratory monitoring by designing a target tracking algorithm and an algorithm for eliminating false peaks to extract high-quality respiratory signals. By gathering the data and choosing several regions of interest on the face, we were able to extract the respiration signal and investigate how different regions affected the monitoring of respiration. The results of the experiment indicate that when the nasal region is used to extract the respiratory signal, it performs experimentally best. Our approach performs better than baseline approaches while transferring fewer data.",10.1109/TIM.2022.3205644,2022,,COLLABORATIVE THREE-TIER ARCHITECTURE NONCONTACT RESPIRATORY RATE MONITORING USING TARGET TRACKING AND FALSE PEAKS ELIMINATING ALGORITHMS,
666,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"This article proposed a PairCon-simultaneous localization and mapping algorithm to construct dense maps of large-scale scenarios in real time, which is operated in an integral platform containing two personal computers (PCs). This platform can operate the mapping thread independently in a PC to guarantee sufficient memory resources. In this context, the synchronous visualization of 3-D maps can be achieved in such a platform. In contrast, traditional algorithms are limited by the short operation distance, under the requirement of simultaneous data collection and 3-D maps construction in a PC. In addition, the memory resource provided by a single PC is limited, which restricts the constructing scale of maps. Thus, we use a separate PC to construct maps independently to relieve the distance constraint and exploit the socket method to conduct the transmission of data with the point cloud. Meanwhile, we introduce the ReBlur algorithm into the semi-direct method to reduce the error accumulation of the odometer in the tracking thread, which improves the robustness performance. In addition, the method combining the memory management and DBow2 algorithm is adopted to improve the accuracy of loop detection. In the considered system, the quality of maps and the performance of the odometer are evaluated by ICL-NUIM and the datasets, such as TUM, DIODE, and so on, respectively. Finally, under the simulation environment of AirSim and Gazebo, we construct maps based on the image data of other scenarios, which is used to show the quality of the construction.",10.1109/TIM.2021.3116288,2021,,"PAIRCON-SLAM: DISTRIBUTED, ONLINE, AND REAL-TIME RGBD-SLAM IN LARGE SCENARIOS",
667,15361,IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT,journal,15579662,"0,820",Q1,119,962,1170,32944,5589,1120,"4,47","34,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Instrumentation (Q1),"18,199",4.016,0.01327,"Surface defect detection is very important for the quality control of product and routine maintenance of facilities, but it is still a big challenge due to the diversity and complexity of defects and environmental factors. To improve the accuracy of defect detection, we proposed a pixel-level segmentation network based on deep feature fusion for surface defect detection. The network adopts encoder-decoder structure, and it extracts low-, middle-, and high-level features via ResNet50 first. Second, by fusing adjacent feature maps at all levels and integrating the highest level feature map, multilevel feature aggregation module makes all feature maps contain context information and more details of defects. Then, multibranch decoder adopts attention modules and a multibranch structure to recover the details of defects gradually and improve the accuracy of defects segmentation. Finally, the segmentation result is produced by fusion of all branches outputs. We have evaluated the proposed network on three public data sets: MT, RSDD, and CFD. The results indicate that our proposed method outperforms the other compared methods in terms of F-measure and intersection of union (MT:73.7%, RSDD:85%, CFD:60.1%).",10.1109/TIM.2020.3033726,2021,,A PIXEL-LEVEL SEGMENTATION CONVOLUTIONAL NEURAL NETWORK BASED ON DEEP FEATURE FUSION FOR SURFACE DEFECT DETECTION,
668,18676,TECHNOLOGY IN SOCIETY,journal,0160791X,"0,819",Q1,51,201,224,14468,1056,222,"4,75","71,98",United Kingdom,Western Europe,Elsevier Ltd.,1979-2020,Business and International Management (Q1); Education (Q1); Human Factors and Ergonomics (Q1); Sociology and Political Science (Q1),"2,735",4.192,0.00214,"Due to the importance of big data technology in decision-making, production and service provision, enterprises have adopted various big data technologies and platforms to improve their operational efficiency. However, the number of enterprises that have adopted big data is not promising. The purpose of this study is to explore the current status of big data adoption by Chinese enterprises and to reveal the possible factors that hinder big data adoption from the group behaviour network perspective. Based on a real case survey of 54 big data platforms (BDPs), four types of networks—i.e., the enterprise-platform network, enterprise network, platform network and industry similarity and difference (ISD) network—are constructed and analysed on the basis of social network analysis (SNA). This study finds that among Chinese enterprises, the level and scope of big data adoption are generally low and are imbalanced among industries; the cognitive level and adoption behaviour of enterprises on BDPs are inconsistent, the compatibility of BDPs is different, and the density and distance-based cohesion of networks are weak; although the current big data adoption behaviours of Chinese enterprises have formed some structural features, core-periphery structures and maximal complete cliques are found, and the current network structure has little impact on individual enterprises and platforms; enterprises in the same industry prefer to adopt the same kind of big data technology or platform. Based on these findings, several strategies and suggestions to improve big data adoption are provided.",https://doi.org/10.1016/j.techsoc.2021.101570,2021,Zhimei Lei and Yandan Chen and Ming K. Lim,MODELLING AND ANALYSIS OF BIG DATA PLATFORM GROUP ADOPTION BEHAVIOUR BASED ON SOCIAL NETWORK ANALYSIS,article
669,18676,TECHNOLOGY IN SOCIETY,journal,0160791X,"0,819",Q1,51,201,224,14468,1056,222,"4,75","71,98",United Kingdom,Western Europe,Elsevier Ltd.,1979-2020,Business and International Management (Q1); Education (Q1); Human Factors and Ergonomics (Q1); Sociology and Political Science (Q1),"2,735",4.192,0.00214,"With its rapid growth and increasing adoption, big data is producing a substantial impact in society. Its usage is opening both opportunities such as new business models and economic gains and risks such as privacy violations and discrimination. Europe is in need of a comprehensive strategy to optimise the use of data for a societal benefit and increase the innovation and competitiveness of its productive activities. In this paper, we contribute to the definition of this strategy with a research roadmap to capture the economic, social and ethical, legal and political benefits associated with the use of big data in Europe. The present roadmap considers the positive and negative externalities associated with big data, maps research and innovation topics in the areas of data management, processing, analytics, protection, visualisation, as well as non-technical topics, to the externalities they can tackle, and provides a time frame to address these topics in order to deliver social impact, skills development and standardisation. Finally, it also identifies what sectors will be most benefited by each of the research efforts. The goal of the roadmap is to guide European research efforts to develop a socially responsible big data economy, and to allow stakeholders to identify and meet big data challenges and proceed with a shared understanding of the societal impact, positive and negative externalities and concrete problems worth investigating in future programmes.",https://doi.org/10.1016/j.techsoc.2018.03.005,2018,Martí Cuquet and Anna Fensel,THE SOCIETAL IMPACT OF BIG DATA: A RESEARCH ROADMAP FOR EUROPE,article
670,24482,CHILDREN AND YOUTH SERVICES REVIEW,journal,01907409,"0,816",Q1,89,978,1349,58646,3628,1315,"2,29","59,97",United Kingdom,Western Europe,Elsevier Ltd.,1979-2020,Education (Q1); Social Work (Q1); Sociology and Political Science (Q1); Developmental and Educational Psychology (Q2),"13,303",2.393,0.01343,"Numerous approaches are available for improving governance of the child welfare system, all of which require longitudinal data reporting on child welfare clients. A substantial amount of agency administrative information – big data – can be transformed into knowledge for policy and management actions through a rigorous information generation process. Important properties of the information generation process are that it must generate accurate, timely information while protecting the confidentiality of the clients. In addition, it must be extensible to serve an ever-changing policy and technology environment. Knowledge discovery and data mining (KDD), aka data science, is a method developed in the private sector to mine consumer data and can be used in public settings to support evidence based governance. KDD consists of a rigorous 5-step process that includes a Web-based end-user interface. The relationship between KDD and governance is a continuous feedback cycle that enables ongoing development of new information and knowledge as stakeholders identify emerging needs. In this paper, we synthesis the different frameworks for utilizing big data for public governance, introduce the KDD process, describe the nature of big data in child welfare, and then present an updated KDD architecture that can support these frameworks to utilize big data for governance. We also demonstrate the role KDD plays in child welfare management through 2 case studies. We conclude with a discussion on implications for agency–university partnerships and research-to-practice.",https://doi.org/10.1016/j.childyouth.2015.09.014,2015,Hye-Chung Kum and C. {Joy Stewart} and Roderick A. Rose and Dean F. Duncan,USING BIG DATA FOR EVIDENCE BASED GOVERNANCE IN CHILD WELFARE,article
671,18838,PREVENTIVE VETERINARY MEDICINE,journal,01675877,"0,816",Q1,95,299,618,12546,1722,609,"2,50","41,96",Netherlands,Western Europe,Elsevier,1982-2020,Animal Science and Zoology (Q1); Food Animals (Q1),"9,469",2.670,0.00645,"Concurrent with global economic development in the last 50 years, the opportunities for the spread of existing diseases and emergence of new infectious pathogens, have increased substantially. The activities associated with the enormously intensified global connectivity have resulted in large amounts of data being generated, which in turn provides opportunities for generating knowledge that will allow more effective management of animal and human health risks. This so-called Big Data has, more recently, been accompanied by the Internet of Things which highlights the increasing presence of a wide range of sensors, interconnected via the Internet. Analysis of this data needs to exploit its complexity, accommodate variation in data quality and should take advantage of its spatial and temporal dimensions, where available. Apart from the development of hardware technologies and networking/communication infrastructure, it is necessary to develop appropriate data management tools that make this data accessible for analysis. This includes relational databases, geographical information systems and most recently, cloud-based data storage such as Hadoop distributed file systems. While the development in analytical methodologies has not quite caught up with the data deluge, important advances have been made in a number of areas, including spatial and temporal data analysis where the spectrum of analytical methods ranges from visualisation and exploratory analysis, to modelling. While there used to be a primary focus on statistical science in terms of methodological development for data analysis, the newly emerged discipline of data science is a reflection of the challenges presented by the need to integrate diverse data sources and exploit them using novel data- and knowledge-driven modelling methods while simultaneously recognising the value of quantitative as well as qualitative analytical approaches. Machine learning regression methods, which are more robust and can handle large datasets faster than classical regression approaches, are now also used to analyse spatial and spatio-temporal data. Multi-criteria decision analysis methods have gained greater acceptance, due in part, to the need to increasingly combine data from diverse sources including published scientific information and expert opinion in an attempt to fill important knowledge gaps. The opportunities for more effective prevention, detection and control of animal health threats arising from these developments are immense, but not without risks given the different types, and much higher frequency, of biases associated with these data.",https://doi.org/10.1016/j.prevetmed.2015.05.012,2015,Dirk U. Pfeiffer and Kim B. Stevens,SPATIAL AND TEMPORAL EPIDEMIOLOGICAL ANALYSIS IN THE BIG DATA ERA,article
672,17316,IEEE SIGNAL PROCESSING LETTERS,journal,15582361,"0,815",Q1,138,381,1094,10344,5598,1092,"4,68","27,15",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1994-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1); Applied Mathematics (Q2),"13,590",3.109,0.02152,"Recent studies have demonstrated that a bilateral filter can increase the quality of edge-preserving image smoothing significantly. Different strategies or mechanisms have been used to eliminate the brute-force computation in bilateral filters. However, blindly decreasing the processing time of the bilateral filter cannot further ameliorate the effectiveness of filter. In addition, even when the processing speed of the filter is increased, inherent problem occurred in the Gaussian range kernel when facing a noise filtering input and its effect on edge-preserving image smoothing operation are barely discussed. In this letter, we propose a novel Gaussian-adaptive bilateral filter (GABF) to resolve the aforementioned problem. The basic idea is to acquire a low-pass guidance for the range kernel by a Gaussian spatial kernel. Such low-pass guidance lead to a clean Gaussian range kernel for later bilateral composite. The results of experiments conducted on several test datasets indicate that the proposed GABF outperforms most existing bilateral-filter-based methods.",10.1109/LSP.2020.3024990,2020,,GAUSSIAN-ADAPTIVE BILATERAL FILTER,
673,17316,IEEE SIGNAL PROCESSING LETTERS,journal,15582361,"0,815",Q1,138,381,1094,10344,5598,1092,"4,68","27,15",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1994-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1); Applied Mathematics (Q2),"13,590",3.109,0.02152,"In this letter, a concise gamma-correction-based dehazing model (GDM) is proposed. This GDM explicitly describes the inner relationship between the gamma correction (GC) and the traditional scattering model. Combined with the existing priori constraints, GDM is further approximated into a one-dimensional (1-D) function to seek the only unknown constant that is used for haze removal. Using the determined constant, the scene albedo can be recovered, eliminating the haze from single hazy images. The proposed GDM is able to suppress the halo/blocking artifacts in the recovered results due to the scene albedo, which is less sensitive to the determined constant. Simulation results on different types of benchmark images verify that the proposed technique outperforms state-of-the-art methods in terms of both recovery, quality, and real-time performance.",10.1109/LSP.2018.2839580,2018,,GAMMA-CORRECTION-BASED VISIBILITY RESTORATION FOR SINGLE HAZY IMAGES,
674,17316,IEEE SIGNAL PROCESSING LETTERS,journal,15582361,"0,815",Q1,138,381,1094,10344,5598,1092,"4,68","27,15",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1994-2020,Electrical and Electronic Engineering (Q1); Signal Processing (Q1); Applied Mathematics (Q2),"13,590",3.109,0.02152,"Different from traditional image super-resolution task, real image super-resolution(Real-SR) focus on the relationship between real-world high-resolution(HR) and low-resolution(LR) image. Most of the traditional image SR obtains the LR sample by applying a fixed down-sampling operator. Real-SR obtains the LR and HR image pair by incorporating different quality optical sensors. Generally, Real-SR has more challenges as well as broader application scenarios. Previous image SR methods fail to exhibit similar performance on Real-SR as the image data is not aligned inherently. In this article, we propose a Dual-path Dynamic Enhancement Network(DDet) for Real-SR, which addresses the cross-camera image mapping by realizing a dual-way dynamic sub-pixel weighted aggregation and refinement. Unlike conventional methods which stack up massive convolutional blocks for feature representation, we introduce a content-aware framework to study non-inherently aligned image pair in image SR issue. First, we use a content-adaptive component to exhibit the Multi-scale Dynamic Attention(MDA). Second, we incorporate a long-term skip connection with a Coupled Detail Manipulation(CDM) to perform collaborative compensation and manipulation. The above dual-path model is joint into a unified model and works collaboratively. Extensive experiments on the challenging benchmarks demonstrate the superiority of our model.",10.1109/LSP.2020.2978410,2020,,DDET: DUAL-PATH DYNAMIC ENHANCEMENT NETWORK FOR REAL-WORLD IMAGE SUPER-RESOLUTION,
675,110111,IEEE INTELLIGENT SYSTEMS,journal,15411672,"0,806",Q1,124,107,155,882,834,145,"4,41","8,24",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2001-2020,Artificial Intelligence (Q1); Computer Networks and Communications (Q1),"3,738",3.405,0.00265,"The implementation of a cyber-physical approach to information provision control in a corporate information system brings a wide range of opportunities to improve the quality of the user experience both for employees and for visitors of an organization. A dynamic analysis of user preferences based on data collected via various sensors and history of user activity allows personalization of the provision of information services. In this paper, an approach to customize the user interaction with information services is considered through an example of a Corporate In-formation Providing System to a scientific organization. The architecture of the system, which is developed to manage intelligent display notifications for various groups of users, is discussed. Several types of users and their access rights are discussed, taking into account the specifics of information consumption in a scientific organization. An algorithm for analyzing user preferences in providing a corporate notification service is presented. Deploying the proposed approach allows to cover the content delivered according to user preferences, which will further improve the user experience and the service personalization.",10.1109/IS48319.2020.9199955,2020,,PERSONALIZATION OF USER INTERACTION WITH CORPORATE INFORMATION PROVIDING SYSTEM BASED ON ANALYSIS OF USER PREFERENCES,
676,26811,COMPUTER NETWORKS,journal,13891286,"0,798",Q1,135,383,896,19762,4981,877,"5,93","51,60",Netherlands,Western Europe,Elsevier,"1977-1984, 1989-1990, 1996-2020",Computer Networks and Communications (Q1),"11,644",4.474,0.00957,"Data are an extremely important asset. Governments around the world encourage big data sharing and trading to promote the big data economy. However, existing data trading platforms are not fully trusted. Such platforms face the problems of a single point of failure (SPOF), opaque transactions, uncontrollability, untraceability, and issues of data privacy. Several blockchain-based big data trading methods have been proposed; however, they do not adequately address the security issues introduced by dishonesty in the data provider and data agent or the fairness of data revenue distribution and price bargaining. In this paper, we propose a blockchain-based decentralized data trading system in which data trading is completed by smart contract-based data matching, price negotiation, and reward assigning. Moreover, the proposed data trading system evaluates the data quality on the basis of three metrics, records the evaluation results in a side-chain, and distributes the data users’ application revenue to the data provider according to the evaluated data quality. We verify the security, usability, and efficiency of the proposed big data trading system.",https://doi.org/10.1016/j.comnet.2021.107994,2021,Donghui Hu and Yifan Li and Lixuan Pan and Meng Li and Shuli Zheng,A BLOCKCHAIN-BASED TRADING SYSTEM FOR BIG DATA,article
677,26811,COMPUTER NETWORKS,journal,13891286,"0,798",Q1,135,383,896,19762,4981,877,"5,93","51,60",Netherlands,Western Europe,Elsevier,"1977-1984, 1989-1990, 1996-2020",Computer Networks and Communications (Q1),"11,644",4.474,0.00957,"The explosive growth in the number of devices connected to the Internet of Things (IoT) and the exponential increase in data consumption only reflect how the growth of big data perfectly overlaps with that of IoT. The management of big data in a continuously expanding network gives rise to non-trivial concerns regarding data collection efficiency, data processing, analytics, and security. To address these concerns, researchers have examined the challenges associated with the successful deployment of IoT. Despite the large number of studies on big data, analytics, and IoT, the convergence of these areas creates several opportunities for flourishing big data and analytics for IoT systems. In this paper, we explore the recent advances in big data analytics for IoT systems as well as the key requirements for managing big data and for enabling analytics in an IoT environment. We taxonomized the literature based on important parameters. We identify the opportunities resulting from the convergence of big data, analytics, and IoT as well as discuss the role of big data analytics in IoT applications. Finally, several open challenges are presented as future research directions.",https://doi.org/10.1016/j.comnet.2017.06.013,2017,Ejaz Ahmed and Ibrar Yaqoob and Ibrahim Abaker Targio Hashem and Imran Khan and Abdelmuttlib Ibrahim Abdalla Ahmed and Muhammad Imran and Athanasios V. Vasilakos,THE ROLE OF BIG DATA ANALYTICS IN INTERNET OF THINGS,article
678,26811,COMPUTER NETWORKS,journal,13891286,"0,798",Q1,135,383,896,19762,4981,877,"5,93","51,60",Netherlands,Western Europe,Elsevier,"1977-1984, 1989-1990, 1996-2020",Computer Networks and Communications (Q1),"11,644",4.474,0.00957,"According to McKinsey & Company, about a third of food produced is lost or wasted every year, amounting to a $940 billion economic hit. Inefficiencies in planting, harvesting, water use, reduced animal contributions, as well as uncertainty about weather, pests, consumer demand and other intangibles contribute to the loss. Precision Agriculture (PA) and Precision Livestock Farming (PLF) come to assist in optimizing agricultural and livestock production and minimizing the wastes and costs aforementioned. PA is a technology-enabled, data-driven approach to farming management that observes, measures, and analyzes the needs of individual fields and crops. PLF is also a technology-enabled, data-driven approach to livestock production management, which exploits technology to quantitatively measure the behavior, health and performance of animals. Big data delivered by a plethora of data sources related to these domains, has a multitude of payoffs including precision monitoring of fertilizer and fungicide levels to optimize crop yields, risk mitigation that results from monitoring when temperature and humidity levels reach dangerous levels for crops, increasing livestock production while minimizing the environmental footprint of livestock farming, ensuring high levels of welfare and health for animals, and more. By adding analytics to these sensor and image data, opportunities also exist to further optimize PA and PLF by having continuous data on how a field or the livestock is responding to a protocol. For these domains, two main challenges exist: 1) to exploit this multitude of data facilitating dedicated improvements in performance, and 2) to make available advanced infrastructure so as to harness the power of this information in order to benefit from the new insights, practices and products, efficiently time-wise, lowering responsiveness down to seconds so as to cater for time-critical decisions. The current paper aims to introduce CYBELE, a platform aspiring to safeguard that the stakeholders involved in the agri-food value chain (research community, SMEs, entrepreneurs, etc.) have integrated, unmediated access to a vast amount of very large scale datasets of diverse types and coming from a variety of sources, and that they are capable of actually generating value and extracting insights out of these data, by providing secure and unmediated access to large-scale High Performance Computing (HPC) infrastructures supporting advanced data discovery, processing, combination and visualization services, solving computationally-intensive challenges modelled as mathematical algorithms requiring very high computing power and capability.",https://doi.org/10.1016/j.comnet.2019.107035,2020,Konstantinos Perakis and Fenareti Lampathaki and Konstantinos Nikas and Yiannis Georgiou and Oskar Marko and Jarissa Maselyne,CYBELE – FOSTERING PRECISION AGRICULTURE & LIVESTOCK FARMING THROUGH SECURE ACCESS TO LARGE-SCALE HPC ENABLED VIRTUAL INDUSTRIAL EXPERIMENTATION ENVIRONMENTS FOSTERING SCALABLE BIG DATA ANALYTICS,article
679,26811,COMPUTER NETWORKS,journal,13891286,"0,798",Q1,135,383,896,19762,4981,877,"5,93","51,60",Netherlands,Western Europe,Elsevier,"1977-1984, 1989-1990, 1996-2020",Computer Networks and Communications (Q1),"11,644",4.474,0.00957,"In recent years, the Internet of Things (IoT) has emerged as a new opportunity. Thus, all devices such as smartphones, transportation facilities, public services, and home appliances are used as data creator devices. All the electronic devices around us help our daily life. Devices such as wrist watches, emergency alarms, and garage doors and home appliances such as refrigerators, microwaves, air conditioning, and water heaters are connected to an IoT network and controlled remotely. Methods such as big data and data mining can be used to improve the efficiency of IoT and storage challenges of a large data volume and the transmission, analysis, and processing of the data volume on the IoT. The aim of this study is to investigate the research done on IoT using big data as well as data mining methods to identify subjects that must be emphasized more in current and future research paths. This article tries to achieve the goal by following the conference and journal articles published on IoT-big data and also IoT-data mining areas between 2010 and August 2017. In order to examine these articles, the combination of Systematic Mapping and literature review was used to create an intended review article. In this research, 44 articles were studied. These articles are divided into three categories: Architecture & Platform, framework, and application. In this research, a summary of the methods used in the area of IoT-big data and IoT-data mining is presented in three categories to provide a starting point for researchers in the future.",https://doi.org/10.1016/j.comnet.2018.04.001,2018,Shabnam Shadroo and Amir Masoud Rahmani,SYSTEMATIC SURVEY OF BIG DATA AND DATA MINING IN INTERNET OF THINGS,article
680,21100337101,IEEE CONSUMER ELECTRONICS MAGAZINE,trade journal,21622256,"0,786",Q1,31,137,305,1161,1085,305,"3,97","8,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"2012, 2014-2020",Electrical and Electronic Engineering (Q1); Hardware and Architecture (Q1); Human-Computer Interaction (Q1); Computer Science Applications (Q2),"1,193",3.789,0.00183,"In the digital era, extended reality (XR) is considered the next frontier. However, XR systems are computationally intensive, and they must be implemented within strict latency constraints. Thus, XR devices with finite computing resources are limited in terms of quality of experience (QoE) they can offer, particularly in the cases of big 3D data. This problem can be effectively addressed by offloading the highly intensive rendering tasks to a remote server. Therefore, we proposed a remote rendering enabled XR system that presents the 3D city model of New York City on the Microsoft HoloLens. Experimental results indicate that remote rendering outperforms local rendering for the New York City model with significant improvement in average QoE by at least 21%. In addition, we clarified the network traffic pattern in the proposed XR system developed under the OpenXR standard.",10.1109/MCE.2022.3165961,2022,,INTERACTING WITH NEW YORK CITY DATA BY HOLOLENS THROUGH REMOTE RENDERING,
681,21100337101,IEEE CONSUMER ELECTRONICS MAGAZINE,trade journal,21622256,"0,786",Q1,31,137,305,1161,1085,305,"3,97","8,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"2012, 2014-2020",Electrical and Electronic Engineering (Q1); Hardware and Architecture (Q1); Human-Computer Interaction (Q1); Computer Science Applications (Q2),"1,193",3.789,0.00183,"No one yet knows what the expected proliferation of the many new product categories in the emerging Internet of Things (IoT) will look like in the coming years, but one thing is certain; their success or failure will be driven by unwavering consumer demands for increased quality. Simply put, nobody wants an expensive piece of technological wonder that leaves one questioning why it was bought in the first place. It is therefore imperative that any discussion about the ""IoT"" be linked directly to the concept of the ""quality of things."" In this new age of devices with embedded sensors that interconnect and converse with one another, quality is not a nice-tohave extra?it is mission critical. The IoT inevitably will ramp up consumer quality expectations, and producing less than stellar results will be unacceptable.",10.1109/MCE.2016.2519058,2016,,THE QUEST FOR THE QUALITY OF THINGS: CAN THE INTERNET OF THINGS DELIVER A PROMISE OF THE QUALITY OF THINGS?,
682,21100337101,IEEE CONSUMER ELECTRONICS MAGAZINE,trade journal,21622256,"0,786",Q1,31,137,305,1161,1085,305,"3,97","8,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"2012, 2014-2020",Electrical and Electronic Engineering (Q1); Hardware and Architecture (Q1); Human-Computer Interaction (Q1); Computer Science Applications (Q2),"1,193",3.789,0.00183,"In recent years driving violations have increased in big and crowded cities specially in developing countries. This has resulted in the escalation of traffic congestions and number of accidents, making them difficult to handle by a central managing authority. New technologies can be used in order to mitigate this problem. Hence, in this article, we propose a novel concept, called self-fining vehicle, using blockchain infrastructure on top of the vehicular edge computing. Self-fining vehicle is a vehicle that detects and records driving violations, issues tickets, and pays fines without the need for a centralized management system. Violations can be coded into on-board units and detected by vehicular communications. The conceptual architecture of secure self-fining vehicle is proposed and discussed in this article. The proposed architecture improves violation data security, processing speed, and communication delay using encryption, authentication, blockchain, and edge computing (EC), enhancing quality of service and consumers’ quality of experience. The performance analysis of the proposed architecture proves its efficiency in terms of latency in service delivery.",10.1109/MCE.2020.3038029,2022,,PROPOSING A SECURE SELF-FINING VEHICLE USING BLOCKCHAIN AND VEHICULAR EDGE COMPUTING,
683,21100337101,IEEE CONSUMER ELECTRONICS MAGAZINE,trade journal,21622256,"0,786",Q1,31,137,305,1161,1085,305,"3,97","8,47",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,"2012, 2014-2020",Electrical and Electronic Engineering (Q1); Hardware and Architecture (Q1); Human-Computer Interaction (Q1); Computer Science Applications (Q2),"1,193",3.789,0.00183,"This article is a single-source introduction to the emerging concept of smart cities. It can be used for familiarizing researchers with the vast scope of research possible in this application domain. The smart city is primarily a concept, and there is still not a clear and consistent definition among practitioners and academia. As a simplistic explanation, a smart city is a place where traditional networks and services are made more flexible, efficient, and sustainable with the use of information, digital, and telecommunication technologies to improve the city's operations for the benefit of its inhabitants. Smart cities are greener, safer, faster, and friendlier. The different components of a smart city include smart infrastructure, smart transportation, smart energy, smart health care, and smart technology. These components are what make the cities smart and efficient. Information and communication technology (ICT) are enabling keys for transforming traditional cities into smart cities. Two closely related emerging technology frameworks, the Internet of Things (IoT) and big data (BD), make smart cities efficient and responsive. The technology has matured enough to allow smart cities to emerge. However, there is much needed in terms of physical infrastructure, a smart city, the digital technologies translate into better public services for inhabitants and better use of resources while reducing environmental impacts. One of the formal definitions of the smart city is the following: a city ""connecting the physical infrastructure, the information-technology infrastructure, the social infrastructure, and the business infrastructure to leverage the collective intelligence of the city"". Another formal and comprehensive definition is ""a smart sustainable city is an innovative city that uses information and communication technologies (ICTs) and other means to improve quality of life, efficiency of urban operations and services, and competitiveness, while ensuring that it meets the needs of present and future generations with respect to economic, social and environmental aspects"". Any combination of various smart components can make cities smart. A city need not have all the components to be labeled as smart. The number of smart components depends on the cost and available technology.",10.1109/MCE.2016.2556879,2016,,EVERYTHING YOU WANTED TO KNOW ABOUT SMART CITIES: THE INTERNET OF THINGS IS THE BACKBONE,
684,19901,IEEE TRANSACTIONS ON BROADCASTING,journal,15579611,"0,782",Q1,80,84,209,2773,980,206,"4,99","33,01",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Media Technology (Q1),"2,375",3.863,0.00249,"Recently, the prevalence of mobile devices together with the outburst of user-generated contents has fueled the tremendous growth of the Internet traffic taken by video streaming. To improve user-perceived quality-of-experience (QoE), dynamic adaptive streaming via HTTP (DASH) has been widely adopted by practical systems to make streaming smooth under limited bandwidth. However, previous DASH approaches mostly performed complicated rate adaptation based on bandwidth estimation, which has been proven to be unreliable over HTTP. In this paper, we simplify the design by only exploiting client-side buffer state information and propose a pure buffer-based DASH scheme to optimize user QoE. Our approach can not only get rid of the drawback caused by inaccurate bandwidth estimation, but also incur very limited overhead. We explicitly define an integrated user QoE model, which takes playback freezing, bitrate switch, and video quality into account, and then formulate the problem into a non-linear stochastic optimal control problem. Next, we utilize control theory to design a dynamic buffer-based controller for DASH, which determines video bitrate of each chunk to be requested and stabilize the buffer level in the meanwhile. Extensive experiments have been conducted to validate the advantages of our approach, and the results show that our approach can achieve the best performance compared with other alternative approaches.",10.1109/TBC.2018.2789580,2018,,BUFFER STATE IS ENOUGH: SIMPLIFYING THE DESIGN OF QOE-AWARE HTTP ADAPTIVE VIDEO STREAMING,
685,19901,IEEE TRANSACTIONS ON BROADCASTING,journal,15579611,"0,782",Q1,80,84,209,2773,980,206,"4,99","33,01",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Media Technology (Q1),"2,375",3.863,0.00249,"The discrete CSO/CTB intermodulation distortion has a big influence on the CATV net quality. This article describes a new method to calculate the composite second order (CSO) and composite triple beat (CTB) intermodulation distortion spectrum for the full frequency range of a coaxial cable CATV amplifier for any input frequency plan. The calculation takes into account the output level ripple and preemphasis, using frequency dependent intermodulation coefficients. These coefficients have been established through CSO/CTB measurements on multichannel test systems for standard frequency plans at 5-8 intermodulation frequencies or on distortion arrays for the two (three) oscillator measuring test system. The defined intermodulation coefficients are unrelated to the frequency plan and the input/output level ripple. It is also possible to calculate the CSO/CTB spectrum caused by analogue channels within digital QAM channels. The results equally apply to optical CATV receivers. Simulation results have been verified using extensive data from multichannel measurement systems.",10.1109/11.715324,1998,,CALCULATING THE CSO/CTB SPECTRUM OF CATV AMPLIFIERS AND OPTICAL RECEIVERS,
686,19901,IEEE TRANSACTIONS ON BROADCASTING,journal,15579611,"0,782",Q1,80,84,209,2773,980,206,"4,99","33,01",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q1); Media Technology (Q1),"2,375",3.863,0.00249,"Internet Protocol Television (IPTV) over IEEE 802.11 Wireless LANs, which are considered today as the de-facto wireless access network for local distribution (home networks, hotspots), brings forth a big challenge to guarantee high quality multicast/broadcast delivery over unreliable and time-variant wireless channels. However, in IEEE 802.11 Wireless LANs, current standard MAC layer protocols do not provide any error correction scheme for broadcast/multicast. In our previous work, we enhanced a Leader Based Protocol (LBP) and proposed a Beacon-driven Leader Based Protocol (BLBP) for the MAC layer multicast error control. However, as pure Automatic Repeat reQuest (ARQ) schemes, both LBP and BLBP are not efficient for large multicast groups. In this paper, we combine BLBP and packet level Forward Error Correction (FEC) and propose a Hybrid Leader Based Protocol (HLBP) for the MAC layer multicast error control. HLBP transmits the original data packets using raw broadcast and retransmits parity packets using an improved BLBP which is based on block feedback. To guarantee the required Packet Loss Ratio (PLR) under strict delay constraints for multicast delivery over a Gilbert-Elliott (GE) channel, we analyze LBP, BLBP and HLBP, develop analytic performance models that allow optimizing the configurations. The performance models are verified via simulation experiments. Both the theoretical analysis and simulation results show that HLBP is much more efficient than LBP and BLBP especially for large multicast groups and is also more efficient than the best application layer multicast error correction scheme. BLBP needs the minimum number of redundancy transmissions among all pure ARQ based schemes while HLBP needs the near-minimum number of redundancy transmissions among all schemes. Due to the simplicity and efficiency, BLBP is a good choice for IPTV multicast delivery for small groups in Wireless LANs while HLBP is a better choice for large multicast groups.",10.1109/TBC.2009.2016502,2009,,MAC LAYER MULTICAST ERROR CONTROL FOR IPTV IN WIRELESS LANS,
687,21728,JOURNAL OF SURGICAL RESEARCH,journal,00224804,"0,780",Q2,108,688,1666,19607,3583,1614,"1,96","28,50",United States,Northern America,Academic Press Inc.,1961-2021,Surgery (Q2),"17,062",2.192,0.01875,"As more and more health systems have converted to the use of electronic health records, the amount of searchable and analyzable data is exploding. This includes not just provider or laboratory created data but also data collected by instruments, personal devices, and patients themselves, among others. This has led to more attention being paid to the analysis of these data to answer previously unaddressed questions. This is especially important given the number of therapies previously found to be beneficial in clinical trials that are currently being re-scrutinized. Because there are orders of magnitude more information contained in these data sets, a fundamentally different approach needs to be taken to their processing and analysis and the generation of knowledge. Health care and medicine are drivers of this phenomenon and will ultimately be the main beneficiaries. Concurrently, many different types of questions can now be asked using these data sets. Research groups have become increasingly active in mining large data sets, including nationwide health care databases, to learn about associations of medication use and various unrelated diseases such as cancer. Given the recent increase in research activity in this area, its promise to radically change clinical research, and the relative lack of widespread knowledge about its potential and advances, we surveyed the available literature to understand the strengths and limitations of these new tools. We also outline new databases and techniques that are available to researchers worldwide, with special focus on work pertaining to the broad and rapid monitoring of drug safety and secondary effects.",https://doi.org/10.1016/j.jss.2019.09.053,2020,Ali Zarrinpar and Ting-Yuan {David Cheng} and Zhiguang Huo,WHAT CAN WE LEARN ABOUT DRUG SAFETY AND OTHER EFFECTS IN THE ERA OF ELECTRONIC HEALTH RECORDS AND BIG DATA THAT WE WOULD NOT BE ABLE TO LEARN FROM CLASSIC EPIDEMIOLOGY?,article
688,3100147401,ECOLOGICAL INFORMATICS,journal,15749541,"0,774",Q1,55,109,273,5588,964,271,"3,43","51,27",Netherlands,Western Europe,Elsevier,2006-2020,"Modeling and Simulation (Q1); Applied Mathematics (Q2); Computational Theory and Mathematics (Q2); Computer Science Applications (Q2); Ecological Modeling (Q2); Ecology (Q2); Ecology, Evolution, Behavior and Systematics (Q2)","2,893",3.142,0.00332,"The recent availability of species occurrence data from numerous sources, standardized and connected within a single portal, has the potential to answer fundamental ecological questions. These aggregated big biodiversity databases are prone to numerous data errors and biases. The data-user is responsible for identifying these errors and assessing if the data are suitable for a given purpose. Complex technical skills are increasingly required for handling and cleaning biodiversity data, while biodiversity scientists possessing these skills are rare. Here, we estimate the effect of user-level data cleaning on species distribution model (SDM) performance. We implement several simple and easy-to-execute data cleaning procedures, and evaluate the change in SDM performance. Additionally, we examine if a certain group of species is more sensitive to the use of erroneous or unsuitable data. The cleaning procedures used in this research improved SDM performance significantly, across all scales and for all performance measures. The largest improvement in distribution models following data cleaning was for small mammals (1g–100g). Data cleaning at the user level is crucial when using aggregated occurrence data, and facilitating its implementation is a key factor in order to advance data-intensive biodiversity studies. Adopting a more comprehensive approach for incorporating data cleaning as part of data analysis, will not only improve the quality of biodiversity data, but will also impose a more appropriate usage of such data.",https://doi.org/10.1016/j.ecoinf.2016.06.001,2016,Tomer Gueta and Yohay Carmel,QUANTIFYING THE VALUE OF USER-LEVEL DATA CLEANING FOR BIG DATA: A CASE STUDY USING MAMMAL DISTRIBUTION MODELS,article
689,3100147401,ECOLOGICAL INFORMATICS,journal,15749541,"0,774",Q1,55,109,273,5588,964,271,"3,43","51,27",Netherlands,Western Europe,Elsevier,2006-2020,"Modeling and Simulation (Q1); Applied Mathematics (Q2); Computational Theory and Mathematics (Q2); Computer Science Applications (Q2); Ecological Modeling (Q2); Ecology (Q2); Ecology, Evolution, Behavior and Systematics (Q2)","2,893",3.142,0.00332,"Over recent years, the frequency and intensity of droughts have increased and there has been a large drying trend over many parts of the world. Consequently, drought monitoring using big data analytic has gained an explosive interest. Droughts stand among the most damaging natural disasters. It threatens agricultural production, ecological environment, and socio-economic development. For this reason, early warning, accurate evaluation, and efficient prediction are an emergency especially for the nations that are the most menaced by this danger. There are numerous emerging studies addressing big data and its applications in drought monitoring. In fact, big data handle data heterogeneity which is an additive value for the prediction of drought, it offers a view of the different dimensions such as the spatial distribution, the temporal distribution and the severity detection of this phenomenon. Big data analytic and drought are introduced and reviewed in this paper. Besides, this review includes different studies, researches and applications of big data to drought monitoring. Challenges related to data life cycle such as data challenges, data processing challenges and data infrastructure management challenges are also discussed. Finally, we conclude that big data analytic can be beneficial in drought monitoring but there is a need for statistical and artificial intelligence-based approaches.",https://doi.org/10.1016/j.ecoinf.2020.101136,2020,Hanen Balti and Ali {Ben Abbes} and Nedra Mellouli and Imed Riadh Farah and Yanfang Sang and Myriam Lamolle,"A REVIEW OF DROUGHT MONITORING WITH BIG DATA: ISSUES, METHODS, CHALLENGES AND RESEARCH DIRECTIONS",article
690,23235,HEART LUNG AND CIRCULATION,journal,14439506,"0,770",Q2,46,327,744,9995,1363,618,"1,93","30,57",United Kingdom,Western Europe,Elsevier Ltd.,2000-2020,Cardiology and Cardiovascular Medicine (Q2); Pulmonary and Respiratory Medicine (Q2),"4,050",2.975,0.0073,"Cardiovascular diseases (CVD) are leading causes of death and morbidity in Australia and worldwide. Despite improvements in treatment, there remain large gaps in our understanding to prevent, treat and manage CVD events and associated morbidities. This article lays out a vision for enhancing CVD research in Australia through the development of a Big Data system, bringing together the multitude of rich administrative and health datasets available. The article describes the different types of Big Data available for CVD research in Australia and presents an overview of the potential benefits of a Big Data system for CVD research and some of the major challenges in establishing the system for Australia. The steps for progressing this vision are outlined.",https://doi.org/10.1016/j.hlc.2021.04.023,2021,Ellie Paige and Kerry Doyle and Louisa Jorm and Emily Banks and Meng-Ping Hsu and Lee Nedkoff and Tom Briffa and Dominique A. Cadilhac and Ray Mahoney and Johan W. Verjans and Girish Dwivedi and Michael Inouye and Gemma A. Figtree,A VERSATILE BIG DATA HEALTH SYSTEM FOR AUSTRALIA: DRIVING IMPROVEMENTS IN CARDIOVASCULAR HEALTH,article
691,29439,ADVANCES IN CHILD DEVELOPMENT AND BEHAVIOR,journal,00652407,"0,767",Q2,41,18,55,1682,106,8,"1,81","93,44",United States,Northern America,Academic Press Inc.,"1964-1965, 1967, 1969-1976, 1978-1980, 1982, 1984-1985, 1987, 1989, 1991, 1993-1994, 1996, 1999, 2001-2020","Developmental and Educational Psychology (Q2); Pediatrics, Perinatology and Child Health (Q2); Behavioral Neuroscience (Q3)","1,055",2.182,0.00113,"Big data are everywhere. In this chapter, we focus on one source: long-form, child-centered recordings collected using wearable technologies. Because these recordings are simultaneously unobtrusive and encompassing, they may be a breakthrough technology for clinicians and researchers from several diverse fields. We demonstrate this possibility by outlining three applications for the recordings—clinical treatment, large-scale interventions, and language documentation—where we see the greatest potential. We argue that incorporating these recordings into basic and applied research will result in more equitable treatment of patients, more reliable measurements of the effects of interventions on real-world behavior, and deeper scientific insights with less observational bias. We conclude by outlining a proposal for a semistructured online platform where vast numbers of long-form recordings could be hosted and more representative, less biased algorithms could be trained.",https://doi.org/10.1016/bs.acdb.2021.12.001,2022,Margaret Cychosz and Alejandrina Cristia,CHAPTER ONE - USING BIG DATA FROM LONG-FORM RECORDINGS TO STUDY DEVELOPMENT AND OPTIMIZE SOCIETAL IMPACT,incollection
692,19700171401,WORLD NEUROSURGERY,journal,18788750,"0,734",Q2,95,2675,7491,64788,14126,6927,"1,78","24,22",United States,Northern America,Elsevier Inc.,2010-2020,Neurology (clinical) (Q2); Surgery (Q2),"23,506",2.104,0.04375,"Objective
The National Inpatient Sample (NIS) (the largest all-payer inpatient database in the United States) is an important instrument for big data analysis of neurosurgical inquiries. However, earlier research has determined that many NIS studies are limited by common methodological pitfalls. In this study, we provide the first primer of NIS methodological procedures in the setting of neurosurgical research and review all reported neurosurgical studies using the NIS.
Methods
We designed a protocol for neurosurgical big data research using the NIS, based on our subject matter expertise, NIS documentation, and input and verification from the Healthcare Cost and Utilization Project. We subsequently used a comprehensive search strategy to identify all neurosurgical studies using the NIS in the PubMed and MEDLINE, Embase, and Web of Science databases from inception to August 2021. Studies underwent qualitative categorization (years of NIS studied, neurosurgical subspecialty, age group, and thematic focus of study objective) and analysis of longitudinal trends.
Results
We identified a canonical, 4-step protocol for NIS analysis: study population selection; defining additional clinical variables; identification and coding of outcomes; and statistical analysis. Methodological nuances discussed include identifying neurosurgery-specific admissions, addressing missing data, calculating additional severity and hospital-specific metrics, coding perioperative complications, and applying survey weights to make nationwide estimates. Inherent database limitations and common pitfalls of NIS studies discussed include lack of disease process–specific variables and data after the index admission, inability to calculate certain hospital-specific variables after 2011, performing state-level analyses, conflating hospitalization charges and costs, and not following proper statistical methodology for performing survey-weighted regression. In a systematic review, we identified 647 neurosurgical studies using the NIS. Although almost 60% of studies were reported after 2015, <10% of studies analyzed NIS data after 2015. The average sample size of studies was 507,352 patients (standard deviation = 2,739,900). Most studies analyzed cranial procedures (58.1%) and adults (68.1%). The most prevalent topic areas analyzed were surgical outcome trends (35.7%) and health policy and economics (17.8%), whereas patient disparities (9.4%) and surgeon or hospital volume (6.6%) were the least studied.
Conclusions
We present a standardized methodology to analyze the NIS, systematically review the state of the NIS neurosurgical literature, suggest potential future directions for neurosurgical big data inquiries, and outline recommendations to improve the design of future neurosurgical data instruments.",https://doi.org/10.1016/j.wneu.2022.02.113,2022,Oliver Y. Tang and Alisa Pugacheva and Ankush I. Bajaj and Krissia M. {Rivera Perla} and Robert J. Weil and Steven A. Toms,THE NATIONAL INPATIENT SAMPLE: A PRIMER FOR NEUROSURGICAL BIG DATA RESEARCH AND SYSTEMATIC REVIEW,article
693,21100836194,ICT EXPRESS,journal,24059595,"0,733",Q1,22,85,141,1553,813,140,"6,30","18,27",South Korea,Asiatic Region,Korean Institute of Communications Information Sciences,2015-2020,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1); Artificial Intelligence (Q2),789,4.317,0.0014,"This work assesses the quality of Internet of Things data not only as an intrinsic quality on how well it represents the related phenomenon but also, on how much information it contains to educate an artificial entity. The quality metrics here proposed are tested with real datasets. Also, they are implemented on OpenCPU, so the open data repositories can use them off-the-shelf to rate their datasets without computational cost and minimum human intervention, making them more attractive to potential users and gaining visibility and impact.",https://doi.org/10.1016/j.icte.2022.06.001,2022,Aurora González-Vidal and Alfonso P. Ramallo-González and Antonio F. Skarmeta,INTRINSIC AND EXTRINSIC QUALITY OF DATA FOR OPEN DATA REPOSITORIES,article
694,17388,IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING,journal,15582345,"0,732",Q1,65,83,230,2309,719,216,"3,23","27,82",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1988-2020,"Electrical and Electronic Engineering (Q1); Industrial and Manufacturing Engineering (Q1); Condensed Matter Physics (Q2); Electronic, Optical and Magnetic Materials (Q2)","1,889",2.874,0.00154,"As requirements on data volumes, rates, quality, merging, and analytics increase exponentially in the digital universe, semiconductor manufacturers are faced with a need for new approaches to data management and use across the Fab. These are often termed “big data” challenges. In our industry big data solutions will be key to scaling advanced process control (APC) solutions to finer levels of control and diagnostics. However the main impact will be to better enable more effective predictive technologies such as predictive maintenance (PdM), virtual metrology and yield prediction, all of which utilize data from traditional APC capabilities that include fault detection and classification and run-to-run control. PdM represents one area where big data solutions are generating significant benefits across a variety of process types. Moving to big data solutions involves addressing the aforementioned requirements either with enhancements of existing systems or moving to more big data friendly platforms. Big data friendly platforms applied to APC systems provide quantifiable cost-of-ownership and speed improvements, thereby better enabling high quality prediction solutions. Initially, big data solutions will largely be delegated to off-line and on-time critical tasks; over the longer term these big data solutions will increasingly be leveraged for time critical and real-time capabilities.",10.1109/TSM.2016.2574130,2016,,BIG DATA CAPABILITIES APPLIED TO SEMICONDUCTOR MANUFACTURING ADVANCED PROCESS CONTROL,
695,19700182731,EGYPTIAN INFORMATICS JOURNAL,journal,11108665,"0,728",Q1,34,47,59,1655,415,59,"6,94","35,21",Egypt,Africa/Middle East,"Faculty of Computers and Information, Cairo University",2010-2020,Information Systems (Q1); Computer Science Applications (Q2); Management Science and Operations Research (Q2),820,3.943,0.00093,"Internet of Things (IoT) is a fundamental concept of a new technology that will be promising and significant in various fields. IoT is a vision that allows things or objects equipped with sensors, actuators, and processors to talk and communicate with each other over the internet to achieve a meaningful goal. Unfortunately, one of the major challenges that affect IoT is data quality and uncertainty, as data volume increases noise, inconsistency and redundancy increases within data and causes paramount issues for IoT technologies. And since IoT is considered to be a massive quantity of heterogeneous networked embedded devices that generate big data, then it is very complex to compute and analyze such massive data. So this paper introduces a new model named NRDD-DBSCAN based on DBSCAN algorithm and using resilient distributed datasets (RDDs) to detect outliers that affect the data quality of IoT technologies. NRDD-DBSCAN has been applied on three different datasets of N-dimensions (2-D, 3-D, and 25-D) and the results were promising. Finally, comparisons have been made between NRDD-DBSCAN and previous models such as RDD-DBSCAN model and DBSCAN algorithm, and these comparisons proved that NRDD-DBSCAN solved the low dimensionality issue of RDD-DBSCAN model and also solved the fact that DBSCAN algorithm cannot handle IoT data. So the conclusion is that NRDD-DBSCAN proposed model can detect the outliers that exist in the datasets of N-dimensions by using resilient distributed datasets (RDDs), and NRDD-DBSCAN can enhance the quality of data exists in IoT applications and technologies.",https://doi.org/10.1016/j.eij.2019.12.001,2020,Haitham Ghallab and Hanan Fahmy and Mona Nasr,DETECTION OUTLIERS ON INTERNET OF THINGS USING BIG DATA TECHNOLOGY,article
696,19700176215,IEEE PHOTONICS JOURNAL,journal,19430647,"0,725",Q1,73,389,1797,11671,4920,1794,"2,65","30,00",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2009-2020,"Electrical and Electronic Engineering (Q1); Atomic and Molecular Physics, and Optics (Q2)","9,400",2.443,0.01577,"Additive haze model (AHM), due to its high simplicity, has a potential to increase the efficiency of the restoration procedure of images degraded by scattering media. However, AHM is designed for hazy remote sensing data and is not suitable to be used on outdoor images. In this paper, according to the low-frequency feature (LFC) of haze, AHM is modified via gamma correction technique to make it suitable for modeling outdoor images. Benefitting from the modified AHM (MAHM), a simple yet effective method called VROHI is proposed to enhance the visibility of an outdoor hazy image. In specific, a low complexity LFC extraction method is designed by utilizing characteristic of the discrete cosine transform. Subsequently, by constructing the linear function of unknown parameters and imposing the saturation prior on MAHM, the image dehazing problem can be derived into a global optimization function. Experiments reveal that the proposed VROHI is superior to the other state-of-the-art techniques in terms of both the processing efficiency and recovery quality.",10.1109/JPHOT.2020.3036873,2020,,VROHI: VISIBILITY RECOVERY FOR OUTDOOR HAZY IMAGE IN SCATTERING MEDIA,
697,19700176215,IEEE PHOTONICS JOURNAL,journal,19430647,"0,725",Q1,73,389,1797,11671,4920,1794,"2,65","30,00",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2009-2020,"Electrical and Electronic Engineering (Q1); Atomic and Molecular Physics, and Optics (Q2)","9,400",2.443,0.01577,"Multiple optical scattering occurs when light propagates in a non-uniform medium. During the multiple scattering, images were distorted and the spatial information they carried became scrambled. However, the image information is not lost but presents in the form of speckle patterns (SPs). In this study, we built up an optical random scattering system based on an liquid crystal display (LCD) and an RGB laser source. We found that the image classification can be improved by the help of random scattering which is considered as a feedforward neural network to extracts features from image. Along with the ridge classification deployed on computer, we achieved excellent classification accuracy higher than 94%, for a variety of data sets covering medical, agricultural, environmental protection and other fields. In addition, the proposed optical scattering system has the advantages of high speed, low power consumption, and miniaturization, which is suitable for deploying in edge computing applications.",10.1109/JPHOT.2021.3109016,2021,,IMPROVEMENT OF IMAGE CLASSIFICATION BY MULTIPLE OPTICAL SCATTERING,
698,23315,PHYSICS AND CHEMISTRY OF THE EARTH,journal,14747065,"0,724",Q2,82,111,303,5038,923,293,"2,87","45,39",United Kingdom,Western Europe,Elsevier Ltd.,"1982, 1991-1992, 1995, 2002-2020",Geochemistry and Petrology (Q2); Geophysics (Q2),"5,794",2.712,0.00279,"Rapid urbanization, population increase, emerging contaminants and increasing water scarcity have put a major constraint on the wastewater treatment system. Scarcity of water is steering current way of water recycle, and the drive focus towards resource recovery. Zero waste pathway in circular bioeconomy can bring transformation of wastewater commercialization by adding value with resource recovery. The complex biological reactions, unforeseen microbial behaviours, lack of reliable on-line instrumentation, complex modelling, lack of visualize techniques, low-quality industrial measurements and highly time-varying intensive data-driven operations call for the intelligence techniques and operations. The study is a review of sustainable circularity and intelligent data-driven operations and control of the wastewater treatment plant. Water surveillance and monitoring, circular economy and sustainability, automation pyramid, digital transformation, artificial intelligence, data pipeline, digital twin, data mining, and data-driven visualization, cyber-physical systems and water-energy-health management were reviewed. The deployment of the digital systems has evidently proven to bridges the gap between the data-driven soft sensor, operation and control systems in WWTP. Accurate prediction of the WWTP variables can support process design and control, reduce operation cost, improve system reliability, predictive maintenance and troubleshooting, increase water quality, increase stakeholder's engagement and endorse optimization of the plant performance. This procures the best compliance with international standards and diversification. The inclusion of life cycle environmental or cost management technologies in optimization models is an interesting pathway towards sustainable water treatment in-line with sustainable development goals, circular bioeconomy and industry 4.0.",https://doi.org/10.1016/j.pce.2022.103152,2022,Anthony Njuguna Matheri and Belaid Mohamed and Freeman Ntuli and Esther Nabadda and Jane Catherine Ngila,SUSTAINABLE CIRCULARITY AND INTELLIGENT DATA-DRIVEN OPERATIONS AND CONTROL OF THE WASTEWATER TREATMENT PLANT,article
699,21100784665,IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS,journal,23798939,"0,714",Q1,41,129,183,3440,783,180,"4,03","26,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2016-2020,Software (Q1); Artificial Intelligence (Q2),758,3.379,0.00155,"The ability of robots to write Chinese strokes, which is recognized as a sophisticated task, involves complicated kinematic control algorithms. The conventional approaches for robotic writing of Chinese strokes often suffer from limited font generation methods, which limits the ability of robots to perform high-quality writing. This article instead proposes a developmental evolutionary learning framework that enables a robot to learn to write fundamental Chinese strokes. The framework first considers the learning process of robotic writing as an evolutionary easy-to-difficult procedure. Then, a developmental learning mechanism called “Lift-constraint, act and saturate” that stems from developmental robotics is used to determine how the robot learns tasks ranging from simple to difficult by building on the learning results from the easy tasks. The developmental constraints, which include altitude adjustments, number of mutation points, and stroke trajectory points, determine the learning complexity of robot writing. The developmental algorithm divides the evolutionary procedure into three developmental learning stages. In each stage, the stroke trajectory points gradually increase, while the number of mutation points and adjustment altitudes gradually decrease, allowing the learning difficulties involved in these three stages to be categorized as easy, medium, and difficult. Our robot starts with an easy learning task and then gradually progresses to the medium and difficult tasks. Under various developmental constraint setups in each stage, the robot applies an evolutionary algorithm to handle the basic shapes of the Chinese strokes and eventually acquires the ability to write with good quality. The experimental results demonstrate that the proposed framework allows a calligraphic robot to gradually learn to write five fundamental Chinese strokes and also reveals a developmental pattern similar to that of humans. Compared to an evolutionary algorithm without the developmental mechanism, the proposed framework achieves good writing quality more rapidly.",10.1109/TCDS.2021.3098229,2022,,A DEVELOPMENTAL EVOLUTIONARY LEARNING FRAMEWORK FOR ROBOTIC CHINESE STROKE WRITING,
700,21100784665,IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS,journal,23798939,"0,714",Q1,41,129,183,3440,783,180,"4,03","26,67",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2016-2020,Software (Q1); Artificial Intelligence (Q2),758,3.379,0.00155,"Seizure prediction from intracranial electroencephalogram (iEEG) has great potentials to improve the life quality of epileptic patients, but faces big challenges. One major difficulty lies in which the brain signal changes occasionally during long-term monitoring, due to electrode movements or the nonstationary brain dynamics. This leads to a serious situation that a predictor learned from historical data usually only works well in a short time period as long as the data do not change much. While in a long time span, the performance of the learned features decreases or even becomes totally invalid. To deal with the problem, we propose a domain adaptation convolutional neural network to learn robust preictal features that is invariant across different time periods. Specifically, the preictal feature is learned and enhanced by multiscale temporal convolutions in the neural network. Based on this, a domain adaptation method is adopted to constrain that the learned features should be invariant across different time periods. Experimental results demonstrate that our approach can effectively improve seizure prediction performance against signal changes.",10.1109/TCDS.2021.3100270,2022,,LEARNING ROBUST FEATURES FROM NONSTATIONARY BRAIN SIGNALS BY MULTISCALE DOMAIN ADAPTATION NETWORKS FOR SEIZURE PREDICTION,
701,27952,JOURNAL OF THE FORMOSAN MEDICAL ASSOCIATION,journal,09296646,"0,708",Q2,54,340,615,9529,1377,512,"2,25","28,03",China,Asiatic Region,Excerpta Medica Asia Ltd.,"1961-1962, 1972-2020",Medicine (miscellaneous) (Q2),"5,341",3.282,0.00513,"Background
The need is growing to create medical big data based on the electronic health records collected from different hospitals. Errors for sure occur and how to correct them should be explored.
Methods
Electronic health records of 9,197,817 patients and 53,081,148 visits, totaling about 500 million records for 2006–2016, were transmitted from eight hospitals into an integrated database. We randomly selected 10% of patients, accumulated the primary keys for their tabulated data, and compared the key numbers in the transmitted data with those of the raw data. Errors were identified based on statistical testing and clinical reasoning.
Results
Data were recorded in 1573 tables. Among these, 58 (3.7%) had different key numbers, with the maximum of 16.34/1000. Statistical differences (P < 0.05) were found in 34 (58.6%), of which 15 were caused by changes in diagnostic codes, wrong accounts, or modified orders. For the rest, the differences were related to accumulation of hospital visits over time. In the remaining 24 tables (41.4%) without significant differences, three were revised because of incorrect computer programming or wrong accounts. For the rest, the programming was correct and absolute differences were negligible. The applicability was confirmed using the data of 2,730,883 patients and 15,647,468 patient-visits transmitted during 2017–2018, in which 10 (3.5%) tables were corrected.
Conclusion
Significant magnitude of inconsistent data does exist during the transmission of big data from diverse sources. Systematic validation is essential. Comparing the number of data tabulated using the primary keys allow us to rapidly identify and correct these scattered errors.",https://doi.org/10.1016/j.jfma.2021.12.024,2022,Yi-Chia Lee and Ying-Ting Chao and Pei-Ju Lin and Yen-Yun Yang and Yu-Cih Yang and Cheng-Chieh Chu and Yu-Chun Wang and Chin-Hao Chang and Shu-Lin Chuang and Wei-Chun Chen and Hsing-Jen Sun and Hsin-Cheng Tsou and Cheng-Fu Chou and Wei-Shiung Yang,QUALITY ASSURANCE OF INTEGRATIVE BIG DATA FOR MEDICAL RESEARCH WITHIN A MULTIHOSPITAL SYSTEM,article
702,19700174607,JOURNAL OF COMPUTATIONAL SCIENCE,journal,18777503,"0,704",Q1,46,123,485,5550,2325,465,"4,97","45,12",Netherlands,Western Europe,Elsevier,2010-2020,Computer Science (miscellaneous) (Q1); Modeling and Simulation (Q2); Theoretical Computer Science (Q2),"3,198",3.976,0.00489,"The application of the optimisation problems in the daily decisions of companies is able to be used for finding the best management according to the necessities of the organisations. However, optimisation problems imply a high computational complexity, increased by the current necessity to include a massive quantity of data (Big Data), for the creation of optimisation problems to customise products and services for their clients. The irruption of Big Data technologies can be a challenge but also an important mechanism to tackle the computational difficulties of optimisation problems, and the possibility to distribute the problem performance. In this paper, we propose a solution that lets the query of a data set supported by Big Data technologies that imply the resolution of Constraint Optimisation Problem (COP). This proposal enables to: (1) model COPs whose input data are obtained from distributed and heterogeneous data; (2) facilitate the integration of different data sources to create the COPs; and, (3) solve the optimisation problems in a distributed way, to improve the performance. It is done by means of a framework and supported by a tool capable of modelling, solving and querying the results of optimisation problems. The tool integrates the Big Data technologies and commercial solvers of constraint programming. The suitability of the proposal and the development have been evaluated with real data sets whose computational study and results are included and discussed.",https://doi.org/10.1016/j.jocs.2020.101180,2020,Álvaro Valencia-Parra and Ángel Jesús Varela-Vaca and Luisa Parody and María Teresa Gómez-López,UNLEASHING CONSTRAINT OPTIMISATION PROBLEM SOLVING IN BIG DATA ENVIRONMENTS,article
703,19700174607,JOURNAL OF COMPUTATIONAL SCIENCE,journal,18777503,"0,704",Q1,46,123,485,5550,2325,465,"4,97","45,12",Netherlands,Western Europe,Elsevier,2010-2020,Computer Science (miscellaneous) (Q1); Modeling and Simulation (Q2); Theoretical Computer Science (Q2),"3,198",3.976,0.00489,"Smart manufacturing refers to a future-state of manufacturing and it can lead to remarkable changes in all aspects of operations through minimizing energy and material usage while simultaneously maximizing sustainability enabling a futuristic more digitalized scenario of manufacturing. This research develops a big data analytics framework that optimizes the maintenance schedule through condition-based maintenance (CBM) optimization and also improves the prediction accuracy to quantify the remaining life prediction uncertainty. Through effective utilization of condition monitoring and prediction information, CBM would enhance equipment reliability leading to reduction in maintenance cost. The proposed framework uses a CBM optimization method that utilizes a new linguistic interval-valued fuzzy reasoning method for predicting the information. The proposed big data analytics framework in our study for estimating the uncertainty based on backward feature elimination and fuzzy unordered rule induction algorithm prediction errors, is an innovative contribution to the remaining life prediction field. Our paper elaborates on the basic underlying structure of CBM system that is defined by transaction matrix and the threshold value of failure probability. We developed this framework for analysing the CBM policy cost more accurately and to find the probabilistic threshold values of covariate that corresponds to the lowest price of predictive maintenance cost. The experimental results are performed on a big dataset which is generated from a sophisticated simulator of a gas turbine propulsion plant. A comparative analysis confirms that the method used in the proposed framework outpaces the classical methods in terms of classification accuracy and other statistical performance evaluation metrics.",https://doi.org/10.1016/j.jocs.2017.06.006,2018,Ajay Kumar and Ravi Shankar and Lakshman S. Thakur,A BIG DATA DRIVEN SUSTAINABLE MANUFACTURING FRAMEWORK FOR CONDITION-BASED MAINTENANCE PREDICTION,article
704,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"With growing data volumes and the scaling of data center clusters, communication resources often become a bottleneck in service provisioning for many MapReduce applications (e.g., training machine learning models). Therefore, data placements that bring data blocks closer to data consumers (e.g., MapReduce applications) are seen as a promising solution. In this article, we propose an efficient data-placement technique that considers network traffic reduction as well as QoS guarantees for the data blocks to optimize the communication resources. We first formulate the joint optimization of the data-placement problem, propose a generic model for minimizing communication costs, and show that the joint data-placement problem is NP-hard. To solve this problem, we propose a heuristic algorithm considering traffic flows in the network topology of data centers by first seeking optimal QoS-aware data placement based on golden division on a Zipflike replica distribution, then transforming the joint data-placement problem into a block-dependence tree (BDT) construction problem, and finally reducing the BDT construction to a graph-partitioning problem. The experimental results demonstrate that our data-placement approach could effectively improve the performance of MapReduce jobs with lower communication costs and less job execution time for big-data processing.",10.1109/TEM.2020.2971717,2021,,QOS-AWARE DATA PLACEMENT FOR MAPREDUCE APPLICATIONS IN GEO-DISTRIBUTED DATA CENTERS,
705,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"The recent advances in Internet of Things (IoT), computational analytics, processing power, and assimilation of Big Data (BD) are playing an important role in revolutionizing maintenance and operations regimes within the wider facilities management (FM) sector. The BD offers the potential for the FM to obtain valuable insights from a large amount of heterogeneous data collected through various sources and IoT allows for the integration of sensors. The aim of this article is to extend the exploratory studies conducted on Big Data analytics (BDA) implementation and empirically test and categorize the associated drivers and challenges. Using exploratory factor analysis (EFA), the researchers aim to bridge the current knowledge gap and highlight the principal factors affecting the BDA implementation. Questionnaires detailing 26 variables are sent to the FM organization in the U.K. who are in the process or have already implemented BDA initiatives within their FM operations. Fifty-two valid responses are analyzed by conducting EFA. The findings suggest that driven by market competition and ambitious sustainability goals, the industry is moving to holistically integrate analytics into its decision making. However, data quality, technological barriers, inadequate preparedness, data management, and governance issues and skill gaps are posing to be significant barriers to the fulfillment of expected opportunities. The findings of this study have important implications for FM businesses that are evaluating the potential of the BDA and IoT applications for their operations. Most importantly, it addresses the role of the BD maturity in FM organizations and its implications for perception of drivers.",10.1109/TEM.2019.2959914,2022,,DRIVERS AND CHALLENGES ASSOCIATED WITH THE IMPLEMENTATION OF BIG DATA WITHIN U.K. FACILITIES MANAGEMENT SECTOR: AN EXPLORATORY FACTOR ANALYSIS APPROACH,
706,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"In order to maximize the value of an organization's data assets, it is important to keep data in its databases up-to-date. In the era of big data, however, constantly changing data sources make it a challenging task to assure data timeliness in enterprise systems. For instance, due to the high frequency of purchase transactions, purchase data stored in an enterprise resource planning system can easily become outdated, affecting the accuracy of inventory data and the quality of inventory replenishment decisions. Despite the importance of data timeliness, updating a database as soon as new data arrives is typically not optimal because of high update cost. Therefore, a critical problem in this context is to determine the optimal update policy for database systems. In this study, we develop a Markov decision process model, solved via dynamic programming, to derive the optimal update policy that minimizes the sum of data staleness cost and update cost. Based on real-world enterprise data, we conduct experiments to evaluate the performance of the proposed update policy in relation to benchmark policies analyzed in the prior literature. The experimental results show that the proposed update policy outperforms fixed interval update policies and can lead to significant cost savings.",10.1109/TEM.2017.2648516,2017,,A MARKOV-BASED UPDATE POLICY FOR CONSTANTLY CHANGING DATABASE SYSTEMS,
707,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"In the big data era, managing data-driven hospital operations have become one of the most important tasks for healthcare executives, increasing responsiveness to exceptional disruptions such as those caused by the COVID-19 pandemic. However, they are still facing the challenges of how best to orchestrate the digital medical resources for improving operational performance such as cost, delivery, and quality. Therefore, drawing upon resource orchestration theory, this article investigates how hospitals orchestrate data-driven culture (DDC) and digital technology orientation (DTO) to develop big data analytics capability (BDAC) for operational performance improvement. Survey data were collected from 105 hospitals in China and analyzed using structural equation modeling and ordinary least square regression. The results show that DDC has a significant positive impact on DTO. More interestingly, there is no significant interaction effect between DDC and DTO, indicating that DDC and DTO affect BDAC independently, and not synergistically. The results further reveal that BDAC fully mediates the DTO&#x2013;operational performance relationship. The findings offer useful and timely guidance on how healthcare executives can manage data-driven hospital operations to improve operational performance during and post the COVID-19 pandemic.",10.1109/TEM.2021.3098541,2021,,EXPLORING THE EFFECTS OF DATA-DRIVEN HOSPITAL OPERATIONS ON OPERATIONAL PERFORMANCE FROM THE RESOURCE ORCHESTRATION THEORY PERSPECTIVE,
708,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"The purpose of this article is to identify and evaluate the limitations and emerging trends of Six Sigma from the perspectives of Six Sigma experts. The authors developed an online global survey and deployed the survey to 1250 Six Sigma experts of which 307 experts responded. The article finds integration of Six Sigma with Big Data to be the topmost among Asian, South American, and African experts, whereas European and North American experts felt Six Sigma in Small and Medium Sized Enterprises and Micro-enterprises would be very beneficial. The manufacturing sector experts nominated the topmost emerging trend as Six Sigma in Small and Medium Sized Enterprises and Micro-enterprises to be very challenging and will be rewarding if implemented properly. In the service sector, the topmost emerging trend was the integration of Six Sigma with Big Data. However, public sector experts felt variance reduction should not be the only goal of Six Sigma implementation. The that master black belts perceived Six Sigma in Small and Medium Sized Enterprises and Micro-enterprises would be advantageous, whereas Black and Green Belts perceived Integration of Six Sigma with Big Data to be topmost emerging trend.",10.1109/TEM.2020.2995168,2022,,AN EMPIRICAL STUDY INTO THE LIMITATIONS AND EMERGING TRENDS OF SIX SIGMA: FINDINGS FROM A GLOBAL SURVEY,
709,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"The concept of the smart city has been created in response to the increasing numbers of people living in cities. Just as the development of technology has evolved rapidly, smart life has also emerged. The goal of the smart city is one day to enable all affairs of daily life to be completed with the single touch of a finger through cutting-edge technology. New and innovative information must be applied effectively to the industry. With the industrial revolution, propelled by the Internet of Things (IoT), big data and the cloud platform have birthed the “smart city,” integrating the IoT and the cloud through mobile devices and applying technology to fields like logistics, finance, healthcare, recreation, surveillance, and traffic transportation, thus providing people with greater well-being and convenience. Following the era of the big data knowledge economy, the IoT has become an important pillar of national economic development. The IoT is expected to provide substantial support for continued and sustainable development of the smart city. Therefore, effective use of the IoT has become an important topic in smart city development. The purpose of this paper is to build a conceptual framework of service innovation, relying on the smart city case of Taiwan. Based on a literature review, in-depth interviews, and case interviews, the proposed conceptual framework of IoT is rooted in the market, policy, and technical aspects. It incorporates eight steps: composition of the project team, service idea generation, service idea screening, development concept selection, design and development, service testing, commercialization, and service quality, to generate new service value and thereby create customer satisfaction. In fact, the IoT is designed to support the smart city vision; thus, this paper describes the various innovation modes of the smart city. Furthermore, the paper presents and discusses the technical solutions and best-practice guidelines adopted in the Taiwan Smart City project. Finally, it discusses the meaning and future research direction of the smart city through the use of the IoT. With wave after wave of digital development civilizing the city's evolution and with the phenomenon of Internet access through mobile phones for each person, the smart city of human factors is clearly coming.",10.1109/TEM.2019.2908962,2021,,ELEVATED PERFORMANCE OF THE SMART CITY—A CASE STUDY OF THE IOT BY INNOVATION MODE,
710,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"Society 5.0 refers to an advanced society based on big data, artificial intelligence, sensors, and robots to improve many aspects of life in a smart city. The role of sensors in Society 5.0 is critical. Sensors and the Internet of Things can be considered to work as a service system. Specifically, sensors can track millions of objects to support city security. This article considers the competitive sensor networks in terms of Quality of Service, which can be quantified by service price. The sensors are modeled as an <formula><tex>$M/M/1/n$</tex></formula> queueing service system with a location on a secured grid area. A competitive admission fee is considered for tracking orders from society, which makes the arriving tracking demands price-sensitive. Moreover, a bi-level nonlinear program is developed wherein the first level maximizes the sensors&#x2019; revenue and social benefit revenue while also minimizing the wait time of tracking orders from society; in the second level, the expected damage cost is minimized from a disruptive scenario toward valuable infrastructure. Moreover, the second-level model is linearized, and it solves the problem by a branch and bound and enumeration algorithm. Finally, an illustrative example of the proposed model is presented.",10.1109/TEM.2021.3088389,2021,,"AN INTEGRATED PRICING, QOS-AWARE SENSOR LOCATION MODEL FOR SECURITY PROTECTION IN SOCIETY 5.0",
711,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"With the vigorous development of big data and information technology, promoting science and technology resources opening and sharing (STROS) has become a promising strategy to develop national innovation capacity. China has established various STROS platforms (STROSP) at the national and regional levels to encourage resources and knowledge sharing. However, STROSP efficiency evaluation is challenged in a vague environment, in which subjective and imprecise information in acquiring evaluation preferences of decision makers is a key obstacle. To solve these problems, an innovative model for STROSP efficiency evaluation is developed. An indicator assessment system explicitly considers the key evaluation aspects, namely, service quantity, service quality, and service effect. This article combines fuzzy analytic hierarchy process (FAHP) and backpropagation (BP) neural network algorithm into an integrated model to quantify the efficiency of STROS. Prior knowledge of experts was fully utilized by FAHP. The neural network algorithm enabled the intelligent extraction and rapid inference of sample data features. The proposed model maximizes fuzzy mathematics in solving fuzzy and nonquantifiable problems and utilizes the advantages of the BP neural network on nonlinear mapping. The accuracy and reliability of the model are validated by a case study of six national STROSP in China. Estimation results demonstrate that the model is a powerful method for the real-time evaluation of STROS efficiency evaluation.",10.1109/TEM.2022.3173370,2022,,A VAGUENESS ADAPTIVE EFFICIENCY EVALUATION METHOD OF SCIENCE AND TECHNOLOGY RESOURCES OPENING AND SHARING PLATFORMS BASED ON FAHP AND BP NEURAL NETWORK,
712,17359,IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT,journal,15580040,"0,702",Q1,92,252,223,6766,668,212,"2,81","26,85",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1969-2020,Electrical and Electronic Engineering (Q1); Strategy and Management (Q2),"4,148",6.146,0.00209,"The seven papers in this special section focus on services computing management for artificial intelligence and machine learning. The goal of services computing is to enable IT services and computing technology to perform business services more efficiently and effectively. The pervasive nature of services computing management is exhibited in almost all industry settings. In everyday life, new business service innovations will give rise to an emergent data- and information-focused economy that will only pick up steam as both consumer and business utilization of Internet of Things are advanced. These AI services can be formed from high-level computational intelligence that leverages emerging analytical techniques associated with big data, web analytics, data and text mining, ontology engineering, semantic web, and many other advances. At the same time, it becomes increasingly important to anticipate technical and practical challenges and to identify best practices learned through experience.",10.1109/TEM.2020.3024363,2021,,EDITORIAL: SPECIAL SECTION ON SERVICES COMPUTING MANAGEMENT FOR ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING,
713,21100241218,ASTRONOMY AND COMPUTING,journal,22131337,"0,692",Q2,31,46,133,2012,475,132,"3,53","43,74",Netherlands,Western Europe,Elsevier BV,2013-2020,Astronomy and Astrophysics (Q2); Computer Science Applications (Q2); Space and Planetary Science (Q2),796,1.927,0.0025,"As the demand for software to support the processing and analysis of massive radio astronomy datasets increases in the era of the SKA, we demonstrate the interactive workflow building, data mining, processing, and visualisation capabilities of DUG Insight. We test the performance and flexibility of DUG Insight by processing almost 68,000 full sky radio images produced from the Engineering Development Array (EDA2) over the course of a three day period. The goal of the processing was to passively detect and identify known Resident Space Objects (RSOs: satellites and debris in orbit) and investigate how radio interferometry could be used to passively monitor aircraft traffic. These signals are observable due to both terrestrial FM radio signals reflected back to Earth and out-of-band transmission from RSOs. This surveillance of the low Earth orbit and airspace environment is useful as a contribution to space situational awareness and aircraft tracking technology. From the observations, we made 40 detections of 19 unique RSOs within a range of 1,500 km from the EDA2. This is a significant improvement on a previously published study of the same dataset and showcases the flexible features of DUG Insight that allow the processing of complex datasets at scale. Future enhancements of our DUG Insight workflow will aim to realise real-time acquisition, detect unknown RSOs, and continue to process data from SKA-relevant facilities.",https://doi.org/10.1016/j.ascom.2022.100619,2022,D. Grigg and S.J. Tingay and M. Sokolowski and R.B. Wayth,"DUG INSIGHT: A SOFTWARE PACKAGE FOR BIG-DATA ANALYSIS AND VISUALISATION, AND ITS DEMONSTRATION FOR PASSIVE RADAR SPACE SITUATIONAL AWARENESS USING RADIO TELESCOPES",article
714,26792,CLINICS IN LABORATORY MEDICINE,journal,02722712,"0,690",Q2,55,52,173,2113,398,149,"1,61","40,63",United Kingdom,Western Europe,W.B. Saunders Ltd,1981-2020,Biochemistry (medical) (Q2); Clinical Biochemistry (Q3),"1,772",1.935,0.00186,,https://doi.org/10.1016/j.cll.2019.11.009,2020,Emily L. Gill and Stephen R. Master,BIG DATA EVERYWHERE: THE IMPACT OF DATA DISJUNCTION IN THE DIRECT-TO-CONSUMER TESTING MODEL,article
715,3200147819,PERVASIVE AND MOBILE COMPUTING,journal,15741192,"0,687",Q1,64,68,350,2760,1558,342,"4,67","40,59",Netherlands,Western Europe,Elsevier,2005-2020,Computer Networks and Communications (Q1); Computer Science (miscellaneous) (Q1); Hardware and Architecture (Q1); Information Systems (Q1); Software (Q1); Applied Mathematics (Q2); Computer Science Applications (Q2),"2,540",3.453,0.00335,"With gigabit networking becoming economically feasible and widely installed at homes, there are new opportunities to revisit in-home, personalized telehealth services. In this paper, we describe a novel telehealth eldercare service that we developed viz., “PhysicalTherapy-as-a-Service” (PTaaS) that connects a remote physical therapist at a clinic to a senior at home. The service leverages a high-speed, low-latency network connection through an interactive interface built on top of Microsoft Kinect motion sensing capabilities. The interface that is built using user-centered design principles for wellness coaching exercises is essentially a ‘Synchronous Big Data’ application due to its: (i) high data-in-motion velocity (i.e., peak data rate is ≈400 Mbps), (ii) considerable variety (i.e., measurements include 3D sensing, network health, user opinion surveys and video clips of RGB, skeletal and depth data), and (iii) large volume (i.e., several GB of measurement data for a simple exercise activity). The successful PTaaS delivery through this interface is dependent on the veracity analytics needed for correlation of the real-time Big Data streams within a session, in order to assess exercise balance of the senior without any bias due to network quality effects. Our experiments with PTaaS in an actual testbed involving senior homes in Kansas City with Google Fiber connections and our university clinic demonstrate the network configuration and time synchronization related challenges in order to perform online analytics. Our findings provide insights on how to: (a) enable suitable resource calibration and perform network troubleshooting for high user experience for both the therapist and the senior, and (b) realize a Big Data architecture for PTaaS and other similar personalized healthcare services to be remotely delivered at a large-scale in a reliable, secure and cost-effective manner.",https://doi.org/10.1016/j.pmcj.2015.09.004,2016,Prasad Calyam and Anup Mishra and Ronny Bazan Antequera and Dmitrii Chemodanov and Alex Berryman and Kunpeng Zhu and Carmen Abbott and Marjorie Skubic,SYNCHRONOUS BIG DATA ANALYTICS FOR PERSONALIZED AND REMOTE PHYSICAL THERAPY,article
716,23831,JOURNAL OF CARDIOTHORACIC AND VASCULAR ANESTHESIA,journal,10530770,"0,678",Q2,82,770,1616,22269,2501,1041,"1,58","28,92",United Kingdom,Western Europe,W.B. Saunders Ltd,1991-2020,Anesthesiology and Pain Medicine (Q2); Cardiology and Cardiovascular Medicine (Q2),"7,080",2.628,0.00838,,https://doi.org/10.1053/j.jvca.2019.11.012,2020,Michael R. Mathis and Timur Z. Dubovoy and Matthew D. Caldwell and Milo C. Engoren,MAKING SENSE OF BIG DATA TO IMPROVE PERIOPERATIVE CARE: LEARNING HEALTH SYSTEMS AND THE MULTICENTER PERIOPERATIVE OUTCOMES GROUP,article
717,22285,SEMINARS IN VASCULAR SURGERY,journal,08957967,"0,644",Q2,48,17,46,398,66,38,"0,75","23,41",United Kingdom,Western Europe,W.B. Saunders Ltd,1990-2020,Cardiology and Cardiovascular Medicine (Q2); Surgery (Q2),734,1.000,0.00065,"ABSTRACT
The field of vascular surgery is in constant evolution. Administrative data and registries can provide important contemporary evidence to inform clinical decision making and the delivery of health services. The following review outlines some important considerations for retrospective studies using administrative health databases and registries. First, these data sources have advantages (e.g. real-world applicability, timely data access, relatively lower research cost) and disadvantages (e.g. potential missing data, selection bias, confounding bias) that may be more or less relevant to different administrative databases or registries. Second, we discuss a framework to guide data source selection and provide a summary of frequently used data sources in vascular surgery research. Third, a retrospective study design warrants pre-planned exposure, outcome and covariate definitions and, when studying an exposure-outcome association, careful consideration of confounders through direct acyclic graphs. Finally, investigators must plan the most appropriate analytic approach and we distinguish descriptive, explanatory, and predictive analyses.",https://doi.org/10.1053/j.semvascsurg.2022.09.002,2022,Jean Jacob-Brassard and Charles {de Mestral},BIG DATA: USING DATABASES AND REGISTRIES,article
718,22285,SEMINARS IN VASCULAR SURGERY,journal,08957967,"0,644",Q2,48,17,46,398,66,38,"0,75","23,41",United Kingdom,Western Europe,W.B. Saunders Ltd,1990-2020,Cardiology and Cardiovascular Medicine (Q2); Surgery (Q2),734,1.000,0.00065,"ABSTRACT
Artificial intelligence (AI) is the next great advance informing medical science. Several disciplines, including vascular surgery, use AI-based decision-making tools to improve clinical performance. Although applied widely, AI functions best when confronted with voluminous, accurate data. Consistent, predictable analytic technique selection also challenges researchers. This article contextualizes AI analyses within evidence-based medicine, focusing on “big data” and health services research, as well as discussing opportunities to improve data collection and realize AI's promise.",https://doi.org/10.1053/j.semvascsurg.2021.10.005,2021,Devin S. Zarkowsky and David P. Stonko,ARTIFICIAL INTELLIGENCE'S ROLE IN VASCULAR SURGERY DECISION-MAKING,article
719,19309,JOURNAL OF SYSTEMS AND SOFTWARE,journal,01641212,"0,642",Q1,109,183,619,11845,3058,590,"4,94","64,73",United States,Northern America,Elsevier Inc.,"1979, 1981-2021",Hardware and Architecture (Q1); Information Systems (Q2); Software (Q2),"6,579",2.829,0.00727,"Deep learning (DL) based software systems are difficult to develop and maintain in industrial settings due to several challenges. Data management is one of the most prominent challenges which complicates DL in industrial deployments. DL models are data-hungry and require high-quality data. Therefore, the volume, variety, velocity, and quality of data cannot be compromised. This study aims to explore the data management challenges encountered by practitioners developing systems with DL components, identify the potential solutions from the literature and validate the solutions through a multiple case study. We identified 20 data management challenges experienced by DL practitioners through a multiple interpretive case study. Further, we identified 48 articles through a systematic literature review that discuss the solutions for the data management challenges. With the second round of multiple case study, we show that many of these solutions have limitations and are not used in practice due to a combination of four factors: high cost, lack of skill-set and infrastructure, inability to solve the problem completely, and incompatibility with certain DL use cases. Thus, data management for data-intensive DL models in production is complicated. Although the DL technology has achieved very promising results, there is still a significant need for further research in the field of data management to build high-quality datasets and streams that can be used for building production-ready DL systems. Furthermore, we have classified the data management challenges into four categories based on the availability of the solutions.",https://doi.org/10.1016/j.jss.2022.111359,2022,Aiswarya Raj Munappy and Jan Bosch and Helena Holmström Olsson and Anders Arpteg and Björn Brinne,DATA MANAGEMENT FOR PRODUCTION QUALITY DEEP LEARNING MODELS: CHALLENGES AND SOLUTIONS,article
720,19309,JOURNAL OF SYSTEMS AND SOFTWARE,journal,01641212,"0,642",Q1,109,183,619,11845,3058,590,"4,94","64,73",United States,Northern America,Elsevier Inc.,"1979, 1981-2021",Hardware and Architecture (Q1); Information Systems (Q2); Software (Q2),"6,579",2.829,0.00727,"Context
Big Data Cybersecurity Analytics (BDCA) systems leverage big data technologies for analyzing security events data to protect organizational networks, computers, and data from cyber attacks.
Objective
We aimed at identifying the most frequently reported quality attributes and architectural tactics for BDCA systems.
Method
We used Systematic Literature Review (SLR) method for reviewing 74 papers.
Result
Our findings are twofold: (i) identification of 12 most frequently reported quality attributes for BDCA systems; and (ii) identification and codification of 17 architectural tactics for addressing the identified quality attributes. The identified tactics include six performance tactics, four accuracy tactics, two scalability tactics, three reliability tactics, and one security and usability tactic each.
Conclusion
Our study reveals that in the context of BDCA (a) performance, accuracy and scalability are the most important quality concerns (b) data analytics is the most critical architectural component (c) despite the significance of interoperability, modifiability, adaptability, generality, stealthiness, and privacy assurance, these quality attributes lack explicit architectural support (d) empirical investigation is required to evaluate the impact of the codified tactics and explore the quality trade-offs and dependencies among the tactics and (e) the reported tactics need to be modelled using a standardized modelling language such as UML.",https://doi.org/10.1016/j.jss.2019.01.051,2019,Faheem Ullah and Muhammad {Ali Babar},ARCHITECTURAL TACTICS FOR BIG DATA CYBERSECURITY ANALYTICS SYSTEMS: A REVIEW,article
721,19309,JOURNAL OF SYSTEMS AND SOFTWARE,journal,01641212,"0,642",Q1,109,183,619,11845,3058,590,"4,94","64,73",United States,Northern America,Elsevier Inc.,"1979, 1981-2021",Hardware and Architecture (Q1); Information Systems (Q2); Software (Q2),"6,579",2.829,0.00727,"The most successful organizations in the world are data-driven businesses. Data is at the core of the business of many organizations as one of the most important assets, since the decisions they make cannot be better than the data on which they are based. Due to this reason, organizations need to be able to trust their data. One important activity that helps to achieve data reliability is the evaluation and certification of the quality level of organizational data repositories. This paper describes the results of the application of a data quality evaluation and certification process to the repositories of three European organizations belonging to different sectors. We present findings from the point of view of both the data quality evaluation team and the organizations that underwent the evaluation process. In this respect, several benefits have been explicitly recognized by the involved organizations after achieving the data quality certification for their repositories (e.g., long-term organizational sustainability better internal knowledge of data, and a more efficient management of data quality). As a result of this experience, we have also identified a set of best practices aimed to enhance the data quality evaluation process.",https://doi.org/10.1016/j.jss.2021.110938,2021,Fernando Gualo and Moisés Rodriguez and Javier Verdugo and Ismael Caballero and Mario Piattini,DATA QUALITY CERTIFICATION USING ISO/IEC 25012: INDUSTRIAL EXPERIENCES,article
722,19309,JOURNAL OF SYSTEMS AND SOFTWARE,journal,01641212,"0,642",Q1,109,183,619,11845,3058,590,"4,94","64,73",United States,Northern America,Elsevier Inc.,"1979, 1981-2021",Hardware and Architecture (Q1); Information Systems (Q2); Software (Q2),"6,579",2.829,0.00727,"Apache Spark is one of the most popular big data frameworks that abstract the underlying distributed computation details. However, even though Spark provides various abstractions, developers may still encounter challenges related to the peculiarity of distributed computation and environment. To understand the challenges that developers encounter, and provide insight for future studies, in this paper, we conduct an empirical study on the questions that developers encounter. We manually analyze 1,000 randomly selected questions that we collected from Stack Overflow. We find that: 1) questions related to data processing (e.g., transforming data format) are the most common among the 11 types of questions that we uncovered. 2) Even though data processing questions are the most common ones, they require the least amount of time to receive an answer. Questions related to configuration and performance require the most time to receive an answer. 3) Most of the issues are caused by developers’ insufficient knowledge in API usages, data conversation across frameworks, and environment-related configurations. We also discuss the implication of our findings for researchers and practitioners. In summary, our work provides insights for future research directions and highlight the need for more software engineering research in this area.",https://doi.org/10.1016/j.jss.2022.111488,2022,Zehao Wang and Tse-Hsun (Peter) Chen and Haoxiang Zhang and Shaowei Wang,AN EMPIRICAL STUDY ON THE CHALLENGES THAT DEVELOPERS ENCOUNTER WHEN DEVELOPING APACHE SPARK APPLICATIONS,article
723,19309,JOURNAL OF SYSTEMS AND SOFTWARE,journal,01641212,"0,642",Q1,109,183,619,11845,3058,590,"4,94","64,73",United States,Northern America,Elsevier Inc.,"1979, 1981-2021",Hardware and Architecture (Q1); Information Systems (Q2); Software (Q2),"6,579",2.829,0.00727,"In this paper we present a collection of ontologies specifically designed to model the information exchange needs of combined software and data engineering. Effective, collaborative integration of software and big data engineering for Web-scale systems, is now a crucial technical and economic challenge. This requires new combined data and software engineering processes and tools. Our proposed models have been deployed to enable: tool-chain integration, such as the exchange of data quality reports; cross-domain communication, such as interlinked data and software unit testing; mediation of the system design process through the capture of design intents and as a source of context for model-driven software engineering processes. These ontologies are deployed in web-scale, data-intensive, system development environments in both the commercial and academic domains. We exemplify the usage of the suite on case-studies emerging from two complex collaborative software and data engineering scenarios: one from the legal sector and the other from the Social sciences and Humanities domain.",https://doi.org/10.1016/j.jss.2018.12.017,2019,Monika Solanki and Bojan Božić and Christian Dirschl and Rob Brennan,TOWARDS A KNOWLEDGE DRIVEN FRAMEWORK FOR BRIDGING THE GAP BETWEEN SOFTWARE AND DATA ENGINEERING,article
724,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"In the big data era, large amounts of data are under generation and accumulation in various industries. However, users usually feel hindered by the data quality issues when extracting values from the big data. Thus, data quality issues are gaining more and more attention from data quality management analysts. Cutting-edge solutions like data ETL, data cleaning, and data quality monitoring systems have many deficiencies in capability and efficiency, making it difficult to cope with complicated situations on big data. These problems inspire us to build SparkDQ, a generic distributed data quality management model and framework that provides a series of data quality detection and repair interfaces. Users can quickly build custom tasks of data quality computing for various needs by utilizing these interfaces. In addition, SparkDQ implements a set of algorithms that in a parallel manner with optimizations. These algorithms aim at various data quality goals. We also propose several system-level optimizations, including the job-level optimization with multi-task execution scheduling and the data-level optimization with data state caching. The experimental evaluation shows that the proposed distributed algorithms in SparkDQ run up to 12 times faster compared to the corresponding stand-alone serial and multi-thread algorithms. Compared with the cutting-edge distributed data quality solution Apache Griffin, SparkDQ has more features, and its execution time is only around half of Apache Griffin on average. SparkDQ achieves near-linear data and node scalability.",https://doi.org/10.1016/j.jpdc.2021.05.012,2021,Rong Gu and Yang Qi and Tongyu Wu and Zhaokang Wang and Xiaolong Xu and Chunfeng Yuan and Yihua Huang,SPARKDQ: EFFICIENT GENERIC BIG DATA QUALITY MANAGEMENT ON DISTRIBUTED DATA-PARALLEL COMPUTATION,article
725,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"One of the major applications of future generation parallel and distributed systems is in big-data analytics. Data repositories for such applications currently exceed exabytes and are rapidly increasing in size. Beyond their sheer magnitude, these datasets and associated applications’ considerations pose significant challenges for method and software development. Datasets are often distributed and their size and privacy considerations warrant distributed techniques. Data often resides on platforms with widely varying computational and network capabilities. Considerations of fault-tolerance, security, and access control are critical in many applications (Dean and Ghemawat, 2004; Apache hadoop). Analysis tasks often have hard deadlines, and data quality is a major concern in yet other applications. For most emerging applications, data-driven models and methods, capable of operating at scale, are as-yet unknown. Even when known methods can be scaled, validation of results is a major issue. Characteristics of hardware platforms and the software stack fundamentally impact data analytics. In this article, we provide an overview of the state-of-the-art and focus on emerging trends to highlight the hardware, software, and application landscape of big-data analytics.",https://doi.org/10.1016/j.jpdc.2014.01.003,2014,Karthik Kambatla and Giorgos Kollias and Vipin Kumar and Ananth Grama,TRENDS IN BIG DATA ANALYTICS,article
726,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"Real-time monitoring of cloud resources is crucial for a variety of tasks such as performance analysis, workload management, capacity planning and fault detection. Applications producing big data make the monitoring task very difficult at high sampling frequencies because of high computational and communication overheads in collecting, storing, and managing information. We present an adaptive algorithm for monitoring big data applications that adapts the intervals of sampling and frequency of updates to data characteristics and administrator needs. Adaptivity allows us to limit computational and communication costs and to guarantee high reliability in capturing relevant load changes. Experimental evaluations performed on a large testbed show the ability of the proposed adaptive algorithm to reduce resource utilization and communication overhead of big data monitoring without penalizing the quality of data, and demonstrate our improvements to the state of the art.",https://doi.org/10.1016/j.jpdc.2014.08.007,2015,Mauro Andreolini and Michele Colajanni and Marcello Pietri and Stefania Tosi,"ADAPTIVE, SCALABLE AND RELIABLE MONITORING OF BIG DATA ON CLOUDS",article
727,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,,https://doi.org/10.1016/j.jpdc.2017.05.020,2017,Xian-He Sun and Marc Frincu and Charalampos Chelmis,SPECIAL ISSUE ON SCALABLE COMPUTING SYSTEMS FOR BIG DATA APPLICATIONS,article
728,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"This paper discusses approaches and environments for carrying out analytics on Clouds for Big Data applications. It revolves around four important areas of analytics and Big Data, namely (i) data management and supporting architectures; (ii) model development and scoring; (iii) visualisation and user interaction; and (iv) business models. Through a detailed survey, we identify possible gaps in technology and provide recommendations for the research community on future directions on Cloud-supported Big Data computing and analytics solutions.",https://doi.org/10.1016/j.jpdc.2014.08.003,2015,Marcos D. Assunção and Rodrigo N. Calheiros and Silvia Bianchi and Marco A.S. Netto and Rajkumar Buyya,BIG DATA COMPUTING AND CLOUDS: TRENDS AND FUTURE DIRECTIONS,article
729,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"The proliferation of Internet of Things (IoT) has led to the emergence of enabling many interesting applications within the realm of several domains including smart cities. However, the accumulation of data from smart IoT devices poses significant challenges for data storage while there are needs to deliver relevant and high quality services to consumers. In this paper, we propose QDaS, a novel domain agnostic framework as a solution for effective data storage and management of IoT applications. The framework incorporates a novel data summarisation mechanism that uses an innovative data quality estimation technique. This proposed data quality estimation technique computes the quality of data (based on their utility) without requiring any feedback from users of this IoT data or domain awareness of the data. We evaluate the effectiveness of the proposed QDaS framework using real world datasets.",https://doi.org/10.1016/j.jpdc.2018.03.013,2019,Jonathan Liono and Prem Prakash Jayaraman and A.K. Qin and Thuong Nguyen and Flora D. Salim,QDAS: QUALITY DRIVEN DATA SUMMARISATION FOR EFFECTIVE STORAGE MANAGEMENT IN INTERNET OF THINGS,article
730,25621,JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING,journal,07437315,"0,638",Q1,87,169,592,7166,2473,568,"4,72","42,40",United States,Northern America,Academic Press Inc.,1984-2021,Computer Networks and Communications (Q1); Hardware and Architecture (Q1); Artificial Intelligence (Q2); Software (Q2); Theoretical Computer Science (Q2),"4,371",3.734,0.00477,"Record Linkage (RL) is the task of identifying duplicate entities in a dataset or multiple datasets. In the era of Big Data, this task has gained notorious attention due to the intrinsic quadratic complexity of the problem in relation to the size of the dataset. In practice, this task can be outsourced to a cloud service, and thus, a service customer may be interested in estimating the costs of a record linkage solution before executing it. Since the execution time of a record linkage solution depends on a combination of various algorithms, their respective parameter values and the employed cloud infrastructure, in practice it is hard to perform an a priori estimation of infrastructure costs for executing a record linkage task. Besides estimating customer costs, the estimation of record linkage costs is also important to evaluate whether (or not) the application of a set of RL parameter values will satisfy predefined time and budget restrictions. Aiming to tackle these challenges, we propose a theoretical model for estimating RL costs taking into account the main steps that may influence the execution time of the RL task. We also propose an algorithm, denoted as TBF, for evaluating the feasibility of RL parameter values, given a set of predefined customer restrictions. We evaluate the efficacy of the proposed model combined with regression techniques using record linkage results processed in real distributed environments. Based on the experimental results, we show that the employed regression technique has significant influence over the estimated record linkage costs. Moreover, we conclude that specific regression techniques are more suitable for estimating record linkage costs, depending on the evaluated scenario.",https://doi.org/10.1016/j.jpdc.2020.05.003,2020,Dimas Cassimiro Nascimento and Carlos Eduardo Santos Pires and Tiago Brasileiro Araujo and Demetrio Gomes Mestre,ESTIMATING RECORD LINKAGE COSTS IN DISTRIBUTED ENVIRONMENTS,article
731,20492,ANNALS OF VASCULAR SURGERY,journal,08905096,"0,635",Q2,74,844,1561,16904,2242,1527,"1,37","20,03",United States,Northern America,Elsevier Inc.,1986-2020,Cardiology and Cardiovascular Medicine (Q2); Medicine (miscellaneous) (Q2); Surgery (Q2),"7,121",1.466,0.00916,,https://doi.org/10.1016/j.avsg.2020.04.022,2020,Fabien Lareyre and Cédric Adam and Marion Carrier and Juliette Raffort,ARTIFICIAL INTELLIGENCE IN VASCULAR SURGERY: MOVING FROM BIG DATA TO SMART DATA,article
732,13681,COMPUTER COMMUNICATIONS,journal,01403664,"0,627",Q1,105,616,599,24961,2424,591,"4,08","40,52",Netherlands,Western Europe,Elsevier,1978-2020,Computer Networks and Communications (Q1),"6,725",3.167,0.00513,"Nowadays, the world knows a high-speed development and evolution of technologies, vulnerable economic environments, market changes, and personalised consumer trends. The issue and challenge related to enterprises networks design are more and more critical. These networks are often designed for short terms since their strategies must be competitive and better adapted to the environment, social and economical changes. As a solution, to design a flexible and robust network, it is necessary to deal with the trade-off between conflicting qualitative and quantitative criteria such as cost, quality, delivery time, and competition, etc. To this end, using Big Data (BD) as emerging technology will enhance the real performances of these kinds of networks. Moreover, even if the literature is rich with BD models and frameworks developed for a single supply chain network (SCN), there is a real need to scale and extend these BD models to networked supply chains (NSCs). To do so, this paper proposes a BD architecture to drive a mixed-network of SCs that collaborate in serial and parallel fashions. The collaboration is set up by sharing their resources, capabilities, competencies, and information to imitate a unique organisation. The objective is to increase internal value to their shareholders (where value is seen as wealth) and deliver better external value to the end-customer (where value represents customer satisfaction). Within a mixed-network of SCs, both values are formally calculated considering both serial and parallel networks configurations. Besides, some performance factors of the proposed BD architecture such as security, flexibility, robustness and resilience are discussed.",https://doi.org/10.1016/j.comcom.2021.05.008,2021,Lahcen Tamym and Lyes Benyoucef and Ahmed {Nait Sidi Moh} and Moulay Driss {El Ouadghiri},A BIG DATA BASED ARCHITECTURE FOR COLLABORATIVE NETWORKS: SUPPLY CHAINS MIXED-NETWORK,article
733,13681,COMPUTER COMMUNICATIONS,journal,01403664,"0,627",Q1,105,616,599,24961,2424,591,"4,08","40,52",Netherlands,Western Europe,Elsevier,1978-2020,Computer Networks and Communications (Q1),"6,725",3.167,0.00513,"Mobile crowdsensing has become an efficient paradigm for performing large-scale sensing tasks. Many quality-aware incentive mechanisms for mobile crowdsensing have been proposed. However, most of them measure the data quality by one single metric from a specific perspective. Moreover, they usually use the real-time quality, which cannot provide sufficient incentive for the workers with long-term high quality. In this paper, we refine the generalized data quality into the fine-grained ability requirement. We present a mobile crowdsensing system to achieve the fine-grained quality control, and formulate the problem of maximizing the social cost such that the fine-grained ability requirement of all sensing tasks can be satisfied. To stimulate the workers with long-term high quality, we design two ability reputation systems to assess workers’ fine-grained abilities online. The incentive mechanism based on the reverse auction and fine-grained ability reputation system is proposed. We design a greedy algorithm to select the winners and determine the payment based on the bids and fine-grained ability reputation of workers. Through both rigorous theoretical analysis and extensive simulations, we demonstrate that the proposed mechanisms achieve computational efficiency, individual rationality, truthfulness, whitewashing proof, and guaranteed approximation. Moreover, the designed mechanisms show prominent advantage in terms of social cost and average ability achievement ratio.",https://doi.org/10.1016/j.comcom.2021.09.026,2021,Zhuangye Luo and Jia Xu and Pengcheng Zhao and Dejun Yang and Lijie Xu and Jian Luo,TOWARDS HIGH QUALITY MOBILE CROWDSENSING: INCENTIVE MECHANISM DESIGN BASED ON FINE-GRAINED ABILITY REPUTATION,article
734,13681,COMPUTER COMMUNICATIONS,journal,01403664,"0,627",Q1,105,616,599,24961,2424,591,"4,08","40,52",Netherlands,Western Europe,Elsevier,1978-2020,Computer Networks and Communications (Q1),"6,725",3.167,0.00513,"Technology has become inevitable in human life, especially the growth of Internet of Things (IoT), which enables communication and interaction with various devices. However, IoT has been proven to be vulnerable to security breaches. Therefore, it is necessary to develop fool proof solutions by creating new technologies or combining existing technologies to address the security issues. Deep learning, a branch of machine learning has shown promising results in previous studies for detection of security breaches. Additionally, IoT devices generate large volumes, variety, and veracity of data. Thus, when big data technologies are incorporated, higher performance and better data handling can be achieved. Hence, we have conducted a comprehensive survey on state-of-the-art deep learning, IoT security, and big data technologies. Further, a comparative analysis and the relationship among deep learning, IoT security, and big data technologies have also been discussed. Further, we have derived a thematic taxonomy from the comparative analysis of technical studies of the three aforementioned domains. Finally, we have identified and discussed the challenges in incorporating deep learning for IoT security using big data technologies and have provided directions to future researchers on the IoT security aspects.",https://doi.org/10.1016/j.comcom.2020.01.016,2020,Mohamed Ahzam Amanullah and Riyaz Ahamed Ariyaluran Habeeb and Fariza Hanum Nasaruddin and Abdullah Gani and Ejaz Ahmed and Abdul Salam Mohamed Nainar and Nazihah Md Akim and Muhammad Imran,DEEP LEARNING AND BIG DATA TECHNOLOGIES FOR IOT SECURITY,article
735,13681,COMPUTER COMMUNICATIONS,journal,01403664,"0,627",Q1,105,616,599,24961,2424,591,"4,08","40,52",Netherlands,Western Europe,Elsevier,1978-2020,Computer Networks and Communications (Q1),"6,725",3.167,0.00513,"Huge volumes of data are generated at rates faster than the speed of computing resources and executing processors available in market place. This anticipates a draft of information challenges associated with the performance capacity and the ability of big data processing systems to retort in real-time. Moreover, the elapsed time between probabilistic failures drops as the scale of information increases. An error occurred at a specific cluster node of a large Cyber–Physical System influences the overall computation requires to unfold big data transactions. Numerous failure characteristics, statistical response time and lifetime evaluation can be modeled through Weibull Distribution. In this paper, to scrutinize the latency for a data infrastructure, the three-parameter Weibull Cumulative Distribution is used through software defined networking in cyber–physical system. This speculation predicts that the shape of the response time distribution confide in the shape of the learning curve and depicts its parameters to the criterion of the input distribution.",https://doi.org/10.1016/j.comcom.2019.11.018,2020,Gifty R. and Bharathi R.,WEIBULL CUMULATIVE DISTRIBUTION BASED REAL-TIME RESPONSE AND PERFORMANCE CAPACITY MODELING OF CYBER–PHYSICAL SYSTEMS THROUGH SOFTWARE DEFINED NETWORKING,article
736,16319,IEEE TRANSACTIONS ON NANOBIOSCIENCE,journal,15582639,"0,620",Q2,63,75,242,2866,949,230,"3,69","38,21",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2002-2020,Bioengineering (Q2); Biomedical Engineering (Q2); Biotechnology (Q2); Computer Science Applications (Q2); Electrical and Electronic Engineering (Q2); Medicine (miscellaneous) (Q2); Nanoscience and Nanotechnology (Q2); Pharmaceutical Science (Q2),"2,008",2.935,0.0027,"Unlike Quality by Testing approach, where products were tested only after drug manufacturing, Quality by Design (QbD) is a proactive control quality paradigm, which handles risks from the early development steps. In QbD, regression models built from experimental data are used to predict a risk mapping called Design Space in which the developers can identify values of critical input factors leading to acceptable probabilities to meet the efficacy and safety specifications for the expected product. These empirical models are often limited to quantitative responses. Moreover, in practice the smallness and incompleteness of datasets degrade the quality of predictions. In this study, a Bayesian approach including variable selection, parameter estimation and model quality assessment is proposed and assessed using a real case study devoted to the development of a Cationic Nano-Lipid Structures for siRNA Transfection. Two original model structures are also included to describe both binary and percentage response variables. The results confirm the practical relevance and applicability of the Bayesian implementation of the QbD analysis.",10.1109/TNB.2022.3213412,2022,,A BAYESIAN IMPLEMENTATION OF QUALITY-BY-DESIGN FOR THE DEVELOPMENT OF CATIONIC NANO-LIPID FOR SIRNA TRANSFECTION,
737,21100332403,JOURNAL OF INFORMATION SECURITY AND APPLICATIONS,journal,22142126,"0,610",Q2,40,183,297,8559,1526,292,"5,43","46,77",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Computer Networks and Communications (Q2); Safety, Risk, Reliability and Quality (Q2); Software (Q2)","1,526",3.872,0.00209,"The implementation of the GDPR that aims at protecting European citizens’ privacy is still a real challenge. In particular, in Big Data systems where data are voluminous and heterogeneous, it is hard to track data evolution through its complex life cycle ranging from collection, ingestion, storage and analytics. In this context, from 2016 to 2021 research has been conducted and several security tools designed. However, they are either specific to particular applications or address partially the regulation articles. To identify the covered parts, the missed ones and the necessary metrics for comparing different works, we propose a framework for GDPR compliance. The framework identifies the main components for the regulation implementation by mapping requirements aligned with GDPR’s provisions to IT design requirements. Based on this framework, we compare the main GDPR solutions in the Big Data domain and we propose a guideline for GDPR verification and implementation in Big Data systems.",https://doi.org/10.1016/j.jisa.2021.102896,2021,Mouna Rhahla and Sahar Allegue and Takoua Abdellatif,GUIDELINES FOR GDPR COMPLIANCE IN BIG DATA SYSTEMS,article
738,21100332403,JOURNAL OF INFORMATION SECURITY AND APPLICATIONS,journal,22142126,"0,610",Q2,40,183,297,8559,1526,292,"5,43","46,77",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Computer Networks and Communications (Q2); Safety, Risk, Reliability and Quality (Q2); Software (Q2)","1,526",3.872,0.00209,"The technical features of blockchain, including decentralization, data transparency, tamper-proofing, traceability, privacy protection and open-sourcing, make it a suitable technology for solving the information asymmetry problem in personal credit reporting transactions. Applying blockchain technology to credit reporting meets the needs of social credit system construction and may become an important technical direction in the future. This paper analyzed the problems faced by China’s personal credit reporting market, designed the framework of personal credit information sharing platform based on blockchain 3.0 architecture, studied the technical details of the platform and the technical advantages, and finally, applied the platform to the credit blacklist sharing transaction and explored the possible implementation approach. The in-depth integration of blockchain technology and personal credit reporting helps to realize the safe sharing of credit data and reduce the cost of credit data collection, thereby helping the technological and efficiency transformation of the personal credit reporting industry and promoting the overall development of the social credit system.",https://doi.org/10.1016/j.jisa.2020.102659,2020,Jing Zhang and Rong Tan and Chunhua Su and Wen Si,DESIGN AND APPLICATION OF A PERSONAL CREDIT INFORMATION SHARING PLATFORM BASED ON CONSORTIUM BLOCKCHAIN,article
739,21100332403,JOURNAL OF INFORMATION SECURITY AND APPLICATIONS,journal,22142126,"0,610",Q2,40,183,297,8559,1526,292,"5,43","46,77",United Kingdom,Western Europe,Elsevier Ltd.,2013-2020,"Computer Networks and Communications (Q2); Safety, Risk, Reliability and Quality (Q2); Software (Q2)","1,526",3.872,0.00209,"Nowadays, IoT, cloud computing, mobile and social networks are generating a transformation in social processes. Nevertheless, this technological change rise to new threats and security attacks that produce new and complex cybersecurity scenarios with large volumes of data and different attack vectors that can exceeded the cognitive skills of security analysts. In this context, cognitive sciences can enhance the cognitive processes, which can help to security analysts to establish actions in less time and more efficiently within cybersecurity operations. This works presents a cognitive security model that integrates technological solutions such as Big Data, Machine Learning, and Support Decision Systems with the cognitive processes of security analysts used to generate knowledge, understanding and execution of security response actions. The model considers alternatives to establish the automation process in the execution of cognitive tasks defined in the cyber operations processes and includes the analyst as the central axis in the processes of validation and decision making through the use of MAPE-K, OODA and Human in the Loop.",https://doi.org/10.1016/j.jisa.2019.06.008,2019,Roberto O Andrade and Sang Guun Yoo,COGNITIVE SECURITY: A COMPREHENSIVE STUDY OF COGNITIVE SCIENCE IN CYBERSECURITY,article
740,18732,INFORMATION AND SOFTWARE TECHNOLOGY,journal,09505849,"0,606",Q2,103,121,420,6853,2316,403,"5,12","56,64",Netherlands,Western Europe,Elsevier,"1970, 1987-2020",Computer Science Applications (Q2); Information Systems (Q2); Software (Q2),"5,172",2.730,0.00554,"Context
The need for business intelligence has led to advances in machine learning in the business domain, especially with the rise of big data analytics. However, the resulting predictive systems often fail to maintain a satisfactory level of performance in production. Besides, for predictive systems used in business-to-business scenarios, user trust is subject to the model performance. Therefore, the processes of creating, evaluating, and deploying machine learning systems in the business domain need innovative solutions to solve the critical challenges of assuring the quality of the resulting systems.
Objective
Applying machine learning in business-to-business situations imposes specific requirements. This paper aims at providing an integrated solution to businesses to help them transform their data into actions.
Method
The paper presents MLean, an end-to-end framework, that aims at guiding businesses in designing, developing, evaluating, and deploying business-to-business predictive systems. The framework employs the Lean Startup methodology and aims at maximizing the business value while eliminating wasteful development practices.
Results
To evaluate the proposed framework, with the help of our industrial partner, we applied the framework to a case study to build a predictive product. The case study resulted in a predictive system to predict the risks of software license cancellations. The system was iteratively developed and evaluated while adopting the management and end-user perspectives.
Conclusion
It is concluded that, in industry, it is important to be aware of the businesses requirements before considering the application of machine learning. The framework accommodates business perspective from the beginning to produce a holistic product. From the results of the case study, we think that this framework can help businesses define the right opportunities for applying machine learning, developing solutions, evaluating the effectiveness of these solutions, and maintaining their performance in production.",https://doi.org/10.1016/j.infsof.2019.05.009,2019,Mona Nashaat and Aindrila Ghosh and James Miller and Shaikh Quader and Chad Marston,M-LEAN: AN END-TO-END DEVELOPMENT FRAMEWORK FOR PREDICTIVE MODELS IN B2B SCENARIOS,article
741,18732,INFORMATION AND SOFTWARE TECHNOLOGY,journal,09505849,"0,606",Q2,103,121,420,6853,2316,403,"5,12","56,64",Netherlands,Western Europe,Elsevier,"1970, 1987-2020",Computer Science Applications (Q2); Information Systems (Q2); Software (Q2),"5,172",2.730,0.00554,"Context: Big Data systems are a class of software systems that ingest, store, process and serve massive amounts of heterogeneous data, from multiple sources. Despite their undisputed impact in current society, their engineering is still in its infancy and companies find it difficult to adopt them due to their inherent complexity. Existing attempts to provide architectural guidelines for their engineering fail to take into account important Big Data characteristics, such as the management, evolution and quality of the data. Objective: In this paper, we follow software engineering principles to refine the λ-architecture, a reference model for Big Data systems, and use it as seed to create Bolster, a software reference architecture (SRA) for semantic-aware Big Data systems. Method: By including a new layer into the λ-architecture, the Semantic Layer, Bolster is capable of handling the most representative Big Data characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity). Results: We present the successful implementation of Bolster in three industrial projects, involving five organizations. The validation results show high level of agreement among practitioners from all organizations with respect to standard quality factors. Conclusion: As an SRA, Bolster allows organizations to design concrete architectures tailored to their specific needs. A distinguishing feature is that it provides semantic-awareness in Big Data Systems. These are Big Data system implementations that have components to simplify data definition and exploitation. In particular, they leverage metadata (i.e., data describing data) to enable (partial) automation of data exploitation and to aid the user in their decision making processes. This simplification supports the differentiation of responsibilities into cohesive roles enhancing data governance.",https://doi.org/10.1016/j.infsof.2017.06.001,2017,Sergi Nadal and Victor Herrero and Oscar Romero and Alberto Abelló and Xavier Franch and Stijn Vansummeren and Danilo Valerio,A SOFTWARE REFERENCE ARCHITECTURE FOR SEMANTIC-AWARE BIG DATA SYSTEMS,article
742,18732,INFORMATION AND SOFTWARE TECHNOLOGY,journal,09505849,"0,606",Q2,103,121,420,6853,2316,403,"5,12","56,64",Netherlands,Western Europe,Elsevier,"1970, 1987-2020",Computer Science Applications (Q2); Information Systems (Q2); Software (Q2),"5,172",2.730,0.00554,"Context:
Over the last decade, Agile methods have changed the software development process in an unparalleled way and with the increasing popularity of Big Data, optimizing development cycles through data analytics is becoming a commodity.
Objective:
Although a myriad of research exists on software analytics as well as on Agile software development (ASD) practice on itself, there exists no systematic overview of the research done on ASD from a data analytics perspective. Therefore, the objective of this work is to make progress by linking ASD with Big Data analytics (BDA).
Method:
As the primary method to find relevant literature on the topic, we performed manual search and snowballing on papers published between 2011 and 2019.
Results:
In total, 88 primary studies were selected and analyzed. Our results show that BDA is employed throughout the whole ASD lifecycle. The results reveal that data-driven software development is focused on the following areas: code repository analytics, defects/bug fixing, testing, project management analytics, and application usage analytics.
Conclusions:
As BDA and ASD are fast-developing areas, improving the productivity of software development teams is one of the most important objectives BDA is facing in the industry. This study provides scholars with information about the state of software analytics research and the current trends as well as applications in the business environment. Whereas, thanks to this literature review, practitioners should be able to understand better how to obtain actionable insights from their software artifacts and on which aspects of data analytics to focus when investing in such initiatives.",https://doi.org/10.1016/j.infsof.2020.106448,2021,Katarzyna Biesialska and Xavier Franch and Victor Muntés-Mulero,BIG DATA ANALYTICS IN AGILE SOFTWARE DEVELOPMENT: A SYSTEMATIC MAPPING STUDY,article
743,12888,CHINESE JOURNAL OF CHEMICAL ENGINEERING,journal,10049541,"0,595",Q2,54,355,874,15618,2755,871,"3,16","43,99",China,Asiatic Region,Chemical Industry Press,1993-2020,Chemical Engineering (miscellaneous) (Q2); Chemistry (miscellaneous) (Q2); Environmental Engineering (Q2); Biochemistry (Q3),"6,469",3.171,0.00619,"Owing to wide applications of automatic control systems in the process industries, the impacts of controller performance on industrial processes are becoming increasingly significant. Consequently, controller maintenance is critical to guarantee routine operations of industrial processes. The workflow of controller maintenance generally involves the following steps: monitor operating controller performance and detect performance degradation, diagnose probable root causes of control system malfunctions, and take specific actions to resolve associated problems. In this article, a comprehensive overview of the mainstream of control loop monitoring and diagnosis is provided, and some existing problems are also analyzed and discussed. From the viewpoint of synthesizing abundant information in the context of big data, some prospective ideas and promising methods are outlined to potentially solve problems in industrial applications.",https://doi.org/10.1016/j.cjche.2016.05.039,2016,Xinqing Gao and Fan Yang and Chao Shang and Dexian Huang,A REVIEW OF CONTROL LOOP MONITORING AND DIAGNOSIS: PROSPECTS OF CONTROLLER MAINTENANCE IN BIG DATA ERA,article
744,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The use of freely available online data is rapidly increasing, as companies have detected the possibilities and the value of these data in their businesses. In particular, data from social media are seen as interesting as they can, when properly treated, assist in achieving customer insight into business decision making. However, the unstructured and uncertain nature of this kind of big data presents a new kind of challenge: how to evaluate the quality of data and manage the value of data within a big data architecture? This paper contributes to addressing this challenge by introducing a new architectural solution to evaluate and manage the quality of social media data in each processing phase of the big data pipeline. The proposed solution improves business decision making by providing real-time, validated data for the user. The solution is validated with an industrial case example, in which the customer insight is extracted from social media data in order to determine the customer satisfaction regarding the quality of a product.",10.1109/ACCESS.2015.2490723,2015,,EVALUATING THE QUALITY OF SOCIAL MEDIA DATA IN BIG DATA ARCHITECTURE,
745,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"QoS-aware big data analysis is critical in Information-Centric Internet of Things (IC-IoT) system to support various applications like smart city, smart grid, smart health, intelligent transportation systems, and so on. The employment of non-volatile memory (NVM) in cloud or edge system provides good opportunity to improve quality of data analysis tasks. However, we have to face the data recovery problem led by NVM failure due to the limited write endurance. In this paper, we investigate the data recovery problem for QoS guarantee and system robustness, followed by proposing a rarity-aware data recovery algorithm. The core idea is to establish the rarity indicator to evaluate the replica distribution and service requirement comprehensively. With this idea, we give the lost replicas with distinguishing priority and eliminate the unnecessary replicas. Then, the data replicas are recovered stage by stage to guarantee QoS and provide system robustness. From our extensive experiments and simulations, it is shown that the proposed algorithm has significant performance improvement on QoS and robustness than the traditional direct data recovery method. Besides, the algorithm gives an acceptable data recovery time.",10.1109/ACCESS.2019.2932259,2019,,ACTIVE DATA REPLICA RECOVERY FOR QUALITY-ASSURANCE BIG DATA ANALYSIS IN IC-IOT,
746,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the boom in data science, big data education has received increasing attention from all kinds of colleges and universities in China, and many of them are in a rush to offer big data education. This paper first analyzes the major areas of big data capability training and the Chinese market needs for various kinds of data science talent. Then, it discusses the curriculum design process for the “Data Science & Big Data Technology” bachelor's degree program, and summarizes some detailed approaches to improving teaching experiments. Finally, this paper proposes a graduating student profile for big data education at applied technical colleges and universities in China. The authors' main ideas include that, at the applied technical colleges and universities, a) a suitable graduating student orientation should be determined as the big data talent needs are hierarchical; b) the redesigned curriculum in big data education should provide students more practical capabilities and knowledge; c) the teaching of the existing mainstream big data technologies and tools should be significant components in the syllabi of big data education.",10.1109/ACCESS.2019.2939196,2019,,CURRICULUM REFORM IN BIG DATA EDUCATION AT APPLIED TECHNICAL COLLEGES AND UNIVERSITIES IN CHINA,
747,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the era of big data, the scientific and social demand for quality data is aggressive and urgent. This paper sheds light on the expanded role of metrology of verifying validated procedures of data production and developing adequate uncertainty evaluation methods to ensure the trustworthiness of data and information. In this regard, I explore the mechanism of the national standard reference data (SRD) program of Korea, which connects various scientific and social sectors to metrology by applying useful metrological concepts and methods to produce reliable data and convert such data into national standards. In particular, the changing interpretation of metrological key concepts, such as “measurement,” “traceability,” and “uncertainty,” will be explored and reconsidered from the perspective of data quality assurance. As a result, I suggest the concept of “data traceability” with “the matrix of data quality evaluation” according to the elements of a data production system and related evaluation criteria. To conclude, I suggest social and policy implications for the new role of metrology and standards for producing and disseminating reliable knowledge sources from big data.",10.1109/ACCESS.2019.2904286,2019,,BIG DATA QUALITY ASSURANCE THROUGH DATA TRACEABILITY: A CASE STUDY OF THE NATIONAL STANDARD REFERENCE DATA PROGRAM OF KOREA,
748,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the application of multimedia big data, the problems such as information leakage and data tampering have emerged. The security of images which is one of the most typical multimedia has become a major problem facing the large-scale open network environment. This paper proposed a blockchain-watermarking scheme to protect the privacy, integrity and availability of compressed sensed images, which effectively combines multimedia watermarking, compressed sensing, Interplanetary File System (IPFS) and blockchain technologies. Based on the reliable authentication of watermarking, the confidentiality protection of compressed sensing, the secure storage of IPFS, and the decentralization and non-tamperability of blockchain, the all-round security protection of the image big data based on compressive sensing can be realized. Experiments show that the proposed scheme is effective and feasible.",10.1109/ACCESS.2021.3072196,2021,,BLOCKCHAIN-WATERMARKING FOR COMPRESSIVE SENSED IMAGES,
749,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The government of China seeks to improve e-government service quality and build a service-oriented government that citizens find satisfactory. To this end, big data is being used as a new tool of government service innovation. However, there is a lack of research on how big data affects the performance of government smart services. This article explores the influence mechanisms of government big data capabilities on the performance of smart service provision, utilizing the carding analysis of relevant literature, published both in China and abroad. To this end, a structural equation model was constructed. Using data from 289 valid questionnaires in Jiangsu, Shandong, Zhejiang, and other provinces and cities in China, the study tests internal mechanisms of big data capabilities and its effect on smart service performance. Following a new definition of government big data capability, the paper divides the capability into three dimensions: big data system capability, big data human capability and big data management capability. The main conclusions are as follows: (1) Big data management capability has a significant positive impact on big data human capability and big data system capability. (2) Big data system capability has a significant positive impact on big data human capability. (3) Big data system capability and big data management capability have a significant positive effect on smart service performance. (4) The impact of big data human capability on smart service performance is not however significant enough to bring about the improvements which the government seeks.",10.1109/ACCESS.2021.3056486,2021,,RESEARCH ON THE IMPACT OF BIG DATA CAPABILITIES ON GOVERNMENT’S SMART SERVICE PERFORMANCE: EMPIRICAL EVIDENCE FROM CHINA,
750,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart urban transportation management can be considered as a multifaceted big data challenge. It strongly relies on the information collected into multiple, widespread, and heterogeneous data sources as well as on the ability to extract actionable insights from them. Besides data, full stack (from platform to services and applications) Information and Communications Technology (ICT) solutions need to be specifically adopted to address smart cities challenges. Smart urban transportation management is one of the key use cases addressed in the context of the EUBra-BIGSEA (Europe-Brazil Collaboration of Big Data Scientific Research through Cloud-Centric Applications) project. This paper specifically focuses on the City Administration Dashboard, a public transport analytics application that has been developed on top of the EUBra-BIGSEA platform and used by the Municipality stakeholders of Curitiba, Brazil, to tackle urban traffic data analysis and planning challenges. The solution proposed in this paper joins together a scalable big and fast data analytics platform, a flexible and dynamic cloud infrastructure, data quality and entity matching algorithms as well as security and privacy techniques. By exploiting an interoperable programming framework based on Python Application Programming Interface (API), it allows an easy, rapid and transparent development of smart cities applications.",10.1109/ACCESS.2019.2936941,2019,,AN INTEGRATED BIG AND FAST DATA ANALYTICS PLATFORM FOR SMART URBAN TRANSPORTATION MANAGEMENT,
751,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Healthcare insurance frauds are causing millions of dollars of public healthcare fund losses around the world in various ways, which makes it very important to strengthen the management of medical insurance in order to guarantee the steady operation of medical insurance funds. Healthcare fraud detection methods can reduce the losses of healthcare insurance funds and improve medical quality. Existing fraud detection studies mostly focus on finding normal behavior patterns and treat those violating normal behavior patterns as fraudsters. However, fraudsters can often disguise themselves with some normal behaviors, such as some consistent behaviors when they seek medical treatments. To address these issues, we combined a MapReduce distributed computing model and association rule mining to propose a medical cluster behavior detection algorithm based on frequent pattern mining. It can detect certain consistent behaviors of patients in medical treatment activities. By analyzing 1.5 million medical claim records, we have verified the effectiveness of the method. Experiments show that this method has better performance than several benchmark methods.",10.1109/ACCESS.2020.3009006,2020,,BIG DATA-DRIVEN ABNORMAL BEHAVIOR DETECTION IN HEALTHCARE BASED ON ASSOCIATION RULES,
752,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Healthcare systems are transformed digitally with the help of medical technology, information systems, electronic medical records, wearable and smart devices, and handheld devices. The advancement in the medical big data, along with the availability of new computational models in the field of healthcare, has enabled the caretakers and researchers to extract relevant information and visualize the healthcare big data in a new spectrum. The role of medical big data becomes a challenging task in the form of storage, required information retrieval within a limited time, cost efficient solutions in terms care, and many others. Early decision making based healthcare system has massive potential for dropping the cost of care, refining quality of care, and reducing waste and error. Scientific programming play a significant role to overcome the existing issues and future problems involved in the management of large scale data in healthcare, such as by assisting in the processing of huge data volumes, complex system modelling, and sourcing derivations from healthcare data and simulations. Therefore, to address this problem efficiently a detailed study and analysis of the available literature work is required to facilitate the doctors and practitioners for making the decisions in identifying the disease and suggest treatment accordingly. The peer reviewed reputed journals are selected for the accumulated of published research work during the period ranges from 2015 - 2019 (a portion of 2020 is also included). A total of 127 relevant articles (conference papers, journal papers, book section, and survey papers) are selected for the assessment and analysis purposes. The proposed research work organizes and summarizes the existing published research work based on the research questions defined and keywords identified for the search process. This analysis on the existence research work will help the doctors and practitioners to make more authentic decisions, which ultimately will help to use the study as evidence for treating patients and suggest medicines accordingly.",10.1109/ACCESS.2020.2995572,2020,,"A COMPREHENSIVE ANALYSIS OF HEALTHCARE BIG DATA MANAGEMENT, ANALYTICS AND SCIENTIFIC PROGRAMMING",
753,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The digital transformations and use of healthcare information system, electronic medical records, wearable technology, and smart devices are increasing with the passage of time. A variety of sources of big data in healthcare are available, such as biometric data, registration data, electronic health record, medical imaging, patient reported data, biomarker data, clinical data, and administrative data. Visualization of data is a key tool for producing images, diagrams, or animations to convey messages from the viewed insight. The role of cardiology in healthcare is obvious for living and life. The function of heart is the control of blood supply to the entire parts of the body. Recent speedy growth in healthcare and the development of computation in the field of cardiology enable researchers and practitioners to mine and visualize new insights from patient data. The role of visualization is to capture the important information from the data and to visualize it for the easiness of doctors and practitioners. To help the doctors and practitioners, the proposed study presents a detailed report of the existing literature on visualization of data in the field of cardiology. This report will support the doctors and practitioners in decision-making process and to make it easier. This detailed study will eventually summarize the results of the existing literature published related to visualization of data in the cardiology. This research uses the systematic literature protocol and the data was collected from the studies published during the year 2009 to 2018 (10 years). The proposed study selected 53 primary studies from different repositories according to the defined exclusion, inclusion, and quality criteria. The proposed study focused mainly on the research work been done on visualization of big data in the field of cardiology, presented a summary of the techniques used for visualization of data in cardiology, and highlight the benefits of visualizations in cardiology. The current research summarizes and organizes the available literature in the form of published materials related to big data visualization in cardiology. The proposed research will help the researchers to view the available research studies on the subject of medical big data in cardiology and then can ultimately be used as evidence in future research. The results of the proposed research show that there is an increase in articles published yearly wise and several studies exist related to medical big data in cardiology. The derivations from the studies are presented in the paper.",10.1109/ACCESS.2019.2936133,2019,,BIG DATA VISUALIZATION IN CARDIOLOGY—A SYSTEMATIC REVIEW AND FUTURE DIRECTIONS,
754,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Unstructured text contains valuable information for a range of enterprise applications and informed decision making. Text analytics is used to extract valuable insights from unstructured big data. Among the most significant challenges of text analytics, quality and usability are critical in affecting the outcome of the analytical process. The enhancement in usability is important for the exploitation of unstructured data. Most of the existing literature focuses on the usability of structured data as compared to unstructured data whereas big data usability has been discussed merely in the context of its assessment. The existing approaches do not provide proper guidelines on the usability enhancement of unstructured data. In this study, a rigorous systematic literature review using PRISMA framework has been conducted to develop a model enhancing the usability of unstructured data bridging the research gap. The recent approaches and solutions for text analytics have been investigated thoroughly. The usability issues of unstructured text data and their consequences on data preparation for analytics have been identified. Defining the usability dimensions for unstructured big data, identification of the usability determinants, and developing a relationship between usability dimension and determinants to derive usability rules are the significant contributions of this research and are integrated to formulate the usability enhancement model. The proposed model is the major outcome of the research. It contributes to make unstructured data usable and facilitates the data preparation activities with more valuable data that eventually improve the analytical process.",10.1109/ACCESS.2021.3089100,2021,,DEVELOPMENT OF USABILITY ENHANCEMENT MODEL FOR UNSTRUCTURED BIG DATA USING SLR,
755,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper presents SeQual, a scalable tool to efficiently perform quality control of large genomic datasets. Our tool currently supports more than 30 different operations (e.g., filtering, trimming, formatting) that can be applied to DNA/RNA reads in FASTQ/FASTA formats to improve subsequent downstream analyses, while providing a simple and user-friendly graphical interface for non-expert users. Furthermore, SeQual takes full advantage of Big Data technologies to process massive datasets on distributed-memory systems such as clusters by relying on the open-source Apache Spark cluster computing framework. Our scalable Spark-based implementation allows to reduce the runtime from more than three hours to less than 20 minutes when processing a paired-end dataset with 251 million reads per input file on an 8-node multi-core cluster.",10.1109/ACCESS.2020.3015016,2020,,SEQUAL: BIG DATA TOOL TO PERFORM QUALITY CONTROL AND DATA PREPROCESSING OF LARGE NGS DATASETS,
756,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Contribution: Recently, real-time data warehousing (DWH) and big data streaming have become ubiquitous due to the fact that a number of business organizations are gearing up to gain competitive advantage. The capability of organizing big data in efficient manner to reach a business decision empowers data warehousing in terms of real-time stream processing. A systematic literature review for real-time stream processing systems is presented in this paper which rigorously look at the recent developments and challenges of real-time stream processing systems and can serve as a guide for the implementation of real-time stream processing framework for all shapes of data streams. Background: Published surveys and reviews either cover papers focusing on stream analysis in applications other than real-time DWH or focusing on extraction, transformation, loading (ETL) challenges for traditional DWH. This systematic review attempts to answer four specific research questions. Research Questions: 1)Which are the relevant publication channels for real-time stream processing research? 2) Which challenges have been faced during implementation of real-time stream processing? 3) Which approaches/tools have been reported to address challenges introduced at ETL stage while processing real-time stream for real-time DWH? 4) What evidence have been reported while addressing different challenges for processing real-time stream? Methodology: A systematic literature was conducted to compile studies related to publication channels targeting real-time stream processing/joins challenges and developments. Following a formal protocol, semi-automatic and manual searches were performed for work from 2011 to 2020 excluding research in traditional data warehousing. Of 679,547 papers selected for data extraction, 74 were retained after quality assessment. Findings: This systematic literature highlights implementation challenges along with developed approaches for real-time DWH and big data stream processing systems and provides their comparisons. This study found that there exists various algorithms for implementing real-time join processing at ETL stage for structured data whereas less work for un-structured data is found in this subject matter.",10.1109/ACCESS.2020.3005268,2020,,CHALLENGES AND SOLUTIONS FOR PROCESSING REAL-TIME BIG DATA STREAM: A SYSTEMATIC LITERATURE REVIEW,
757,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Over the past five years, research on big data analysis has been actively conducted, and many services have been developed to find valuable data. However, low quality of raw data and data loss problem during data analysis make it difficult to perform accurate data analysis. With the enormous generation of both unstructured and structured data, refinement of data is becoming increasingly difficult. As a result, data refinement plays an important role in data analysis. In addition, as part of efforts to ensure research reproducibility, the importance of reuse of researcher data and research methods is increasing; however, the research on systems supporting such roles has not been conducted sufficiently. Therefore, in this paper, we propose a big data analysis system named the unified data analytics suite (UDAS) that focuses on data refinement. UDAS performs data refinement based on the big data platform and ensures the reusability and reproducibility of refinement and analysis through the visual programming language interface. It also recommends open source and visualization libraries to users for statistical analysis. The qualitative evaluation of UDAS using the functional evaluation factor of the big data analysis platform demonstrated that the average satisfaction of the users is significantly high.",10.1109/ACCESS.2018.2857845,2018,,VPL-BASED BIG DATA ANALYSIS SYSTEM: UDAS,
758,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recently, its becomes easy to track down the data due to its availability in a large number. Although for data management, processing, and obtainability, cloud computing is considered a well-known approach for organizational development on the internet. Despite many advantages, cloud computing has still numerous security challenges that can affect the big-data usage on cloud computing. To find the security issues/challenges that are faced by software vendors’ organizations we conducted a systematic literature review (SLR) through which we have find out 103 relevant research publications by developing a search string that is inspired by the research questions. This relevant data was comprised from different databases e.g. Google Scholar, IEEE Explore, ScienceDirect, ACM Digital Library, and SpringerLink. Furthermore, for the detailed literature review, we have accomplished all the steps in SLR, for example, development of SLR protocol, Initials and final assortment of the relevant data, data extraction, data quality assessment, and data synthesis. We identified fifteen (15) critical security challenges which are: data secrecy, geographical data location, unauthorized data access, lack of control, lack of data management, network-level issues, data integrity, data recovery, lack of trust, data sharing, data availability, asset issues, legal amenabilities, lack of quality, and lack of consistency. Furthermore, sixty four (64) standard practices are identified for these critical security challenges using the proposed SLR that could help vendor organizations to overcome the security challenges for big data. The findings of our research study demonstrate the resemblances and divergences in the identified security challenges in different periods, continents, databases, and methods. The proposed SLR will also support software vendor organizations for securing big data on the cloud computing platforms. This paper has the following content: in Section II, we have describe the Literature review; in Section III, research methodology is specified; in Section IV, the findings of the SLR and the analysis of result are discussed; in Section V, the limitations of this research are given; in Section VI, we discussed our conclusions and future work.",10.1109/ACCESS.2021.3100287,2021,,ANALYZING AND EVALUATING CRITICAL CHALLENGES AND PRACTICES FOR SOFTWARE VENDOR ORGANIZATIONS TO SECURE BIG DATA ON CLOUD COMPUTING: AN AHP-BASED SYSTEMATIC APPROACH,
759,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Business processes represent a cornerstone to the operation of any enterprise. They are the operational means for such organizations to fulfill their goals. Nowadays, enterprises are able to gather massive amounts of event data. These are generated as business processes are executed and stored in transaction logs, databases, e-mail correspondences, free form text on (enterprise) social media, and so on. Taping into these data, enterprises would like to weave data analytic techniques into their decision making capabilities. In recent years, the IT industry has witnessed significant advancements in the domain of Big Data analytics. Unfortunately, the business process management (BPM) community has not kept up to speed with such developments and often rely merely on traditional modeling-based approaches. New ways of effectively exploiting such data are not sufficiently used. In this paper, we advocate that a good understanding of the business process and Big Data worlds can play an effective role in improving the efficiency and the quality of various data-intensive business operations using a wide spectrum of emerging Big Data systems. Moreover, we coin the term process footprint as a wider notion of process data than that is currently perceived in the BPM community. A roadmap towards taking business process data intensive operations to the next level is shaped in this paper.",10.1109/ACCESS.2018.2881759,2018,,BUSINESS PROCESS ANALYTICS AND BIG DATA SYSTEMS: A ROADMAP TO BRIDGE THE GAP,
760,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In an era of super computing, data is increasing exponentially requiring more proficiency from the available technologies of data storage, data processing, and analysis. Such continuous massive growth of structured and unstructured data is referred to as a “Big data”. The processing and storage of big data through a conventional technique is not possible. Due to improved proficiency of Big Data solution in handling data, such as NoSQL caused the developers in the previous decade to start preferring big data databases, such as Apache Cassandra, Oracle, and NoSQL. NoSQL is a modern database technology that is designed to provide scalability to support voluminous data, leading to the rise of NoSQL as the most viable database solution. These modern databases aim to overcome the limitations of relational databases such as unlimited scalability, high performance, data modeling, data distribution, and continuous availability. These days, the larger enterprises need to shift NoSQL databases due to their more flexible models. It is a great challenge for business organizations and enterprises to transform their existing databases to NoSQL databases considering heterogeneity and complexity in relational data. In addition, with the emergence of big data, data cleansing has become a great challenge. In this paper, we proposed an approach that has two modules: data transformation and data cleansing module. The first phase is the transformation of a relational database to Oracle NoSQL database through model transformation. The second phase provides data cleansing ability to improve data quality and prepare it for big data analytics. The experiments show the proposed approach successfully transforms the relational database to a big data database and improve data quality.",10.1109/ACCESS.2019.2916912,2019,,INTELLIGENT DATA ENGINEERING FOR MIGRATION TO NOSQL BASED SECURE ENVIRONMENTS,
761,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Application of big data and artificial intelligence has become one influence factor of English teaching, which have broken the balance of the teaching Eco-environment for English. In this article, the artificial intelligence and big data are introduced into English teaching to propose a new teaching Eco-environment construction method to meet the needs of the social development and international communication in English. In the proposed method, the characteristics of English teaching under big data environment are analyzed in detail. Then the big data technology is used to construct a new Eco-environment of English teaching to improve the teaching and learning quality. The data mining method is one of artificial intelligence methods, which is used to analyze the relationship of interdependence and mutual restriction among various factors in English teaching in order to build and implement a new Eco-environment with the information sharing, quality teaching and personalized learning of English. Finally, through the practical application of the constructed Eco-environment, the experiment results show that the proposed method can help students update their learning concepts, methods and contents of English, inspire their interest and initiative by comparing with some existed teaching methods, so as to improve their learning effects and application ability of English. Therefore, the constructed Eco-environment provides a new idea and direction for English teaching reform by application of big data and artificial intelligence.",10.1109/ACCESS.2020.3033068,2020,,ECO-ENVIRONMENT CONSTRUCTION OF ENGLISH TEACHING USING ARTIFICIAL INTELLIGENCE UNDER BIG DATA ENVIRONMENT,
762,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data releasing is a key part bridging between the collection of big data and their applications. Traditional methods release the static version of dataset or publish the snapshot with a fixed sampling interval, which cannot meet the dynamic query requirements and query precision for big data. Moreover, the quality of published data cannot reflect the characteristics of the dynamic changes of big data, which often leads to subsequent data analysis and mining errors. This paper proposes an adaptive sampling mechanism and privacy protection method for the release of big location data. In order to reflect the dynamic change of data in time, we design an adaptive sampling mechanism based on the proportional-integral-derivative (PID) controller according to the temporal and spatial correlation of the location data. To ensure the privacy of published data, we propose a heuristic quad-tree partitioning method as well as a corresponding privacy budget allocation strategy. Experiments and analysis prove that the adaptive sampling mechanism proposed in this paper can effectively track the trend of dynamic changes of data, and the designed differential privacy method can improve the accuracy of counting query and enhance the availability of published data under the premise of certain privacy intensity. The proposed methods can also be readily extended to other areas of big data release applications.",10.1109/ACCESS.2019.2951364,2019,,DYNAMIC RELEASE OF BIG LOCATION DATA BASED ON ADAPTIVE SAMPLING AND DIFFERENTIAL PRIVACY,
763,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the era of data science and big data analytics, people analytics help organizations and their human resources (HR) managers to reduce attrition by changing the way of attracting and retaining talent. In this context, employee attrition presents a critical problem and a big risk for organizations as it affects not only their productivity but also their planning continuity. In this context, the salient contributions of this research are as follows. Firstly, we propose a people analytics approach to predict employee attrition that shifts from a big data to a deep data context by focusing on data quality instead of its quantity. In fact, this deep data-driven approach is based on a mixed method to construct a relevant employee attrition model in order to identify key employee features influencing his/her attrition. In this method, we started thinking `big' by collecting most of the common features from the literature (an exploratory research) then we tried thinking `deep' by filtering and selecting the most important features using survey and feature selection algorithms (a quantitative method). Secondly, this attrition prediction approach is based on machine, deep and ensemble learning models and is experimented on a large-sized and a medium-sized simulated human resources datasets and then a real small-sized dataset from a total of 450 responses. Our approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three datasets when compared previous solutions. Finally, while rewards and payments are generally considered as the most important keys to retention, our findings indicate that `business travel', which is less common in the literature, is the leading motivator for employees and must be considered within HR policies to retention.",10.1109/ACCESS.2021.3074559,2021,,FROM BIG DATA TO DEEP DATA TO SUPPORT PEOPLE ANALYTICS FOR EMPLOYEE ATTRITION PREDICTION,
764,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data in the real world is often dirty. Inconsistency is an important kind of dirty data; before repairing inconsistency, we need to detect them first. The time complexities of the current inconsistency detection algorithms are super-linear to the size of data and not suitable for the big data. For the inconsistency detection of big data, we develop an algorithm that detects inconsistency within the one-pass scan of the data according to both the functional dependency (FD) and the conditional functional dependency (CFD) in our previous work. In this paper, we propose inconsistency detection algorithms in terms of FD, CFD, and Denial Constraint (DC). DCs are more expressive than FDs and CFDs. Developing the algorithm to detect the violation of DCs increases the applicability of our inconsistency detection algorithms. We compare the performance of our algorithm with the performance of implementing SQL queries in MySQL and BigQuery. The experimental results indicate the high efficiency of our algorithms.",10.1109/ACCESS.2019.2898707,2019,,ONE-PASS INCONSISTENCY DETECTION ALGORITHMS FOR BIG DATA,
765,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Brain health quality pre-monitoring has become an urgent need, and this is a system of complex engineering. From the perspective of intelligent decision-making based on big data, the intelligent air index prediction is introduced, the popular classification algorithm is introduced, the hidden information of historical data is mined, and the brain health quality prediction is realized. The brain health quality monitoring system based on the Internet of Things is constructed, and the classification algorithm is used to realize real-time acquisition, intelligent processing of data. In order to improve the data processing speed and enhance the real-time performance of brain health quality prediction, this paper introduces cloud computing technology to accelerate data processing. In order to enable users to understand the air index, anytime and anywhere, it is also designed based on the problem of large historical data of air index and real-time data collection. The Android platform develops an air index forecast client.",10.1109/ACCESS.2018.2885142,2018,,AIR QUALITY FORECAST MONITORING AND ITS IMPACT ON BRAIN HEALTH BASED ON BIG DATA AND THE INTERNET OF THINGS,
766,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cloud computing has emerged as a powerful paradigm for delivering data-intensive services over the Internet. Cloud computing has enabled the implementation and success of big data, a recent phenomenon handling huge data being generated from different sources. Competing clouds have made it challenging to select a cloud provider that guarantees quality of cloud service (QoCS). Also, cloud providers' claims of guaranteeing QoCS are exaggerated for marketing purposes; hence, they cannot often be trusted. Therefore, a comprehensive trust model is necessary to evaluate the QoCS prior to making any selection decision. In this paper, we propose a multi-dimensional trust model for big data workflow processing over different clouds. It evaluates the trustworthiness of cloud providers based on: the most up-to-date cloud resource capabilities, the reputation evidence measured by neighboring users, and a recorded personal history of experiences with the cloud provider. The ultimate goal is to ensure an efficient selection of trustworthiness cloud provider who eventually will guarantee high QoCS and fulfills key big data workflow requirements. Various experiments were conducted to validate our proposed model. The results show that our model captures the different components of trust, ensures high QoCS, and effectively adapts to the dynamic nature of the cloud.",10.1109/ACCESS.2018.2856623,2018,,A MULTI-DIMENSIONAL TRUST MODEL FOR PROCESSING BIG DATA OVER COMPETING CLOUDS,
767,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Under the background of cyber-physical systems and Industry 4.0, intelligent manufacturing has become an orientation and produced a revolutionary change. Compared with the traditional manufacturing environments, the intelligent manufacturing has the characteristics as highly correlated, deep integration, dynamic integration, and huge volume of data. Accordingly, it still faces various challenges. In this paper, we summarize and analyze the current research status in both domestic and aboard, including industrial big data collection, modeling of the intelligent product lines based on ontology, the predictive diagnosis based on industrial big data, group learning of product line equipment and the product line reconfiguration of intelligent manufacturing. Based on the research status and the problems, we propose the research strategies, including acquisition schemes of industrial big data under the environment of intelligent, ontology modeling and deduction method based intelligent product lines, predictive diagnostic methods on production lines based on deep neural network, deep learning among devices based on cloud supplements and 3-D selforganized reconfiguration mechanism based on the supplements of cloud. In our view, this paper will accelerate the implementation of smart factory.",10.1109/ACCESS.2017.2741105,2017,,INDUSTRIAL BIG DATA ANALYSIS IN SMART FACTORY: CURRENT STATUS AND RESEARCH STRATEGIES,
768,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In today's digital world the information surges with the widespread use of the internet and global communication systems. Healthcare systems are also facing digital transformations with the enhancement in the utilization of healthcare information systems, electronic records in medical, wearable, smart devices, handheld devices, and so on. A bulk of data is produced from these digital transformations. The recent increase in medical big data and the development of computational techniques in the field of cardiology enables researchers and practitioners to extract and visualize medical big data in a new spectrum. The role of medical big data in cardiology becomes a challenging task. Early decision making in cardiac healthcare system has massive potential for dropping the cost of care, refining quality of care, and reducing waste and error. Therefore, to facilitate this process a detailed report of the existing literature will be feasible to help the doctors and practitioners in decision making for the purpose of identifying and treating cardiac diseases. This detailed study will summarize results from the existing literature on big data in the field cardiac disease. This research uses the systematic literature protocol as presented by Kitchenham et al. The data was collected from the published materials from 2008 to 2018 as conference or journal publications, books, magazines and other online sources. 190 papers were included relying on the defined inclusion, exclusion, and checking the quality criteria. The current study helped to identify medical big data features, the application of medical big data, and the analytics of the big data in cardiology. The results of the proposed research shows that several studies exist that are associated to medical big data specifically to cardiology. This research summarizes and organizes the existing literature based on the defined keywords and research questions. The analysis will help doctors to make more authentic decisions, which ultimately will help to use the study as evidence for treating patients with heart related diseases.",10.1109/ACCESS.2019.2941898,2019,,"BIG DATA FEATURES, APPLICATIONS, AND ANALYTICS IN CARDIOLOGY—A SYSTEMATIC LITERATURE REVIEW",
769,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The maritime industry expects several improvements to efficiently manage the operation processes by introducing Industry 4.0 enabling technologies. Seaports are the most critical point in the maritime logistics chain because of its multimodal and complex nature. Consequently, coordinated communication among any seaport stakeholders is vital to improving their operations. Currently, Electronic Data Interchange (EDI) and Port Community Systems (PCS), as primary enablers of digital seaports, have demonstrated their limitations to interchange information on time, accurately, efficiently, and securely, causing high operation costs, low resource management, and low performance. For these reasons, this contribution presents the Seaport Data Space (SDS) based on the Industrial Data Space (IDS) reference architecture model to enable a secure data sharing space and promote an intelligent transport multimodal terminal. Each seaport stakeholders implements the IDS connector to take part in the SDS and share their data. On top of SDS, a Big Data architecture is integrated to manage the massive data shared in the SDS and extract useful information to improve the decision-making. The architecture has been evaluated by enabling a port authority and a container terminal to share its data with a shipping company. As a result, several Key Performance Indicators (KPIs) have been developed by using the Big Data architecture functionalities. The KPIs have been shown in a dashboard to allow easy interpretability of results for planning vessel operations. The SDS environment may improve the communication between stakeholders by reducing the transaction costs, enhancing the quality of information, and exhibiting effectiveness.",10.1109/ACCESS.2019.2963283,2020,,SEAPORT DATA SPACE FOR IMPROVING LOGISTIC MARITIME OPERATIONS,
770,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the advent of big data era, enormous volumes of data are generated every second. Varied data processing algorithms and architectures have been proposed in the past to achieve better execution of data mining algorithms. One such algorithm is extracting most frequently occurring patterns from the transactional database. Dependency of transactions on time and location further makes frequent itemset mining task more complex. The present work targets to identify and extract the frequent patterns from such time and location-aware transactional data. Primarily, the spatio-temporal dependency of air quality data is leveraged to find out frequently co-occurring pollutants over several locations of Delhi, the capital city of India. Varied approaches have been proposed in the past to extract frequent patterns efficiently, but this work suggests a generalized approach that can be applied to any numeric spatio-temporal transactional data, including air quality data. Furthermore, a comprehensive description of the algorithm along with a sample running example on air quality dataset is shown in this work. A detailed experimental evaluation is carried out on the synthetically generated datasets, benchmark datasets, and real world datasets. Furthermore, a comparison with spatio-temporal apriori as well as the other state-of-the-art non-apriori-based algorithms is shown. Results suggest that the proposed algorithm outperformed the existing approaches in terms of execution time of algorithm and memory resources.",10.1109/ACCESS.2019.2930004,2019,,FREQUENT PATTERN MINING ON TIME AND LOCATION AWARE AIR QUALITY DATA,
771,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Green parks in urban areas are believed to enhance the well-being of residents. The importance of green spaces to support health and fitness in urban areas has recently regained interest. Reports released in 2010-2016 by the World Health Organization (WHO) on urban planning, environment, and health stated that green spaces can have a positive impact on physical activity, social and mental well-being, enhance air quality and decrease noise exposure. We analyzed the number of check-ins in various parks of Shanghai by utilizing geotagged social media network check-in data. This article presents a descriptive study using social media data by obtaining the three-year comparison of spatial and temporal patterns of park visits to raise public awareness that green parks provide a healthy environment that can be beneficial for the well-being of urban citizens. We investigated the visitor spatiotemporal behavior in more than 115 green parks in 10 districts of Shanghai with approximately 250,000 check-ins. We examined 3 years of geotagged data and our main findings are: (i) the spatial and temporal variations of users in urban green parks (ii) the gender differences in space and time with relation to urban green parks. The main objective of this article is to present evident data for policymakers on the advantages of providing green spaces access to urban citizens and to facilitate cities with systematic approaches to provide green space access to improve the health of urban citizens.",10.1109/ACCESS.2020.2973177,2020,,SPATIOTEMPORAL PATTERNS OF VISITORS IN URBAN GREEN PARKS BY MINING SOCIAL MEDIA BIG DATA BASED UPON WHO REPORTS,
772,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Aiming at the low efficiency, poor performance and weak stability of traditional clustering algorithms and the poor response to the processing of massive data in real time, a real-time streaming controllable clustering edge computing algorithm (SCCEC) is proposed. First, the data tuples that arrive in real time are pre-processed by coarse clustering, the number of clusters, and the position of the center point are determined, and a set formed by macro clusters having differences is formed. Secondly, the macro cluster set obtained by the coarse clustering is sampled, and then K-means parallel clustering is performed with the largest and smallest distances, thereby realizing fine clustering of data. Finally, the completely clustering algorithm and the edge-computing algorithm are combined to realize the clustering analysis under the edge-computing framework. The experimental results show that the proposed algorithm has the advantages of high efficiency, good quality, and strong stability. It can quickly obtain the global optimal solution, and deal with massive data with high real-time performance. It can be used for real-time streaming data aggregation under big data background.",10.1109/ACCESS.2019.2955992,2019,,RESEARCH AND ANALYSIS FOR REAL-TIME STREAMING BIG DATA BASED ON CONTROLLABLE CLUSTERING AND EDGE COMPUTING ALGORITHM,
773,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Quality prediction is one of the key links of quality control. Benefitting from the development of digital manufacturing, manufacturing process data have grown rapidly, which allows product quality predictions to be made based on a real-time manufacturing process. A real-time quality control system (RTQCS) based on manufacturing process data is presented in this paper. In this study, the relationship between the product real-time quality status and processing task process was established by analyzing the relationship between the product manufacturing resources and the quality status. The key quality characteristics of the product were identified by analyzing the similarity of the product quality characteristic variations in the manufacturing process based on the big data technology, and a quality-resource matrix was constructed. Based on the quality-resource matrix, the RTQCS was established by introducing an association-rule incremental-update algorithm. Finally, the RTQCS was applied in actual production, and the performance of RTQCS was verified by experiments. The experiments showed that the RTQCS can effectively guarantee the quality of product manufacturing and improve the manufacturing efficiency during production.",10.1109/ACCESS.2020.3038394,2020,,A REAL-TIME QUALITY CONTROL SYSTEM BASED ON MANUFACTURING PROCESS DATA,
774,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the widespread use of the Internet of Things, data-driven services take the lead of both online and off-line businesses. Especially, personal data draw heavy attention of service providers because of the usefulness in value-added services. With the emerging big-data technology, a data broker appears, which exploits and sells personal data about individuals to other third parties. Due to little transparency between providers and brokers/consumers, people think that the current ecosystem is not trustworthy, and new regulations with strengthening the rights of individuals were introduced. Therefore, people have an interest in their privacy valuation. In this sense, the willingness-to-sell (WTS) of providers becomes one of the important aspects for data brokers; however, conventional studies have mainly focused on the willingness-to-buy (WTB) of consumers. Therefore, this paper proposes an optimized trading model for data brokers who buy personal data with proper incentives based on the WTS, and they sell valuable information from the refined dataset by considering the WTB and the dataset quality. This paper shows that the proposed model has a global optimal point by the convex optimization technique and proposes a gradient ascent-based algorithm. Consequently, it shows that the proposed model is feasible even if the data brokers spend costs to gather personal data.",10.1109/ACCESS.2019.2904248,2019,,PERSONAL DATA TRADING SCHEME FOR DATA BROKERS IN IOT DATA MARKETPLACES,
775,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Big Data (BD), Machine Learning (ML) and Internet of Things (IoT) are expected to have a large impact on Smart Farming and involve the whole supply chain, particularly for rice production. The increasing amount and variety of data captured and obtained by these emerging technologies in IoT offer the rice smart farming strategy new abilities to predict changes and identify opportunities. The quality of data collected from sensors greatly influences the performance of the modelling processes using ML algorithms. These three elements (e.g., BD, ML and IoT) have been used tremendously to improve all areas of rice production processes in agriculture, which transform traditional rice farming practices into a new era of rice smart farming or rice precision agriculture. In this paper, we perform a survey of the latest research on intelligent data processing technology applied in agriculture, particularly in rice production. We describe the data captured and elaborate role of machine learning algorithms in paddy rice smart agriculture, by analyzing the applications of machine learning in various scenarios, smart irrigation for paddy rice, predicting paddy rice yield estimation, monitoring paddy rice growth, monitoring paddy rice disease, assessing quality of paddy rice and paddy rice sample classification. This paper also presents a framework that maps the activities defined in rice smart farming, data used in data modelling and machine learning algorithms used for each activity defined in the production and post-production phases of paddy rice. Based on the proposed mapping framework, our conclusion is that an efficient and effective integration of all these three technologies is very crucial that transform traditional rice cultivation practices into a new perspective of intelligence in rice precision agriculture. Finally, this paper also summarizes all the challenges and technological trends towards the exploitation of multiple sources in the era of big data in agriculture.",10.1109/ACCESS.2021.3069449,2021,,"TOWARDS PADDY RICE SMART FARMING: A REVIEW ON BIG DATA, MACHINE LEARNING, AND RICE PRODUCTION TASKS",
776,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Many hospitals are suffering from ineffective use of big data analytics with electronic health records (EHRs) to generate high quality insights for their clinical practices. Organizational learning has been a key role in improving the use of big data analytics with EHRs. Drawing on the knowledge-based view and big data lifecycle, we investigate how the three modes of knowledge can achieve meaningful use of big data analytics with EHRs. To test the associations in the proposed research model, we surveyed 580 nurses of a large hospital in China in 2019. Structural equation modelling was used to examine relationships between knowledge mode of EHRs and meaningful use of EHRs. The results reveal that know-what about EHRs utilization, know-how EHRs storage and utilization, and know-why storage and utilization can improve nurses' meaningful use of big data analytics with EHRs. This study contributes to the existing digital health and big data literature by exploring the proper adaptation of analytical tools to EHRs from the different knowledge mode in order to shape meaningful use of big data analytics with EHRs.",10.1109/ACCESS.2019.2939158,2019,,OPTIMIZING THE ELECTRONIC HEALTH RECORDS THROUGH BIG DATA ANALYTICS: A KNOWLEDGE-BASED VIEW,
777,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the context of epidemic prevention and control, food safety monitoring, data analysis and food safety traceability have become more important. At the same time, the most important reason for food safety issues is incomplete, opaque, and asymmetric information. The most fundamental way to solve these problems is to do a good job of traceability, and establish a reasonable and reliable food safety traceability system. The traceability system is currently an important means to ensure food quality and safety and solve the crisis of trust between consumers and the market. Research on food safety traceability systems based on big data, artificial intelligence and the Internet of Things provides ideas and methods to solve the problems of low credibility and difficult data storage in the application of traditional traceability systems. Therefore, this research takes rice as an example and proposes a food safety traceability system based on RFID two-dimensional code technology and big data storage technology in the Internet of Things. This article applies RFID technology to the entire system by analyzing the requirements of the system, designing the system database and database tables, encoding the two-dimensional code and generating the design for information entry. Using RFID radio frequency technology and the data storage function in big data to obtain information in the food production process. Finally, the whole process of food production information can be traced through the design of dynamic query platform and mobile terminal. In this research, the food safety traceability system based on big data and the Internet of Things guarantees the integrity, reliability and safety of traceability information from a technical level. This is an effective solution for enhancing the credibility of traceability information, ensuring the integrity of information, and optimizing the data storage structure.",10.1109/ACCESS.2021.3078536,2021,,CONSTRUCT FOOD SAFETY TRACEABILITY SYSTEM FOR PEOPLE’S HEALTH UNDER THE INTERNET OF THINGS AND BIG DATA,
778,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"While organizations in the current era of big data are generating massive volumes of data, they also need to ensure that its quality is maintained for it to be useful in decision-making purposes. The problem of dirty data plagues every organization. One aspect of dirty data is the presence of duplicate data records that negatively impact the organization's operations in many ways. Many existing approaches attempt to address this problem by using traditional data cleansing methods. In this paper, we address this problem by using an in-house crowdsourcing-based framework, namely, DedupCrowd. One of the main obstacles of crowdsourcing-based approaches is to monitor the performance of the crowd, by which the integrity of the whole process is maintained. In this paper, a statistical quality control-based technique is proposed to regulate the performance of the crowd. We apply our proposed framework in the context of a contact center, where the Customer Service Representatives are used as the crowd to assist in the process of deduplicating detection. By using comprehensive working examples, we show how the different modules of the DedupCrowd work not only to monitor the performance of the crowd but also to assist in duplicate detection.",10.1109/ACCESS.2019.2924979,2019,,QUALITY MANAGEMENT OF WORKERS IN AN IN-HOUSE CROWDSOURCING-BASED FRAMEWORK FOR DEDUPLICATION OF ORGANIZATIONS’ DATABASES,
779,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The Internet of Things (IoT) technologies plays a key role in the Fourth Industrial Revolution (Industry 4.0). This implies the digitisation of the industry and its services to improve productivity. To obtain the necessary information throughout the different processes, useful data streams are obtained to provide Artificial Intelligence and Big Data algorithms. However, strategic decision-making based on these algorithms may not be successful if they have been developed based on inadequate low-quality data. This research work proposes a set of metrics to measure Data Quality (DQ) in streaming time series, and implements and validates a set of techniques and tools that allow monitoring and improving the quality of the information. These techniques allow the early detection of problems that arise in relation to the quality of the data collected; and, in addition, they provide some mechanisms to solve these problems. Later, as part of the work, a use case related to industrial field is presented, where these techniques and tools have been deployed into a data management, monitoring and data analysis platform. This integration provides additional functionality to the platform, a Decision Support System (DSS) named DQ-REMAIN (Data Quality REport MAnagement and ImprovemeNt), for decision-making regarding the quality of data obtained from streaming time series.",10.1109/ACCESS.2022.3195338,2022,,"ON THE EVALUATION, MANAGEMENT AND IMPROVEMENT OF DATA QUALITY IN STREAMING TIME SERIES",
780,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Infant failure analyzing is an effective approach to improve production quality continuously. The root causes of infant failure have always been a puzzle to manufacturers. To satisfy the increasing demand for the fuzzy root cause analysis of product infant failure in the era of big data, a novel root cause identification approach based on the associated tree and fuzzy data envelopment analysis (DEA) is presented for product infant failure. First, to decrease fuzziness with regard to the mechanism of infant failure, the associated tree is adapted to guide the analysis process for possible root causes based on axiomatic domain mapping. Second, considering the fuzzy mechanism and massive data, the fuzzy DEA technique is adopted to cluster all the potential factors of functional parameters, physical parameters, and process parameters from big data regarding product life cycle. Third, the ranking method of decision-making unit efficiency in fuzzy DEA is used to model and rank the weight of each node in the established associated tree of infant failure. Finally, a case study of root cause identification for a typical infant failure of the vibration and noise of a washing machine is presented to demonstrate the feasibility and validity of the proposed method.",10.1109/ACCESS.2019.2904759,2019,,BIG DATA-ORIENTED PRODUCT INFANT FAILURE INTELLIGENT ROOT CAUSE IDENTIFICATION USING ASSOCIATED TREE AND FUZZY DEA,
781,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Building big data analytics (BDA) applications in the cloud introduces inevitable challenges, such as loss of control and uncertainty. To address the existing challenges, numerous efforts have been made on BDA application engineering to optimize the quality of BDA applications in the cloud, such as performance and reliability. However, there is still a lack of systematic view on engineering BDA applications in the cloud. Therefore, in this paper, we present a conceptual framework named CF4BDA to analyze the existing work on BDA applications from two perspectives: 1) the lifecycle of BDA applications and 2) the objects involved in the context of BDA applications in the cloud. The framework can help researchers and practitioners identify the research opportunities in a structured way and guide implementing BDA applications in the cloud. We perform a preliminary evaluation of the usefulness of CF4BDA by applying it to analyze a set of representative studies.",10.1109/ACCESS.2015.2490085,2015,,CF4BDA: A CONCEPTUAL FRAMEWORK FOR BIG DATA ANALYTICS APPLICATIONS IN THE CLOUD,
782,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of multimedia editing technologies, the copyright protection has attacked more attentions. Reversible data hiding (RDH), in which the cover can be recovered losslessly, is an effect method to eliminate embedding distortions. As a typical RDH method, histogram shifting (HS) is used widely. Most existing RDH schemes based on HS usually build sharp histograms by predicting and sorting techniques. To make use of spatial correlations of multimedia, several RDH schemes based on multiple HS (MHS) are proposed to protect copyright, in which some rigid rules are used to build multiple histograms. Against images, videos have more spatial and temple correlations and it is easier to acquire sharper histograms. In this paper, a video MHS scheme based on compression sensing (CS) is proposed. As a linear sensing algorithm, CS can measure macroblock residuals by reducing corrections among pixels to acquire distinguishable macroblock features, while keeping their statistical characteristics immutable. By employing CS, macroblocks with similar characteristics cluster together to formulate multiple histograms. For each of these histograms, data embedding is implemented to reduce shifting distortions by expanding the outermost bins while other bins are unchanged. Experimental results show that the quality of most test videos in our scheme are higher than that in the state-of-art schemes.",10.1109/ACCESS.2021.3137398,2022,,MULTIPLE HISTOGRAMS SHIFTING-BASED VIDEO DATA HIDING USING COMPRESSION SENSING,
783,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Obtrusive sleep apnea (OSA) is one of the most important sleep disorders because it has a direct adverse impact on the quality of life. Intellectual deterioration, decreased psychomotor performance, behavior, and personality disorders are some of the consequences of OSA. Therefore, a real-time monitoring of this disorder is a critical need in healthcare solutions. There are several systems for OSA detection. Nevertheless, despite their promising results, these systems not guiding their treatment. For these reasons, this research presents an innovative system for both to detect and support of treatment of OSA of elderly people by monitoring multiple factors such as sleep environment, sleep status, physical activities, and physiological parameters as well as the use of open data available in smart cities. Our system architecture performs two types of processing. On the one hand, a pre-processing based on rules that enables the sending of real-time notifications to responsible for the care of elderly, in the event of an emergency situation. This pre-processing is essentially based on a fog computing approach implemented in a smart device operating at the edge of the network that additionally offers advanced interoperability services: technical, syntactic, and semantic. On the other hand, a batch data processing that enables a descriptive analysis that statistically details the behavior of the data and a predictive analysis for the development of services, such as predicting the least polluted place to perform outdoor activities. This processing uses big data tools on cloud computing. The performed experiments show a 93.3% of effectivity in the air quality index prediction to guide the OSA treatment. The system's performance has been evaluated in terms of latency. The achieved results clearly demonstrate that the pre-processing of data at the edge of the network improves the efficiency of the system.",10.1109/ACCESS.2018.2849822,2018,,A SMART SYSTEM FOR SLEEP MONITORING BY INTEGRATING IOT WITH BIG DATA ANALYTICS,
784,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013-2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8% with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm.",10.1109/ACCESS.2017.2694446,2017,,DISEASE PREDICTION BY MACHINE LEARNING OVER BIG DATA FROM HEALTHCARE COMMUNITIES,
785,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper proposes three hierarchical levels of a competitive big-data market model. We consider that a service provider gathers data from multiple data sources and provides valuable information from refined data as a service to its customers. Under our approach, a service provider determines optimal data procurement from multiple data sources within its budget constraint. The multiple data sources follow the service provider's action by independently submitting bidding prices to the service provider. Further, customers decide whether to subscribe or not based on the subscription fee, their willingness-to-pay, and the quality of the refined data. We study the economic benefits of such a market model by analyzing the hierarchical decision making procedures as a Stackelberg game. We show the existence and the uniqueness of the Nash equilibrium (NE), and the NE solution is given as a closed form. Finally, we reveal that the obtained unique equilibrium solution maximizes the payoff of all market participants.",10.1109/ACCESS.2018.2845105,2018,,THREE HIERARCHICAL LEVELS OF BIG-DATA MARKET MODEL OVER MULTIPLE DATA SOURCES FOR INTERNET OF THINGS,
786,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the emergence of microblogging platforms and social media applications, large amounts of user-generated data in the form of comments, reviews, and brief text messages are produced every day. Microblog data is typically of poor quality; hence improving the quality of the data is a significant scientific and practical challenge. In spite of the relevance of the problem, there has been not much work so far, especially in regard to microblog data quality for Short-Text Topic Modelling (STTM) purposes. This paper addresses this problem and proposes an approach called the Social Media Data Cleansing Model (SMDCM) to improve data quality for STTM. We evaluate SMDCM using six topic modelling methods, namely the Latent Dirichlet Allocation (LDA), Word-Network Topic Model (WNTM), Pseudo-document-based Topic Modelling (PTM), Biterm Topic Model (BTM), Global and Local word embedding-based Topic Modeling (GLTM), and Fuzzy Topic modelling (FTM). We used the Real-world Cyberbullying Twitter (RW-CB-Twitter) and the Cyberbullying Mendeley (CB-MNDLY) datasets in the evaluation. The results proved the efficiency of the GLTM and WNTM over the other STTM models when applying the SMDCM techniques, which achieved optimum topic coherence and high accuracy values on RW-CB-Twitter and CB-MNDLY datasets.",10.1109/ACCESS.2022.3211396,2022,,ENHANCING BIG SOCIAL MEDIA DATA QUALITY FOR USE IN SHORT-TEXT TOPIC MODELING,
787,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the explosive growth of image big data in the agriculture field, image segmentation algorithms are confronted with unprecedented challenges. As one of the most important images segmentation technologies, the fuzzy c-means (FCMs) algorithm has been widely used in the field of agricultural image segmentation as it provides simple computation and high-quality segmentation. However, due to its large amount of computation, the sequential FCM algorithm is too slow to finish the segmentation task within an acceptable time. This paper proposes a parallel FCM segmentation algorithm based on the distributed memory computing platform Apache Spark for agricultural image big data. The input image is first converted from the RGB color space to the lab color space and generates point cloud data. Then, point cloud data are partitioned and stored in different computing nodes, in which the membership degrees of pixel points to different cluster centers are calculated and the cluster centers are updated iteratively in a data-parallel form until the stopping condition is satisfied. Finally, point cloud data are restored after clustering for reconstructing the segmented image. On the Spark platform, the performance of the parallel FCMs algorithm is evaluated and reaches an average speedup of 12.54 on ten computing nodes. The experimental results show that the Spark-based parallel FCMs algorithm can obtain a significant increase in speedup, and the agricultural image testing set delivers a better performance improvement of 128% than the Hadoop-based approach. This paper indicates that the Spark-based parallel FCM algorithm provides faster speed of segmentation for agricultural image big data and has better scale-up and size-up rates.",10.1109/ACCESS.2019.2907573,2019,,A SPARK-BASED PARALLEL FUZZY  $C$ -MEANS SEGMENTATION ALGORITHM FOR AGRICULTURAL IMAGE BIG DATA,
788,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data-driven knowledge acquisition is one of the key research fields in data mining. Dealing with large amounts of data has received a lot of attention in the field recently, and a number of methodologies have been proposed to extract insights from data in an automated or semi-automated manner. However, these methodologies generally target a specific aspect of the data mining process, such as data acquisition, data preprocessing, or data classification. However, a comprehensive knowledge acquisition method is crucial to support the end-to-end knowledge engineering process. In this paper, we introduce a knowledge acquisition system that covers all major phases of the cross-industry standard process for data mining. Acknowledging the importance of an end-to-end knowledge engineering process, we designed and developed an easy-to-use data-driven knowledge acquisition tool (DDKAT). The major features of the DDKAT are: (1) a novel unified features scoring approach for data selection; (2) a user-friendly data processing interface to improve the quality of the raw data; (3) an appropriate decision tree algorithm selection approach to build a classification model; and (4) the generation of production rules from various decision tree classification models in an automated manner. Furthermore, two diabetes studies were performed to assess the value of the DDKAT in terms of user experience. A total of 19 experts were involved in the first study and 102 students in the artificial intelligence domain were involved in the second study. The results showed that the overall user experience of the DDKAT was positive in terms of its attractiveness, as well as its pragmatic and hedonic quality factors.",10.1109/ACCESS.2018.2817022,2018,,A DATA-DRIVEN KNOWLEDGE ACQUISITION SYSTEM: AN END-TO-END KNOWLEDGE ENGINEERING PROCESS FOR GENERATING PRODUCTION RULES,
789,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Vehicular Internet-of-Things applications require an efficient Vehicle-to-Everything (V2X) communication scheme. However, it is particularly challenging to achieve a high throughput and low latency with limited wireless resources in highly dynamic vehicular networks. In this article, we propose a scheme that enhances V2V communications through integration of vehicle edge-based forwarding and learning-based edge selection policy optimization. The proposed scheme has three main characteristics. First, the Hierarchical edge-based preemptive route creation is introduced to create hierarchical edges and conduct efficient packet forwarding as well as route aggregation. Second, Two-stage learning is introduced to select efficient edge nodes using big data driven traffic prediction and reinforcement learning-based edge node selection. Third, Context-aware edge selection is employed to improve the performance of edge-based forwarding in various contexts. We use real traffic big data and realistic vehicular network simulations to evaluate the performance of the proposed scheme and show the advantage over other baseline approaches.",10.1109/ACCESS.2020.2964707,2020,,EDGE-BASED V2X COMMUNICATIONS WITH BIG DATA INTELLIGENCE,
790,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The number of Web services has increased dramatically during the last few years. This has resulted in an increase in the volume of candidate services for tasks in composition systems. This has led to growth in the variety of nonfunctional properties in service selection, resulting in uncertainty (veracity issues) among such properties, which has severely affected the NP-hard aspects of service selection. Despite this, consumers in many areas would like access to a variety of selection methods such as linear programming and dynamic programming techniques. An additional problem is that the composition length (the number of tasks) of the workflow has increased, with the incorporation of research domains such as data science. These trending composition issues are challenging the computational power of existing methods. Such concerns have opened the door to research involving Big Data space. We propose a flexible, distributed selection algorithm that facilitates heterogeneous-selection methods to satisfy multiobjective composition requirements rather than rigid, specific composition requirements. However, service-selection processes in a Big Data space will inevitably increase traffic congestion caused by the increased volume of internal communication, particularly external traffic, such as Zipf and Pareto phenomena, and internal traffic during shuffling. To address these concerns, we propose solutions for each case. Our experiments demonstrate that the proposed traffic-efficient multiobjective method is well behaved when selecting services in Big Data space.",10.1109/ACCESS.2018.2867633,2018,,QOS-AWARE RULE-BASED TRAFFIC-EFFICIENT MULTIOBJECTIVE SERVICE SELECTION IN BIG DATA SPACE,
791,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Complete data are required for the operation, maintenance, and detection of faults in semiconductor equipment. Missing data occur frequently because of defects such as sensor, data storage, and communication faults, leading to reductions in yield, quality, and productivity. Although many attempts have been made to solve this problem in other fields, few studies have specifically addressed data imputation in the semiconductor industry. In this study, an improved generative adversarial network (GAN)-based missing data imputation for the semiconductor industry called Semi-GAN is proposed. This study introduces a machine learning approach for dealing with data imputation in the semiconductor industry. The proposed method was applied to real data and evaluated using traditional techniques. In particular, the proposed method showed excellent results compared to traditional attribution methods when all missing data ratios in the experiments were less than 20%. It was also observed to be superior when simple and repetitive patterns were omitted rather than repetitive but not simple patterns.",10.1109/ACCESS.2022.3188871,2022,,SEMI-GAN: AN IMPROVED GAN-BASED MISSING DATA IMPUTATION METHOD FOR THE SEMICONDUCTOR INDUSTRY,
792,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of educational informatization, it has enabled education to enter the era of big data. How to extract effective information from educational big data and realize adaptive personalized learning goals have become the current research hotspot. The traditional static data only analyzes the students' learning degree based on the students' final answer, but ignores the dynamic data in the process of answering questions, such as the modification and the time it answered on the question, which makes it difficult to fully and accurately mine the correlation between the massive data, so it turns from static data mining to dynamic data mining. The paper proposes an optimized mining algorithm for analyzing students' learning degree based on dynamic data. The algorithm first uses the optimized text classification technology to match the question texts to the knowledge points automatically, so as to improves the efficiency and quality. Then, it uses the subjective weighting method combined with the expert experience to generate the learning degree matrix of students on knowledge points based on dynamic data of the students' records. Finally, the DBSCAN clustering algorithm is used to cluster the personalized learning characteristics of students according to the learning degree matrix. The experimental result shows that the algorithm can deal with massive data automatically and effectively, and analyze the students' learning degree on knowledge points comprehensively and accurately, so as to classify students and realize personalized teaching.",10.1109/ACCESS.2020.3001749,2020,,AN OPTIMIZED MINING ALGORITHM FOR ANALYZING STUDENTS’ LEARNING DEGREE BASED ON DYNAMIC DATA,
793,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Detecting and analyzing patient insights from social media enables healthcare givers to better understand what patients want and also to identify their pain points. Healthcare institutions cannot neglect the need to monitor and analyze popular social media outlets such as Twitter and Facebook. To have a study success, a healthcare giver needs to be able to engage with their patients and adapt to their preferences effectively. However, data-driven decision-making is no longer enough, as the best-in-class organizations struggle to realize tangible benefits from their data-driven analytics investments. Relying on simplistic textual analytics that use big data technologies to learn consumer/patient insights is no longer sufficient as most of these analytics utilize sort of bag-of-words counting algorithms. The majority of projects utilizing big data analytics have failed due to the obsession with metrics at the expense of capturing the customer's perspective data, as well as the failure in turning consumer insights into actions. Most of the consumer insights can be captured with qualitative research methods that work with small, even statistically insignificant, sample sizes. Employing qualitative analytics provide some kind of actionable intelligence which acquires understanding to broad questions about the consumer needs in tandem with analytical power. Generating insight, on one hand, requires sound techniques to measure consumers' engagement more precisely and offers depth analytics to the consumer data story. On the other hand, turning relevant insights into actions requires incorporating actionable intelligence across the business by verify hypotheses based on qualitative findings by using web analytics to see if these axioms apply to a large number of customers. The first component of our visionary approach is dedicated to identifying the relationships between constituents of the healthcare pain points as echoed by the social media conversation in terms of sociographic network where the elements composing these conversations are described as nodes and their interactions as links. In this part, conversation groups of nodes that are heavily connected will be identified representing what we call conversation communities. By identifying these conversation communities several consumer hidden insights can be inferred from using techniques such as visualizing conversation graphs relevant to given pain point, conversation learning from question answering, conversations summaries, conversation timelines, conversation anomalies and other conversation pattern learning techniques. These techniques will identify and learn the patient insights without forgetting from the context of conversation communities, are tagged as “thick data analytics”. Additionally machine learning methods can be used as assistive techniques to learn from the identified thick data and build models around identified thick data. With the use of transfer learning we also can fine tune these models with the arrival of new conversations. The author is currently experimenting with these seven insights driven learning methods described in this paper with massive geo-located Twitter data to infer the quality of care related to the current COVID-19 outbreak.",10.1109/ACCESS.2020.2995763,2020,,ENVISIONING INSIGHT-DRIVEN LEARNING BASED ON THICK DATA ANALYTICS WITH FOCUS ON HEALTHCARE,
794,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The design and optimization of wireless networks have mostly been based on strong mathematical and theoretical modeling. Nonetheless, as novel applications emerge in the era of 5G and beyond, unprecedented levels of complexity will be encountered in the design and optimization of the network. As a result, the use of Artificial Intelligence (AI) is envisioned for wireless network design and optimization due to the flexibility and adaptability it offers in solving extremely complex problems in real-time. One of the main future applications of AI is enabling user-level personalization for numerous use cases. AI will revolutionize the way we interact with computers in which computers will be able to sense commands and emotions from humans in a non-intrusive manner, making the entire process transparent to users. By leveraging this capability, and accelerated by the advances in computing technologies, wireless networks can be redesigned to enable the personalization of network services to the user level in real-time. While current wireless networks are being optimized to achieve a predefined set of quality requirements, the personalization technology advocated in this article is supported by an intelligent big data-driven layer designed to micro-manage the scarce network resources. This layer provides the intelligence required to decide the necessary service quality that achieves the target satisfaction level for each user. Due to its dynamic and flexible design, personalized networks are expected to achieve unprecedented improvements in optimizing two contradicting objectives in wireless networks: saving resources and improving user satisfaction levels. This article presents some foundational background on the proposed network personalization technology and its enablers. Then, an AI-enabled big data-driven surrogate-assisted multi-objective optimization formulation is proposed and tested to illustrate the feasibility and prominence of this technology.",10.1109/ACCESS.2020.3014301,2020,,PERSONALIZED RESOURCE ALLOCATION IN WIRELESS NETWORKS: AN AI-ENABLED AND BIG DATA-DRIVEN MULTI-OBJECTIVE OPTIMIZATION,
795,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Algal bloom is a nonlinear and time-varying process, which brings challenges for the accurate prediction. For the existing mechanism model of algae ignores the external key factors, we propose an algae growth model (AGM) optimized by action dependent heuristic dynamic programming (ADHDP). This model has the structure of information interaction with the outside, which can predict algal bloom with well adaptive ability. In this paper, chlorophyll-a concentration is used as the representative factor of algal bloom. We use ADHDP approach to map the external key factors to the time-varying parameters, so the AGM can be adjusted to realize the self-adaptive prediction with the changes in external environments. Compared with different prediction methods, the simulation result shows that the ADHDP-AGM prediction model can accurately predict the chlorophyll-a concentration under different data distributions. Moreover, the prediction process shows that the time-varying parameters in AGM conform to the evolution trend of chlorophyll-a concentration in fact, which further improves the interpretability of prediction model. It provides a new perspective for building a data-driven prediction model with clear physical significance, and makes the mechanism research and data science further fusion.",10.1109/ACCESS.2020.2971244,2020,,AN ACTION DEPENDENT HEURISTIC DYNAMIC PROGRAMMING APPROACH FOR ALGAL BLOOM PREDICTION WITH TIME-VARYING PARAMETERS,
796,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Current trends in medicine regarding issues of accessibility to and the quantity and quality of information and quality of service are very different compared to former decades. The current state requires new methods for addressing the challenge of dealing with enormous amounts of data present and growing on the Web and other heterogeneous data sources such as sensors and social networks and unstructured data, normally referred to as big data. Traditional approaches are not enough, at least on their own, although they were frequently used in hybrid architectures in the past. In this paper, we propose an architecture to process big data, including heterogeneous sources of information. We have defined an ontology-oriented architecture, where a core ontology has been used as a knowledge base and allows data integration of different heterogeneous sources. We have used natural language processing and artificial intelligence methods to process and mine data in the health sector to uncover the knowledge hidden in diverse data sources. Our approach has been applied to the field of personalized medicine (study, diagnosis, and treatment of diseases customized for each patient) and it has been used in a telemedicine system. A case study focused on diabetes is presented to prove the validity of the proposed model.",10.1109/ACCESS.2018.2857499,2018,,AN ONTOLOGY-ORIENTED ARCHITECTURE FOR DEALING WITH HETEROGENEOUS DATA APPLIED TO TELEMEDICINE SYSTEMS,
797,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions.",10.1109/ACCESS.2017.2682640,2017,,LIVE DATA ANALYTICS WITH COLLABORATIVE EDGE AND CLOUD PROCESSING IN WIRELESS IOT NETWORKS,
798,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Mobile networks possess information about the users as well as the network. Such information is useful for making the network end-to-end visible and intelligent. Big data analytics can efficiently analyze user and network information, unearth meaningful insights with the help of machine learning tools. Utilizing big data analytics and machine learning, this paper contributes in three ways. First, we utilize the call detail records data to detect anomalies in the network. For authentication and verification of anomalies, we use k-means clustering, an unsupervised machine learning algorithm. Through effective detection of anomalies, we can proceed to suitable design for resource distribution as well as fault detection and avoidance. Second, we prepare anomaly free data by removing anomalous activities and train a neural network model. By passing the anomaly and anomaly free data through this model, we observe the effect of anomalous activities in training of the model and also observe mean square error of the anomaly and anomaly free data. At last, we use an autoregressive integrated moving average model to predict future traffic for a user. Through simple visualization, we show that the anomaly free data better generalizes the learning models and performs better on prediction task.",10.1109/ACCESS.2018.2859756,2018,,CALL DETAIL RECORDS DRIVEN ANOMALY DETECTION AND TRAFFIC PREDICTION IN MOBILE CELLULAR NETWORKS,
799,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Today's cities generate tremendous amounts of data, thanks to a boom in affordable smart devices and sensors. The resulting big data creates opportunities to develop diverse sets of context-aware services and systems, ensuring smart city services are optimized to the dynamic city environment. Critical resources in these smart cities will be more rapidly deployed to regions in need, and those regions predicted to have an imminent or prospective need. For example, crime data analytics may be used to optimize the distribution of police, medical, and emergency services. However, as smart city services become dependent on data, they also become susceptible to disruptions in data streams, such as data loss due to signal quality reduction or due to power loss during data collection. This paper presents a dynamic network model for improving service resilience to data loss. The network model identifies statistically significant shared temporal trends across multivariate spatiotemporal data streams and utilizes these trends to improve data prediction performance in the case of data loss. Dynamics also allow the system to respond to changes in the data streams such as the loss or addition of new information flows. The network model is demonstrated by city-based crime rates reported in Montgomery County, MD, USA. A resilient network is developed utilizing shared temporal trends between cities to provide improved crime rate prediction and robustness to data loss, compared with the use of single city-based auto-regression. A maximum improvement in performance of 7.8 % for Silver Spring is found and an average improvement of 5.6 % among cities with high crime rates. The model also correctly identifies all the optimal network connections, according to prediction error minimization. City-to-city distance is designated as a predictor of shared temporal trends in crime and weather is shown to be a strong predictor of crime in Montgomery County.",10.1109/ACCESS.2017.2757841,2017,,DYNAMIC NETWORK MODEL FOR SMART CITY DATA-LOSS RESILIENCE CASE STUDY: CITY-TO-CITY NETWORK FOR CRIME ANALYTICS,
800,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, the Smart City concept has become popular for its promise to improve the quality of life of urban citizens. The concept involves multiple disciplines, such as Smart health care, Smart transportation, and Smart community. Most services in Smart Cities, especially in the Smart healthcare domain, require the real-time sharing, processing, and analyzing of Big Healthcare Data for intelligent decision making. Therefore, a strong wireless and mobile communication infrastructure is necessary to connect and access Smart healthcare services, people, and sensors seamlessly, anywhere at any time. In this scenario, mobile cloud computing (MCC) can play a vital role by offloading Big Healthcare Data related tasks, such as sharing, processing, and analysis, from mobile applications to cloud resources, ensuring quality of service demands of end users. Such resource migration, which is also termed virtual machine (VM) migration, is effective in the Smart healthcare scenario in Smart Cities. In this paper, we propose an ant colony optimization-based joint VM migration model for a heterogeneous, MCC-based Smart Healthcare system in Smart City environment. In this model, the user’s mobility and provisioned VM resources in the cloud address the VM migration problem. We also present a thorough performance evaluation to investigate the effectiveness of our proposed model compared with the state-of-the-art approaches.",10.1109/ACCESS.2017.2707439,2017,,MOBILE CLOUD-BASED BIG HEALTHCARE DATA PROCESSING IN SMART CITIES,
801,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of  $3D$  visualization technology, the amount of geological data information is increasing, and the interactive display of big data faces severe challenges. Because traditional volume rendering methods cannot entirely load large-scale data into the memory owing to hardware limitations, a visualization method based on variational deep embedding clustering fusion Hilbert R-tree is proposed to solve slow display and stuttering issues when rendering massive geological data. By constructing an efficient data index structure, deep clustering algorithms and space-filling curves can be integrated into the data structure to improve the indexing efficiency. In addition, this method combines time forecasting, data scheduling, and loading modules to improve the accuracy and real-time data display rate, thereby improving the stability of  $3D$  visualization of large-scale geological data. This method uses real geological data as the experimental dataset, comparing and analyzing the existing index structure and time-series prediction method. The experimental results indicate that when comparing the index of the variational deep embedded clustering-Hilbert R-tree ( $VDEC-HRT$ ) with that of the K-means Hilbert R-tree ( $KHRT$ ), the time required is reduced by 55.67%, the viewpoint prediction correctness of the proposed method is improved by 22.7% compared with Lagrange interpolation algorithm. And the overall rendering performance and quality of the system achieve the expected results. Ours experiments prove the feasibility and effectiveness of the proposed scheme in the visualization of large-scale geological data.",10.1109/ACCESS.2022.3157823,2022,,FAST 3D VISUALIZATION OF MASSIVE GEOLOGICAL DATA BASED ON CLUSTERING INDEX FUSION,
802,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Non-intrusive transmission cable monitoring is the latest advanced measurement technology for smart grids. It only samples the voltage on a certain part of the transmission cable, and uses intelligent algorithms to identify the quality, which has obvious advantages of low construction and maintenance costs. This paper established a model based on multi-channel data fusion and transfer learning to classify the quality of transmission cable. First, we used the ANSYS Maxwell simulation platform to obtain ten kinds of specific fault data, which solved the time cost of manual labeling. Then, we performed multi-channel data fusion on the original data, which strengthened the expression of important features and was more conducive to the training of the model. Next, we used Depthwise Separable Convolution (DSC) to speed up the learning of the model, and improve the accuracy of the classification. Finally, we transferred the model trained with simulation data into the real scene, realized the transfer from multi classes to two classes, the effectiveness was proved in experiments. The accuracy of the model built in the article to classify the quality of the transmission cables is 98.1%.",10.1109/ACCESS.2021.3094231,2021,,FAULT JUDGMENT OF TRANSMISSION CABLE BASED ON MULTI-CHANNEL DATA FUSION AND TRANSFER LEARNING,
803,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper is concerned with a cognitive cloud radio access network (CRAN) with a special attention to efficient and reliable downlink transmission of big data for secondary users (SUs). Existing approaches either try to maximize the number of accepted SUs or the sum data rate of accepted SUs. The first approach unfairly favors users with small data requests, whereas the second approach allocates most resources to users with better channel conditions. In contrast, this paper develops a novel approach that favors big data requests while simultaneously maintaining a certain degree of fairness among SUs. To this end, we first introduce a novel objective function that allows us to jointly optimize deadline-aware time scheduling, spectrum allocation, SU selection, and remote radio head (RRH) allocation for SUs. Second, we demonstrate that finding the global optimum solution entails the enumeration of all colorful independent sets on a generalized interval graph, which is known to be NP-hard. Third, we propose a dynamic programming (DP) approach, which yields the global optimum solution at a reduced computational cost. Fourth, we analyze the complexity of the proposed DP approach and assess its performance against existing baseline algorithms. Simulation results reveal that our solution favors big data users while incurring only a small degradation in the fairness index. Our proposed solution is practical for small-to-medium size networks. Furthermore, it offers an optimum benchmark for any new sub-optimal low-complexity algorithm.",10.1109/ACCESS.2022.3156584,2022,,GLOBALLY OPTIMAL RESOURCE ALLOCATION AND TIME SCHEDULING IN DOWNLINK COGNITIVE CRAN FAVORING BIG DATA REQUESTS,
804,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The increasing demand for cloud-based services, such as big data analytics and online e-commerce, leads to rapid growth of large-scale internet data centers. In order to provide highly reliable, cost effective, and high quality cloud services, data centers are equipped with sensors to monitor the operational states of infrastructure hardware, such as servers, storage arrays, networking devices, and computer room air conditioning systems. However, such coarse grained monitoring cannot provide fine grained real time information for resource multiplexing and job scheduling. Moreover, the monitoring of node level power consumption plays an important role in the optimization of workload placement and energy efficiency in data centers. In this paper, we propose an edge computing platform for intelligent operational monitoring in data centers. The platform integrates wireless sensors and on-board built-in sensors to collect data during the operation and maintenance of data centers. Using logical functions, we divide the data center clusters into grids, and then deploy wireless sensors and edge servers in each grid. As such, data processing on edge servers can reduce the latency in data transmission to central clouds and thereby enhance the real time resource mapping decisions in data centers. In addition, the proposed platform also provides predictions of resource utilization, workload characteristics, and hardware health trends in data centers.",10.1109/ACCESS.2019.2939614,2019,,AN EDGE COMPUTING PLATFORM FOR INTELLIGENT OPERATIONAL MONITORING IN INTERNET DATA CENTERS,
805,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the fast growth of artificial intelligence and big data computing technologies, more and more software service systems have been developed using diverse machine learning models and technologies to make business and intelligent decisions based on their multimedia input to achieve intelligent features, such as image recognition, recommendation, decision making, prediction, etc. Nevertheless, there are increasing quality problems resulting in erroneous testing costs in enterprises and businesses. Existing work seldom discusses how to perform testing and quality validation for AI software. This paper focuses on quality validation for AI software function features. The paper provides our understanding of AI software testing for new features and requirements. In addition, current AI software testing categories are presented and different testing approaches are discussed. Moreover, test quality assessment and criteria analysis are illustrated. Furthermore, a practical study on quality validation for an image recognition system is performed through a metamorphic testing method. Study results show the feasibility and effectiveness of the approach.",10.1109/ACCESS.2019.2937107,2019,,"TESTING AND QUALITY VALIDATION FOR AI SOFTWARE–PERSPECTIVES, ISSUES, AND PRACTICES",
806,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Light-emitting Diode (LED) lamps have been widely used due to versatility and energy efficiency. However, LEDs are nonlinear loads, the massive usage will inject harmonics into the lighting system, which has influenced the power quality. Total Harmonic Distortion (THD) is an important parameter to evaluate the power quality, but the prediction of THD for LEDs is a challenging task. This paper addresses this issue by designing harmonic characteristics detection experiment and using artificial intelligence algorithm. Firstly, LED lamps with different driving circuits were tested, the relevant data of each harmonic were sampled and analyzed. Then, a THD prediction method based on an improved AdaBoost algorithm is proposed. In this method, a Generalized Regression Neural Network (GRNN) model is established, and its parameters are optimized by Mind Evolution Algorithm (MEA) to improve the search ability of GRNN. On this basis, the AdaBoost algorithm is utilized to integrate multiple MEA-GRNN individuals to form a strong predictor, which improves the generalization ability of the model. To avoid the integration failure caused by improper selection of threshold value, a sigmoid adaptive factor is added to improve the accuracy of AdaBoost algorithm. Finally, the Ada-MEA-GRNN model is trained and simulated with the LED harmonic data collected by the experiment. The simulation results show that the prediction accuracy of the proposed method is better than BP and GRNN, which can reach 95.48%. Meanwhile, even if the input dimension is reduced, the error is still small.",10.1109/ACCESS.2021.3059483,2021,,HARMONIC CHARACTERISTICS DATA-DRIVEN THD PREDICTION METHOD FOR LEDS USING MEA-GRNN AND IMPROVED-ADABOOST ALGORITHM,
807,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"To solve the problem of insufficient sample resources and poor noise immunity in single-image super-resolution (SR) restoration procedure, the paper has proposed the single-image SR algorithm based on structural self-similarity and deformation block features (SSDBF). First, the proposed method constructs a scale model, expands the search space as much as possible, and overcomes the shortcomings caused by the lack of a single-image SR training sample; Second, the limited internal dictionary size is increased by the geometric deformation of the sample block; Finally, in order to improve the anti-noise performance of the reconstructed picture, a group sparse learning dictionary is used to reconstruct the pending image. The experimental results show that, compared with state-of-the-art algorithms such as bicubic interpolation (BI), sparse coding (SC), deep recursive convolutional network (DRCN), multi-scale deep SR network (MDSR), super-resolution convolutional neural network (SRCNN) and second-order directional total generalized variation (DTGV). The SR images with more subjective visual effects and higher objective evaluation can be obtained through the proposed method. Compared with existing algorithms, the structural network converges more rapidly, the image edge and texture reconstruction effects are obviously improved, and the image quality evaluation, such as peak signal-noise ratio (PSNR), root mean square error (RMSE), and structural similarity (SSIM), are also superior and popular in image evaluation.",10.1109/ACCESS.2019.2911892,2019,,NOTICE OF VIOLATION OF IEEE PUBLICATION PRINCIPLES: SINGLE-IMAGE SUPER-RESOLUTION ALGORITHM BASED ON STRUCTURAL SELF-SIMILARITY AND DEFORMATION BLOCK FEATURES,
808,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data transmission is the most critical operation for mobile sensors networks in term of energy waste. Particularly in pervasive healthcare sensors network it is paramount to preserve the quality of service also by means of energy saving policies. Communication and data transmission are among the most critical operation for such devises in term of energy waste. In this paper we present a novel approach to increase battery life-span by means of shorter transmission due to data compression. On the other hand, since this latter operation has a non-neglectable energy cost, we developed a compression efficiency estimator based on the evaluation of the absolute and relative entropy. Such algorithm provides us with a fast mean for the evaluation of data compressibility. Since mobile wireless sensor networks are prone to battery discharge-related problems, such an evaluation can be used to improve the electrical efficiency of data communication. In facts the developed technique, due to its independence from the string or file length, is extremely robust both for small and big data files, as well as to evaluate whether or not to compress data before transmission. Since the proposed solution provides a quantitative analysis of the source's entropy and the related statistics, it has been implemented as a preprocessing step before transmission. A dynamic threshold defines whether or not to invoke a compression subroutine. Such a subroutine should be expected to greatly reduce the transmission length. On the other hand a data compression algorithm should be used only when the energy gain of the reduced transmission time is presumably greater than the energy used to run the compression software. In this paper we developed an automatic evaluation system in order to optimize the data transmission in mobile sensor networks, by compressing data only when this action is presumed to be energetically efficient. We tested the proposed algorithm by using the Canterbury Corpus as well as standard pictorial data as benchmark test. The implemented system has been proven to be time-inexpensive with respect to a compression algorithm. Finally the computational complexity of the proposed approach is virtually neglectable with respect to the compression and transmission routines themselves.",10.1109/ACCESS.2019.2962771,2020,,AN ENTROPY EVALUATION ALGORITHM TO IMPROVE TRANSMISSION EFFICIENCY OF COMPRESSED DATA IN PERVASIVE HEALTHCARE MOBILE SENSOR NETWORKS,
809,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart grids are power grids where clients may actively participate in energy production, storage and distribution. Smart grid management raises several challenges, including the possible changes and evolutions in terms of energy consumption and production, that must be taken into account in order to properly regulate the energy distribution. In this context, machine learning methods can be fruitfully adopted to support the analysis and to predict the behavior of smart grids, by exploiting the large amount of streaming data generated by sensor networks. In this article, we propose a novel change detection method, called ECHAD (Embedding-based CHAnge Detection), that leverages embedding techniques, one-class learning, and a dynamic detection approach that incrementally updates the learned model to reflect the new data distribution. Our experiments show that ECHAD achieves optimal performances on synthetic data representing challenging scenarios. Moreover, a qualitative analysis of the results obtained on real data of a real power grid reveals the quality of the change detection of ECHAD. Specifically, a comparison with state-of-the-art approaches shows the ability of ECHAD in identifying additional relevant changes, not detected by competitors, avoiding false positive detections.",10.1109/ACCESS.2020.3019095,2020,,ECHAD: EMBEDDING-BASED CHANGE DETECTION FROM MULTIVARIATE TIME SERIES IN SMART GRIDS,
810,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Air quality prediction is an important reference for meteorological forecast and air controlling, but over fitting often occurs in prediction algorithms based on a single model. Aiming at the complexity of air quality prediction, a prediction method based on integrated dual LSTM (Long Short-Term Memory) model was proposed in this paper. Firstly, the Seq2Seq (Sequence to Sequence) technology is used to establish a single-factor prediction model which can obtain the predicted value of each component in air quality data, independently. Each component of air quality is regarded as time series data in the forecasting process. Then, the LSTM model with attention mechanism is used as the multi-factor prediction model. The influencing factors of air quality, like the data of neighboring stations and weather data, are considered in the model. Finally, XGBoosting (eXtreme Gradient Boosting) tree is used to integrate two models. The final prediction results can be obtained by accumulating the predicted values of the optimal subtree nodes. Through evaluation and analysis using five evaluation methods, the proposed method has better performance in terms of error and model expression power. Compared with other various models, the precision of prediction data has been greatly improved in our model.",10.1109/ACCESS.2021.3093430,2021,,AIR QUALITY PREDICTION BASED ON INTEGRATED DUAL LSTM MODEL,
811,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This study addresses the causal identification of air pollutants from surrounding cities affecting Beijing's air quality. A novel compressive sensing causality analysis (CS-Causality) method, which combines Granger causality analysis (GCA) and maximum correntropy criterion (MCC), is presented for efficient identification of the air pollutant causality between Beijing and surrounding cities. Firstly, taking the spatiotemporal correlation into consideration, the original data is mapped into low-dimensional space. Valid information is then obtained based on compressive sensing (CS), which can greatly reduce the dimensions of the data, thus decreasing the amount of data analysis required. Secondly, to analyze the causal relations, GCA, represented by the prediction from one time series to another, is extended to rule out “Non-Granger” causes of air pollutants in Beijing originating from its surrounding cities. Thirdly, the greatest impact on Beijing's air quality is confirmed based on MCC. Finally, the accuracy of these results is verified using the transfer entropy.",10.1109/ACCESS.2020.3000767,2020,,CAUSAL IDENTIFICATION BASED ON COMPRESSIVE SENSING OF AIR POLLUTANTS USING URBAN BIG DATA,
812,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Traffic congestion is a significant problem faced by large and growing cities that hurt the economy, commuters, and the environment. Forecasting the congestion level of a road network timely can prevent its formation and increase the efficiency and capacity of the road network. However, despite its importance, traffic congestion prediction is not a hot topic among the researcher and traffic engineers. It is due to the lack of high-quality city-wide traffic data and computationally efficient algorithms for traffic prediction. In this paper, we propose (i) an efficient and inexpensive city-wide data acquisition scheme by taking a snapshot of traffic congestion map from an open-source online web service; Seoul Transportation Operation and Information Service (TOPIS), and (ii) a hybrid neural network architecture formed by combing Convolutional Neural Network, Long Short-Term Memory, and Transpose Convolutional Neural Network to extract the spatial and temporal information from the input image to predict the network-wide congestion level. Our experiment shows that the proposed model can efficiently and effectively learn both spatial and temporal relationships for traffic congestion prediction. Our model outperforms two other deep neural networks (Auto-encoder and ConvLSTM) in terms of computational efficiency and prediction performance.",10.1109/ACCESS.2020.2991462,2020,,"CITY-WIDE TRAFFIC CONGESTION PREDICTION BASED ON CNN, LSTM AND TRANSPOSE CNN",
813,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Intelligence transportation system (ITS) and vehicular networks have attracted the research community in the recent years which generate the “big data” in traffic. However, the collection and application of the big traffic data is limited by the privacy of people who generate data. Besides, data-driven-based ITS only needs information that could reflect one or more types of vehicles at specific intersections, sections, and road networks, rather than that of each individual vehicle. Overall, intelligent analysis and data fusion of multi-source traffic data play an important role to reduce the phenomenon of privacy disclosure and ensure the quality of data. As a result, a complete method of multi-source traffic data analyzing and processing is proposed in this paper, including the data analysis method based on the spatio-temporal regression model and the data fusion method using evidence theory based on the confidence tensor. Finally, the practical data is used to conform the ways proposed before. And not only do the results show that the implicit privacy information has been removed but also present a higher accuracy of the proceed data.",10.1109/ACCESS.2018.2872805,2018,,RESEARCH ON INTELLIGENT ANALYSIS AND DEPTH FUSION OF MULTI-SOURCE TRAFFIC DATA,
814,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Large scale data and predictive analytics are the most challenging tasks in the field of academic data mining. Academic libraries are a great source of information and knowledge to provide a wide range of services to meet end-user requirements. Due to the rapid changes in the educational environment and availability of huge library rental book data, it is required to utilize data mining and machine learning techniques in the context of the academic library to extract and analyze underlying knowledge from rental book data, which is important to facilitate library administration to drive better future decisions to improve and manage library resources effectively. These are the following resources, such as managing future demands of the library books, selection and arrangement of the books, operational efficiency, and also improve the quality of interaction between the library and end-users, etc. This work uses and analyzes a real dataset collected from the library of Jeju National University, the Republic of Korea. The dataset contains 2,211,413 rental book records including 173671 unique book records, 57203 unique number of the rental user, and 78 data parameters. In this paper, we propose a novel model to analyze and predict library rental book data to facilitates library administration in order to plan and manage library resources effectively and provide better services to end-users. The proposed model consists of two different modules; library data analysis and prediction modules. Firstly, we use data mining techniques to analyze and extract useful underlying patterns from library rental book data, which can lead to plan and manage library resources effectively. Secondly, a novel prediction model is proposed based on Deep Neural Network (DNN), Support Vector Regressor (SVR), and Random Forest (RF) to predict future usage of the academic libraries rental books. The performance results of the implemented regression models are evaluated in terms of MAE, MSE, and RMSE. In this paper, it is found that the DNN model performs significantly better than SVR and RF. The experimentation results show that the proposed model improves the future usage of library books to facilitate library administration to plan and manage library resources effectively. Based on the proposed model results, the academic library administration can easily plan and manage resources effectively to provide quality services to end-users.",10.1109/ACCESS.2020.2990765,2020,,TOWARD EFFECTIVE PLANNING AND MANAGEMENT USING PREDICTIVE ANALYTICS BASED ON RENTAL BOOK DATA OF ACADEMIC LIBRARIES,
815,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The automatic standardization of nomenclature for anatomical structures in radiotherapy (RT) clinical data is a critical prerequisite for data curation and data-driven research in the era of big data and artificial intelligence, but it is currently an unmet need. Existing methods either cannot handle cross-institutional datasets or suffer from heavy imbalance and poor-quality delineation in clinical RT datasets. To solve these problems, we propose an automated structure nomenclature standardization framework, 3D Non-local Network with Voting (3DNNV). This framework consists of an improved data processing strategy, namely, adaptive sampling and adaptive cropping (ASAC) with voting, and an optimized feature extraction module. The framework simulates clinicians' domain knowledge and recognition mechanisms to identify small-volume organs at risk (OARs) with heavily imbalanced data better than other methods. We used partial data from an open-source head-and-neck cancer dataset to train the model, then tested the model on three cross-institutional datasets to demonstrate its generalizability. 3DNNV outperformed the baseline model, achieving higher average true positive rates (TPR) over all categories on the three test datasets (+8.27%, +2.39%, and +5.53%, respectively). More importantly, the 3DNNV outperformed the baseline on the test dataset, 28.63% to 91.17%, in terms of F1 score for a small-volume OAR with only 9 training samples. The results show that 3DNNV can be applied to identify OARs, even error-prone ones. Furthermore, we discussed the limitations and applicability of the framework in practical scenarios. The framework we developed can assist in standardizing structure nomenclature to facilitate data-driven clinical research in cancer radiotherapy.",10.1109/ACCESS.2020.2999079,2020,,MINING DOMAIN KNOWLEDGE: IMPROVED FRAMEWORK TOWARDS AUTOMATICALLY STANDARDIZING ANATOMICAL STRUCTURE NOMENCLATURE IN RADIOTHERAPY,
816,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Nowadays, light emitting diode (LED) lamps have been widely utilized for lighting system due to its low-energy consumption. The harmonic emission standard is ignored by most of the manufacturers, high harmonic current will increase harmonic injection and cause fire risk. Existing research focuses on investigating harmonic emissions from several specific LED drivers, but a systematic evaluation approach is not given. The contribution of this paper proposed a LED harmonic evaluation in the management view, which can evaluate the harmonics of the LED lamps, accelerate the elimination of inferior LED lamps, and improve the power quality of distribution network. The evaluation approach combines G1 method and entropy method, which can make the weighting more scientific and rational. An evaluation model is established by collecting data, then the G1-entropy method is used to calculate the weights of harmonic characteristics in this model. Finally, we analyze and discuss the results, a specific evaluation approach is proposed, which can thoroughly and accurately represent the harmonic characteristics of LED lamps.",10.1109/ACCESS.2021.3103052,2021,,AN IMPROVED POWER QUALITY EVALUATION FOR LED LAMP BASED ON G1-ENTROPY METHOD,
817,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart societies have an increasing demand for quality-oriented services and infrastructure in an industrial Internet of Things (IIoT) paradigm. Smart urbanization faces numerous challenges. Among them, secured energy demand-side management (DSM) is of particular concern. The IIoT renders the industrial systems to malware, cyberattacks, and other security risks. The IIoT with the amalgamation of big data analytics can provide efficient solutions to such challenges. This paper proposes a secured and trusted multilayered DSM engine for a smart social society using IIoT-based big data analytics. The major objective is to provide a generic secured solution for smart societies in IIoT environment. The proposed engine uses a centralized approach to achieve optimum DSM over a home area network. To enhance the security of this engine, a payload-based authentication scheme is utilized that relies on a lightweight handshake mechanism. Our proposed method utilizes the lightweight features of the constrained application protocol to facilitate the clients in monitoring various resources residing over the server in an energy-efficient manner. In addition, data streams are processed using big data analytics with MapReduce parallel processing. The proposed authentication approach is evaluated using NetDuino Plus 2 boards that yield a lower connection overhead, memory consumption, response time, and a robust defense against various malicious attacks. On the other hand, our data processing approach is tested on reliable datasets using Apache Hadoop with Apache Spark to verify the proposed DMS engine. The test results reveal that the proposed architecture offers valuable insights into the smart social societies in the context of IIoT.",10.1109/ACCESS.2018.2861421,2018,,A SECURED DATA MANAGEMENT SCHEME FOR SMART SOCIETIES IN INDUSTRIAL INTERNET OF THINGS ENVIRONMENT,
818,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Due to the influence of temperature changes or temperature gradients in the construction process of mass concrete, temperature cracks will occur in the concrete. In order to achieve a reasonable prediction of the temperature change of the mass concrete during the construction process and accurately obtain the temperature change trend, this paper attempts to construct a CART prediction model based on the big data processing technology based on the characteristics of the temperature change of the mass concrete. This paper introduces in detail how to use data processing methods such as outlier identification, missing value filling and random error elimination to improve data quality, as well as the method for constructing the CART prediction model, and combines engineering examples to demonstrate the feasibility of the model method. The results show that the model and method can better predict the temperature change of mass concrete. It has high prediction accuracy and can provide necessary guidance for practical engineering.",10.1109/ACCESS.2022.3161556,2022,,RESEARCH ON CART MODEL OF MASS CONCRETE TEMPERATURE PREDICTION BASED ON BIG DATA PROCESSING TECHNOLOGY,
819,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the ever-increasing popularity of sports and health ideas, people are paying more attentions to gaining high-quality healthy life through various taking various sport items or exercises. Through observing and analyzing the past sport exercise score records, we can cluster the players into different categories, each of which share the same or similar sport preferences or performances. However, the sport exercise score records are often massive and often stored in different cloud platforms, which raise a big difficulty for time-efficient player clustering. Furthermore, the sport exercise score records are a kind of privacy for most players; therefore, it is often not rational or legal to release these sensitive data to the public for similar player clustering purpose. Considering the above two issues, we use SimHash, a kind of privacy-aware approximate neighbor search technique, for similar player clustering by analyzing the sport exercise score records distributed across different cloud platforms. Thus, we can realize privacy-aware similar player clustering through SimHash. At last, we provide a set of experiments to validate the advantages of our proposed privacy-aware similar player clustering algorithm. Reported experimental results show the effectiveness of our proposal in remedying the big data volume and privacy concerns in player clustering based on sport exercise score records.",10.1109/ACCESS.2021.3062735,2021,,A NOVEL SIMILAR PLAYER CLUSTERING METHOD WITH PRIVACY PRESERVATION FOR SPORT PERFORMANCE EVALUATION IN CLOUD,
820,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Incremental mining improves the quality of process mining by analyzing the differences between event logs and a reference model to obtain valuable information to update the reference model. Existing incremental mining methods focus on offline logs by setting thresholds for analysis, which limits process mining efforts by the domain knowledge, log completeness, and business completion time. Aiming at these problems, a real-time incremental mining algorithm based on the trusted behavior interval is proposed to analyze online event streams for updating the reference model. First, a clustering technique to analyze an existing reference model selects the core structure of the model and calculates the trusted behavior interval. Then, the behavioral and structural relationships between the online event streams and the reference model are analyzed to obtain a valid candidate set. Based on this set, an incremental update algorithm is proposed to optimize the model structure to achieve an online dynamic update of the reference model. The proposed algorithm is implemented in PM4PY and Scikit-learn frameworks; a reasonable number of clusters is determined using the elbow method and validated with artificial and real data. Experimental results show that the algorithm improves the efficiency of incremental mining and enhances the quality of the model with both complete and incomplete data.",10.1109/ACCESS.2021.3130758,2021,,ONLINE INCREMENTAL MINING BASED ON TRUSTED BEHAVIOR INTERVAL,
821,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The quality of service (QoS) and lifetime of wireless sensor networks (WSNs) are severely degraded by coverage holes generated by random deployment or battery exhaustion of sensors. This work firstly introduces a novel confident information coverage CIC) model to dramatically reduce the density of sensor nodes and accurately detect confident information coverage holes (CICHs). Then, the problem of repairing confident information coverage holes (RCICHs) for big data collection in a large-scale heterogeneous WSN (LS-HWSN) which widely spreads over a geographic area with thousands of stationary sensor nodes and mobile sensor nodes is formulated, called as RCICH problem, which is to effectively repair CICHs considering that the transmitted data velocity of sensor nodes is different. Furthermore, we prove it to be NP-completeness. The target of the problem is to find a subset of mobile sensor nodes from all mobile sensor nodes while minimizing the amount of lost throughputs LTs) of all dispatched mobile sensor nodes or maximizing the amount of repairing transmission times (RTTs) for all dispatched mobile sensor nodes, with different objectives. Finally, based on the CIC model and the data-centric perspective, two heuristic schemes including a centralized dispatch scheme and a distributed dispatch scheme are proposed to effectively solve the RCICH problem. Simulation results show that the proposed schemes effectively repair CICHs while increasing the QoS and lifetime of the LS-HWSN with the topology control of a fan-shaped clustering (FSC) protocol.",10.1109/ACCESS.2019.2949136,2019,,REPAIRING CONFIDENT INFORMATION COVERAGE HOLES FOR BIG DATA COLLECTION IN LARGE-SCALE HETEROGENEOUS WIRELESS SENSOR NETWORKS,
822,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the emergence of urban computing technology, the development of smart cities has gained much attention as a means to improve citizens' quality of life. As traffic accidents constitute a major problem that affects the quality of life, an effective solution to address this problem can significantly increase the level of intelligence of smart cities. This paper presents the development of a mathematical model for accurate analysis of big data to promote the effectiveness of policy decisions, thereby largely advancing the intelligent transportation systems (ITS) of smart cities. Temporal impulse was designed as a novel and measurable quantity to analyze traffic accidents by identifying the hidden patterns, such as varying causes and diverging impacts of traffic accidents. Based on the big data produced by the South Korean National Police Agency, we analyzed traffic accidents over three years by applying the temporal impulse. The research results suggested that the temporal impulse not only helped in identifying the varying influence of weather and driver conditions but also facilitated the establishment of sophisticated policies in the implementation of smart cities with the use of urban computing technology. As presented in the section VII, our simulation outputs indicated that our temporal model was predictive within the parameter space comprising driver's dynamic behaviors, day of the week, and environmental factors including weather, road surface condition, and road type.",10.1109/ACCESS.2020.2975529,2020,,TEMPORAL IMPULSE OF TRAFFIC ACCIDENTS IN SOUTH KOREA,
823,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Tailings ponds are places for storing industrial waste. The saturation line is the crucial factor in quantifying the safety of tailings ponds. Existing saturation line time-series prediction methods are mainly based on statistical models or shallow machine learning models. Although these models aim to capture the time dependence of the sequence data, the channel and temporal are even unavailable in principle. To mitigate this problem, in this paper, we present a two-stage forecasting method, which embeds the channel and temporal attention into a hybrid CNN-LSTM model to predict the saturation line. The channel and temporal attention are utilized to capture subtle high-dimensional time-series dependence. In the first stage, the discrete wavelet transform (DWT) is applied to capture the refined sequence information. In the second stage, the CNN-LSTM model is utilized to learn the basic spatial and temporal features in the time series. Furthermore, the channel and temporal attention model are embedded into the CNN-LSTM model to enhance the feature-extracting ability in the channel and temporal dimensions. Consequently, our proposed model is shown to outperform classic models on multiple real-world datasets in terms of RMSE, MAPE, R2 and MAE, respectively.",10.1109/ACCESS.2022.3222817,2022,,SATURATION LINE FORECASTING VIA A CHANNEL AND TEMPORAL ATTENTION-BASED NETWORK,
824,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Service quality is a significant concern for both providers and users of public transportation. It is crucial for transit agencies to clearly recognize the causes of unreliability before adapting any improvement strategy. However, evaluation of main causes of bus service unreliability has not been investigated well. Existing studies have three main limitations in context of recognizing causes of service unreliability. First, public transport networks and traffic condition are highly complex systems and most of the existing models are not capable to accurately determine the relationship between service irregularity and impact factors. Second, definition of “Big data” has been neglected and most of the studies only focused on one source of large scale data set to determine the causes of unreliability. Third, bus service unreliability can impact the users' perception toward the public transport, significantly. It has been recommended by number of studies that bus service reliability should be evaluated from both service providers' and users' perspective. However, the impact of service unreliability from passengers' perception is not well investigated, yet. Consequently, we proposed a novel simulation-based sensitivity analysis to evaluating main causes of bus service unreliability using a combination of three different sources of big data. Moreover, for the first time we developed a simulation model in R studio which is an open source and powerful coding environment. According to the results, the level of reliability in Route U32 showed the highest sensitivity to headway variations. Waiting time can be decreased by 61% if only bus operators can reduce the headway variation by 25% of the actual observed data. Big gap and bus bunching could be almost disappeared by decreasing headway variations. Moreover, the terminal departure policy could significantly improve the passenger waiting time. Waiting time can be decreased by 36% when almost all the buses depart the terminal on-time.",10.1109/ACCESS.2020.3036285,2020,,SIMULATION-BASED SENSITIVITY ANALYSIS FOR EVALUATING FACTORS AFFECTING BUS SERVICE RELIABILITY: A BIG AND SMART DATA IMPLEMENTATION,
825,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Federated learning (FL) is the up-to-date approach for privacy constraints Internet of Things (IoT) applications in next-generation mobile network (NGMN), 5th generation (5G), and 6th generation (6G), respectively. Due to 5G/6G is based on new radio (NR) technology, the multiple-input and multiple-output (MIMO) of radio services for heterogeneous IoT devices have been performed. The autonomous resource allocation and the intelligent quality of service class identity (IQCI) in mobile networks based on FL systems are obligated to meet the requirements of privacy constraints of IoT applications. In massive FL communications, the heterogeneous local devices propagate their local models and parameters over 5G/6G networks to the aggregation servers in edge cloud areas. Therefore, the assurance of network reliability is compulsory to facilitate end-to-end (E2E) reliability of FL communications and provide the satisfaction of model decisions. This paper proposed an intelligent lightweight scheme based on the reference software-defined networking (SDN) architecture to handle the massive FL communications between clients and aggregators to meet the mentioned perspectives. The handling method adjusts the model parameters and batches size of the individual client to reflect the apparent network conditions classified by the k-nearest neighbor (KNN) algorithm. The proposed system showed notable experimented metrics, including the E2E FL communication latency, throughput, system reliability, and model accuracy.",10.1109/ACCESS.2021.3101871,2021,,RELIABLE FEDERATED LEARNING SYSTEMS BASED ON INTELLIGENT RESOURCE SHARING SCHEME FOR BIG DATA INTERNET OF THINGS,
826,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Intelligent capabilities are of utmost importance in future wireless communication systems. For optimum resource utilization, wireless communication systems require knowledge of the prevalent situation in a frequency band through learning. To learn appropriately, it is imperative for practitioners to select the right parameters for building robust data-driven learning models as well as use the appropriate algorithms and performance evaluation methods. In this paper, we evaluate the performance of deep learning models against the performance of other machine learning methods for wireless communication systems. We explore the different wireless communication scenarios in which deep learning can be used given Radio Frequency (RF) data, and evaluate its performance in various scenarios. Furthermore, we express it as a distribution alignment problem in which deep learning models do not perform well when learning from RF data of a particular distribution and evaluating on RF data from a different distribution. We also discuss our results in the light of how signal quality affects deep learning model leveraging on the knowledge from computer vision domain. The effect of Signal-to-Noise Ratio (SNR) selection for training on the model performance as it relates to practical implementation of deep learning in communications systems is also discussed. From our analysis, we conclude that the design and use of RF spectrum learning must be tailored to each specific scenario being considered in practice.",10.1109/ACCESS.2020.3015939,2020,,ROBUST DEEP RADIO FREQUENCY SPECTRUM LEARNING FOR FUTURE WIRELESS COMMUNICATIONS SYSTEMS,
827,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Seamlessly integrating image compression technique and secret data hiding technique into a single procedure for security and efficient data transmission is a novel research issue in modern, decentralized digital communication environments. The first joint data hiding and compression (JDHC) scheme on block truncation coding (BTC) compression domain is presented in this paper. In the compressing and embedding procedure, for the complex blocks, modified block truncation coding (MBTC) is utilized to embed secret data and compress blocks simultaneously, while further controlling the visual distortion that is caused during data embedding. For the smooth blocks, according to the current embedding bit, either image inpainting or block search order coding (BSOC) is used to embed secret data and compress blocks simultaneously with maintaining acceptable compression performance. According to the image compression codes that are provided as output, image decompression and secret bits extraction procedures can be conducted simultaneously. Experimental results indicate that outstanding compression bit rate can be achieved by the proposed JDHC scheme with satisfactory visual quality and hiding capacity.",10.1109/ACCESS.2019.2935907,2019,,JOINT DATA HIDING AND COMPRESSION SCHEME BASED ON MODIFIED BTC AND IMAGE INPAINTING,
828,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The key to achieving high-quality and practical van der Waals heterostructure devices made from various two-dimensional (2D) materials lies in the efficient control over clean and flexible interfaces. Inspired by the “movable-type printing”, one of the four great inventions of ancient China, we demonstrate the “movable-type” transfer and stacking of 2D materials, which utilizes prefabricated polyvinyl alcohol (PVA) film to engineer the interfacial adhesion to 2D materials, and provides a flexible, efficient and batchable transfer scheme for 2D materials. The experiments also verify the “movable-type” transfer can preciously control the position and orientation of 2D materials, which meets the burgeoning requirements such as the preparation of twisted graphene and other heterostructures. Importantly, water-solubility of PVA film ensures an ideal interface of the materials without introducing contamination. We illustrate the superiority of this method with a WSe2 vertical spin valve device, whose performance verifies the applicability and advantages of such a method for spintronics. Our PVA-assisted “movable-type” transfer process may promote the development of high-performance 2D-material-based devices.",10.1109/ACCESS.2020.2984942,2020,,MOVABLE-TYPE TRANSFER AND STACKING OF VAN DER WAALS HETEROSTRUCTURES FOR SPINTRONICS,
829,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In process mining, converting event data to event logs is related to the quality of analysis results. In general, to convert event data into event logs, it is necessary to identify process entities, such as the case identifier, activity label, activity originator, and activity timestamp, from the data fields in the event data, as well as other optional attributes. Up to now, the event log conversion process has been attempted by relying on an expert’s intuition or an analyst’s experience. However, the conversion is a challenging procedure without sufficient prior knowledge of process mining. To automate the conversion process, an event log–converting algorithm based on the convolutional neural network (CNN) was developed with a new embedding method called Event Density Embedding (EDE). To verify the performance of the proposed embedding method and the automatic event log conversion framework, a comparative experiment was performed using nine pieces of real-world event data. The experiments show that our method is 5–20% higher conversion accuracy than the other methods. It is expected that business experts will be able to easily apply the method to process mining technology by utilizing system-derived event data.",10.1109/ACCESS.2022.3143609,2022,,AUTOMATIC CONVERSION OF EVENT DATA TO EVENT LOGS USING CNN AND EVENT DENSITY EMBEDDING,
830,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Security threats and economic loss caused by network attacks, intrusions, and vulnerabilities have motivated intensive studies on network security. Normally, data collected in a network system can reflect or can be used to detect security threats. We define these data as network security-related data. Studying and analyzing security-related data can help detect network attacks and intrusions, thus making it possible to further measure the security level of the whole network system. Obviously, the first step in detecting network attacks and intrusions is to collect security-related data. However, in the context of big data and 5G, there exist a number of challenges in collecting these security-related data. In this paper, we first briefly introduce network security-related data, including its definition and characteristics, and the applications of network data collection. We then provide the requirements and objectives for security-related data collection and present a taxonomy of data collection technologies. Moreover, we review existing collection nodes, collection tools, and collection mechanisms in terms of network data collection and analyze them based on the proposed requirements and objectives toward high quality security-related data collection. Finally, we discuss open research issues and conclude with suggestions for future research directions.",10.1109/ACCESS.2018.2817921,2018,,A SURVEY ON NETWORK SECURITY-RELATED DATA COLLECTION TECHNOLOGIES,
831,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cyber-physical-social (CPS) systems integrate Big Data Collectors (BDCs), Service Organizers (SOs) and users to build a unified data-centric computing framework. In CPS systems, BDCs leverage a vast variety of sensing devices to collect cyber-physical-social data, and report these data to SOs to orchestrate various services provided to users, thus offering a great potential for solving complex network tasks that are far beyond the capabilities of existing networks. However, due to the lack of an economic model to describe such complex data interactions, their applications are limited. So, a game-based economic model is proposed in this paper to make smart price decisions in CPS systems. Specifically, it has the following innovations: (a) The economic model gives a dynamic game income matrix which can accurately describe the revenue changes of BDCs in the game, so as to help BDCs select appropriate game parameters and strategies, and make BDCs competitive in the game. (b) The economic model can help SOs to make optimized data purchase price and service selling price based on data collection cost and competitor price analysis, so that SOs can have a better Quality of Service (QoS) and users attraction, and maximize the profit. Experimental results demonstrate that the proposed model can help BDCs and SOs find the most suitable game strategy and price adjustment principle, which has great significance in applications.",10.1109/ACCESS.2019.2934515,2019,,A GAME-BASED ECONOMIC MODEL FOR PRICE DECISION MAKING IN CYBER-PHYSICAL-SOCIAL SYSTEMS,
832,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Low-dose computed tomography (LDCT) technique is an important imaging modality, but LDCT images are always severely degraded by mottle noise and streak artifacts. The recently proposed nonlocally centralized sparse representation (NCSR) algorithm has good performance in natural image denoising, but it suffers from residual streak artifacts and can't preserve edges structure information well when implemented in LDCT image denoising. In addition, it has high computational complexity. To address this problem, in this paper, we propose an improved model, i.e. SNCSR model, based on the stationary PCA sub-dictionaries, nonlocally centralized sparse representation and relative total variation. In the SNCSR model, in order to learn more accurate sub-dictionaries, the LDCT image is preprocessed by the improved total variation (ITV) model in which the weighted coefficient of the regularization term is constructed depending on a clipped and normalized local activity. In addition, the maximum eigenvalue of the gradient covariance matrix of the image patch is used to distinguish edge structure information from background region so that the restored image can be represented more sparsely. Moreover, unlike the NCSR model that needs to learn sub-dictionaries in each outer loop, the proposed model learns stationary sub-dictionaries only once before iteration starts, which shorten the computation time significantly. At last, the relative total variation (RTV) algorithm is applied to further reduce the residual artifacts in the recovered image more thoroughly. The experiments are performed on the simulated pelvis phantom, the actual thoracic phantom and the clinical abdominal data. Compared with several other competitive denoising algorithms, both subjective visual effect and objective evaluation criteria show that the proposed SNCSR model has lower computational complexity and can improve LDCT images quality more effectively.",10.1109/ACCESS.2019.2932754,2019,,LOW-DOSE CT IMAGE DENOISING MODEL BASED ON SPARSE REPRESENTATION BY STATIONARILY CLASSIFIED SUB-DICTIONARIES,
833,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Content-Based recommender systems (CB) filter relevant items to users in overloaded search spaces using information about their preferences. However, classical CB scheme is mainly based on matching between items descriptions and user profile, without considering that context may influence user preferences. Therefore, it cannot achieve high accuracy on user preference prediction. This paper aims to handle context-awareness (CA) to improve quality of recommendation taking contextual information as the trend in current trend interest, in which a stream of status updates can be analyzed to model the context. It proposes a novel CA-CB approach that recommends question/answer items by considering context awareness based on topic detection within current trend interest. A case study and related experiments were developed in the big data framework Spark to show that the context integration benefits recommendation performance.",10.1109/ACCESS.2019.2957881,2019,,A BIG DATA SEMANTIC DRIVEN CONTEXT AWARE RECOMMENDATION METHOD FOR QUESTION-ANSWER ITEMS,
834,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Hadoop framework has been evolved to manage big data in cloud. Hadoop distributed file system and MapReduce, the vital components of this framework, provide scalable and fault-tolerant big data storage and processing services at a lower cost. However, Hadoop does not provide any robust authentication mechanism for principals’ authentication. In fact, the existing state-of-the-art authentication protocols are vulnerable to various security threats, such as man-in-the-middle, replay, password guessing, stolen-verifier, privileged-insider, identity compromization, impersonation, denial-of-service, online/off-line dictionary, chosen plaintext, workstation compromization, and server-side compromisation attacks. Beside these threats, the state-of-the-art mechanisms lack to address the server-side data integrity and confidentiality issues. In addition to this, most of the existing authentication protocols follow a single-server-based user authentication strategy, which, in fact, originates single point of failure and single point of vulnerability issues. To address these limitations, in this paper, we propose a fault-tolerant authentication protocol suitable for the Hadoop framework, which is called the efficient authentication protocol for Hadoop (HEAP). HEAP alleviates the major issues of the existing state-of-the-art authentication mechanisms, namely operating-system-based authentication, password-based approach, and delegated token-based schemes, respectively, which are presently deployed in Hadoop. HEAP follows two-server-based authentication mechanism. HEAP authenticates the principal based on digital signature generation and verification strategy utilizing both advanced encryption standard and elliptic curve cryptography. The security analysis using both the formal security using the broadly accepted real-or-random (ROR) model and the informal (non-mathematical) security shows that HEAP protects several well-known attacks. In addition, the formal security verification using the widely used automated validation of Internet security protocols and applications ensures that HEAP is resilient against replay and man-in-the-middle attacks. Finally, the performance study contemplates that the overheads incurred in HEAP is reasonable and is also comparable to that of other existing state-of-the-art authentication protocols. High security along with comparable overheads makes HEAP to be robust and practical for a secure access to the big data storage and processing services.",10.1109/ACCESS.2018.2883105,2018,,HEAP: AN EFFICIENT AND FAULT-TOLERANT AUTHENTICATION AND KEY EXCHANGE PROTOCOL FOR HADOOP-ASSISTED BIG DATA PLATFORM,
835,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, optical field imaging technology has received extensive attention in the academic circle for its novel imaging characteristics of shooting first and focusing later, variable depth of field, variable viewpoint, and so on. However, the existing optical field acquisition equipment can only acquire a limited number of discrete angle signals, so image aliasing caused by under sampling of optical field angle signals reduces the quality of optical field images. Based on the camera array system as a platform, this paper studies the optical field imaging and depth estimation method based on the Big Data in Internet of Things obtained from camera array around the angle sampling characteristics of the optical field data set, and has achieved some innovative research results in the following aspects. On the basis of analyzing the characteristics of different depth clues in the optical field data set, a depth estimation method combining parallax method and focusing method is proposed. First, this paper analyzes the disparity clues and focus clues contained in the multi-view data set and the light field refocusing image set of the camera array, respectively, and points out the differences and relationships between the two depth clues extraction methods in the light field sampling frequency domain space, that is, the disparity method focuses on the energy concentration characteristics near the frequency domain spatial angle axis, while the focus method focuses on the high frequency proportion of energy distribution on the angle axis. Then, the weighted linear fusion method based on image gradient is used to fuse the two calculation results, which improves the accuracy and robustness of depth estimation. Finally, the results of depth estimation experiments on different sets of scenes show that compared with the method based on a single depth cue, the method in this paper has higher accuracy in depth calculation in discontinuous areas of scene depth and similar texture areas.",10.1109/ACCESS.2018.2870394,2018,,RESEARCH ON DEPTH ESTIMATION METHOD OF LIGHT FIELD IMAGING BASED ON BIG DATA IN INTERNET OF THINGS FROM CAMERA ARRAY,
836,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Crowd counting is a challenging task due to the influence of various factors, such as scene transformation, complex crowd distribution, uneven illumination, and occlusion. To overcome such problems, scale-adaptive convolutional neural network (SaCNN) used a convolutional neural network to obtain high-quality crowd density map estimation and integrate the density map to get the estimated headcount. To obtain better performance on crowd counting, an improved crowd counting method based on SaCNN was proposed in this paper. The spread parameter, i.e., the standard variance, of geometry-adaptive Gaussian kernel used in SaCNN was optimized to generate a higher quality ground truth density map for training. The absolute count loss with weight 4e-5 was used to jointly optimize with the density map loss to improve the network generalization ability for crowd scenes with few pedestrians. Also, a random cropping method was applied to improve the diversity of training samples to enhance network generalization ability. The experimental results upon ShanghaiTech public dataset showed that the proposed method can obtain more accurate and more robust results on crowd counting than those of SaCNN.",10.1109/ACCESS.2019.2899939,2019,,IMPROVED CROWD COUNTING METHOD BASED ON SCALE-ADAPTIVE CONVOLUTIONAL NEURAL NETWORK,
837,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This article unveils the importance of statistical quality of service (QoS) for resource allocation in a two-hop network. Particularly, an access point (AP) serves multiple IoT devices for information transfer with the assistance of the energy harvesting (EH) relaying. To explore the maximum constant data arrival metric, we aim to maximize the effective capacity (EC) under specified QoS requirements. Also, the statistical QoS inspired resource allocation policies are investigated for half/full duplex (HD/FD) modes, respectively, to jointly optimize power allocation and power splitting (PS) ratio. To solve the formulated problem, we first derive the closed-form solution of the optimal power allocation at the AP and the PS ratio. To gain more insights, we further derive the boundary conditions of optimal power allocation and PS ratio. Finally, numerical results are demonstrated to validate the theoretical derivations, which highlights the proposed scheme in terms of EC performance in comparison to the benchmark scheme.",10.1109/ACCESS.2020.3021832,2020,,STATISTICAL QOS AWARE FOR WIRELESS POWERED COOPERATIVE COMMUNICATIONS IN INTERNET OF THINGS,
838,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The continued ability to detect malicious network intrusions has become an exercise in scalability, in which data mining techniques are playing an increasingly important role. We survey and categorize the fields of data mining and intrusion detection systems, providing a systematic treatment of methodologies and techniques. We apply a criterion-based approach to select 95 relevant articles from 2007 to 2017. We identified 19 separate data mining techniques used for intrusion detection, and our analysis encompasses rich information for future research based on the strengths and weaknesses of these techniques. Furthermore, we observed a research gap in establishing the effectiveness of classifiers to identify intrusions in modern network traffic when trained with aging data sets. Our review points to the need for more empirical experiments addressing real-time solutions for big data against contemporary attacks.",10.1109/ACCESS.2018.2872784,2018,,DATA MINING TECHNIQUES IN INTRUSION DETECTION SYSTEMS: A SYSTEMATIC LITERATURE REVIEW,
839,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Privacy protection, high labeling cost, and varying characteristics of seizures among patients and at different times are the main obstacles to building seizure detection models. Considering these issues, we propose a novel Mentor-Student architecture for Patient-Specific seizure detection (MS4PS). It contains a new method of knowledge transferring called mentor-select-for-student, which exploits the knowledge of a mentor model by using this model to select data for training a student model, making it possible to avoid transferring patient data and the negative influence of transferring parameters/structures of pre-trained models. It also contains a new method of active learning, which uses both an experienced mentor model and a quick-learning student model to select high-quality samples for doctors to label. Each of the two models is coupled with a particular sample selection strategy that combines uncertainty/certainty and the distance between the unlabeled samples and labeled seizure samples. The proposed method can quickly train a suitable detector for a patient at his/her first epilepsy diagnosis with the help of: (1) an experienced mentor model that chooses the most category-certain electroencephalography (EEG) data segments; (2) a student model (detector itself) that chooses the most category-uncertain EEG data segments; (3) doctors who label these data segments selected by both the mentor model and student model. By replacing or improving the mentor model and refining the historical models of patients when they come next time, the MS4PS system can be sustainably promoted. The proposed method is tested on the CHB-MIT and NEO datasets, and the results demonstrate its effectiveness and efficiency.",10.1109/ACCESS.2022.3158348,2022,,MS4PS: A MENTOR-STUDENT ARCHITECTURE FOR PATIENT-SPECIFIC SEIZURE DETECTION WITH COMBINATION OF TRANSFER LEARNING AND ACTIVE LEARNING,
840,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"To monitor product quality in the production process in real time, this thesis proposes a quality monitoring model based on PaddlePaddle You Only Look Once (PP-YOLO). First, in the preprocessing stage, the data enhancement method and the K-means++ method are used to improve the robustness of the algorithm, and the generated anchor box can screen more refined features earlier. Second, ResNet50-vd with the deformable convolution idea is selected as the backbone of the detection model, the feature pyramid network structure and the composition of the loss function are improved, and the feature learning ability of the model is enhanced to enable it to detect multiple scales of defects. Finally, pruning is performed on the basis of the trained model to reduce the number of model parameters so that it can be deployed in industrial scenarios with limited hardware conditions. Experimental results show that the proposed quality monitoring model can meet the requirements for detection speed and accuracy in actual production, providing a new concept for the deployment of deep learning models in the industrial field.",10.1109/ACCESS.2021.3085338,2021,,RESEARCH ON A PRODUCT QUALITY MONITORING METHOD BASED ON MULTI SCALE PP-YOLO,
841,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recently, many IoT applications, such as smart transportation, healthcare, and virtual and augmented reality experiences, have emerged with fifth-generation (5G) technology to enhance the Quality of Service (QoS) and user experience. The revolution of 5G-enabled IoT supports distinct attributes, including lower latency, higher system capacity, high data rate, and energy saving. However, such revolution also delivers considerable increment in data generation that further leads to a major requirement of intelligent and effective data analytic operation across the network. Furthermore, data growth gives rise to data security and privacy concerns, such as breach and loss of sensitive data. The conventional data analytic and security methods do not meet the requirement of 5G-enabled IoT including its unique characteristic of low latency and high throughput. In this paper, we propose a Deep Learning (DL) and blockchain-empowered security framework for intelligent 5G-enabled IoT that leverages DL competency for intelligent data analysis operation and blockchain for data security. The framework's hierarchical architecture wherein DL and blockchain operations emerge across the four layers of cloud, fog, edge, and user is presented. The framework is simulated and analyzed, employing various standard measures of latency, accuracy, and security to demonstrate its validity in practical applications.",10.1109/ACCESS.2021.3077069,2021,,DEEP LEARNING AND BLOCKCHAIN-EMPOWERED SECURITY FRAMEWORK FOR INTELLIGENT 5G-ENABLED IOT,
842,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"2D image quality assessment (IQA) and stereoscopic 3D IQA are considered as two different tasks in the literature. In this paper, we present an index for both no-reference 2D and 3D IQA. We propose to transform the IQA task into a task of quality comparison between images. By generating image pairs, the amount of training data reaches the square of the original amount of data, effectively solving the lacking of training samples. We also propose a learning to rank model using Siamese convolutional neural networks (LRSN) for quality comparison. The presented LRSN has two branches that have the same structure, share weights with each other, and take two image patches as inputs. The goal of LRSN is learning to rank the quality scores between the two input image patches. The relative quality score of a test image is obtained by first comparing its image patches with many image patches of other images and counts the number of times that its image patches are ranked superior to other patches. The experimental results on three 2D (LIVE, CSIQ, and TID2013) and three 3D (LIVE 3D Phase-I, LIVE 3D Phase-II, and NBU) IQA databases demonstrate that the proposed LRSN model works well for both 2D and 3D IQA and outperforms the state-of-the-art no-reference 2D and 3D IQA metrics.",10.1109/ACCESS.2019.2930707,2019,,SIAMESE-NETWORK-BASED LEARNING TO RANK FOR NO-REFERENCE 2D AND 3D IMAGE QUALITY ASSESSMENT,
843,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Existing image-to-image translation methods usually adopt an encoder-decoder structure to generate images. The encoder extracts the features of input images using a sequence of convolution layers until a bottleneck, and then, the intermediate features are decoded to the target image. However, the existence of bottleneck layer in such structure may lead to blurry and bad quality of the translated images, since different domain translations may be related to the global or local region in the input image or even in an abstract level. To prevent these problems, we propose the channel attention networks for image translation in this paper. It is a novel model that supports the multi-domain image-to-image translation using one single model. Conditioning on the target domain label, an auto-encoder-like network with multiple attention connections is trained to translate the input image into the target domain. The attention connections better shuttle the low-level information in the encoder to the decoder, which helps to preserve the structure. A multi-level attention mechanism is also designed in the proposed model to further improve the performance of our model. More specially, the feature maps in the encoder are first squeezed by average pooling and used to output a channel-wise attention mask. The attention mask softly determines which channels of the feature maps are translated and which channels are kept. By enforcing the model to learn a cyclic domain transformation during training, our model does not require paired training data, which greatly improves the versatility to different kinds of data. We experimentally demonstrated the effectiveness of our proposed model on the facial and clothing image translation tasks. The extensive ablations are also conducted to further validate the contribution of the proposed attention module used in our model.",10.1109/ACCESS.2019.2926882,2019,,CHANNEL ATTENTION NETWORKS FOR IMAGE TRANSLATION,
844,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"When misalignment, deformation, and tracking failures occur, the appearance of the target tends to change significantly. How to effectively learn the change of target's appearance is an essential problem in visual tracking. Recently, most recent trackers based on convolutional neural networks update the tracker online to learn the change of target's appearance. These methods collect tracking results as online training samples. Thus, the reliability of training samples is very important for online updates. We propose a self-paced selection model, which integrates the self-paced learning model into the tracking framework for the goal of distinguishing the reliable samples from the tracking results. It estimates the reliability of the tracking results by the self-paced function. We design a method that adaptively calculates the value of the pace, which determines the number of samples selected. And this method is based on the number of tracking results. At the same time, the quality of the target's features plays a key role in the performance of the tracker. We employ dense connectivity learning to enhance the flow of information throughout the network, which makes the target's features represent better. The extensive experiments demonstrate that our self-paced dense connectivity learning tracker (SPDCT) performs favorably against the state-of-the-art trackers over four benchmark datasets.",10.1109/ACCESS.2019.2904315,2019,,SELF-PACED DENSE CONNECTIVITY LEARNING FOR VISUAL TRACKING,
845,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet of Things (IoT) data analytics is underpinning numerous applications, however, the task is still challenging predominantly due to heterogeneous IoT data streams, unreliable networks, and ever increasing size of the data. In this context, we propose a two-layer architecture for analyzing IoT data. The first layer provides a generic interface using a service oriented gateway to ingest data from multiple interfaces and IoT systems, store it in a scalable manner and analyze it in real-time to extract high-level events; whereas second layer is responsible for probabilistic fusion of these high-level events. In the second layer, we extend state-of-the-art event processing using Bayesian networks in order to take uncertainty into account while detecting complex events. We implement our proposed solution using open source components optimized for large-scale applications. We demonstrate our solution on real-world use-case in the domain of intelligent transportation system where we analyzed traffic, weather, and social media data streams from Madrid city in order to predict probability of congestion in real-time. The performance of the system is evaluated qualitatively using a web-interface where traffic administrators can provide the feedback about the quality of predictions and quantitatively using F-measure with an accuracy of over 80%.",10.1109/ACCESS.2018.2804623,2018,,REAL-TIME PROBABILISTIC DATA FUSION FOR LARGE-SCALE IOT APPLICATIONS,
846,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the field of facial expression recognition, deep learning is extensively used. However, insufficient and unbalanced facial training data in available public databases is a major challenge for improving the expression recognition rate. Generative Adversarial Networks (GANs) can produce more one-to-one faces with different expressions, which can be used to enhance databases. StarGAN can perform one-to-many translations for multiple expressions. Compared with original GANs, StarGAN can increase the efficiency of sample generation. Nevertheless, there are some defects in essential areas of the generated face, such as the mouth and the fuzzy side face image generation. To address these limitations, we improved StarGAN to alleviate the defects of images generation by modifying the reconstruction loss and adding the Contextual loss. Meanwhile, we added the Attention U-Net to StarGAN's generator, replacing StarGAN's original generator. Therefore, we proposed the Contextual loss and Attention U-Net (LAUN) improved StarGAN. The U-shape structure and skip connection in Attention U-Net can effectively integrate the details and semantic features of images. The network's attention structure can pay attention to the essential areas of the human face. The experimental results demonstrate that the improved model can alleviate some flaws in the face generated by the original StarGAN. Therefore, it can generate person images with better quality with different poses and expressions. The experiments were conducted on the Karolinska Directed Emotional Faces database, and the accuracy of facial expression recognition is 95.97%, 2.19% higher than that by using StarGAN. Meanwhile, the experiments were carried out on the MMI Facial Expression Database, and the accuracy of expression is 98.30%, 1.21% higher than that by using StarGAN. Moreover, experiment results have better performance based on the LAUN improved StarGAN enhanced databases than those without enhancement.",10.1109/ACCESS.2020.3021531,2020,,LAUN IMPROVED STARGAN FOR FACIAL EMOTION RECOGNITION,
847,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Video streaming is a dominant application over today’s Internet. The current mainstream video streaming solution is to utilize the services of a Content Delivery Network (CDN) provider. By replicating video content closer to the network edge, caching provides an effective mechanism for alleviating the demand for massive bandwidth for the Internet backbone. It reduces the network traffic and capital expense for streaming the video content, and in the meantime, enhance Internet’s Quality of Service (QoS). In this paper, we propose a neural adaptive caching approach, named NA-Caching, for helping cache learn to make caching decisions from its own experiences rather than a specific mathematical model, in a way similar to how a human being learns a new skill (e.g. cycling, swimming). NA-Caching leverages the benefits of the Recurrent Neural Network (RNN) as well as the Deep Reinforcement Learning (DRL) to maximize the cache efficiency by jointly learning request features, caching space dynamics and making decisions. Specifically, we utilize Gated Recurrent Unit (GRU) to characterize the evolving features of the dynamic requests and caching space. Moreover, the above GRU-based representation network is integrated into a Deep Q-Network (DQN) framework for making adaptive caching decisions online. To evaluate the performance of the proposed approach, we conduct extensive experiments on anonymized real-world traces from a video provider. The results demonstrate that our algorithm significantly outperform several candidate methods.",10.1109/ACCESS.2019.2947460,2019,,NA-CACHING: AN ADAPTIVE CONTENT MANAGEMENT APPROACH BASED ON DEEP REINFORCEMENT LEARNING,
848,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the dramatic growth of public cloud offerings and heterogeneous data information, how to discover potentially valuable information from big history behavior data and design intelligent recommendation techniques has become more and more important. Due to the dynamics of cloud environment, both user behaviors and QoS (Quality of Service) performance of cloud services are sensitive to contextual information, such as time and location. However, the consideration of time and location information brings the increase in the order of rating matrix and the data sparsity problem. In view of these challenges, we propose a spatial-temporal aware intelligent service recommendation method based on distributed tensor factorization to address the above problems. First, the time and location information are introduced into the recommendation models by distinguishing time-sensitive QoS metrics and region-sensitive QoS metrics from stable QoS metrics. To deal with the sparse rating data, time slots and regions are clustered respectively. Then, a high-order tensor factorization technique is applied to mine the latent factors among users, services, time information, and location information. Moreover, to improve the scalability of our recommendation models in big data environment, a fast distributed asynchronous SGD (Stochastic Gradient Descent) mechanism is employed to get a good balance between the convergence speed and prediction accuracy. Finally, experiments based on both real-world data set and big synthetic data set are conducted to validate the effectiveness and scalability of our proposal. The experimental results show that our proposal achieves a good balance between the recommendation accuracy and scalability.",10.1109/ACCESS.2018.2872351,2018,,SPATIAL-TEMPORAL AWARE INTELLIGENT SERVICE RECOMMENDATION METHOD BASED ON DISTRIBUTED TENSOR FACTORIZATION FOR BIG DATA APPLICATIONS,
849,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Truckload spot rate (TSR), defined as a price offered on the spot to transport a certain cargo by using an entire truck on a target transportation line, usually price per kilometer-ton, is a key factor in shaping the freight market. In particular, the prediction of short-term TSR is of great importance to the daily operations of the trucking industry. However, existing predictive practices have been limited largely by the availability of multilateral information, such as detailed intraday TSR information. Fortunately, the emerging online freight exchange (OFEX) platforms provide unique opportunities to access and fuse more data for probing the trucking industry. As such, this paper aims to leverage the high-resolution trucking data from an OFEX platform to forecast short-term TSR. Specifically, a lagged coefficient weighted matrix-based multiple linear regression modeling (Lag-WMR) is proposed, and exogenous variables are selected by the light gradient boosting (LGB) method. This model simultaneously incorporates the dependency between historical and current TSR (temporal correlation) and correlations between the rates on alternative routes (between-route correlation). In addition, the effects of incorporating temporal and between-route correlations, time-lagged correlation and exogenous variable selection in modeling are emphasized and assessed through a case study on short-term TSR in Southwest China. The comparative results show that the proposed Lag-WMR model outperforms autoregressive integrated moving average (ARIMA) model and LGB in terms of model fitting and the quality and stability of predictions. Further research could focus on rates' standardization, to define a practical freight index for the trucking industry. Although our results are specific to the Chinese trucking market, the method of analysis serves as a general model for similar international studies.",10.1109/ACCESS.2020.2990751,2020,,SHORT-TERM TRUCKLOAD SPOT RATES’ PREDICTION IN CONSIDERATION OF TEMPORAL AND BETWEEN-ROUTE CORRELATIONS,
850,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet-of-Things (IoT) will connect billions of smart devices and generate inundant data through prominent solutions, such as machine type communication. The Third Generation Partnership Project has launched the corresponding standards for multiple heterogeneous wireless smart devices in the long term evolution (LTE)/LTE-advanced. In the forthcoming years, the valuable information hidden in the deluge of data will be extracted and utilized in every field to improve quality and efficiency. However, the bottleneck of realizing this magnificent vista of future intelligent lives lies in how to satisfy the practical demands to transmit huge data volume through efficient wireless communication in diverse scenarios. Herein, multi-scenario wireless communication triggers critical problems in wireless channel modeling and soundings for 5G IoT, which by far, are understudied. In this paper, we introduce a general wireless channel model and its multiple up-to-date corresponding channel sounding methods for future 5G IoT green wireless communication. Through adopting the perspective of wireless big data excavation, the smart channel sounder transforms the traditional passive wireless communication scheme into an active expectation-guaranteed wireless communication scheme, which helps achieve efficient and green communication. To demonstrate the validity and efficiency of this smart sounder scheme, we make a compatible prototype testified in multiple scenarios. The multiple real-scenario experiments demonstrate that the smart sounder can function effectively, especially in those scenarios where traditional channel state information is not available or imperfect.",10.1109/ACCESS.2016.2628820,2016,,SMART CHANNEL SOUNDER FOR 5G IOT: FROM WIRELESS BIG DATA TO ACTIVE COMMUNICATION,
851,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, we propose a multi-layer mobile application (app) scheduling method to extend the capability of low-end Android devices. With a quantitative analysis, we find that the increase of installed apps will negatively affect quality of experience (QoE) of the user, e.g., the action response time of a mobile device, by producing more periodically or irregularly background tasks. On the other hand, the user tends to install more apps than needed in case they could play a role someday, as indicated by the consumer app usage statistics. When the storage is running out, being forced to choose an app to uninstall due to space budget is a painful experience for the user. This contradiction is intensified for low-end devices due to limited resources. We try to reduce this dilemma by a multi-layer app scheduling (MAS) schema, along with a cloud service. For the first layer, we utilize the “freeze”feature of Android to prevent non-essential background activities. For the second layer, it is a network scheduler, which automatically schedules the available apps, together with their data, between local and cloud according to user's personal policy generated by big data analysis. By dynamically scheduling the apps among three states, QoE of a low-end Android device is improved. At the same time, with the help of an app state recovery mechanism, the user can directly access a large number of apps provided by the cloud with consistent app view. Experimental results on a low-end smartphone, i.e., Samsung Galaxy ON5, and a smart watch based on Newton2_Plus wearable development board show the benefits of the proposed MAS schema.",10.1109/ACCESS.2018.2865177,2018,,EXTEND CAPABILITY OF LOW-END ANDROID DEVICES BY SCHEDULING APPS BETWEEN LOCAL AND CLOUD,
852,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Under the explosive growth of information available on the Web, recommender systems have been used as an effective technology to filter useless information and attempt to recommend the most useful items. The proliferation of smart phones, smart wearable devices and other Internet of Thing (IoT) devices has gradually driven many novel emerging services which are latency-sensitive and computation-intensive with a higher quality-of-service. Under such circumstances, the data sources contain four key characteristics (i.e., sparsity, heterogeneity, mobility, volatility). The conventional recommender systems based on cloud computing are incapable of digging the information of user demands. Mobile edge computing is a novel computing paradigm via pushing computation/storage resource from the remote cloud servers to the network edge servers to provide more intelligent and personalized service. This paper comprehensively reviews the state of the art literature on the convergence of recommender systems and edge computing, and identify the future directions along this dimension. This paper can provide an array of new perspectives on the convergence for researchers, practitioners, and tap into the richness of this interdisciplinary research area.",10.1109/ACCESS.2020.2978896,2020,,CONVERGENCE OF RECOMMENDER SYSTEMS AND EDGE COMPUTING: A COMPREHENSIVE SURVEY,
853,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Web service recommendation based on the quality of service (QoS) is important for users to find the exact Web service among many functionally similar Web services. Although service recommendations have been recently studied, the performance of the existing ones is unsatisfactory because: 1) the current QoS predicting algorithms still experience data sparsity and cannot predict the QoS values accurately and 2) the previous approaches fail to consider the QoS variance according to the users and services' locations carefully. A Web service recommendation method based on the QoS prediction and hierarchical tensor decomposition is proposed in this paper. The method is called QoSHTD that is based on location clustering and hierarchical tensor decomposition. First, the users and services of the QoSHTD cluster into several local groups based on their location and models local and global triadic tensors for the user-service-time relationship. The hierarchical tensor decomposition is then performed on the local and global triadic tensors. Finally, the predicted QoS value through local and global tensor decomposition is combined as the missing QoS values. The comprehensive experiment shows that the proposed method achieves a high prediction accuracy and recommending quality of Web service, and can partially address data sparsity.",10.1109/ACCESS.2019.2909548,2019,,PERSONALIZED WEB SERVICE RECOMMENDATION BASED ON QOS PREDICTION AND HIERARCHICAL TENSOR DECOMPOSITION,
854,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Air pollution has become an extremely serious problem, with particulate matter having a significantly greater impact on human health than other contaminants. The small diameter of fine particulate matter (PM2.5) allows it to penetrate deep into the alveoli as far as the bronchioles, interfering with a gas exchange within the lungs. Long-term exposure to particulate matter has been shown to cause the cardiovascular disease, respiratory disease, and increase the risk of lung cancers. Therefore, forecasting air quality has also become important to help guide individual actions. This paper aims to forecast air quality for up to 48 h using a combination of multiple neural networks, including an artificial neural network, a convolutional neural network, and a long-short-term memory to extract spatial-temporal relations. The proposed predictive model considers various meteorology data from the previous few hours as well as information related to the elevation space to extract terrain impact on air quality. The model includes trends from multiple locations, extracted from correlations between adjacent locations, and among similar locations in the temporal domain. Experiments employing Taiwan and Beijing data sets show that the proposed model achieves excellent performance and outperforms current state-of-the-art methods.",10.1109/ACCESS.2018.2849820,2018,,ADAPTIVE DEEP LEARNING-BASED AIR QUALITY PREDICTION MODEL USING THE MOST RELEVANT SPATIAL-TEMPORAL RELATIONS,
855,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Seeking a collaborator is one of the important academic activities of scholars because the right collaborators will help improve the quality of scholars’ research and accelerate their research process. Therefore, it is becoming more and more important to recommend scientific collaborators based on big scholarly data. However, previous works mainly consider the research topic as the key academic factor, whereas many scholars’ demographic characteristics such as career age, gender, etc are overlooked. It has been studied that scientific collaboration patterns may vary with scholars’ career ages. It is not surprising that scholars at different career ages may have different collaboration strategies. To this end, we aim to design a scientific collaboration recommendation model that is sensitive to scholars’ career age. For this purpose, we design a career age-aware scientific collaboration model. The model is mainly consisted of three parts, including authorship extraction from the digital libraries, topic extraction based on publication titles/abstract, and career age-aware random walk for measuring scholar similarity. Experimental results on two real-world datasets demonstrate that our proposed model can achieve the best performance by comparison with six baseline methods in terms of precision and recall.",10.1109/ACCESS.2019.2941022,2019,,CAREER AGE-AWARE SCIENTIFIC COLLABORATOR RECOMMENDATION IN SCHOLARLY BIG DATA,
856,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Image quality that is consistent with human opinion is assessed by a perceptual image quality assessment (IQA) that defines/utilizes a computational model. A good model should take effectiveness and efficiency into consideration, but most of the previously proposed IQA models do not simultaneously consider these factors. Therefore, this paper attempts to develop an effective and efficient IQA metric. Contrast is an inherent visual attribute that indicates image quality, and visual saliency (VS) is a quality that attracts the attention of human beings. The proposed model utilized these two features to characterize the image quality. After obtaining the local contrast quality map and the global VS quality map, we added the weighted standard deviation of the previous two quality maps together to yield the final quality score. The experimental results for three benchmark databases (LIVE, TID2008, and CSIQ) demonstrated that our model performs the best in terms of a correlation with the human judgment of visual quality. Furthermore, compared with competing IQA models, this proposed model is more efficient. The MATLAB source code of the proposed method is public available online at http://www.scholat.com/vpost.html?pid=98172..",10.1109/ACCESS.2018.2878739,2018,,CONTRAST AND VISUAL SALIENCY SIMILARITY-INDUCED INDEX FOR ASSESSING IMAGE QUALITY,
857,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of network-enabled sensors and artificial intelligence algorithms, various human-centered smart systems are proposed to provide services with higher quality, such as smart healthcare, affective interaction, and autonomous driving. Considering cognitive computing is an indispensable technology to develop these smart systems, this paper proposes human-centered computing assisted by cognitive computing and cloud computing. First, we provide a comprehensive investigation of cognitive computing, including its evolution from knowledge discovery, cognitive science, and big data. Then, the system architecture of cognitive computing is proposed, which consists of three critical technologies, i.e., networking (e.g., Internet of Things), analytics (e.g., reinforcement learning and deep learning), and cloud computing. Finally, it describes the representative applications of human-centered cognitive computing, including robot technology, emotional communication system, and medical cognitive system.",10.1109/ACCESS.2018.2791469,2018,,"COGNITIVE COMPUTING: ARCHITECTURE, TECHNOLOGIES AND INTELLIGENT APPLICATIONS",
858,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Mobile crowdsensing has emerged as an efficient paradigm for performing large-scale sensing tasks. Improving both the quantity and quality of users is still the pivotal problem for mobile crowdsensing system. This paper gives a comprehensive solution to improve the quantity and quality of users simultaneously through the social mobile crowdsensing architecture. To incentive the users based on the novel architecture, we first propose a universal initial diffuser selection algorithm to accommodate two widely studied diffusion models and, then a lightweight, multi-metric comprehensive, and parameter-free user quality evaluation method is presented. Finally, we propose a reverse auction to optimize the new criterion, which takes both social cost and user quality into consideration. Through both rigorous theoretical analysis and extensive simulations, we demonstrate that the proposed incentive mechanisms achieve computational efficiency, individual rationality, truthfulness, and guaranteed approximation. Meanwhile, the proposed incentive mechanisms show prominent advantage in total unit quality cost and running time.",10.1109/ACCESS.2018.2860900,2018,,IMPROVING BOTH QUANTITY AND QUALITY: INCENTIVE MECHANISM FOR SOCIAL MOBILE CROWDSENSING ARCHITECTURE,
859,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Stream processor has been widely used in multimedia processing because of the high performance gained by parallelism. In order to achieve higher parallelism, the stream processor employs large width structure of VLIW (very long instruction word, VLIW) and multiple parallelizable instructions are organized into one VLIW. Because the width of VLIW is fixed, there are a large number of empty operations (non-operation, NOP) filled in VLIW, which results in serious code size expansion problem. Aiming at this issue, the horizontal code compression and vertical code compression methods are applied on the VLIW of stream processor respectively. First the VLIW is divided into several subfields according to the logic characteristics of VLIW instruction, then the horizontal code compression scheme which based on Huffman coding is applied on each subfield and this method can achieve approximately 78% code size reduction on average. However, the extra-long time required to decode the compressed VLIW before instruction execution may cause system performance penalty. In order to reduce the decompression time consumption, the vertical compression scheme is proposed. The vertical compression can reduce the code size nearly 70% by deleting the NOPs of VLIW in vertical direction. Furthermore the VLIW after vertical compression can be executed directly without decompression operation by using banked instruction memory. Specifically, the vertical compression can compress stream processor VLIW code size significantly and without any negative influence on performance.",10.1109/ACCESS.2020.2985501,2020,,AN EFFICIENT AND FAST VLIW COMPRESSION SCHEME FOR STREAM PROCESSOR,
860,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As an integral part of source code files, code comments help improve program readability and comprehension. However, developers sometimes do not comment their program code adequately due to the incurred extra efforts, lack of relevant knowledge, unawareness of the importance of code commenting or some other factors. As a result, code comments can be inadequate, absent or even mismatched with source code, which affects the understanding, reusing and the maintenance of software. To solve these problems of code comments, researchers have been concerned with generating code comments automatically. In this work, we aim at conducting a survey of automatic code commenting researches. First, we generally analyze the challenges and research framework of automatic generation of program comments. Second, we present the classification of representative algorithms, the design principles, strengths and weaknesses of each category of algorithms. Meanwhile, we also provide an overview of the quality assessment of the generated comments. Finally, we summarize some future directions for advancing the techniques of automatic generation of code comments and the quality assessment of comments.",10.1109/ACCESS.2019.2931579,2019,,A SURVEY OF AUTOMATIC GENERATION OF SOURCE CODE COMMENTS: ALGORITHMS AND TECHNIQUES,
861,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of modern teaching technology, the construction of smart campus has become the focus of modern college education reform. The application of technologies, such as the Internet of Things and big data, plays an important role in improving the teaching environment of colleges and universities, improving the utilization of teaching resources, and the flexibility of education. As an important part of campus activities, teaching performance evaluation scientifically and effectively utilizes teaching information and teacher and student interaction information to evaluate teachers' teaching performance, which helps to motivate teachers' work enthusiasm, improve teaching quality, and enhance school core competitiveness. This paper analyzes the salient features of smart campus from the perspectives of technology, business, and construction mode, and proposes a smart campus architecture model. According to the research content of teaching performance evaluation, the framework model of smart campus education data collection and storage platform is established, which provides a reference model for the construction of smart campus in colleges and universities. The evaluation of teaching performance in smart campus first analyzes the shortcomings of traditional evaluation methods and proposes the necessity of combining teaching performance evaluation with modern technology. Second, six principal components were determined using the PCA algorithm. Then, use the AHP to calculate the weights of each layer of the indicator set, avoiding the decision errors caused by subjective factors. Finally, the gray correlation degree is used to improve the TOPSIS algorithm for multi-objective decision analysis. The evaluation results of the AHP-TOPSIS teaching performance model are consistent with the actual situation. The application of the smart campus education data platform combined with the AHP and the gray correlation improvement TOPSIS algorithm is more targeted to the teacher's teaching performance evaluation and provides a new evaluation method for scientific performance evaluation, and avoid the problem of strong subjectivity of traditional teaching performance evaluation.",10.1109/ACCESS.2018.2884022,2018,,TEACHING PERFORMANCE EVALUATION IN SMART CAMPUS,
862,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In traditional transductive learning, all queries are used in learning to rank in order to generate pseudo-labels when sufficient training data are not available. However, low quality queries may affect retrieval performance in transductive learning. We thus think that it is important to improve the quality of queries in transductive learning to train an effective ranking model. By using a small number of reliable samples and data close to the boundaries of classification, we propose building a query quality estimator by establishing a relationship between the benefits of good retrieval performance and features of the normalized query commitment that influence query quality. In our proposed transduction model, all queries available are filtered by the proposed query quality estimator and only high quality queries that enhance the effectiveness of retrieval such that they yield performance-related benefits, are used to generate pseudo-labels for learning to rank. Queries that can degrade performance benefits are discarded while creating the pseudo-labels. Pseudo-labels aggregated by high quality queries in transductive learning are then leveraged in learning to rank scenarios without sufficient training data. The results of extensive experiments on the standard LETOR 4.0 dataset showed that our proposed method can outperform strong baselines and the average normalized discounted cumulative gain is enhanced up to 7.77% in some case.",10.1109/ACCESS.2020.3043459,2020,,IMPROVING QUERY QUALITY FOR TRANSDUCTIVE LEARNING IN LEARNING TO RANK,
863,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper describes an on-road air quality monitoring and control approach by proposing an agent-based system for modeling the urban road network infrastructure, establishing the real-time and predicted air pollution indexes in different road segments and generating recommendations and regulation proposals for road users. This can help by reducing vehicle emissions in the most polluted road sections, optimizing the pollution levels while maximizing the vehicle flow. For this, we use data sets gathered from a set of air quality monitoring stations, embedded low-cost e-participatory pollution sensors, contextual data, and the road network available data. These data are used in the air quality indexes calculation and then the generation of a dynamic traffic network. This network is represented by a weighted graph in which the edges weights evolve according to the pollution indexes. In this paper, we propose to combine the benefits of agent technology with both machine learning and big data tools. An artificial neural networks model and the Dijkstra algorithm are used for air quality prediction and the least polluted path finding in the road network. All data processing tasks are performed over a Hadoop-based framework: HBase and MapReduce.",10.1109/ACCESS.2017.2725984,2017,,AN AGENT BASED TRAFFIC REGULATION SYSTEM FOR THE ROADSIDE AIR QUALITY CONTROL,
864,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Despite the growing trend towards the use of big data methodologies, there is still limited application of such techniques to understand how spectrum is used in mobile networks. In this paper we analyse how low (<; 1 GHz) and high (>1 GHz) frequency spectrum is used in 4G networks in urban areas, in relation to eNodeB density, available bandwidth, Reference Signal Received Power (RSRP) and Reference Signal Received Quality (RSRQ). We present a method to analyse the strategies used by Mobile Network Operators (MNOs) to deal with traffic congestion, and the degree to which they must densify their networks depending on their spectrum portfolio. Using crowdsourced data from 2017 from a popular mobile app, we apply this method to Greater London. We find that the fraction of sites that fully use all available bands to the MNO range from 2% to 20%. Additionally, MNOs with large bandwidth use 42% fewer sites on average in dense urban environments. This difference decreases in suburban areas to 23% fewer sites. The lowest frequencies in each eNodeB tend to exhibit lower RSRP values, as they are often used to serve cell-edge users. These frequencies also show lower RSRQ values because of higher interference caused by neighbouring cells. Similarly, large (high frequency) bandwidth improves RSRQ as it allows for fewer users per MHz, which reduces interference and enables larger cell sizes. We conclude that in dense urban environments, the available bandwidth, rather than propagation properties, determines the preferred band for network deployment by MNOs.",10.1109/ACCESS.2020.3031963,2020,,HOW DOES SPECTRUM AFFECT MOBILE NETWORK DEPLOYMENTS? EMPIRICAL ANALYSIS USING CROWDSOURCED BIG DATA,
865,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the smart mariculture, the timely and accurate predictions of water quality can help farmers take countermeasures before the ecological environment deteriorates seriously. However, the openness of the mariculture environment makes the variation of water quality nonlinear, dynamic and complex. Traditional methods face challenges in prediction accuracy and generalization performance. To address these problems, an accurate water quality prediction scheme is proposed for pH, water temperature and dissolved oxygen. First, we construct a new huge raw data set collected in time series consisting of 23,204 groups of data. Then, the water quality parameters are preprocessed for data cleaning successively through threshold processing, mean proximity method, wavelet filter, and improved smoothing method. Next, the correlation between the water quality to be predicted and other dynamics parameters is revealed by the Pearson correlation coefficient method. Meanwhile, the data for training is weighted by the discovered correlation coefficients. Finally, by adding a backward SRU node to the training sequence, which can be integrated into the future context information, the deep Bi-S-SRU (Bi-directional Stacked Simple Recurrent Unit) learning network is proposed. After training, the prediction model can be obtained. The experimental results demonstrate that our proposed prediction method achieve higher prediction accuracy than the method based on RNN (Recurrent Neural Network) or LSTM (Long Short-Term Memory) with similar or less time computing complexity. In our experiments, the proposed method takes 12.5ms to predict data on average, and the prediction accuracy can reach 94.42% in the next 3~8 days.",10.1109/ACCESS.2020.2971253,2020,,ACCURATE PREDICTION SCHEME OF WATER QUALITY IN SMART MARICULTURE WITH DEEP BI-S-SRU LEARNING NETWORK,
866,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"To scientifically and accurately recommend suitable teachers for university courses and improve teaching quality, designing an effective recommendation algorithm is necessary. Therefore, we construct quantitative models of teacher characteristics, course characteristics, and teaching evaluations under the theories and methods of education and build a sparse experimental data matrix based on the quantified data. On this basis, we propose a teacher recommendation algorithm (PRLFM) based on the improved latent factor model (LFM) and the improved PersonalRank algorithm. Firstly, the improved LFM is used to predict the evaluation scores of those courses that teachers have not taught. The scores which are higher than the specified threshold are used to fill the corresponding missing items in the sparse matrix to reduce the matrix's sparsity. Then, the bipartite graph model based on the teacher set and course set is constructed according to the filled experimental data matrix. The weight of edges in the bipartite graph is replaced by the teacher and course's evaluation score multiplied by the course difficulty, which reflects the correlation between course and evaluation score. Next, an improved probability transition matrix based on the bipartite graph is constructed. The access probability in the matrix is replaced by the node's out degree's reciprocal multiplied by the edge's weight. The correlation degree between the course and all teachers is quickly calculated using the matrix algorithm of PersonalRank. Finally, a teacher recommendation model is constructed to realize teachers' top-N recommendation by combining the correlation degree with teachers' characteristics. Experiments show that the PRLFM algorithm can effectively improve the accuracy of prediction and top-N recommendation. It solves the problem of lack of scientific basis in recommending suitable teachers for university courses and improving the teaching quality.",10.1109/ACCESS.2021.3101469,2021,,A COURSE TEACHER RECOMMENDATION ALGORITHM BASED ON IMPROVED LATENT FACTOR MODEL AND PERSONALRANK,
867,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of information technology, the name ambiguity problem has become one of the primary issues in the fields of information retrieval, data mining, and scientific measurement. Name disambiguation is used to promote computer technology and big data information, which maps virtual relational networks to real social networks to solve the problem that the same name points to multiple entities. At present many literature search platforms launched their respective scholar system, name ambiguity problem will inevitably affect the precision of other information calculations, reduce the credibility of the system, and affect the information quality and content quality. Most work deals with this issue by using graph theory and clustering. However, the name disambiguation problem is still not well resolved. In this paper, we propose a multi-level name disambiguation algorithm. This algorithm is mainly based on the unsupervised algorithm, which combines hierarchical agglomerative clustering (HAC) and graph theory for disambiguating. The experimental results show that the proposed solution achieves clearly better performance (+17 ~ 25% in terms of F1-Measure) than several methods, including HAC and Graph.",10.1109/ACCESS.2019.2931592,2019,,A MULTI-LEVEL AUTHOR NAME DISAMBIGUATION ALGORITHM,
868,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"One major result of the Industrial Digitalization is the access to a large set of digitalized data and information, i.e. Big Data. The market of analytic tools offers a huge variety of algorithms and software to exploit big datasets. Implementing their advantages into one approach brings better results and empower possibilities for process analysis. Its application in the manufacturing industry requires a high level of effort and remains to be challenging due to product complexity, human-centric processes, and data quality. In this manuscript, the authors combine process mining and value streams methods for analyzing the data from the information management system, applying the approach to the data delivered by one specific manufacturing system. The manufacturing process to be examined is the process of assembling gas meters in the manufacture. This specific and important part of the whole supply-chain process was taken as suitable for the study due to almost full-automated line with data about each process activity of the value-stream in the information system. The paper applies process mining algorithms in discovering a descriptive process model that plays the main role as a basis for further analysis. At the same time, modern techniques of the bottleneck analysis are described, and two new comprehensible methods of bottlenecks detection (TimeLag and Confidence intervals methods), as well as their advantages, will be discussed. Achieved results can be subsequently used for other sources of big data and industrial-compliant Information Management Systems.",10.1109/ACCESS.2022.3152211,2022,,SCREENING PROCESS MINING AND VALUE STREAM TECHNIQUES ON INDUSTRIAL MANUFACTURING PROCESSES: PROCESS MODELLING AND BOTTLENECK ANALYSIS,
869,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Under the high load, high frequency and high strength operating environment, the frequent occurrence of vehicle fault gradually attracts the attention of the society. The real-time monitoring and data recording function of vehicle-mounted equipment provides data support for vehicle status assessment and fault warning. In this paper, the real-time data collected by CAN-BUS system of Beijing Bus Group are preprocessed and discretized. On the basis of the traditional rough set theory, a new coding method is set up, and the dependency between conditional attributes and decision attributes is set as an adaptive function, which is reduced by genetic algorithm and cellular genetic algorithm respectively. The calculation results show that the key fault information of public transport vehicles is instrumental speed, oil pressure, percentage of torque, timing engine speed, and coolant temperature. By comparing the results of reduction, it is found that the cellular genetic algorithm has higher applicability than the genetic algorithm in terms of algorithm efficiency, stability, and convergence quality. Although the genetic algorithm attribute reduction is slightly better than the cellular genetic algorithm attribute reduction in the rule matching, the cellular genetic algorithm has a better ability to excavate information within the acceptable compatibility range. Finally, the selected key factors will be deployed on the Beijing Bus Group's big data platform and displayed in real time. The conclusion of this paper enriches the theory of bus engine fault warning and establishes an engine failure warning system, which can effectively reduce the failure rate of bus vehicles and reduce the maintenance cost expenditure. It has certain guiding significance for the bus operation work of Beijing Bus Group.",10.1109/ACCESS.2020.2964791,2020,,RESEARCH ON CONSTRUCTION OF CRUDE SET MODEL OF CRITICAL FAULT INFORMATION FOR BUS BASED ON CAN-BUS DATA,
870,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Wireless sensor networks (WSNs) and mobile crowdsensing (MCS) are two important paradigms in urban dynamic sensing. In both sensing paradigms, task allocation is a significant problem, which may affect the completion quality of sensing tasks. In this paper, we give a survey of task allocation in WSNs and MCS from the contrastive perspectives in terms of data quality and sensing cost, which help to better understand related objectives and strategies. We first analyze the different characteristics of two sensing paradigms, which may lead to difference in task allocation issues or strategies. Then, we present some common issues in task allocation with objectives in data quality and sensing cost. Furthermore, we provide reviews of unique task allocation issues in MCS according to its new characteristics. Finally, we identify some potential opportunities for the future research.",10.1109/ACCESS.2019.2896226,2019,,A SURVEY OF TASK ALLOCATION: CONTRASTIVE PERSPECTIVES FROM WIRELESS SENSOR NETWORKS AND MOBILE CROWDSENSING,
871,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, we present a novel method, process, and system for calculating dyslexic symptoms, generating metric data for an individual user, community, or group in general. We present a mobile multimedia Internet of Things (IoT)-based environment that can capture multimodal smartphone or tab-based user interaction data during dyslexia testing and share it via a mobile edge network, which employs auto-grading algorithms to find dyslexia symptoms. In addition to algorithm-based auto-grading, the captured mobile multimedia payload is stored in a decentralized repository that can be shared with a medical practitioner for replay and further manual analysis purposes. Since the framework is language-independent and based on Blockchain and a decentralized big data repository, dyslexic patterns and a massive amount of captured multimedia IoT test data can be shared for further clinical research, statistical analysis, and quality assurance. Notwithstanding, our proposed Blockchain and off-chain-based decentralized and secure dyslexia data storage, management, and sharing framework will allow security, anonymity, and multimodal visualization of the captured test data for mobile users. This paper presents the detailed design, implementation, and test results, which demonstrate the strong potential for wider adoption of the dyslexia mobile health management globally.",10.1109/ACCESS.2018.2875242,2018,,SPATIAL BLOCKCHAIN-BASED SECURE MASS SCREENING FRAMEWORK FOR CHILDREN WITH DYSLEXIA,
872,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The impressive evolution of the Internet of Things and the great amount of data flowing through the systems provide us with an inspiring scenario for Big Data analytics and advantageous real-time context-aware predictions and smart decision-making. However, this requires a scalable system for constant streaming processing, also provided with the ability of decision-making and action taking based on the performed predictions. This paper aims at proposing a scalable architecture to provide real-time context-aware actions based on predictive streaming processing of data as an evolution of a previously provided event-driven service-oriented architecture which already permitted the context-aware detection and notification of relevant data. For this purpose, we have defined and implemented a microservice-based architecture which provides real-time context-aware actions based on predictive streaming processing of data. As a result, our architecture has been enhanced twofold: on the one hand, the architecture has been supplied with reliable predictions through the use of predictive analytics and complex event processing techniques, which permit the notification of relevant context-aware information ahead of time. On the other, it has been refactored towards a microservice architecture pattern, highly improving its maintenance and evolution. The architecture performance has been evaluated with an air quality case study.",10.1109/ACCESS.2019.2960516,2019,,REAL-TIME CONTEXT-AWARE MICROSERVICE ARCHITECTURE FOR PREDICTIVE ANALYTICS AND SMART DECISION-MAKING,
873,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, various food-safety issues have aroused public concern regarding safety in the food supply chain. Since grains are closely linked to human life and health, it is necessary to effectively manage information in the grain supply chain. The grain supply chain is characterized by a long life cycle, complex links, various hazards, and heterogeneous information sources. Problems with traditional traceability systems include easy data tampering, difficult hazardous-material information management, the “information isolated island” problem, and low traceability efficiency in the whole supply chain. Blockchain is a distributed computing paradigm characterized by decentralization, network-wide recording, security, and reliability. As such, it can reduce administrative costs and improve the efficiency of information management. Based on literature research and a field investigation of wheat-processing enterprises in Shandong Province, We analyze the operation process of grain supply chain. This study, therefore, proposed a new system architecture in the entire grain supply chain based on blockchain technology and designed a multimode storage mechanism that combines chain storage. This prototype system was tested and verified using actual cases and application scenarios. Compared to traditional systems, the proposed system is characterized by data security and reliability, information interconnection and intercommunication, real-time sharing of hazardous-material information, and dynamic and credible whole-process tracing. As such, this system is highly significant and has reference value for guaranteeing food quality and safety-process traceability.",10.1109/ACCESS.2020.2975415,2020,,BLOCKCHAIN-BASED SAFETY MANAGEMENT SYSTEM FOR THE GRAIN SUPPLY CHAIN,
874,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Low-dose computed tomography (LDCT) images are polluted by mottle noise and streak artifacts. To improve LDCT images quality, this paper proposes a novel total variation (NTV) model. A weighted coefficient of the regularization term of NTV model is constructed by standard deviation, gray-level probability and gradient magnitude to smooth LDCT images adaptively, since the standard deviation and the gray-level probability of detail region are higher than that of the noisy background, and the gradient magnitude of edges is higher than that of the noisy background. Besides, to preserve details and edges effectively, the fidelity term of the proposed NTV model is constructed by the block-matching 3d filter because it performs well in details and edges preservation. The experiments are performed on the computer simulated phantom and the actual phantom. Compared with several other competitive methods, both subjective visual effect and objective evaluation criteria show that the proposed NTV model can improve LDCT images quality more effectively such as noise and artifacts suppression, details, and edges preservation.",10.1109/ACCESS.2018.2885514,2018,,A NOVEL TOTAL VARIATION MODEL FOR LOW-DOSE CT IMAGE DENOISING,
875,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Electronic health records (EHRs) are providing increased access to healthcare data that can be made available for advanced data analysis. This can be used by the healthcare professionals to make a more informed decision providing improved quality of care. However, due to the inherent heterogeneous and imbalanced characteristics of medical data from EHRs, data analysis task faces a big challenge. In this paper, we address the challenges of imbalanced medical data about a brain tumor diagnosis problem. Morphometric analysis of histopathological images is rapidly emerging as a valuable diagnostic tool for neuropathology. Oligodendroglioma is one type of brain tumor that has a good response to treatment provided the tumor subtype is recognized accurately. The genetic variant, 1p-/19q-, has recently been found to have high chemosensitivity, and has morphological attributes that may lend it to automated image analysis and histological processing and diagnosis. This paper aims to achieve a fast, affordable, and objective diagnosis of this genetic variant of oligodendroglioma with a novel data mining approach combining a feature selection and ensemble-based classification. In this paper, 63 instances of brain tumor with oligodendroglioma are obtained due to prevalence and incidence of the tumor variant. In order to minimize the effect of an imbalanced healthcare data set, a global optimization-based hybrid wrapper-filter feature selection with ensemble classification is applied. The experiment results show that the proposed approach outperforms the standard techniques used in brain tumor classification problem to overcome the imbalanced characteristics of medical data.",10.1109/ACCESS.2016.2647238,2016,,A HYBRID FEATURE SELECTION WITH ENSEMBLE CLASSIFICATION FOR IMBALANCED HEALTHCARE DATA: A CASE STUDY FOR BRAIN TUMOR DIAGNOSIS,
876,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The operational stability of public transport is significant for both passengers and operators. Affected by many stochastic factors, such as traffic congestion, traffic signals and passenger demand at stops, the headway always become uneven, which greatly reduces the service quality. This paper used the big global positioning systems (GPS) trajectory data to analyze the headway stability of bus system from the perspective of network. A statistical method is proposed to analyze the operational vehicle performance of bus network. The GPS trajectory data of Jinan is used to test the model. The results show that the average dwell time, actual headway, and headway stability index of stations follow lognormal distributions with obvious right tails. Moreover, the seriously unstable situations do not appear in the peak hours, but in the time periods before peak hours. In addition, the stations with most unstable headway are located in the suburbs and the fringe area of downtown. The outcomes suggest that operators should pay more attention to the suburbs and the fringe area of downtown, and the time periods before peak hours to efficiently improve the service quality.",10.1109/ACCESS.2019.2930279,2019,,A DATA-DRIVEN ANALYSIS FOR OPERATIONAL VEHICLE PERFORMANCE OF PUBLIC TRANSPORT NETWORK,
877,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Pharmaceutical manufacturers need to analyse a vast number of products in their daily activities. Many times, the same product can be registered several times by different systems using different attributes, and these companies require accurate and quality information regarding their products since these products are drugs. The central hypothesis of this research work is that machine learning can be applied to this domain to efficiently merge different data sources and match the records related to the same product. No human is able to do this in a reasonable way because the number of records to be matched is extremely high. This article presents a framework for pharmaceutical record matching based on machine learning techniques in a big data environment. The proposed framework aims to explode the well-known rules for the matching of records from different databases for training machine learning models. Then the trained models are evaluated by predicting matches with records that do not follow these known rules. Finally, the production environment is simulated by generating a huge amount of combinations of records and predicting the matches. The obtained results show that, despite the good results obtained with the training datasets, in the production environment, the average accuracy of the best model is around 85%. That shows that matches which do not follow the known rules can be predicted and, considering that there is not a human way to process this amount of data, the results are promising.",10.1109/ACCESS.2020.3024558,2020,,AUTOMATIC LEARNING FRAMEWORK FOR PHARMACEUTICAL RECORD MATCHING,
878,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As an important part of the new generation of information technology, the Internet of Things (IoT), with its ubiquitous connection and service characteristics, has penetrated into various fields of application and played an important role. In this paper, based on the study of the basic technology of the environmental Internet of Things, combined with the service-oriented technology architecture SOA, J2EE, multi-level system architecture MVC, real-time database and other technologies and project practice experience, summarized and proposed a kind of environmental quality monitoring integrated management platform design and implementation feasibility scheme. Firstly, the background of the era of big data is described in detail, the urgency and necessity of information security monitoring under the background of big data is clarified, and the three elements of information security monitoring mechanism, namely network monitoring personnel, environment and technology, are proposed, and the three elements as the starting point to establish the information security monitoring mechanism; Starting from the relevant monitoring strategies and safety monitoring technologies, this paper explains the basic principles of constructing the evaluation index system, and establishes the evaluation index system according to the key influencing factors of enterprise information security level in the environment of big data. AHP fuzzy comprehensive evaluation method is chosen on the basis of analyzing various comprehensive evaluation methods, and the weight of each evaluation index is determined and the comprehensive evaluation model is constructed. The establishment of information security monitoring and evaluation system, the use of information security monitoring and evaluation system, for information security monitoring work to provide reference standards. Finally, on the basis of the foregoing, relevant strategies for information security monitoring are proposed, and necessary suggestions are provided for information security work.",10.1109/ACCESS.2021.3064350,2021,,INFORMATION SECURITY MONITORING AND MANAGEMENT METHOD BASED ON BIG DATA IN THE INTERNET OF THINGS ENVIRONMENT,
879,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Low-dose CT images contain severe mottle noise and streak artifacts, which seriously affect the physician’s diagnosis of the disease. Hence, in this paper, we propose a novel anisotropic fourth-order diffusion model for low-dose CT image processing. The proposed diffusion model uses both image gradient magnitude and weighted residual local energy to determine the diffusion coefficient. Gradient magnitude is used to detect the image edges, while the weighted residual local energy preserves textures and details in the image. In addition, the fidelity term is introduced into the diffusion model to avoid excessive smoothing and weaken the blocky effects. Experimental results show that when compared with the anisotropic fourth-order diffusion model, the proposed algorithm protects the texture details and suppresses the blocky effects. In comparison with other state-of-the-art algorithms, the proposed model effectively suppresses mottle noise and streak artifacts while simultaneously improving the low-dose CT image quality.",10.1109/ACCESS.2022.3172975,2022,,IMAGE PROCESSING FOR LOW-DOSE CT VIA NOVEL ANISOTROPIC FOURTH-ORDER DIFFUSION MODEL,
880,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the booming development of medical informatization and the ubiquitous connections in the fifth generation mobile communication technology (5G) era, the heterogeneity and explosive growth of medical data have brought huge challenges to data access, security and privacy, as well as information processing in Internet of Medical Things (IoMT). This article provides a comprehensive review of how to realize the timely processing and analysis of medical big data and the sinking of high-quality medical resources under the constraints of the existing medical environment and medical-related equipment. We mainly focus on the advantages brought by the cloud computing, edge computing and artificial intelligence technologies to the IoMT. We also explore how to rationalize the use of medical resources and the security and privacy of medical data, so that high-quality medical services can be provided to patients. Finally, we discuss the current challenges and possible future research directions in the edge-cloud computing and artificial intelligence related IoMT.",10.1109/ACCESS.2020.2997831,2020,,"EDGE-CLOUD COMPUTING AND ARTIFICIAL INTELLIGENCE IN INTERNET OF MEDICAL THINGS: ARCHITECTURE, TECHNOLOGY AND APPLICATION",
881,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In wireless sensor networks, sensor nodes, the miniature embedded devices, have limitation of energy, storage, computing, and etc. One of the tasks of the nodes is to use their limited resources to complete work efficiently. Choosing high quality link communication can effectively save energy. In this paper, we propose a link quality estimation model that is based on deep forest. To avoid a noise sample becoming a center point in the clustering, we use an improved K-medoids algorithm based on step increasing and optimizing medoids (INCK) when dividing the link quality grades. During the sample preprocessing stage, the Pauta criterion is used to delete the noise link samples, and we fill the mean value of each grade into the missing values. The feature extraction performance of deep forest is improved by combining the stratified sampling to change the unbalance distribution of link quality samples. And then the Stratified Sampling Cascade Forest link quality estimation (SCForest-LQE) is constructed by combining stratified sampling with cascade forest. The experiments are conducted in three real application scenarios. Compared with the existing six link quality estimation models, SCForest-LQE has better estimation performance and stability.",10.1109/ACCESS.2020.3047648,2021,,A LINK QUALITY ESTIMATION METHOD FOR WIRELESS SENSOR NETWORKS BASED ON DEEP FOREST,
882,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Road-based mass transit systems are an effective means to combat the negative impact of transport that is based on private vehicles. Providing quality of service in this type of transit system is a priority for transport authorities. In these systems, travel time (TT) is a basic factor in quality of service. This paper presents a methodology, based on data mining, for analyzing TT in a mass transit system that is planned by timetable. The objective of the methodology is to understand the behavior patterns of TTs on the different routes of the transport network, as well as the factors that influence these patterns. To achieve this objective, the methodology uses clustering techniques to process the GPS data provided by the vehicles of the public transport fleet. The results that were obtained when implementing this methodology in a public transport company are presented as a use case, demonstrating its validity.",10.1109/ACCESS.2018.2837498,2018,,SYSTEMATIC APPROACH TO ANALYZE TRAVEL TIME IN ROAD-BASED MASS TRANSIT SYSTEMS BASED ON DATA MINING,
883,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Building a scientific and reasonable reputation evaluation mechanism for crowdsourcing participants is an effective way to solve the problem of transaction fraud, to establish the trust of traders and ensure the quality of task completion. Under the big data environment, machine learning methods have been applied in the domain of e-commerce of physical goods to improve the traditional reputation evaluation methods, and achieved good results. However, few studies have applied machine learning methods to crowdsourcing, a form of service e-commerce, to evaluate the reputation of participants. This paper proposes a reputation evaluation model (i.e. LDA-RF) for crowdsourcing participants of Random Forest based on Linear Discriminant Analysis. The model consists of five steps: firstly, building a multidimensional reputation evaluation index system for crowdsourcing participants, collecting real data sets, and preprocessing data; secondly, data dimensionality reduction methods, including Linear Discriminant Analysis, Principal Component Analysis, Mean Impact Value method and ReliefF feature selection method, are used to eliminate redundant variables; thirdly, data normalization; fourthly, with selected feature subset, five machine learning techniques, Random Forest, Decision Tree, Back propagation Neural Network, Radial Basis Function Neural Network and Support Vector Machine are used to train the model; Fifthly, the validity of the model is tested by four evaluation measures: 10 fold cross validation, confusion matrix, Kruskal-wallis test and dispersion degree. The results show that the LDA-RF model on accuracy, F1-measure, generalization ability and robustness are better than those of other models, and it has better performance and effectiveness. This study represents a new contribution to establish reputation evaluation of crowdsourcing participants under big data environment.",10.1109/ACCESS.2019.2933147,2019,,IMPROVE REPUTATION EVALUATION OF CROWDSOURCING PARTICIPANTS USING MULTIDIMENSIONAL INDEX AND MACHINE LEARNING TECHNIQUES,
884,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Synthetic aperture imaging, which has been proved to be an effective approach for occluded object imaging, is one of the challenging problems in the field of computational imaging. Currently most of the related researches focus on fixed synthetic aperture which usually accompanies with mixed observation angle and foreground de-focus blur. But the existence of them is frequently a source of perspective effect decrease and occluded object imaging quality degradation. In order to solve this problem, we propose a novel data-driven variable synthetic aperture imaging based on semantic feedback. The semantic content we concerned for better de-occluded imaging is the foreground occlusions rather than the whole scene. Therefore, unlike other methods worked on pixel-level, we start from semantic layer and present a semantic labeling method based on feedback. Semantic labeling map deeply mines visual data in synthetic image and preserves the semantic information of foreground occluder. On the basis of semantic feedback strategy, semantic labeling map will conversely pass to synthetic imaging process. The proposed data-driven variable synthetic aperture imaging contains two levels: one is adaptive changeable imaging aperture driven by synthetic depth and perspective angle, the other is light ray screening driven by visual information in semantic labeling map. On this basis, the hybrid camera view and superimposition of foreground occlusion can be removed. Evaluations on several complex indoor scenes and real outdoor environments demonstrate the superiority and robustness performance of our proposed approach.",10.1109/ACCESS.2019.2953560,2019,,DATA-DRIVEN VARIABLE SYNTHETIC APERTURE IMAGING BASED ON SEMANTIC FEEDBACK,
885,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Aiming at the current multimodal medical image fusion methods that cannot fully characterize the complex textures and edge information of the lesion in the fused image, a method based on Gabor representation of multi-CNN combination and fuzzy neural network is proposed. This method first filters the CT and MR image sets through a set of Gabor filter banks with different proportions and directions to obtain different Gabor representations pairs of CT and MR, each pair of different Gabor representations is used to train the corresponding CNN to generate a G- CNN and multiple G- CNN form a G- CNN group, namely G- CNNs; then when fusing CT and MR images, CT and MR are represented by Gabors to get Gabor representation pairs firstly, each Gabor representation pair is put into the corresponding trained G- CNN for preliminary fusion, then use the fuzzy neural network to fuse multiple outputs of the G- CNNs to obtain the final fused image. Compared with the nine recent state-of-the-art multimodal fusion methods, the average mutual information of the three groups of experiments has increased by 13%, 10.3%, and 10% respectively; the average spatial frequency has increased by 10.3%, 20%, and 10.7%; the average standard deviation has increased respectively 12.4%, 10.8%, 14.4%; the average edge retention information increased by 33.5%, 22%, and 43%. The experimental results show that the proposed fusion method is significantly better than the other comparative fusion methods in objective evaluation and visual quality. It has the best performance on the four indicators and can better integrate the rich texture features and the clear edge information of the source images into the final fused image, which improves the quality of multimodal medical image fusion, and effectively assists doctors in disease diagnosis.",10.1109/ACCESS.2021.3075953,2021,,MULTIMODAL MEDICAL IMAGE FUSION BASED ON GABOR REPRESENTATION COMBINATION OF MULTI-CNN AND FUZZY NEURAL NETWORK,
886,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The Essential Climate Variable (ECV) soil moisture (SM) datasets, originated from the European Space Agency, have revealed great potential for application in hydrology and agriculture. Hence, it is essential to continuously enhance the data quality and spatial completeness to satisfy the increasing scientific research requirements. In this study, we explore the potential possibility of Soil Moisture Active Passive (SMAP) datasets in filling the gaps of ECV SM. The comprehensive assessment results show that: (1) The data missing percent of gap-filled ECV decreases 20% on average, which can be one step closer to generate a seamlessly covered global land surface SM product with favorable quality. (2) Compared to the original ECV, the gap-filled ECV products express similar good response to the in-situ measurements, suggesting that the SMAP SM products could be taken to efficiently fill the gaps and consistently maintain favorable accuracy at the same time. (3) Compared to the in-situ measurements, the original ECV SM products demonstrate extremely high probability density peak percentages. Fortunately, this eminent high value could be effectively rectified through gap-filling progress using SMAP. Overall, this study conducts objective and detailed evaluation on the performance of applying SMAP to fill the gaps of ECV, and is expected to act as a valuable reference in ECV SM gap-filling method.",10.1109/ACCESS.2020.3009977,2020,,POTENTIAL APPLICABILITY OF SMAP IN ECV SOIL MOISTURE GAP-FILLING: A CASE STUDY IN EUROPE,
887,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, we present an experimental image quality assessment (IQA) method for image/video patches with compression artifacts. Using the High Efficiency Video Coding (HEVC) standard, we create a new database of image patches with compression artifacts. Then, we conduct a completed subjective testing process to obtain the `ground truth' quality scores for the mentioned database. Finally, we employ an end-to-end learning method to estimate the IQA model for the patches with HEVC compression artifacts. In such proposed method, a modified convolutional neural network (CNN) architecture is exploited for feature extraction while an adaptive moment estimation optimizer solution is used to perform the training process. Experimental results show that the proposed end-to-end IQA method significantly outperforms the relevant IQA benchmarks, especially when the compression artifacts are strongly realized in image/video patches. The proposed IQA method is expected to drive a new set of image/video compression solutions in future image/video coding and transmissions.",10.1109/ACCESS.2020.3040416,2020,,END-TO-END IMAGE PATCH QUALITY ASSESSMENT FOR IMAGE/VIDEO WITH COMPRESSION ARTIFACTS,
888,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Big data generated from social media and smart mobile devices has been regarded as a key to obtain insights into human behavior and been extensively utilized for launching marketing activities. A successful marketing activity requires attracting high social popularity to their contents, since higher popularity usually indicates stronger influence, more fame and higher revenue. In this paper, we focus on the question of how to improve popularity of videos sharing on websites like YouTube in mobile computing environment. Obviously, composing high quality titles and tags is beneficial for viewers to discover videos of their interests and increase their tendency to watch more videos. However, it is not an easy task for uploaders, which is especially true since the screen is tight for most mobile devices. To this end, this paper proposes a novel hybrid method based on multi-modal content analysis that recommends keywords for video uploaders to compose titles and tags of their videos and then to gain higher popularity. The method generates candidate keywords by integrating techniques of textual semantic analysis of original tags and recognition of video content. On one hand, taking the original keywords of a video as input, the method obtains most relevant words from WordNet and related video titles gathered from the three top video sharing sites (YouTube, Yahoo Video, Bing Video). On the other hand, through recognizing video content with deep learning technology, the method extracts the entity name of video content as candidate keywords. Finally, a TF-SIM algorithm is proposed to rank the candidate keywords and the most relevant keywords are recommended to uploaders for optimizing the titles and tags of their videos. The experimental results show that the proposed method can effectively improve the social popularity of the videos as well as extend the length of video viewing time per playback.",10.1109/ACCESS.2019.2961392,2020,,AN INTELLIGENT VIDEO TAG RECOMMENDATION METHOD FOR IMPROVING VIDEO POPULARITY IN MOBILE COMPUTING ENVIRONMENT,
889,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart city advancements are driving massive transformations of healthcare, the largest global industry. The drivers include increasing demands for ubiquitous, preventive, and personalized healthcare, to be provided to the public at reduced risks and costs. Mobile cloud computing could potentially meet the future healthcare demands by enabling anytime, anywhere capture and analyses of patients' data. However, network latency, bandwidth, and reliability are among the many challenges hindering the realization of next-generation healthcare. This paper proposes a ubiquitous healthcare framework, UbeHealth, that leverages edge computing, deep learning, big data, high-performance computing (HPC), and the Internet of Things (IoT) to address the aforementioned challenges. The framework enables an enhanced network quality of service using its three main components and four layers. Deep learning, big data, and HPC are used to predict network traffic, which in turn are used by the Cloudlet and network layers to optimize data rates, data caching, and routing decisions. Application protocols of the traffic flows are classified, enabling the network layer to meet applications' communication requirements better and to detect malicious traffic and anomalous data. Clustering is used to identify the different kinds of data originating from the same application protocols. A proof of concept UbeHealth system has been developed based on the framework. A detailed literature review is used to capture the design requirements for the proposed system. The system is described in detail including the algorithmic implementation of the three components and four layers. Three widely used data sets are used to evaluate the UbeHealth system.",10.1109/ACCESS.2018.2846609,2018,,UBEHEALTH: A PERSONALIZED UBIQUITOUS CLOUD AND EDGE-ENABLED NETWORKED HEALTHCARE SYSTEM FOR SMART CITIES,
890,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In order to address the unreasonable distributed corners in single threshold Harris detection and expensive computation cost incurred from image region matching performed by normalized cross correlation (NCC) algorithm, multi-threshold corner detection and region matching algorithm based on texture classification are proposed. Firstly, the input image is split into sub-blocks which are classified into four different categories based on the specific texture: flat, weak, middle texture and strong regions. Subsequently, an algorithm is suggested to decide threshold values for different texture type, and interval calculation for the sub-blocks is performed to improve operation efficiency in the algorithm implementation. Finally, based on different texture characteristics, Census, interval-sampled NCC, and complete NCC are employed to perform image matching. As demonstrated by the experimental results, corner detection based on texture classification is capable to obtain a reasonable corner number as well as a more uniform spatial distribution, when compared to the traditional Harris algorithm. If combined with the interval classification, speedup for texture classification is approximately 30%. In addition, the matching algorithm based on texture classification is capable to improve the speed of 26.9%~29.9% while maintaining the comparable accuracy of NCC. In general, for better splicing quality, the overall stitching speed is increased by 14.1%~18.4%. Alternatively, for faster speed consideration, the weak texture region which accounts for a large proportion of an image and provides less effective information can be ignored, for which 23.9%~28.4% speedup can be achieved at the cost of a 1.9%~3.9% reduction in corner points. Therefore, the proposed algorithm is made potentially suited to uniformly distributed corner point calculation and high computation efficiency requirement scenarios.",10.1109/ACCESS.2019.2940137,2019,,MULTI-THRESHOLD CORNER DETECTION AND REGION MATCHING ALGORITHM BASED ON TEXTURE CLASSIFICATION,
891,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Random forest (RF) is an ensemble classifier method, all decision trees participate in voting, some low-quality decision trees will reduce the accuracy of random forest. To improve the accuracy of random forest, decision trees with larger degree of diversity and higher classification accuracy are selected for voting. In this paper, the RF based on Kappa measure and the improved binary artificial bee colony algorithm (IBABC) are proposed. Firstly, Kappa measure is used for pre-pruning, and the decision trees with larger degree of diversity are selected from the forest. Then, the crossover operator and leaping operator are applied in ABC, and the improved binary ABC is used for secondary pruning, and the decision trees with better performance are selected for voting. The proposed method (Kappa+IBABC) are tested on a quantity of UCI datasets. Computational results demonstrate that Kappa+IBABC improves the performance on most datasets with fewer decision trees. The Wilcoxon signed-rank test is used to verify the significant difference between the Kappa+IBABC method and other pruning methods. In addition, Chinese haze pollution is becoming more and more serious. This proposed method is used to predict haze weather and has achieved good results.",10.1109/ACCESS.2021.3105796,2021,,A MODIFIED RANDOM FOREST BASED ON KAPPA MEASURE AND BINARY ARTIFICIAL BEE COLONY ALGORITHM,
892,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Modeling and analyzing the performance of distributed file systems (DFSs) benefit the reliability and quality of data processing in data-intensive applications. Hadoop Distributed File System (HDFS) is a typical representative of DFSs. Its internal heterogeneity and complexity as well as external disturbance contribute to HDFS's built-in features of nonlinearity as well as randomness in system level, which raises a great challenge in modeling these features. Particularly, the randomness results in the uncertainty of HDFS performance model. Due to the complex mathematical structure and parameters hardly estimated of analytical models, it is highly complicated and computationally impossible to build an explicit and precise analytical model of the randomness. The measurement-based methodology is a promising way to model HDFS performance in terms of randomness since it requires no knowledge of system's internal behaviors. In this paper, the estimation of HDFS performance models on account of the randomness is transformed to an optimization problem of finding out the real best design of performance model structure with large design space. Core ideas of ordinal optimization (OO) are introduced to solve this problem with a limited computing budget. Piecewise linear (PL) model is applied to approximate the nonlinear characteristics and randomness of HDFS performance. The experimental results show that the proposed method is effective and practical to estimate the optimal design of the PL-based performance model structure for HDFS. It not only provides a globally consistent evaluation of the design space but also guarantees the goodness of the solution with high probability. Moreover, it improves the accuracy of system model-based HDFS performance models.",10.1109/ACCESS.2019.2962724,2020,,ORDINAL OPTIMIZATION-BASED PERFORMANCE MODEL ESTIMATION METHOD FOR HDFS,
893,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid increase of internet information, personalized recommendation systems are an effective way to alleviate the information overload problem, which has attracted extensive attention in recent years. The traditional collaborative filtering utilizes matrix factorization methods to learn hidden feature representations of users and/or items. With deep learning achieved good performance in representation learning, the autoencoder model is widely applied in recommendation systems for the advantages of fast convergence and no label requirement. However, the previous recommendation systems may take the reconstruction output of an autoencoder as the prediction of missing values directly, which may deteriorate their performance and cause unsatisfactory results of recommendation. In addition, the parameters of an autoencoder need to be pre-trained ahead, which greatly increases the time complexity. To address these problems, in this paper, we propose a Hybrid Collaborative Recommendation method via Dual-Autoencoder (HCRDa). More specifically, firstly, a novel dual-autoencoder is utilized to simultaneously learn the feature representations of users and items in our HCRDa, which obviously reduces time complexity. Secondly, embedding matrix factorization into the training process of the autoencoder further improves the quality of hidden features for users and items. Finally, additional attributes of users and items are utilized to alleviate the cold start problem and to make hybrid recommendations. Comprehensive experiments on several real-world data sets demonstrate the effectiveness of our proposed method in comparison with several state-of-the-art methods.",10.1109/ACCESS.2020.2979255,2020,,HYBRID COLLABORATIVE RECOMMENDATION VIA DUAL-AUTOENCODER,
894,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Particle swarm optimization (PSO) algorithms have low-quality initial particle swarm, which is generated by a random method when handling the problem of task scheduling in networked data centres. Such algorithms also fall easily into local optimum when searching for the optimal solution. To address these problems, this study proposes combining opposition-based learning (OBL) and tentative perception (TP) with PSO; the proposed method is called OBL-TP-PSO. This algorithm uses reverse learning to generate the initial population, such that the quality of the initial particle swarm can be improved. Before the particle speed and location are updated, the TP method is used to search for the individual optimum around each particle, thereby reducing the possibility of missing the potential optimal solution during the process of searching. In this manner, the problem in which the PSO algorithm easily falls into the local optimal is effectively solved. To evaluate the performance of the proposed algorithm, simulation experiments are performed on CloudSim toolkit. Experimental results show that in comparison with other algorithms (namely, Min-Min, Max-Min and PSO algorithm), the proposed OBL-TP-PSO algorithm has better performance in terms of the total execution time, load balancing and quality of service.",10.1109/ACCESS.2020.2981972,2020,,IMPROVED PSO ALGORITHM INTEGRATED WITH OPPOSITION-BASED LEARNING AND TENTATIVE PERCEPTION IN NETWORKED DATA CENTRES,
895,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As an important tool of social network analysis, network representation learning also called network embedding maps the network to a latent space and learns low-dimensional and dense real vectors of nodes, while preserving the structure and internal attributes of network. The learned representations or embedding vectors can be used for node clustering, link prediction, network visualization and other tasks for network analysis. Most of the existing network representation learning algorithms mainly focus on the preservation of micro or macro network structure, ignoring the mesoscopic community structure information. Although a few network embedding methods are proposed to preserve the community structure, they all ignore the prior information about communities. Inspired by the semi-supervised community detection in complex networks, in this article, a novel Semi-Supervised DeepWalk method(SSDW) is proposed for network representation learning, which successfully preserves the community structure of network in the embedding space. Specifically, a semi-supervised random walk sampling method which effectively integrates the pairwise constraints is proposed. By doing so, the SSDW model can guide the transition probability in the random walk process and obtain the node context sequence in line with the prior knowledge. The experimental results on eight real networks show that comparing with the popular network embedding methods, the node representation vectors integrating pairwise constraints into the random walk process can obtain higher accuracy on node clustering task, and the results of link prediction, network visualization tasks indicate that the semi-supervised model SSDW is more discriminative than unsupervised ones.",10.1109/ACCESS.2020.3044367,2020,,THE NETWORK REPRESENTATION LEARNING ALGORITHM BASED ON SEMI-SUPERVISED RANDOM WALK,
896,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Realizing an accurate laying rate prediction based on environmental factors plays a vital role in livestock and poultry breeding. In this paper, multiple environmental factors were considered to improve the accuracy of egg production rate prediction. A method was proposed by combining the Random Forest (RF) and Long Short-Term Memory (LSTM) to analyze the impact of the external environmental factors on the laying rate. Firstly, using RF, feature importance selection was implemented on environmental factors affecting laying rate. Secondly, the extreme Gradient Boosting (XGBoost) was introduced as a comparison to evaluate the accuracy and reliability of the RF feature importance selection. Finally, by discarding the features with low importance one by one, the multi-variable RF-LSTM laying rate prediction was conducted. Experiment results showed that the proposed RF-LSTM method significantly improved the prediction accuracy on laying rate.",10.1109/ACCESS.2021.3105189,2021,,A NOVEL METHOD TO PREDICT LAYING RATE BASED ON MULTIPLE ENVIRONMENT VARIABLES,
897,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The process capability index (PCI) is widely used in an on-line quality control stage for measuring and controlling the quality level of a production process. The calculation of PCI requires a large number of samples, but in the off-line quality control stage, a certain production process in off-line quality control stage only has a few individual observations. From the perspective of quality loss and tolerance cost, this paper proposes a parameter and tolerance economic design approach for multivariate quality characteristics based on the modified PCI with individual observations. The response surface models of mean and variance are constructed using individual observations, and exponential models are fitted according to the tolerance cost data of design variables. A modified PCI is proposed with the consideration of three types of quality characteristics. The optimal design variables and tolerances are obtained by a comprehensive optimization model that is constructed based on the proposed PCI. An example of an isobutylene-isoprene rubber (IIR) inner tube is used to (i) demonstrate the implementation of our proposed approach, (ii) improve the PCI value and reflect the sensitivity of the deviation between process mean and specification, and (iii) reduce the risk of increasing cost of quality caused by replicated experimental design and some other unknown reasons.",10.1109/ACCESS.2019.2913215,2019,,PARAMETER AND TOLERANCE ECONOMIC DESIGN FOR MULTIVARIATE QUALITY CHARACTERISTICS BASED ON THE MODIFIED PROCESS CAPABILITY INDEX WITH INDIVIDUAL OBSERVATIONS,
898,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This study aims at developing a stochastic hierarchical multimodal hub location modeling framework for cargo delivery systems to capture uncertainty in hub construction cost and travel time at the strategic level. From a ring-star-star type network design perspective, a stochastic model is established to formulate this problem formally via the expected value and chance-constrained programming techniques. In particular, three types of chance constraints are proposed to ensure that the on-time delivery with pre-specified confidence levels in their respective layer networks. For normal distributions, the original stochastic model can be reformulated as a crisp equivalent mixed-integer linear programming (MILP) model by invoking the central limit theorem. Since the number of constraints and variables increases drastically with the size of cargo delivery distribution network, a memetic algorithm (MA) is designed. This algorithm incorporates genetic search and local intensification to obtain optimal/near-optimal solutions for realistic instance size within a reasonable time limit. For general distributions, it is difficult to convert the stochastic model into its deterministic counterpart. Hence, a hybrid methodology is further designed by combining the MA and Monte Carlo (MC) simulation to solve the proposed stochastic model. To demonstrate the properties of the proposed model and the performance of the designed algorithm, a series of numerical experiments are set up based on the Civil Aeronautics Board (CAB) and Turkish network data sets. Computational results indicate as the confidence level increases, the airport hubs are located further apart in the cargo delivery distribution network for gaining a greater time advantage. In addition, comparative results demonstrate that the MA algorithm proposed herein performs better than the genetic algorithm (GA) in terms of computing speed and quality of the solution.",10.1109/ACCESS.2020.2981669,2020,,STOCHASTIC HIERARCHICAL MULTIMODAL HUB LOCATION PROBLEM FOR CARGO DELIVERY SYSTEMS: FORMULATION AND ALGORITHM,
899,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the emergence of Internet of Things, the number of connected devices has been dramatically increasing, causing severe spectrum shortage problem. To fully explore the spectrum resources, big data, and cloud computing can be employed by cognitive radio networks, to make efficient use of various sensing results from different sensing sources. However, the massive growth of sensing data brings tremendous load pressure on the data center, resulting in long service response time and poor Quality of Experience. Edge computing and fog computing deal with these issues by placing computation resources at the network edge. However, compared with the data center, the capabilities at edge servers are limited. Therefore, a services routing-based caching scheme (SRCS) is proposed, which can greatly lighten the load on the data center and maintain the advantages of global intelligent computing of traditional cloud computing. Specifically, SRCS first introduces the concept of transmitting service flow. At the edge layer, data are converted to service flow by network hardware and software, thus achieving the network architecture centered on service computing. Then, SRCS proposes a service routing based on service similarity, transmits similar services through the same path, and service data are fused on the path to minimize transmission load. Moreover, SRCS caches services in content routers (CRs). When the service is requested again, CRs are used as service providers to return data, thus achieving the nearest access to the content. Both theoretical analysis and experiment results demonstrate that comparing existing schemes, SRCS improves service response time by 13.67%–51.15%, reduces transmitting data amount by 23.62%–30.3%, and makes energy consumption more balanced.",10.1109/ACCESS.2018.2815039,2018,,A SERVICES ROUTING BASED CACHING SCHEME FOR CLOUD ASSISTED CRNS,
900,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Depression disorder has become one of the major psychological diseases endangering human health. Researcher in the affective computing community is supporting the development of reliable depression severity estimation system, from multiple modalities (speech, face, text), to assist doctors in their diagnosis. However, the limited amount of annotated data has become the main bottleneck restricting the study on depression screening, especially when deep learning models are used. To alleviate this issue, in this work we propose to use Deep Convolutional Generative Adversarial Network (DCGAN) for features augmentation to improve depression severity estimation from speech. To the best of our knowledge, this approach is the first attempt to apply the Generative Adversarial Network for depression severity estimation from speech. Besides, to measure the quality of the augmented features, we propose three different measurement criteria, characterizing the spatial, frequency and representation learning of the augmented features. Finally, the augmented features are used to train depression estimation models. Experiments are carried out on speech signals from the Audio Visual Emotion Challenge (AVEC2016) depression dataset, and the relationship between the model performance and data size is explored. Our experimental results show that: 1) The combination of the three proposed evaluation criteria can effectively and comprehensively evaluate the quality of the augmented features. 2) When increasing the size of the augmented data, the performance of depression severity estimation gradually improves and the model converges to a certain stable state. 3) The proposed DCGAN based data augmentation approach effectively improves the performance of depression severity estimation, with the root mean square error (RMSE) reduced to 5.520 and mean absolute error (MAE) reduced to 4.634, which is better than most of the state of the art results on AVEC 2016.",10.1109/ACCESS.2020.2970496,2020,,FEATURE AUGMENTING NETWORKS FOR IMPROVING DEPRESSION SEVERITY ESTIMATION FROM SPEECH SIGNALS,
901,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Emerging spatial crowdsourcing (SC) provides an approach for collecting and analyzing spatiotemporal information from intelligent transportation systems. However, the exposure of massive location privacy to potential adversaries for the purpose of quality control makes workers more vulnerable. To protect workers’ location privacy, an obfuscation scheme is proposed to incorporate uncertainties into the SC quality control problem through obfuscating the standard location data in terms of both space and time. Two measures, location entropy and results accuracy, are used to evaluate the performance of location privacy protection. We theoretically and experimentally confirm the security and accuracy of the obfuscation approach. The results of experiments show that: a) hiding workers’ location from the requester reduces the quality of SC; and b) obfuscation arithmetic with appropriate obfuscation coefficients protects workers’ location privacy with little effect on SC quality. Under the protection of this obfuscation scheme, the new system provides better security and similar quality compared to the existing SC system.",10.1109/ACCESS.2019.2949409,2019,,PRESERVING LOCATION PRIVACY IN SPATIAL CROWDSOURCING UNDER QUALITY CONTROL,
902,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Insomnia is a prevalent sleep disorder that causes serious harm to individuals and society. It is closely linked to not only personal factors but also social, economic and other factors. This study explores the influencing factors and spatial differentiation of insomnia from the perspective of social media. This paper chose China's largest social media platform, Sina Weibo, as its data source. Then, based on the collected relevant data of 288 Chinese cities from 2013 to 2017, it explored the impact of economic, social, and environmental factors and an educated population on insomnia. Additionally, the importance and interaction of each influencing factor were analyzed. According to the results, the gross domestic product (GDP), proportion of households connected to the Internet and number of students in regular institutions of higher education are the major factors that influence insomnia, and their influences show obvious spatial nonstationarity. Rapid GDP growth has increased the probability of insomnia, and the positive correlation between the proportion of households connected to the internet and insomnia has strengthened annually. Although the impact of insomnia on college students decreased in some regions, the overall impact was still increasing annually, and spatial nonstationarity was obvious. Properly controlling GDP growth and unnecessary time spent online and guiding people to develop healthy Internet surfing habits and lifestyles will help improve their sleep quality. Our research results will help relevant professionals better understand the distribution of regional insomnia and provide a reference for related departments to formulate regional insomnia prevention and treatment policies.",10.1109/ACCESS.2020.2976881,2020,,SOCIAL MEDIA BIG DATA-BASED RESEARCH ON THE INFLUENCING FACTORS OF INSOMNIA AND SPATIOTEMPORAL EVOLUTION,
903,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The biggest fear when deploying machine learning models to the real world is their ability to handle the new data. This problem is significant especially in medicine, where models trained on rich high-quality data extracted from large hospitals do not scale to small regional hospitals. One of the clinical challenges addressed in this work is magnetic resonance image generalization for improved visualization and diagnosis of hip abnormalities such as femoroacetabular impingement and dysplasia. Domain Generalization (DG) is a field in machine learning that tries to solve the model's dependency on the training data by leveraging many related but different data sources. We present a new method for DG that is both efficient and fast, unlike the most current state of art methods, which add a substantial computational burden making it hard to fine-tune. Our model trains an autoencoder setting on top of the classifier, but the encoder is trained on the adversarial reconstruction loss forcing it to forget style information while extracting features useful for classification. Our approach aims to force the encoder to generate domain-invariant representations that are still category informative by pushing it in both directions. Our method has proven universal and was validated on four different benchmarks for domain generalization, outperforming state of the art on RMNIST, VLCS and IXMAS with a 0.70% increase in accuracy and providing comparable results on PACS with a 0.02% difference. Our method was also evaluated for unsupervised domain adaptation and has shown to be quite an effective method against over-fitting.",10.1109/ACCESS.2021.3066041,2021,,ADVERSARIAL RECONSTRUCTION LOSS FOR DOMAIN GENERALIZATION,
904,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The Rich Model of the Gabor filter (referred to as the GFR steganalytic feature) can detect JPEG-adaptive steganography objects. However, feature dimensionality that is too high will lead to too much computation and will correspondingly reduce the detection efficiency. To reduce the dimensionality and the operating time of GFR steganalytic features and to improve the stego image detection accuracy, this paper proposes a multi-scale feature selection method for steganalytic feature GFR. First, we use the SNR criterion to measure the uselessness of each feature component and to provide a basis for the removal of useless steganalytic feature components. Second, we improve the Relief algorithm to measure the importance of feature components in detecting stego images, which provides a basis for the selection of important feature components. Then, we set the threshold value for deleting the useless feature components, and we select the important feature components as the final feature. Finally, we conduct experiments on feature selection for GFR with high-dimensional steganalytic features, and we compared the proposed method with the Fisher-based method, the PCA-based method, the SSFC method, and the Steganalysis-α method. The results show that the method proposed in this paper is effective and fast.",10.1109/ACCESS.2020.2981738,2020,,A MULTI-SCALE FEATURE SELECTION METHOD FOR STEGANALYTIC FEATURE GFR,
905,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Rough set theory is a tool for dealing with uncertainty problems. How to measure the uncertainty of a knowledge is an important issue in the theory. However, the existing uncertainty measures may not accurately reflect the uncertainty degree. This study analyzes the causes of it and explores a reasonable solution to it. Firstly, the existing accuracy models only focuses on some factors related to the target set while neglecting its own important influence on the model. Secondly, since no one gives a clear definition of knowledge uncertainty in approximation space, it is difficult to evaluate the accuracy and rationality of a knowledge uncertainty measure. Thirdly, most uncertain measures of knowledge are constructed based on the structure of knowledge itself, while neglecting other factors in the approximation model. In view of these, we first propose a new accuracy model which fully considers the important role of the target set itself. Second, two definitions of accuracy measure of knowledge are proposed to explain what the uncertainty of a knowledge is. And then, two uncertainty measures of knowledge are proposed and a method for quickly calculating them is designed. At last, an uncertain entropy is constructed for more conveniently calculating of knowledge uncertainty.",10.1109/ACCESS.2020.2992582,2020,,ON UNCERTAINTY MEASURE ISSUES IN ROUGH SET THEORY,
906,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"It is difficult and challenging to evaluate the aesthetics quality of images from multiple angles. Since humans' perception of images comes from many factors, the integrated image aesthetic quality assessment cannot be easily summarized by few attributes. A comprehensive evaluation is supposed to predict many aesthetic attributes across not only one dataset. This requires the model to have not only high accuracy, but also strong generalization ability, resulting in a better prediction on multiple models and datasets. Recent work shows that deep convolution neural network can be used to extract image features and further evaluate the total score of images, and the method of evaluation are lacking of sufficient detailed features. In this paper, we propose a multi-task convolution neural network with more incremental features. We show the results in the way of a hexagon map, which is called aesthetic radar map. This allows the network model to fit different attributes in various datasets better.",10.1109/ACCESS.2019.2958119,2019,,INCREMENTAL LEARNING OF MULTI-TASKING NETWORKS FOR AESTHETIC RADAR MAP PREDICTION,
907,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In forthcoming years, the Internet of Things (IoT) will connect billions of smart devices generating and uploading a deluge of data to the cloud. If successfully extracted, the knowledge buried in the data can significantly improve the quality of life and foster economic growth. However, a critical bottleneck for realizing the efficient IoT is the pressure it puts on the existing communication infrastructures, requiring transfer of enormous data volumes. Aiming at addressing this problem, we propose a novel architecture dubbed Condense which integrates the IoT-communication infrastructure into the data analysis. This is achieved via the generic concept of network function computation. Instead of merely transferring data from the IoT sources to the cloud, the communication infrastructure should actively participate in the data analysis by carefully designed en-route processing. We define the Condense architecture, its basic layers, and the interactions among its constituent modules. Furthermore, from the implementation side, we describe how Condense can be integrated into the Third Generation Partnership Project (3GPP) machine type communications (MTCs) architecture, as well as the prospects of making it a practically viable technology in a short time frame, relying on network function virtualization and software-defined networking. Finally, from the theoretical side, we survey the relevant literature on computing atomic functions in both analog and digital domains, as well as on function decomposition over networks, highlighting challenges, insights, and future directions for exploiting these techniques within practical 3GPP MTC architecture.",10.1109/ACCESS.2016.2585468,2016,,CONDENSE: A RECONFIGURABLE KNOWLEDGE ACQUISITION ARCHITECTURE FOR FUTURE 5G IOT,
908,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this article, a new image encryption algorithm based on compressive sensing (CS) and M sequence is proposed to decrease the image communication load and improve the security of image communication in the internet of things. Most of the available image encryption schemes are based on chaotic systems to shuffle the image pixels. Before shuffling the image pixels, the random sequence, which is produced by a chaotic system, need to be sorted. This sorting operation is avoided by utilizing a modified linear feedback shift register (LFSR) state sequence. Then, the security of the proposed scheme is improved by combining CS with an improved 1D chaotic system, which is used to construct a measurement matrix. The computational complexity is reduced by the use of the improved 1D chaotic system. Simultaneously, the amount of image data is reduced. Simulation results and performance analyses demonstrate that the proposed encryption scheme can greatly reduce the amount of image data and has good security and robustness.",10.1109/ACCESS.2020.3043240,2020,,AN IMAGE ENCRYPTION ALGORITHM BASED ON COMPRESSIVE SENSING AND M SEQUENCE,
909,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Large-scale 3D reconstruction from imagery has received much attention from the computer vision community. However, recovering 3D structures from 2D images is a notoriously complex process that requires expertise with often limited results. This paper presents an end-to-end 3D reconstruction system that can produce high-quality 3D models from a set of unordered image collections. Our workflow is a typical 3D reconstruction architecture that consists of structure from motion (SFM), multi-view stereo (MVS), and surface reconstruction, and can automatically recover desirable 3D models without any interactive operations. Finally, a comprehensive experiment is conducted on several benchmark datasets to assess the presented system. Experimental results show that the presented system achieves significant improvements in reconstruction accuracy and completeness over the existing state-of-the-art approach.",10.1109/ACCESS.2020.3032169,2020,,AN END-TO-END APPROACH TO RECONSTRUCTING 3D MODEL FROM IMAGE SET,
910,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Near-infrared diffuse correlation tomography (DCT) is an emerging technology for non-invasive imaging of the tissue blood flow. The flow imaging quality relies on the image reconstruction algorithm, which, however, is little studied thus far. In this study, we conducted the first investigation of reconstruction algorithm impact on DCT blood flow imaging. Two reconstruction algorithms, i.e., the finite element method (FEM) representing the imaging framework of partial differential equation, and the Nth-order linear (NL) approach, representing the imaging framework of integral equation that was recently proposed by us to incorporate the tissue morphological information, were compared. Both computer simulations and phantom experiment outcomes show that the NL approach performs much better in image accuracy and homogeneity over anomaly or background, when compared with the FEM at the same source-detector configuration and spatial resolution. This study demonstrates that the DCT blood flow imaging is substantially influenced by the reconstruction algorithm, thus it has great potential in future algorithm design and optimization.",10.1109/ACCESS.2020.2973209,2020,,IMPACT OF RECONSTRUCTION ALGORITHMS ON DIFFUSE CORRELATION TOMOGRAPHY BLOOD FLOW IMAGING,
911,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As the intersection of multiple high-speed railway lines, the multi-station high-speed railway hub is the key to improve the transport efficiency of the high-speed railway network. This paper focuses on the optimization of the multi-station high-speed railway hub and models it as a train routing problem (TRP). Considering the capacity of railway infrastructures and the demand of passengers, a mixed integer linear programming model is proposed to minimize the total cost of train routes and passenger routes. The optimized train routes include the macroscopic routes between stations and the microscopic track allocation inside stations and Electric Multiple Units (EMUs) depots. A Lagrangian relaxation (LR) approach is developed to dualize the hard constraints and decompose the origin model into train and passenger subproblems, then a shortest path algorithm is designed to solve the subproblems independently. Numerical experiments based on an illustrative railway hub network and a real-world network are implemented to demonstrate the effectiveness of the model and algorithm. The solution results prove that the LR approach can obtain high-quality solutions within an acceptable computational time. Compared with the existing fixed scheme, the optimization scheme can reduce the total cost by 37.18% and utilize the railway lines and tracks more reasonably.",10.1109/ACCESS.2022.3181815,2022,,OPTIMIZING TRAIN ROUTING PROBLEM IN A MULTISTATION HIGH-SPEED RAILWAY HUB BY A LAGRANGIAN RELAXATION APPROACH,
912,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Multinational corporations have multiple databases distributed throughout their branches, which store millions of transactions per day. For business applications, identifying disjoint clusters of similar and relevant databases contributes to learning the common buying patterns among customers and also increases the profits by targeting potential clients in the future. This process is called clustering, which is an important unsupervised technique for big data mining. In this article, we present an effective approach to search for the optimal clustering of multiple transaction databases in a weighted undirected similarity graph. To assess the clustering quality, we use dual gradient descent to minimize a constrained quasi-convex loss function whose parameters will determine the edges needed to form the optimal database clusters in the graph. Therefore, finding the global minimum is guaranteed in a finite and short time compared with the existing non-convex objectives where all possible candidate clusterings are generated to find the ideal clustering. Moreover, our algorithm does not require specifying the number of clusters a priori and uses a disjoint-set forest data structure to maintain and keep track of the clusters as they are updated. Through a series of experiments on public data samples and precomputed similarity matrices, we show that our algorithm is more accurate and faster in practice than the existing clustering algorithms for multi-database mining.",10.1109/ACCESS.2021.3050404,2021,,A GRADIENT-BASED CLUSTERING FOR MULTI-DATABASE MINING,
913,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet of Things (IoT) is a domain where the transfer of big data is taking place every single second. The security of these data is a challenging task; however, security challenges can be mitigated with cryptography and steganography techniques. These techniques are crucial when dealing with user authentication and data privacy. In the proposed work, a highly secured technique is proposed using IoT protocol and steganography. This work proposes an image steganography procedure by utilizing the combination of various algorithms that build the security of the secret data by utilizing Binary bit-plane decomposition (BBPD) based image encryption technique. Thereafter a Salp Swarm Optimization Algorithm (SSOA) based adaptive embedding process is proposed to increase the payload capacity by setting different parameters in the steganographic embedding function for edge and smooth blocks. Here the SSOA algorithm is used to localize the edge and smooth blocks efficiently. Then, the hybrid Fuzzy Neural Network with a backpropagation learning algorithm is used to enhance the quality of the stego images. Then these stego images are transferred to the destination in the highly secured protocol of IoT. The proposed steganography technique shows better results in terms of security, image quality, and payload capacity in comparison with the existing state of art methods.",10.1109/ACCESS.2021.3089357,2021,,SSII: SECURED AND HIGH-QUALITY STEGANOGRAPHY USING INTELLIGENT HYBRID OPTIMIZATION ALGORITHMS FOR IOT,
914,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"5G is anticipated to embed an artificial intelligence (AI)-empowerment to adroitly plan, optimize and manage the highly complex network by leveraging data generated at different positions of the network architecture. Outages and situation leading to congestion in a cell pose severe hazard for the network. High false alarms and inadequate accuracy are the major limitations of modern approaches for the anomaly—outage and sudden hype in traffic activity that may result in congestion—detection in mobile cellular networks. This indicates wasting limited resources that ultimately leads to an elevated operational expenditure (OPEX) and also interrupting quality of service (QoS) and quality of experience (QoE). Motivated by the outstanding success of deep learning (DL) technology, our study applies it for detection of the above-mentioned anomalies and also supports mobile edge computing (MEC) paradigm in which core network (CN)’s computations are divided across the cellular infrastructure among different MEC servers (co-located with base stations), to relief the CN. Each server monitors user activities of multiple cells and utilizes  $L$ -layer feedforward deep neural network (DNN) fueled by real call detail record (CDR) dataset for anomaly detection. Our framework achieved 98.8% accuracy with 0.44% false positive rate (FPR)—notable improvements that surmount the deficiencies of the old studies. The numerical results explicate the usefulness and dominance of our proposed detector.",10.1109/ACCESS.2019.2942485,2019,,MOBILE EDGE COMPUTING-BASED DATA-DRIVEN DEEP LEARNING FRAMEWORK FOR ANOMALY DETECTION,
915,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Student performance prediction is a fundamental task in online learning systems, which aims to provide students with access to active learning. Generally, student performance prediction is achieved by tracing the evolution of each student's knowledge states via a series of learning activities. Every learning activity record has two types of feature data: student behavior and exercise features. However, most methods use features that are related to exercises, such as correctness and concepts, while other student behavior features are usually ignored. The few studies that have focused on student behavior features through subjective manual selection argue that different student behavior features can be used in an equivalent manner to predict student performance. In this paper, we assume that the integration of student behavior features and exercise features is crucial to improve the precision of prediction, and each feature has a different impact on student performance. Therefore, this paper proposes a novel framework for student performance prediction by making full use of both student behavior features and exercise features and combining the attention mechanism with the knowledge tracing model. Specifically, we first exploit machine learning to capture feature representation automatically. Then, a fusion attention mechanism based on recurrent neural network architecture is used for student performance prediction. Extensive experiments on a real-world dataset show the effectiveness and practicability of our approach. The accuracy of our method is up to 98%, which is superior to previous methods.",10.1109/ACCESS.2020.3033200,2020,,MULTIPLE FEATURES FUSION ATTENTION MECHANISM ENHANCED DEEP KNOWLEDGE TRACING FOR STUDENT PERFORMANCE PREDICTION,
916,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"We built a deep learning algorithm to predict the deterioration of health symptoms among asthmatic children between 8–12 years of age. It is based on Peak Expiratory Flow Rates (PEFR) and indoor air pollution data, as well as meteorological data collected at their indoor residences every 2 minutes using portable monitoring devices with a low-cost sensor between November 2018 and March 2019. The PEFR results collected twice a day were matched with daily PM2.5. A personalized model has been developed to predict the peak expiratory flow rate of the next day, considering indoor air quality data including PM2.5, humidity, temperature, and CO2 level in previous days. Two models were developed incorporating Indoor Air Quality (IAQ) with the PEFR-only model. The IAQ uses the daily IAQ, and 10-minute basis IAQ in predicting the future PEFR. Recurrent Neural Networks (RNN) and Deep Neural Networks (DNN) models were trained using 4 months of linked data to predict PEFR for the next days during the study period. The 10-minute RNN model was found to predict better PEFR with a Root Mean Square Error (RMSE) of 42.5 and a Mean Absolute Percentage Error (MAPE) of 14.0, as it consolidates the cumulative effects of PM2.5 concentrations over time. The highly accurate estimation showed that indoor air quality significantly affects PEFR.",10.1109/ACCESS.2022.3148294,2022,,FORECASTING THE EFFECTS OF REAL-TIME INDOOR PM2.5 ON PEAK EXPIRATORY FLOW RATES (PEFR) OF ASTHMATIC CHILDREN IN KOREA: A DEEP LEARNING APPROACH,
917,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Indoor location-based services have been widely investigated to take advantage of semantic trajectories for providing user oriented services in indoor environments. Although indoor semantic trajectories can provide seamless understanding to users regarding the provided location-based services, studies on the application of deep learning approaches for robust and valid semantic indoor localization are lacking. In this study, we combined a stacked denoising autoencoder and long short term memory technique with a rule-based refinement method applying a rule-based hidden Markov model (HMM) to perform robust and valid semantic trajectory extraction. In particular, our rule-based HMM approach incorporates a direct set of rules into HMM to resolve invalid movements of the extracted semantic trajectories and is extensible to various deep learning techniques. We compared the performance of our proposed approach with that of other cutting-edge deep learning approaches on two different real-world data sets. The experimental results demonstrate the feasibility of our proposed approach to produce more robust and valid semantic trajectories.",10.1109/ACCESS.2021.3080288,2021,,A STACKED DENOISING AUTOENCODER AND LONG SHORT-TERM MEMORY APPROACH WITH RULE-BASED REFINEMENT TO EXTRACT VALID SEMANTIC TRAJECTORIES,
918,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The classical convolution neural network architecture adheres to static declaration procedures, which means that the shape of computation is usually predefined and the computation graph is fixed. In this research, the concept of a pluggable micronetwork, which relaxes the static declaration constraint by dynamic layer configuration relay, is proposed. The micronetwork consists of several parallel convolutional layer configurations and relays only the layer settings, incurring a minimum loss. The configuration selection logic is based on the conditional computation method, which is implemented as an output layer of the proposed micronetwork. The proposed micronetwork is implemented as an independent pluggable unit and can be used anywhere on the deep learning decision surface with no or minimal configuration changes. The MNIST, FMNIST, CIFAR-10 and STL-10 datasets have been used to validate the proposed research. The proposed technique is proven to be efficient and achieves appropriate validity of the research by obtaining state-of-the-art performance in fewer iterations with wider and compact convolution models. We also naively attempt to discuss the involved computational complexities in these advanced deep neural structures.",10.1109/ACCESS.2021.3110709,2021,,PLUGGABLE MICRONETWORK FOR LAYER CONFIGURATION RELAY IN A DYNAMIC DEEP NEURAL SURFACE,
919,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the user selection phase of mobile crowdsensing, most existing incentive mechanisms focus on either single-attribute selection or random selection, which possibly lead to serious consequences such as low user enthusiasm, decreased task completion rate, and increased cost of platform consumption. To tackle these issues, in this paper, we propose a novel incentive mechanism MAIM, which is based on multi-attribute user selection and participation intention analysis function in mobile crowdsensing. In this mechanism, the sensing platform employs the analytic hierarchy process to determine the weights of three attributes: participation threshold, cost, and reputation. The weight calculation results of each sensing user with respect to each attribute are then integrated to obtain the sorted weight of each user, with which the sensing platform will then obtain the optimal user set. From the users' perspective, they can autonomously decide whether to accept task processing requests, as enabled by the participation intention analysis function, thereby voiding the absolute authority and control of the sensing platform over users and achieving a two-way selection between the sensing platform and the sensing users. Furthermore, the sensing platform establishes a score-based reputation reward to inspire active performers and utilizes a punishment mechanism to overawe malicious vandals, which substantially helps activize enthusiasm of user participation and improve sensing data quality. Simulation results indicate that the proposed MAIM has significantly improved the sensing task completion ratio and the budget surplus ratio compared with the existing incentive mechanisms in mobile crowdsensing.",10.1109/ACCESS.2018.2878761,2018,,MAIM: A NOVEL INCENTIVE MECHANISM BASED ON MULTI-ATTRIBUTE USER SELECTION IN MOBILE CROWDSENSING,
920,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper studies the line planning optimization problem based on the coordinate mode of high-speed railway (HSR) passenger trains and freight trains. The multi objective nonlinear mixed integer programming model of HSR passenger train and freight train line planning with passengers and freight is designed on the basis of comprehensive consideration of passenger and freight transport demand. Then, in order to simultaneously determine the types, origin and destination stations, operation sections, stop schemes, operation frequencies, and demand allocation of HSR passenger trains and freight trains, the model is solved iteratively using a hybrid heuristic algorithm combining a column generation algorithm and a genetic algorithm. Finally, a numerical experiment based on the operation data of China’s Dalian-Harbin HSR line is implemented to verify the effectiveness of the proposed model and algorithm, and the solution performance of the CPLEX solver and the hybrid heuristic algorithm is compared. The results show that both the CPLEX solver and the hybrid heuristic algorithm can obtain the global optimal solution set. With the expansion of the scale of the problem, the solution quality and convergence efficiency of the hybrid heuristic algorithm have significantly improved, and it can solve large-scale problems and obtain satisfactory solutions within a shorter time.",10.1109/ACCESS.2022.3210578,2022,,OPTIMIZATION OF HIGH-SPEED RAILWAY LINE PLANNING WITH PASSENGER AND FREIGHT TRANSPORT COORDINATION,
921,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid advance of the Internet of Things (IoT) and cloud computing technologies, the IoT-oriented health is expected to greatly improve the quality of healthcare service. However, data security and privacy concerns have become one of the biggest issues in smart health applications. As a potential and promising solution, attribute-based keyword search (ABKS) can provide fine-grained keyword search and access control over the encrypted data at the same time. Nevertheless, prior ABKS schemes cannot simultaneously support fine-grained, effective, and accurate data retrieval over hierarchical data. In this paper, to tackle these issues, we propose a fine-grained ranked multi-keyword search scheme over hierarchical data by leveraging ciphertext-policy hierarchical attribute-based encryption (CP-HABE) and ranked multi-keyword search (RMKS) technologies. Then, we prove that our proposed scheme is selectively secure through security analysis and we also show the practicability and feasibility of the proposed scheme by performance evaluation.",10.1109/ACCESS.2019.2928441,2019,,FINE-GRAINED RANKED MULTI-KEYWORD SEARCH OVER HIERARCHICAL DATA FOR IOT-ORIENTED HEALTH SYSTEM,
922,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the era of big data, as for an important granular computing model, rough set model is an important tool for us to deal with data. As a kind of extension of classical rough sets, multigranulation rough sets have two forms, including optimistic and pessimistic cases. However, these two models have their shortcomings, one is too loose, and the other is too strict. To overcome the above shortcomings, based on the concept of local multigranulation tolerance rough sets in set-valued information systems, the local generalized multigranulation variable precision tolerance rough sets model by introducing characteristic function is established. Then the related properties are studied and proved. In addition, we define the concepts of lower approximate quality, inner and outer importance of attribute according to different granularity structures in set-valued decision information systems because different granularity structures have different effectives on the decision classes. Finally, the local attribute reduction algorithm and the global attribute reduction algorithm of local generalized multigranulation variable precision tolerance rough sets in set-valued decision information systems are given, and the effectiveness of the algorithms is proved by using UCI data sets.",10.1109/ACCESS.2021.3124339,2021,,LOCAL GENERALIZED MULTIGRANULATION VARIABLE PRECISION TOLERANCE ROUGH SETS AND ITS ATTRIBUTE REDUCTION,
923,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In machine learning and data mining, feature selection aims to seek a compact and discriminant feature subset from the original feature space. It is usually used as a preprocessing step to improve the prediction performance, understandability, scalability, and generalization capability of classifiers. A typical gene microarray data set has the characteristics of high dimensionality, limited samples, and most irrelevant features, and these characteristics make it difficult to discover a compact set of features that really contribute to the response of the model. In this paper, a score-based criteria fusion feature selection method (SCF) is proposed for cancer prediction, and this method aims at improving the prediction performance of the classification model. The SCF method is evaluated on five open gene microarray data sets and three low-dimensional data sets, and it shows superior performance over many well-known feature selection methods when employing two classifiers SVM and KNN to measure the quality of selected features. Experiments verify that SCF is able to find more discriminative features than the competing methods and can be used as a preprocessing algorithm to combine with other methods effectively.",10.1109/ACCESS.2018.2873634,2018,,A NEW FILTER FEATURE SELECTION BASED ON CRITERIA FUSION FOR GENE MICROARRAY DATA,
924,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the further liberalization of the electricity market of China, customers’ requirements, characteristics, and distribution, as well as the quality, security, and reliability of power supplies without interruption, have received considerable attention from power companies, policymakers, and researchers. How to deeply explore the distribution characteristics of electricity customers and analyze their sensitivities to electricity blackouts has become an especially important problem. This paper takes over 0.1 billion data, collected by various smart devices of the Internet of Things in the power system of China, such as smart meters, intelligent power consumption interactive terminals, data concentrators, and other cross-platform data, for example, 95 598 telephone records, complaint information, user bills, user information, and maintenance records, as study objects, to analyze the consumption characteristics of power users. It has been found that there is a wide range of power users who pay different electricity bills; a long-tail distribution following a power law lies in the number of users versus their paid electricity bills. Meanwhile, there are two Pareto effects (2-8 rule): the number of residents and non-residents versus their electricity bills, and the number of large industrial users and general industry (business users) versus in their electricity consumption and bills. Then, a decision tree algorithm is proposed to capture the characteristics of electricity consumers and to recognize the crowd who is power blackout sensitive. The evaluation indexes and parameters of the decision tree are discussed in detail, and a comparison with other intelligent algorithms shows that the decision tree has a good recognition performance over that of others, and the characteristics used to identify the blackout-sensitive crowd is various. All the results state that except for economic factors, positive social effects should also be considered. Various marketing strategies to satisfy different requirements of power users should be provided to promote long-term relationships between the power companies and power customers.",10.1109/ACCESS.2018.2886551,2019,,ANALYSIS AND IDENTIFICATION OF POWER BLACKOUT-SENSITIVE USERS BY USING BIG DATA IN THE ENERGY SYSTEM,
925,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The development and improvement of agricultural financial information service system is of great significance to the development of rural modernization, the improvement of rural comprehensive competitiveness and the construction of new socialist countryside. The construction of rural financial information service platform is directly related to the quality of rural financial information service, and directly affects the construction of new socialist countryside. In order to solve the problems of information collection, processing and integration of rural financial information service platform in China, the diversification, personalization, timeliness and accuracy of information demand are difficult to be met, and the organization and operation mode of the platform are not perfect. In this paper, based on the intelligent sensor, the whole digital transformation is realized through the reference of big data. Based on this, this paper establishes the research model of rural financial information service platform under the smart financial environment. From the current situation of the construction and application of rural financial information service platform in China, it studies the basic situation of the construction of rural financial information service platform in China from three aspects of functional scope, service mode and operation mode, and draws the improvement conclusion. The results show that the efficiency of rural financial information service is increased by 20% after using the improved method in this paper, which has certain use value.",10.1109/ACCESS.2020.3033279,2020,,RURAL FINANCIAL INFORMATION SERVICE PLATFORM UNDER SMART FINANCIAL ENVIRONMENT,
926,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of civil aviation transportation in China, huge demand growth has broken the balance between supply and demand, resulting in airspace congestion and increasing flight delays. The delays of large airports have been increasing year by year, which has seriously affected the air travel experience of passengers. Obtaining their flight delay patterns can help identify defects in flight scheduling and airspace utilization. The investigation based on the actual flight operation data of Tianjin Binhai International Airport (TSN) is conducted, in order to capture the relationship and impact between the factors such as traffic flow direction, airline attributes and hourly average delay distribution. Furthermore, Non-negative Tensor Factorization (NTF) is applied to pattern recognition by introducing CP (CANDECOMP/PARAFAC) decomposition and Block Coordinate Descent (BCD) algorithm for selected data set. Numerical experiments show that the designed method has good performance in terms of computation speed and solution quality. Recognition results indicate the significant pattern characteristics of the Tianjin airport delay are extracted, which can provide some new perspectives for air traffic management unit to alleviate airspace congestion and improve service quality.",10.1109/ACCESS.2019.2955735,2019,,APPLICATION OF NON-NEGATIVE TENSOR FACTORIZATION FOR AIRPORT FLIGHT DELAY PATTERN RECOGNITION,
927,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, machine learning algorithms have been successfully employed to leverage the potential of identifying hidden patterns of financial market behavior and, consequently, have become a land of opportunities for financial applications such as algorithmic trading. In this paper, we propose a statistical arbitrage trading strategy with two key elements: an ensemble of regression algorithms for asset return prediction, followed by a dynamic asset selection. More specifically, we construct an extremely heterogeneous ensemble ensuring model diversity by using state-of-the-art machine learning algorithms, data diversity by using a feature selection process, and method diversity by using individual models for each asset, as well models that learn cross-sectional across multiple assets. Then, their predictive results are fed into a quality assurance mechanism that prunes assets with poor forecasting performance in the previous periods. We evaluate the approach on historical data of component stocks of the S&P500 index. By performing an in-depth risk-return analysis, we show that this setup outperforms highly competitive trading strategies considered as baselines. Experimentally, we show that the dynamic asset selection enhances overall trading performance both in terms of return and risk. Moreover, the proposed approach proved to yield superior results during both financial turmoil and massive market growth periods, and it showed to have general application for any risk-balanced trading strategy aiming to exploit different asset classes.",10.1109/ACCESS.2021.3059187,2021,,ENSEMBLING AND DYNAMIC ASSET SELECTION FOR RISK-CONTROLLED STATISTICAL ARBITRAGE,
928,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Modern trams typically run along semi-exclusive right-of-way. Although tram lanes isolate trams from other traffic in the running sections, the operation process will be affected by signal control. To improve the service quality of trams and reduce the negative impact on intersections caused by bidirectional priority requests, we propose a timetable optimization method for a single two-way tram line based on active transit signal priority strategy. Combining with the characteristics of bidirectional signal priority strategy, trams can pass through the intersections without stopping by adjusting the running times and dwell times. A multiobjective optimization model of a tram timetable is established to minimize the total travel time, dwell time increment, and negative effect of the signal priority strategy. For obtaining a timetable with equal satisfaction for the three objectives, we adopt the fuzzy mathematical programming approach to transform the problems into mixed integer linear programming (MILP) problems, which can be solved by using standard solvers. The case study of Nanjing Qilin Tram Line 1 shows that the timetable optimization method designed in this paper can effectively improve the service efficiency of trams, and reduce the negative impact of the signal priority strategy on social vehicles. These empirical findings can give us some useful insights on the optimum design of tram timetable.",10.1109/ACCESS.2019.2957437,2019,,TIMETABLE OPTIMIZATION FOR A TWO-WAY TRAM LINE WITH AN ACTIVE SIGNAL PRIORITY STRATEGY,
929,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Mobile terminal users applications, such as smartphones or laptops, have frequent computational task demanding but limited battery power. Edge computing is introduced to offload terminals' tasks to meet the quality of service requirements such as low delay and energy consumption. By offloading computation tasks, edge servers can enable terminals to collaboratively run the highly demanding applications in acceptable delay requirements. However, existing schemes barely consider the characteristics of the edge server, which leads to random assignment of tasks among servers and big tasks with high computational intensity (named as “big task”) may be assigned to servers with low ability. In this paper, a task is divided into several subtasks and subtasks are offloaded according to characteristics of edge servers, such as transmission distance and central processing unit (CPU) capacity. With this multi-subtasks-to-multi-servers model, an adaptive offloading scheme based on Hungarian algorithm is proposed with low complexity. Extensive simulations are conducted to show the efficiency of the scheme on reducing the offloading latency with low energy consumption.",10.1109/ACCESS.2019.2946683,2019,,AN ENERGY-EFFICIENT OFF-LOADING SCHEME FOR LOW LATENCY IN COLLABORATIVE EDGE COMPUTING,
930,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Despite ample research on the association between indoor air pollution and allergic disease prevalence, public health and environmental policies still lack predictive evidence for developing a preventive guideline for patients or vulnerable populations mostly due to limitation of real-time big data and model predictability. Recent popularity of IoT and machine learning techniques could provide enabling technologies for collecting real-time big data and analyzing them for more accurate prediction of allergic disease risks for evidence-based intervention, but the effort is still in its infancy. This pilot study explored and evaluated the feasibility of a deep learning algorithm for predicting asthma risk. It is based on peak expiratory flow rates (PEFR) of 14 pediatric asthma patients visiting the Korea University Medical Center and indoor particulate matter PM10 and PM2.5 concentration data collected at their residence every 10 minutes using a PM monitoring device with a low-cost sensor between September 1, 2017 and August 31, 2018. We interpolated the PEFR results collected twice a day for each patient throughout the day so that it can be matched to the PM and other weather data. The PEFR results were classified into three categories such as `Green' (normal), `Yellow' (mild to moderate exacerbation) and `Red' (severe exacerbation) with reference to their best peak flow value. Long Short-Term Memory (LSTM) model was trained using the first 10 months of the linked data and predicted asthma risk categories for the next 2 months during the study period. LSTM model is found to predict the asthma risk categories better than multinomial logistic (MNL) regression as it incorporates the cumulative effects of PM concentrations over time. Upon successful modifications of the algorithm based on a larger sample, this approach could potentially play a groundbreaking role for the scientific data-driven medical decision making.",10.1109/ACCESS.2019.2960551,2020,,PREDICTING ASTHMA ATTACKS: EFFECTS OF INDOOR PM CONCENTRATIONS ON PEAK EXPIRATORY FLOW RATES OF ASTHMATIC CHILDREN,
931,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the field of process discovery, it is worth noting that most process discovery algorithms assume that event logs are clean, i.e., event logs should not contain infrequent behaviors. However, real-life event logs often contain infrequent behaviors (i.e., outliers) and lead to quality issues of the discovered process model. On the other hand, driven by recent trends such as big data and process automation, the volume of event data is rapidly increasing: an event log may contain billions of event data. Unfortunately, some process mining algorithms and platforms may have difficulties handling such event logs. The ever-increasing size of event data and infrequent behaviors in the event log are two main challenges in the field of process discovery nowadays. However, little research has been conducted on simultaneously filtering infrequent behaviors and decreasing the size of the event log: Various filtering methods can filter infrequent behaviors, whereas the volume of the filtered log is still considerable. On the other hand, sampling methods can reduce the size of the event log, but the processed event log may still contain infrequent behaviors. Therefore, this paper proposes a technique to simultaneously filter infrequent behaviors and control the volume of input logs by capturing important behaviors and rating trace variants. Our experiments show that our approach can significantly improve the quality of the discovered process models. Furthermore, our approach can obtain a better process model from 0.001% trace variants than the complete event log and significantly improves the runtime of discovery algorithms.",10.1109/ACCESS.2021.3121997,2021,,PROCESS MODEL ENHANCEMENT THROUGH CAPTURING IMPORTANT BEHAVIORS AND RATING TRACE VARIANTS,
932,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, convolutional neural network (CNN) algorithms promote the development of stereo matching and make great progress, but some mismatches still occur in textureless, occluded and reflective regions. In feature extraction and cost aggregation, CNNs will greatly improve the accuracy of stereo matching by utilizing global context information and high-quality feature representations. In this paper, we design a novel end-to-end stereo matching algorithm named Multi-Attention Network (MAN). To obtain the global context information in detail at the pixel-level, we propose a Multi-Scale Attention Module (MSAM), combining a spatial pyramid module with an attention mechanism, when we extract the image features. In addition, we introduce a feature refinement module (FRM) and a 3D attention aggregation module (3D AAM) during cost aggregation so that the network can extract informative features with high representational ability and high-quality channel attention vectors. Finally, we obtain the final disparity through bilinear interpolation and disparity regression. We evaluate our method on the Scene Flow, KITTI 2012 and KITTI 2015 stereo datasets. The experimental results show that our method achieves state-of-the-art performance and that every component of our network is effective.",10.1109/ACCESS.2020.3003375,2020,,MULTI-ATTENTION NETWORK FOR STEREO MATCHING,
933,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart contract applications based on Ethereum blockchain have been widely used in many fields. They are developed by professional developers using specialized programming languages like solidity. It requires high requirements on knowledge of the specialized field and the proficiency in contract programming. Thus, it is hard for normal users to design a usable smart contract based on their own demands. Most current studies about smart contracts focus on the security of coding while lack of friendly tools for users to design the specialized templates of contracts coding. This paper provides a visual and user-defined smart contract designing systems. It makes the development of domain-specific smart contracts simpler and visualization for contract users. The system implements the domain-specific features extraction about the crawled data sets of smart contract programs by TF-IDF and K-means++ clustering algorithm. Then, it achieves the automatic generation of unified basic function codes by Char-RNN (improved by LSTM) based on the domain-specific features. The system adopts Google Blockly and links the generated codes with UI controls. Finally, it provides a set of specialized templates of basic functions for users to design smart contracts by the friendly interface. It reduces the difficulty and costs of contract programming. The paper offers a case study to design contracts by users. The designed contracts were validated on the existing system to implement the food trading and traders' credit evaluation. The experimental results show that the designed smart contracts achieve good integration with the existing system and they can be deployed and compiled successfully.",10.1109/ACCESS.2019.2920776,2019,,VISUAL AND USER-DEFINED SMART CONTRACT DESIGNING SYSTEM BASED ON AUTOMATIC CODING,
934,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the fast proliferation of device sensing and computing, crowed sensing has become the building block of the Internet of things. Consequently, various data collection and incentive mechanisms are investigated for people-centric services. In this paper, we have investigated the problem of privacy-aware people-centric IoT service based on a tailored auction approach. We applied a bi-tier differential privacy methodology on the data collected from crowdsensing IoT devices. A corresponding pricing scheme is also proposed to ensure the property of incentive compatibility, precise service data, and anonymized query results. Comparing to traditional privacy-aware auction schemes which only focus on the cost, our corresponding precise privacy-aware auction scheme provides a tailored IoT service based on the customers' request. The proposed trial query technique is able to provide a precise assessment of service quality, thus improves the efficiency of the people-centric IoT service. The customer could enjoy the convenience of service evaluation before making a bid, while the actual service data is anonymized to guarantee the service providers' interests. We evaluate the proposed bi-tier differential privacy schema for auction-based service by conducting extensive simulations. The experimental results show that our proposed method yields higher data utility and accuracy for the IoT service customers with privacy concerns.",10.1109/ACCESS.2021.3067138,2021,,BI-TIER DIFFERENTIAL PRIVACY FOR PRECISE AUCTION-BASED PEOPLE-CENTRIC IOT SERVICE,
935,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Prediction of quality of service (QoS) is a critical area of research for cloud service recommendation. The disadvantage of QoS values is that they are directly related to time series of service status and network condition and thus instantly vary over time. The main contribution of this paper is to consider service invocation time as a dynamic factor in the collaborative filtering model and recommend high-quality services for target user. In particular, this paper proposes a time-aware matrix factorization (TMF) model that integrates QoS time series to provide two-phase QoS predictions for cloud service recommendation. The TMF model uses an adaptive matrix factorization model on a sparse QoS dataset to predict the missing QoS values. A temporal smoothing method is then developed and applied to the predicted result to perform the time-varying QoS prediction that accounts for the dependence of QoS values at different time intervals. The numerical experiments presented are conducted to validate the accuracy of the proposed method on a public QoS dataset.",10.1109/ACCESS.2018.2883939,2018,,TIME-AWARE QOS PREDICTION FOR CLOUD SERVICE RECOMMENDATION BASED ON MATRIX FACTORIZATION,
936,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Image quality is important not only for the viewing experience, but also for the performance of image processing algorithms. Image quality assessment (IQA) has been a topic of intense research in the fields of image processing and computer vision. In this paper, we first analyze the factors that affect two-dimensional (2D) and three-dimensional (3D) image quality, and then provide an up-to-date overview on IQA for each main factor. The main factors that affect 2D image quality are fidelity and aesthetics. Another main factor that affects stereoscopic 3D image quality is visual comfort. We also describe the IQA databases and give the experimental results on representative IQA metrics. Finally, we discuss the challenges for IQA, including the influence of different factors on each other, the performance of IQA metrics in real applications, and the combination of quality assessment, restoration, and enhancement.",10.1109/ACCESS.2018.2885818,2019,,2D AND 3D IMAGE QUALITY ASSESSMENT: A SURVEY OF METRICS AND CHALLENGES,
937,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cholecystitis is a common disease with a high incidence, and attracts much attention. It not only harms human health, but also affects quality of work and life. Therefore, the choice of a suitable treatment is badly important for patients. In this paper, a novel selection model of treatments for cholecystitis based on hybrid multiple-criteria group decision-making (MCGDM), which is helpful to choose the most suitable treatment in the case of asymmetric information between doctors and patients. Subsequently, subjective and objective criteria are comprehensively taken into account in the index system of the selection model for cholecystitis, and combines 2-tuple linguistic with quantitative data analysis. Besides, the evaluation information obtained from the patient's conditions, the treatment and the hospital's medical status, etc., including real numbers, interval numbers, and linguistic labels with multi-granularity, is more complete and real. And the 2-tuple linguistic model is used to unify the non-homogeneous information, so the treatment selection is accurate and reliable. Simultaneously, for the unknown index and criteria weight, the improved entropy weight method and the BWM (best-worst-method) are utilized to figure out the index weight and criteria weight, respectively. Further, TODIM (an acronym in Portuguese for interactive and multi-criteria decision-making model) method based on the prospect theory is applied to solve the prioritization of cholecystitis treatments, and give full consideration to the decision maker of risk aversion. Eventually, an empirical study of treatment selection for cholecystitis is conducted. Sensitivity analysis and comparative analysis indicate that the proposed selection model of treatments for cholecystitis patients is reliable and effective.",10.1109/ACCESS.2019.2939211,2019,,A MULTI-CRITERIA 2-TUPLE LINGUISTIC GROUP DECISION-MAKING METHOD BASED ON TODIM FOR CHOLECYSTITIS TREATMENTS SELECTION,
938,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Context: Quality Control (QC) has been constantly an essential concern in many fields like food industry production, medical drugs, environmental protection, and so on. An odor or flavor, as a global fingerprint, can be implemented as a non-invasive mechanism for quality assurance. This computer-based approach can assure accurate detection and precise identification of the product quality or manufactured goods. Objective: This paper aims to achieve a systematic review about e-nose by introducing the achievements made by researchers in this area, to summarize their findings, to provide motivations and challenges to new researchers in the field of e-nose. Methods: The articles that were being utilized in the e-nose field were systematically achieved using three search engines: The online library of IEEE Explore, Web of Science and Science Direct for time span of 7 years (from 2013 to 2020). Both medical literature reviews and technical reviews were considered in the criteria of the research for wider understanding in the field of e-nose. The articles were categorized according to the objective of the research and projected into four classes. Upon completion of screening process 333 research papers using the exclusion and inclusion conditions, as the final set 54 articles were selected. Results: The taxonomy of this research was classified into four categories. The first one included the suggested methods that introduced the utilization of the e-nose for classification purposes (9/54 papers). The second category comprises the methods related to the development of e-nose (24/54 papers). The third one included the review studies about the e-nose (8/54 papers). The fourth group comprises comparative studies and evaluation (13/54 papers). Discussion: This systematic review contributes for a clearer understanding and a full insight in the e- nose research field by surveying and categorizing pertinent research efforts. Conclusion: This review paper will help to address the up-to-date research opportunities, challenges, problems, motivations and recommendations related to the utilization of e-nose in all fields of sciences and industries.",10.1109/ACCESS.2021.3090165,2021,,"A REVIEW ON ELECTRONIC NOSE: COHERENT TAXONOMY, CLASSIFICATION, MOTIVATIONS, CHALLENGES, RECOMMENDATIONS AND DATASETS",
939,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The application of deep learning methods to diagnose diseases has become a new research topic in the medical field. In the field of medicine, skin disease is one of the most common diseases, and its visual representation is more prominent compared with the other types of diseases. Accordingly, the use of deep learning methods for skin disease image recognition is of great significance and has attracted the attention of researchers. In this study, we review 45 research efforts on the identification of skin disease by using deep learning technology since 2016. We analyze these studies from the aspects of disease type, data set, data processing technology, data augmentation technology, model for skin disease image recognition, deep learning framework, evaluation indicators, and model performance. Moreover, we summarize the traditional and machine learning-based skin disease diagnosis and treatment methods. We also analyze the current progress in this field and predict four directions that may become the research topic in the future. Our results show that the skin disease image recognition method based on deep learning is better than those of dermatologists and other computer-aided treatment methods in skin disease diagnosis, especially the multi deep learning model fusion method has the best recognition effect.",10.1109/ACCESS.2020.3037258,2020,,DEEP LEARNING IN SKIN DISEASE IMAGE RECOGNITION: A REVIEW,
940,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This study investigated large-scale semi-supervised training (SST) to improve acoustic models for automatic speech recognition. The conventional self-training, the recently proposed committee-based SST using heterogeneous neural networks and the lattice-based SST were examined and compared. The large-scale SST was studied in deep neural network acoustic modeling with respect to the automatic transcription quality, the importance data filtering, the training data quantity and other data attributes of a large quantity of multi-genre unsupervised live data. We found that the SST behavior on large-scale ASR tasks was very different from the behavior obtained on small-scale SST: 1) big data can tolerate a certain degree of mislabeling in the automatic transcription for SST. It is possible to achieve further performance gains with more unsupervised fresh data, and even the automatic transcriptions have a certain degree of errors; 2) the audio attributes, transcription quality and importance of the fresh data are more important than the increased data quantity for large-scale SST; and 3) there are large differences in performance gains on different recognition tasks, such that the benefits highly depend on the selected data attributes of unsupervised data and the data scale of the baseline ASR system. Furthermore, we proposed a novel utterance filtering approach based on active learning to improve the data selection in large-scale SST. The experimental results showed that the SST with the proposed data filtering yields a 2-11% relative word error rate reduction on five multi-genre recognition tasks, even with the baseline acoustic model that was already well trained on a 10000-hr supervised dataset.",10.1109/ACCESS.2019.2940961,2019,,LARGE-SCALE SEMI-SUPERVISED TRAINING IN DEEP LEARNING ACOUSTIC MODEL FOR ASR,
941,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet of Things applications can greatly benefit from accurate prediction models. The performance of prediction models is highly dependent on the quantity and quality of their training data. In this paper, we investigate the creation of a dynamic ensemble from distributed deep learning models by considering the spatiotemporal patterns embedded in the training data. Our dynamic ensemble does not depend on offline configurations. Instead, it exploits the spatiotemporal patterns embedded in the training data to generate dynamic weights for the underlying weak distributed deep learners to create a stronger learner. Our evaluation experiments using three real-world datasets in the context of the smart city show that our proposed dynamic ensemble strategy leads to an improved error rate of up to 33% compared to the baseline strategy even when using31of the training data. Moreover, using only 20% of the training data, the error rate of the model slightly increased by up to 2 in terms of mean square error. This increase is 82% less than the 11.3 increase seen in the baseline model. Therefore, our approach contributes to the reduced network traffic while not hindering the accuracy significantly.",10.1109/ACCESS.2018.2877153,2018,,EXPLOITING THE SPATIO-TEMPORAL PATTERNS IN IOT DATA TO ESTABLISH A DYNAMIC ENSEMBLE OF DISTRIBUTED LEARNERS,
942,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of cloud computing and container technology, more and more applications are deployed to the cloud, and the scale of cloud platform is expanding. Due to the large number of container instances running in the platform, complex dependency relationship, fast version iteration and other characteristics, the update of business can often cause the change of the whole cloud resource environment, which triggers the repetitive scheduling problem of related tasks and affects stability of the business. In this paper, we propose a self-adapting task scheduling algorithm (ADATSA) using learning automata to solve these problems. Firstly, we design a learning automata model and objective function for the system on task scheduling problem. Then, we realize an effective reward-penalty mechanism for scheduling actions in combination with the idle state of resources and the running state of tasks in the current environment. Meanwhile, the environment is modeled by cluster, node and task, and the probability of action selected is optimized by scheduling execution, thus enhancing the adaptability to the cloud environment of the scheduling and accelerating convergence. Finally, we construct a framework of task load monitoring with buffer queue to achieve dynamic scheduling based on priority. The experimental part verifies the effectiveness of proposed algorithm with different angles such as resource imbalance degree, resource residual degree and QoS. Compared with other learning automata scheduling models such as LAEAS, non-automata technology based algorithms such as PSOS and K8S scheduling engine, ADATSA shows the better performance of environment adaptability, resource optimization efficiency and QoS in dynamic scheduling. The theoretical analysis was consistent with the experimental results.",10.1109/ACCESS.2021.3078773,2021,,A SELF-ADAPTING TASK SCHEDULING ALGORITHM FOR CONTAINER CLOUD USING LEARNING AUTOMATA,
943,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Fine-grained visual classification tasks often suffer from that the subordinate categories within a basic-level category have low inter-class discrepancy and high intra-class variances, which is still challenging research for traditional deep neural networks (DNNs). However, different models extract local parts' features in isolation and neglect the inherent correlations and distribution in high-dimensional space, which limit the single model to achieve better accuracy. In this paper, we propose a novel probability fusion decision framework (named as PFDM-Net) for fine-grained visual classification. More specifically, it first employs data-augmented tricks to enlarge the dataset and pretrain the basic VGG19 and ResNet networks on high-quality images datasets to learn common and domain knowledge simultaneously while fine-tuning with professional skill. Next, refined multiple DNNs with transfer learning are applied to design a multi-stream feature extractor, which utilizes the mixture-granularity information to exploit high-dimensionality features for distinguishing interclass discrepancy and tolerating intra-class variances. Finally, a probability fusion module equipped with gating network and probability fusion layer is developed to fuse different components model with Gaussian distribution as a unified probability representation for the ultimate fine-grained recognition. The input of this module is the various features of multi-models and the output is the fused classification probability. The end-to-end implementation of our framework contain an inner loop about the EM algorithm within an outer loop with the gradient back-propagation optimization of the whole network. Experimental results demonstrate the outperforming performance of PFDM-Net with higher classification accuracy on different fine-grained datasets compared with the state-of-the-arts methods. More discussions are provided to indicate the potential applications in combination with other work.",10.1109/ACCESS.2019.2933169,2019,,PROBABILITY FUSION DECISION FRAMEWORK OF MULTIPLE DEEP NEURAL NETWORKS FOR FINE-GRAINED VISUAL CLASSIFICATION,
944,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart search plays an important role in all walks of life, for example, according to business needs, accurate search of required knowledge from massive resources is an important way to enhance industrial intelligence. Smoothing of the language model is essential for obtaining high-quality search results because it helps to reduce mismatching and overfitting problems caused by data sparseness. Traditional smoothing methods lexically focus on the global corpus and locally cluster documents information without semantic analysis, which leads to deficiency of the semantic correlations between query statements and documents. In this paper, we propose an entity-based language model smoothing approach for smart search that uses semantic correlation and takes entities as bridges to build the entity semantic language model using a knowledge base. In this approach, entities in the documents are linked to an external knowledge base, such as Wikipedia. Then, the entity semantic language model is generated by using soft-fused and hardfused methods. A two-level merging strategy is also presented to smooth the language model according to whether a given word is semantically relevant to the document or not, which integrates the Dir-smoothing and JM-smoothing methods. Experimental results show that the smoothed language model more closely approximates the word probability distribution under the document semantic theme and more accurately estimates the relevance between query and document.",10.1109/ACCESS.2017.2788417,2018,,ENTITY-BASED LANGUAGE MODEL SMOOTHING APPROACH FOR SMART SEARCH,
945,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The dramatic increase in data rates in wireless networks has caused radio spectrum usage to be an essential and critical issue. Spectrum sharing is widely recognized as an affordable, near-term method to address this issue. This paper first characterizes the new features of spectrum sharing in future wireless networks, including heterogeneity in sharing bands, diversity in sharing patterns, crowd intelligence in sharing devices, and hyperdensification in sharing networks. Then, to harness the benefits of these unique features and promote a vision of spectrum without bounds and networks without borders, this paper introduces a new concept of the Internet of spectrum devices (IoSDs) and develops a cloud-based architecture for IoSD over future wireless networks, with the prime aim of building a bridging network among various spectrum monitoring devices and massive spectrum utilization devices, and enabling a highly efficient spectrum sharing and management paradigm for future wireless networks. Furthermore, this paper presents a systematic tutorial on the key enabling techniques of the IoSD, including big spectrum data analytics, hierarchal spectrum resource optimization, and quality of experience-oriented spectrum service evaluation. In addition, the unresolved research issues are also presented.",10.1109/ACCESS.2016.2576286,2016,,A CLOUD-BASED ARCHITECTURE FOR THE INTERNET OF SPECTRUM DEVICES OVER FUTURE WIRELESS NETWORKS,
946,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Photovoltaic (PV) systems are subject to failures during their operation due to the aging effects and external/environmental conditions. These faults may affect the different system components such as PV modules, connection lines, converters/inverters, which can lead to a decrease in the efficiency, performance, and further system collapse. Thus, a key factor to be taken into consideration in high-efficiency grid-connected PV systems is the fault detection and diagnosis (FDD). The performance of the FDD method depends mainly on the quality of the extracted features including real-time changes, phase changes, trend changes, and faulty modes. Thus, the data representation learning is the core stage of intelligent FDD techniques. Recently, due to the enhancement of computing capabilities, the increase of the big data use, and the development of effective algorithms, the deep learning (DL) tool has witnessed a great success in data science. Therefore, this paper proposes an extensive review on deep learning based FDD methods for PV systems. After a brief description of the DL-based strategies, techniques for diagnosing PV systems proposed in recent literature are overviewed and analyzed to point out their differences, advantages and limits. Future research directions towards the improvement of the performance of the DL-based FDD techniques are also discussed. This review paper aims to systematically present the development of DL-based FDD for PV systems and provide guidelines for future research in the field.",10.1109/ACCESS.2021.3110947,2021,,DEEP LEARNING-BASED FAULT DIAGNOSIS OF PHOTOVOLTAIC SYSTEMS: A COMPREHENSIVE REVIEW AND ENHANCEMENT PROSPECTS,
947,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Direct aperture optimization (DAO) is an effective method to generate high-quality intensity-modulated radiation therapy treatment plans. In generic DAO, the direction of negative gradient descent is generally used to determine the aperture shape. However, this strategy can reduce the convergence rate, especially near the optimal value. We propose aperture shape generation based on the direction of gradient descent with momentum, where column generation is implemented as carrier. During aperture shape generation of column generation, the current aperture gradient map is first calculated. Then, the gradient with momentum is calculated based on the existing gradient information. Finally, the direction of gradient descent with momentum is constructed for obtaining the deliverable aperture shape by solving the pricing problem. To verify the effectiveness of the proposed method, we conducted comparative experiments on two head and neck and two prostate tumor cases. Compared with generic column generation, the proposed method can effectively protect the organs at risk while ensuring the required dose distribution to the target. Using the proposed method, the number of apertures and optimization time can be reduced by up to 30.95 and 32.96%, respectively, compared to the conventional approach. The experimental results suggest that the proposed method can accelerate the search speed and improve the quality of treatment plans.",10.1109/ACCESS.2019.2949871,2019,,APERTURE SHAPE GENERATION BASED ON GRADIENT DESCENT WITH MOMENTUM,
948,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In intensity-modulated radiation therapy (IMRT), a network flow is adopted to solve the pricing problem of the generic column generation approach in order to obtain a deliverable aperture. However, excessive computation results from the direct use of a network flow. In addition, a decline in plan quality may result from the direct determination of the leaf position using the gradient information. To overcome these problems, a column generation approach based on region growth is proposed. The proposed method is designed to reduce the computational cost of solving the pricing problem and improve the IMRT plan quality. First, the gradients of the beamlets are obtained by an objective function constructed under the constraint conditions of the organs. Second, the gradients are transformed nonlinearly. Third, the positions of the continuous negative gradient regions in each row of the aperture are determined and stored. Fourth, these gradients are taken as a whole and added to the aperture network flow, which is solved as a shortest-path problem. Finally, the deliverable aperture is obtained and added to the treatment plan. To verify the effectiveness of the proposed method, experiments involving five five-field prostate cancer cases and five nine-field head and neck cancer cases were conducted. Compared with the generic column generation method, the dose distribution of the target is ensured by the proposed method, which also effectively protects organs at risk and reduces the running time. Specifically, in ten groups of comparative experiments, the normal tissue complication probability of the proposed method is reduced by up to 3.37%, and the maximum acceleration rate is 20.44%. According to the experimental results, the proposed method is more consistent with clinical requirements compared with the generic column generation method.",10.1109/ACCESS.2019.2896175,2019,,A COLUMN GENERATION APPROACH BASED ON REGION GROWTH,
949,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Forecasting air pollution is considered as an essential key for early warning and control management of air pollution, especially in emergency situations, where big amounts of pollutants are quickly released in the air, causing considerable damages. Predicting pollution in such situations is particularly challenging due to the strong dynamic of the phenomenon and the various spatio-temporal factors affecting air pollution dispersion. In addition, providing uncertainty estimates of prediction makes the forecasting model more trustworthy, which helps decision-makers to take appropriate actions with more confidence regarding the pollution crisis. In this study, we propose a multi-point deep learning model based on convolutional long short term memory (ConvLSTM) for highly dynamic air quality forecasting. ConvLSTM architectures combines long short term memory (LSTM) and convolutional neural network (CNN), which allows to mine both temporal and spatial data features. In addition, uncertainty quantification methods were implemented on top of our model's architecture and their performances were further excavated. We conduct extensive experimental evaluations using a real and highly dynamic air pollution data set called Fusion Field Trial 2007 (FFT07). The results demonstrate the superiority of our proposed deep learning model in comparison to state-of-the-art methods including machine and deep learning techniques. Finally, we discuss the results of the uncertainty techniques and we derive insights.",10.1109/ACCESS.2021.3052429,2021,,UNCERTAINTY-AWARE DEEP LEARNING ARCHITECTURES FOR HIGHLY DYNAMIC AIR QUALITY PREDICTION,
950,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Length of stay (LoS) in the intensive care unit (ICU) is a common outcome measure used as an indicator of both quality of care and resource use. However, the existing analysis methods of LoS are poorly interpretable and extensible, and there is controversial for the predictive performance of LoS. In this paper, the study includes data from 1,214 unplanned ICU admissions to participate in the ICU of Sichuan Provincial People’s Hospital between Dec. 11, 2015 and Dec. 6, 2018. On the basis of these data, this study creates a highly accurate and predictive model using advanced preprocessing techniques, exploratory data analysis (EDA) and least absolute shrinkage and selection operator (LASSO) algorithm. Next, this study evaluates the predictive performance of the proposed model by 10-fold cross validation and external validation method using the root mean square prediction error (RMSPE), mean absolute error (MAE), and coefficient of determination ( $R^{2}$ ). The predictive performance of the proposed model is 0.88±0.13 day for RMSPE, 0.87±0.07 day for MAE and 0.35±0.09 for  $R^{2}$ . Experimental results show that the performance of the proposed method are competitive with the state-of-the-art methods and results. Furthermore, this study explores the risk factors for ICU LoS in survivors and non-survivors and compare their predictive performance.",10.1109/ACCESS.2019.2934166,2019,,PREDICTION OF LENGTH OF STAY ON THE INTENSIVE CARE UNIT BASED ON LEAST ABSOLUTE SHRINKAGE AND SELECTION OPERATOR,
951,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The traditional K-means algorithm is very sensitive to the selection of the initial clustering point and the calculation of the distance measure, which is likely to result in the convergence of only partly optimal solutions. An improved k-means algorithm is proposed to solve the problem of unbalanced clustering effect caused by the fact that the first initial clustering centre falls in the non-dense region of the boundary in the initial clustering centre optimisation process. An improved k-means algorithm for initial clustering centres is proposed, namely, the optimal matching algorithm for K-means clustering, and related experimental analysis of the algorithm is carried out. The improved algorithm first selects the initial points of the traditional K-means clustering algorithm and analyses the clustering results. Then, the initial clustering centre selection and distance determination were tested and the clustering effect was evaluated by introducing the contour coefficient. Experiments on both artificial data sets and UCI data sets show that the algorithm can achieve better clustering results. The experimental results indicate that the improved algorithm has a much higher clustering quality than the traditional K-means algorithm and other improved algorithms.",10.1109/ACCESS.2020.3044069,2020,,A NOVEL EFFECTIVE DISTANCE MEASURE AND A RELEVANT ALGORITHM FOR OPTIMIZING THE INITIAL CLUSTER CENTROIDS OF K-MEANS,
952,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The purpose of selective clustering ensemble is to select a subset of base clustering partitions with predictive performance and combine these partitions into more accurate and stable final results. Traditional approaches tend to utilize the well-known validity criteria such as NMI to evaluate the quality and diversity of base clustering partitions in the selection process. However, the characteristics of the original data and the data structure itself are commonly neglected. Furthermore, the generation process of base clustering partitions is more concerned with diversity and less consideration of quality. To tackle these problems, we propose a new selective clustering ensemble scheme. In the process of generating base clustering partitions, k-means and hierarchical clustering algorithm alternately combined with random projection method are employed to generate diverse base partitions. Meanwhile, in order to improve the quality of base clustering partitions, we propose a new selection strategy for the number of clusters k in k-means algorithm. In the clustering selection process, both diversity and quality of the base clustering partitions are evaluated by multi-modal metrics from two levels: clustering labels and data structure. Based on five UCI benchmark datasets, experimental results demonstrate that the proposed method not only can generate but also select base clustering partitions with both diversity and quality. Experimental analyses show the validity and stability of the proposed scheme.",10.1109/ACCESS.2018.2877666,2018,,TWO-LEVEL-ORIENTED SELECTIVE CLUSTERING ENSEMBLE BASED ON HYBRID MULTI-MODAL METRICS,
953,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The aperture shape optimization (ASO) is a critical step in the direct aperture optimization (DAO) method. During ASO, the gradient of objective function is calculated with respect to the beamlet weight. These gradient components are directly utilized to generate the new aperture shape. In this way, the beamlet of the large positive gradient value may be grouped into the generated aperture shape. The treatment quality may be deteriorated by adding this aperture into the treatment plan. In order to overcome this drawback, a novel method based on the fuzzy enhancement was proposed to generate the aperture shape. We apply the fuzzy enhancement method to enhance the gradient map that is composed of the gradients of objective function in a beam. The enhanced gradient map was then employed to form a network flow, which was solved to generate the new aperture shape. The optimal aperture shape was generated by removing the beamlet of the large positive gradient value from the new generated aperture shape. To verify the effectiveness, the proposed method was compared with the conventional column generation (CG) method on a prostate cancer case and on a head-and-neck cancer case. Experimental results demonstrate that the new algorithm has a better performance than the CG algorithm. The proposed method can further reduce the dose delivered to the critical structures, when the similar dose coverage is delivered on the targets.",10.1109/ACCESS.2018.2849208,2018,,THE APERTURE SHAPE OPTIMIZATION BASED ON FUZZY ENHANCEMENT,
954,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cloud computing is the next generation computing model, which has a significant position in the field of scientific and business computing. By predicting cloud service's QoS in next period, it is helpful for end users to choose the most suitable cloud service that meets their needs. The underlying hardware/software resources of cloud architecture may have a certain influence on cloud service QoS. However, existing cloud service QoS prediction approaches do not take this influence into account. As these effects are real during the process of cloud service QoS prediction, ignoring the impact of these effects may create a big gap between the prediction results and the actual results. Therefore, in this paper interactive information is first used to describe the correlation between the hardware/software resources and the QoS attributes of the cloud service. Then, a Bayesian network model is established to predict cloud QoS. Bayesian network prediction reasoning algorithm is used to predict and reason about the future QoS values. A set of dedicated experiments is conducted to validate that our approach can accurately predict QoS of cloud service and the accuracy rate is better than state-of-the-art approaches.",10.1109/ACCESS.2017.2779045,2018,,A NOVEL QOS PREDICTION APPROACH FOR CLOUD SERVICES USING BAYESIAN NETWORK MODEL,
955,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the advancements in the Internet of Things (IoT), machine-to-machine communication, big-data, and the associated environment, a new model of the Industrial Internet of Things (IIoT) has emerged. The IIoT brings sensors, intelligent machines and tools, instruments, and analytics together for applications like manufacturing, robotics, and many others. Most of these applications require adaptive and autonomous behavior, Quality of Service (QoS), efficient resource allocation, and reservation. One of these crucial challenges is to build and maintain a data communication schedule. Time Slotted Channel Hopping (TSCH) based network operation promises required QoS for low-power applications and enables high reliability. 6TiSCH layer is being developed by standardizing the protocol stack to achieve industrial performance requirements by using IPv6 over IEEE802.15.4e TSCH MAC. 6TiSCH aims to manage the schedule and configure it with the topology and traffic requirements in the industrial environment. This paper proposes a novel low latency autonomous scheduling scheme for the 6TiSCH networks. It generates a segmented schedule for the network where all source nodes can send application data packets to the root node in a single slotframe. The performance of the proposed technique is compared with existing scheduling techniques. Our scheme outperforms the other techniques. The result shows that the latency is reduced up to 41% in comparison with the other scheduling schemes. The proposed scheme has a lower radio duty cycle as the node’s ON time is reduced, making it more energy efficient and reliable.",10.1109/ACCESS.2022.3188862,2022,,6TISCH LOW LATENCY AUTONOMOUS SCHEDULING FOR INDUSTRIAL INTERNET OF THINGS,
956,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Due to the availability of powerful image-editing software and the growing amount of multimedia data that is transmitted via the Internet, integrity verifications and confidentiality of the data are becoming critical issues. However, currently, the accuracy of detecting and the recovery capability of the tampered images by the existing methods through watermarking strategy is still not at the required level, especially at a higher tampered rate. This paper proposes a new blind and fragile watermarking method to detect tampering and better recovery of tampered images. To improve the quality of both the watermarked and the recovered images, a new feature extraction scheme is introduced which will produce a short but comprehensive recovery code using a new compression strategy. If a block in the image tampers, the proposed embedded feature allows the original data to be extracted for recovery. To overcome tamper coincidence, every block’s watermarked data contains not only the recovery code belonging to the block itself but also its neighbor’s data as a second layer of recovery. Various size blocks were investigated to see the performance and compare their efficiency for recovering an image after different tampering rates. The test showed the smaller block sizes may be more suitable for locating tampering, where the bigger ones are more suitable when the tampering rate is higher. The bigger block sizes in the proposed method can recover an image even after a 60% tampering rate with high quality (more than 31 dB). The experimental results prove that the proposed method can have better efficiency for detecting tampering, and recovery of the original image, compared to the relevant existing methods.",10.1109/ACCESS.2021.3072314,2021,,DETECTION AND RECOVERY OF HIGHER TAMPERED IMAGES USING NOVEL FEATURE AND COMPRESSION STRATEGY,
957,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the tremendous growth of the Internet of Things (IoT), big data, and artificial intelligence (AI), the edge computing-based service paradigm has been introduced to meet the increasing demand of applications. To provide efficient computing services at the network edge, the algorithms and applications are generally deployed based on the container-based microservice strategy, which significantly impacts the system efficiency and QoS. Considering the fundamental system uncertainties, including the dynamic workload and service rate, we investigate how to minimize the long-term system cost through the elastic microservice deployment in this paper. To this end, we formulate the container-based microservice deployment as a stochastic optimization problem to minimize the system cost while maintaining the system QoS and stability. We develop a cost-aware elastic microservice deployment algorithm to solve the formulated problem, which balances the tradeoff between system cost and QoS. Our algorithm makes the real-time decisions based on current queue backlogs and system states without predicting the future knowledge. Finally, we conduct the theoretical analysis and extensive simulations based on data traces from the ResNet-50 model-based visual recognition application. The results demonstrate that our algorithm outperforms the baseline strategies with respect to the system cost, queue backlogs, and the number of Pod replicas.",10.1109/ACCESS.2020.2998767,2020,,TOWARDS COST-EFFICIENT EDGE INTELLIGENT COMPUTING WITH ELASTIC DEPLOYMENT OF CONTAINER-BASED MICROSERVICES,
958,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, the Internet of Things (IoT) has become one of the most familiar names creating a benchmark and scaling new heights. IoT an indeed future of the communication that has transformed the objects (things) of the real world into smarter devices. With the advent of IoT technology, this decade is witnessing a transformation from traditional agriculture approaches to the most advanced ones. In perspective to the current standing of IoT in agriculture, identification of the most prominent application of IoT-based smart farming i.e. greenhouse has been highlighted and presented a systematic analysis and investigated the high quality research work for the implementation of greenhouse farming. The primary objective of this study is to propose an IoT-based network framework for a sustainable greenhouse environment and implement control strategies for efficient resources management. A rigorous discussion on IoT-based greenhouse applications, sensors/devices, and communication protocols have been presented. Furthermore, this research also presents an inclusive review of IoT-based greenhouse sensors/devices and communication protocols. Moreover, we have also presented a rigorous discussion on smart greenhouse farming challenges and security issues as well as identified future research directions to overcome these challenges. This research has explained many aspects of the technologies involved in IoT-based greenhouse and proposed network architecture, topology, and platforms. In the end, research results have been summarized by developing an IoT-based greenhouse farm management taxonomy and attacks taxonomy.",10.1109/ACCESS.2022.3204066,2022,,IOT BASED SMART GREENHOUSE FRAMEWORK AND CONTROL STRATEGIES FOR SUSTAINABLE AGRICULTURE,
959,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The rapid growth of the next-generation communication and networks is bringing video services into more pervasive environments. More and more users access and interact with video content using different devices, such as smart televisions, personal computers, tablets, smartphones, and wearable equipments. Providing heterogeneous Quality of Experience (QoE) that supports a wide variety of multimedia devices is critical to video broadcasting over the next-generation wireless network. This paper reviews practical video broadcasting technologies and examines current requirements ranging from heterogeneous devices to transmission technologies. Meanwhile, various coding methodologies, including QoE modeling, scalable compression efficiency, and flexible transmission, are also discussed. Moreover, this paper presents a typical paradigm as an example for video broadcasting with large-scale heterogeneity support, which enables QoE mapping, joint coding, flexible forward error coding, and cross-layer transmission, as well as optimal and dynamic adaptation to improve the overall receiving quality of heterogeneous devices. Finally, a brief summary of the key ideas and a discussion of interesting open areas are summarized at the end of this paper along with a future recommendation.",10.1109/ACCESS.2015.2506648,2016,,QOE-ENABLED BIG VIDEO STREAMING FOR LARGE-SCALE HETEROGENEOUS CLIENTS AND NETWORKS IN SMART CITIES,
960,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Apple quality classification is an important means to refine apple sales market and promote apple sales. At present, most of classification methods based on a convolutional neural network (CNN) depend on the quantity of training samples to get good performance. But due to the lack of large-scale public apple appearance dataset, it is a big challenge to obtain high accuracy of apple appearance quality classification with small samples. Therefore, we propose an improved method based on CNN for apple appearance, quality classification with small samples. Firstly, support vector machine (SVM) is used for image segmentation to avoid the decrease of recognition accuracy caused by environmental noise. Secondly, the segmented image data are input into deep convolutional generative adversarial networks (DCGAN) model, which is used for data expansion. Thirdly, the improved ResNet50 (Imp-ResNet50) is proposed as follows: Replace the fully-connected layer with global average pooling layer; Add the dropout algorithm and batch normalization algorithm at the fully-connected layer; Replace the activation function ReLU with Swish. Through comparative experiments with 360 apple images, we verify the performance of the proposed method including the training image quality, the running time, and classification accuracy. The result shows that the proposed method can obtain high quality training samples and reduce the running time of the method effectively. At the same time, it can realize higher classification accuracy that is up to 96.5%, which is higher than the previous classification method.",10.1109/ACCESS.2021.3077567,2021,,AN IMPROVED CNN-BASED APPLE APPEARANCE QUALITY CLASSIFICATION METHOD WITH SMALL SAMPLES,
961,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Urban planners, authorities, and numerous additional players have to deal with challenges related to the rapid urbanization process and its effect on human mobility and transport dynamics. Hence, optimize transportation systems represents a unique occasion for municipalities. Indeed, the quality of transport is linked to economic growth, and by decreasing traffic congestion, the life quality of the inhabitants is drastically enhanced. Most state-of-the-art solutions optimize traffic in specific and small zones of cities (e.g., single intersections) and cannot be used to gather insights for an entire city. Moreover, evaluating such optimized policies in a realistic way that is convincing for policy-makers can be extremely expensive. In our work, we propose a reinforcement learning frameworks to overtake these two limitations. In particular, we use human mobility data to optimize the transport dynamics of three real-world cities (i.e., Berlin, Santiago de Chile, Dakar) and a synthesized one (i.e., SynthTown). To this end, we transform the transportation dynamics' simulator MATSim into a realistic reinforcement learning environment able to optimize and evaluate transportation policies using agents that perform realistic daily activities and trips. In this way, we can assess transportation policies in a manner that is convincing for policy-makers. Finally, we develop a model-based reinforcement learning algorithm that approximates MATSim dynamics with a Partially Observable Discrete Event Decision Process (PODEDP) and, with respect to other state-of-art policy optimization techniques, can scale on big transportation data and find optimal policies also on a city-scale.",10.1109/ACCESS.2020.3024979,2020,,OPTIMIZING TRANSPORTATION DYNAMICS AT A CITY-SCALE USING A REINFORCEMENT LEARNING FRAMEWORK,
962,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of big data, artificial intelligence has provided many intelligent solutions to urban life. For instance, an image-based intelligent technology, such as image classification of diseases, is widely used in daily life. However, the image in real life is mostly unlabeled, so the performance of many image-based intelligent models shows limitations. Therefore, how to use a large amount of unlabeled image data to build an efficient and high-quality model for better urban life has been an urgent research topic. In this paper, we propose an unsupervised image feature extraction method that is referred to as a stacked multi-granularity convolution denoising auto-encoder (SMGCDAE). The algorithm is based on a convolutional neural network (CNN), yet it introduces a multi-granularity kernel. This approach resolved issues with image unicity by extracting a diverse category of high-level features. In addition, the denoising auto-encoder ensures stability and improves the classification accuracy by extracting more robust features. The algorithm was assessed using three image benchmark datasets and a series of meningitis images, achieving higher average accuracy than other methods. These results suggest that the algorithm is capable of extracting more discriminative high-level features and thus offers superior performance compared with the existing methodologies.",10.1109/ACCESS.2019.2918409,2019,,A STACKED MULTI-GRANULARITY CONVOLUTION DENOISING AUTO-ENCODER,
963,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cloud resource management research and techniques have received relevant attention in the last years. In particular, recently numerous studies have focused on determining the relationship between server-side system information and performance experience for reducing resource wastage. However, the genuine experiences of clients cannot be readily understood only by using the collected server-side information. In this paper, a cloud resource management framework with two novel turnaround time driven auto-scaling mechanisms is proposed for ensuring the stability of service performance. In the first mechanism, turnaround time monitors are deployed in the client-side instead of the more traditional server-side, and the information collected outside the server is used for driving a dynamic auto-scaling operation. In the second mechanism, a schedule-based auto scaling preconfiguration maker is designed to test and identify the amount of resources required in the cloud. The reported experimental results demonstrate that using our original framework for cloud resource management, stable service quality can be ensured and, moreover, a certain amount of quality variation can be handled in order to allow the stability of the service performance to be increased.",10.1109/ACCESS.2017.2706019,2017,,CLOUD RESOURCE MANAGEMENT WITH TURNAROUND TIME DRIVEN AUTO-SCALING,
964,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Haze is evident in most remote sensing (RS) images, particularly for the RS scenes captured in inclement weather, which severely hinders image interpretation. In this paper, two simple yet effective visibility restoration formulas are proposed for RGB-channel RS (RRS) images and multi-spectral RS (MSRS) images, respectively. More specifically, a robust gamma-correction-based dehazing model (RGDM) is first defined, which can better address the non-uniform illumination problem in hazy images. Then, the scene albedo restoration formula (SARF) used for the RRS images is obtained by imposing the existing prior knowledge on this RGDM, which enables us to simultaneously eliminate the interferences of haze and non-uniform illumination. In subsequence, according to Rayleigh’s law, an expanded restoration formula (E-SARF) is further developed for MSRS data. Using the proposed E-SARF, the spatially varying haze in each band can be thoroughly removed without using any extra information. The experiments are conducted on the challenging RRS and MSRS images, including images with non-uniform illumination, non-uniform haze distribution, and heavy haze. The results reveal that the SARF and the E-SARF are superior to most other state-of-the-art techniques in terms of both the recover quality and the implementation efficiency.",10.1109/ACCESS.2018.2889766,2019,,REMOTE SENSING IMAGE HAZE REMOVAL USING GAMMA-CORRECTION-BASED DEHAZING MODEL,
965,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Feature selection is an important research area for big data analysis. In recent years, various feature selection approaches have been developed, which can be divided into four categories: filter, wrapper, embedded, and combined methods. In the combined category, many hybrid genetic approaches from evolutionary computations combine filter and wrapper measures of feature evaluation to implement a population-based global optimization with efficient local search. However, there are limitations to existing combined methods, such as the two-stage and inconsistent feature evaluation measures, difficulties in analyzing data with high feature interaction, and challenges in handling large-scale features and instances. Focusing on these three limitations, we proposed a hybrid genetic algorithm with wrapper-embedded feature approach for selection approach (HGAWE), which combines genetic algorithm (global search) with embedded regularization approaches (local search) together. We also proposed a novel chromosome representation (intron+exon) for global and local optimization procedures in HGAWE. Based on this “intron+exon” encoding, the regularization method can select the relevant features and construct the learning model simultaneously, and genetic operations aim to globally optimize the control parameters in the above non-convex regularization. We mention that any efficient regularization approach can serve as the embedded method in HGAWE, and a hybrid L1/2 + L2 regularization approach is investigated as an example in this paper. Empirical study of the HGAWE approach on some simulation data and five gene microarray data sets indicates that it outperforms the existing combined methods in terms of feature selection and classification accuracy.",10.1109/ACCESS.2018.2818682,2018,,A HYBRID GENETIC ALGORITHM WITH WRAPPER-EMBEDDED APPROACHES FOR FEATURE SELECTION,
966,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Colleges and universities attach great importance to the quality of undergraduate teaching. To virtually guarantee the course's teaching quality, the key lies in recommending suitable teachers for the course scientifically. It is a seemingly simple but very complicated problem. Moreover, with the development of colleges and universities, new courses are continually set up, and new teachers are introduced, which further complicates the problem. The problem has not been solved well for many years. Therefore, we propose a course teacher recommendation model (FCTR-LFM) based on fuzzy clustering and the latent factor model (LFM) to solve this problem. Firstly, under the guidance of pedagogy theories and methods, we conduct quantitative modeling for teachers and courses' relevant characteristics and combine the quantitative results with historical teaching scores to establish a large-scale sparse course teaching evaluation matrix as the recommendation dataset. Next, we adopt the improved fuzzy clustering model to realize teachers' automatic clustering according to their characteristics and use the teacher cluster to reconstruct the teaching evaluation matrix, significantly reducing the dataset's size and reducing the sparsity. Then, we used the improved LFM to predict the score items in the evaluation matrix, including the missing score items. Finally, the prediction evaluation scores are sorted according to the course, and the TOP-N recommendation of the course teachers is realized. The experimental results show that FCTR-LFM can realize the prediction and recommendation well using the optimized parameters. It effectively solves the problem that there is no scientific basis for recommending suitable teachers for the course for a long time.",10.1109/ACCESS.2020.3039011,2020,,TEACHING TEACHER RECOMMENDATION METHOD BASED ON FUZZY CLUSTERING AND LATENT FACTOR MODEL,
967,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Service-oriented computing (SOC) promises a world of cooperating services loosely connected, constructing agile Web applications in heterogeneous environments conveniently. Web application interface (API) as an emerging technique attracts more and more enterprises and organizations to publish their deep computing functionalities and big data on the Internet, Web API has become the backbone to promote the development of SOC, thus forming the prosperous Web API economy. However, the number of available Web APIs on the Internet is massive and growing constantly, which causes the Web API overload problem. Quality of service (QoS) as an indicator is able to well differentiate the quality of Web APIs and has been widely applied for high quality Web API selection. Since testing QoS for massive Web APIs is resource-consuming, and the QoS performance depends on contextual information such as network and location, hence accurate QoS prediction has become very crucial for personalized Web API recommendation and high quality Web application construction. To address the above issue, this paper presents a context aware deep factorization machine model (CADFM for short) for accurate Web API QoS prediction. Specifically, we first carry out detailed data analysis using real-world QoS dataset and discover a positive relationship between QoS and contextual information, which motivates us to incorporate beneficial contexts for enhancing QoS prediction accuracy. Then, we treat QoS prediction as a regression problem and propose a context aware CADFM framework that integrates the contextual information via embedding technique. Particularly, we adopt MF and MLP for high-order and nonlinear interaction modeling, so as to learn the complex interaction between users and Web APIs accurately. Finally, the experimental results on real-world QoS dataset demonstrate that CADFM outperforms the classic and the state-of-the-art baselines, thereby generating the most accurate QoS predictions and increasing the revenue of Web APIs recommendation.",10.1109/ACCESS.2020.3022891,2020,,CONTEXTS ENHANCE ACCURACY: ON MODELING CONTEXT AWARE DEEP FACTORIZATION MACHINE FOR WEB API QOS PREDICTION,
968,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"For the zero-shot image classification without intersection between training and testing sets, the high-quality representation of image attributes and features plays a key role to improve the classification performance. In order to overcome the limitations related to insufficient attribute and feature expression in zero-shot image classification, we propose a broad attribute prediction model with enhanced attribute and feature (EAF-BAP) based on broad learning and elastic net constraint. Firstly, the EAF-BAP enhances pre-defined attributes by elastic net constraint to obtain hybrid attributes, which effectively improves the finiteness of semantic attributes. Secondly, the enhanced features are constructed by broad learning to increase the discrimination ability of features in different classes. Meanwhile, the broad learning is employed to train multiple attribute classifiers synchronously, which is more efficient compared to traditional support vector machines. Finally, the similarity between predicted attributes and hybrid attributes in testing classes is calculated by Manhattan distance, which is further used to implement image classification. Experiments on both AwA and Shoes datasets show that the proposed EAF-BAP model is capable of improving the accuracy of zero-shot image classification efficiently.",10.1109/ACCESS.2019.2938349,2019,,BROAD ATTRIBUTE PREDICTION MODEL WITH ENHANCED ATTRIBUTE AND FEATURE,
969,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Panoramic video with its flawless immersive tele-presence is considered to be the near-future video format of choice since they carry 360 degree coverage of the designated scenes. However, the viewers may focus their specific attention on perfectly lip-synchronized video as part of the panoramic video scene, hence only have a peripheral vision of the remaining parts of a frame. Therefore, it is intuitive to allocate stronger protection to the panoramic video region of interest. As a solution, we propose Region of Interest Aware Unequal Error Protection (ROI-UEP) for wireless transmission of high-efficiency video code (HEVC) sequences. Specifically, the ROI of a panoramic frame may be deemed to be within the 120° angular range of the viewing center, which can be estimated from the viewing trajectory of a head mounted display. Then, the most appropriate unequal forward error correction (FEC) coding rates will be found for the ROI signals by minimizing the expected video distortion. Moreover, the so-called weighted peak signal-to-noise ratio (WPSNR) is proposed for evaluating the quality of the reconstructed panoramic video, where the weights of pixels are taken into account for calculating the distortion caused by the related pixels. Our simulation results show that the ROI based equal error protection (ROI-EEP) scheme substantially outperforms the EEP by a WPSNR of more than 10 dB, while the ROI-UEP scheme further improves its ROI-EEP counterpart by a WPSNR of 9.4 dB at a channel Eb/N0 of 6 dB.",10.1109/ACCESS.2019.2921880,2019,,UNEQUAL ERROR PROTECTION AIDED REGION OF INTEREST AWARE WIRELESS PANORAMIC VIDEO,
970,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Passengers on metro platforms can board a train only when the train has surplus capacity and the dwell time is sufficient, while the latter condition is omitted in previous studies. Taking into account the impacts of train capacity and dwell time on passengers boarding, this study develops a model on optimizing metro timetable to reduce passenger travel time and metro operating cost, through regulating trains' inter-station run-time, dwell time and headway. The NSGA-II algorithm is employed to obtain the near-optimal Pareto Frontier of the proposed model. To address insufficient dwell time scheduled in the timetable, three operating strategies are proposed and compared: a. sticking to nominal timetable; b. extending dwell time only; c. extending dwell time and recovering delay as soon as possible by compressing train inter-station run-time. Case studies on real-life metro line prove that some passengers cannot board the train during peak hours due to insufficient dwell time. In this context, strategy a brings low-quality service because passengers are stranded at platform even though the train has surplus capacity. In contrast, more passengers can board the train with strategies b and c because dwell time is extended for passengers' boarding when train has surplus capacity. Compared to strategy b, strategy c reduces the average in-vehicle time of passengers by 2.5% through compressing inter-station run-time to recover the delay. The timetable optimized based on strategy c saves total travel time of passengers by 3.1% without increasing operating cost when compared to the practical timetable.",10.1109/ACCESS.2020.3004274,2020,,METRO SCHEDULING TO MINIMIZE TRAVEL TIME AND OPERATING COST CONSIDERING SPATIAL AND TEMPORAL CONSTRAINTS ON PASSENGER BOARDING,
971,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, we propose a holographic zoom system based on two adjustable lenses. Different from the traditional holographic system, a digital conical lens and a liquid lens are used as the zoomable lenses. The liquid lens with large effective image aperture is designed and produced by a 3D printer. By mechanically controlling the curvature of the liquid-liquid surface, the focal length of the liquid lens can be changed easily. Compared with the other lenses, the conical lens has a larger focal depth. By encoding the phase information of the conical lens on the liquid crystal on silicon, the focal length and focal depth of the conical lens can be adjusted easily. The liquid lens and conical lens cooperate with each other so as to realize the high quality of holographic zoom projection. With such a system, the size and depth of the reconstructed image can be changed easily according to the requirement. Experimental results verify the feasibility of the proposed system.",10.1109/ACCESS.2020.2990992,2020,,HOLOGRAPHIC ZOOM SYSTEM WITH LARGE FOCAL DEPTH BASED ON ADJUSTABLE LENS,
972,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, long term evolution for railway (LTE-R) has been a promising technology to meet the growing demand for railway wireless communication. To realize the active maintenance of LTE-R base station, it is of great significance to precisely predict the communication quality (CQ) of LTE-R base station. Given that the existing LTE CQ prediction methods can not support the active maintenance of LTE-R base station. Furthermore, the LTE-R base station has its unique characteristics in time relationship and regional impact, one of the most challenging problems is to effectively integrate the temporal and spatial information to improve the effect of CQ prediction. To solve the above problems, we choose daily evolved radio access bearer (E-RAB) abnormal release ratio as the CQ indicator, and propose a new deep learning-based CQ prediction approach for LTE-R. Considering the influence of adjacent base stations, this method conducts temporal-spatial collaborative prediction on multivariate time series collected from the CQ data of these stations. First, to eliminate the negative effect of redundant variables, a new variable filter method based on max-relevance, and min-redundancy (MRMR) criterion and binary particle swarm optimization (BPSO) is proposed to select a variable set from the CQ data of related base stations. Second, a new recurrent convolutional neural network (RCNN) model with a self-attention mechanism is proposed to extract temporal-spatial features from the selected variable set. With these features, we build a collaborative prediction model for CQ prediction. Experimental results on real-world LTE-R CQ datasets demonstrate the superiority of the proposed method in CQ prediction.",10.1109/ACCESS.2020.2995478,2020,,TEMPORAL-SPATIAL COLLABORATIVE PREDICTION FOR LTE-R COMMUNICATION QUALITY BASED ON DEEP LEARNING,
973,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Blasting quality is a key factor in determining the productivity and total cost of the shaft blasting excavation construction, so it is of great engineering and theoretical importance to evaluate blasting quality rationally. The existing evaluation methods rely more on previous experience and the knowledge level of technicians, which are more subjective and cannot be judged by quantitative or unified standards, so the evaluation results have limitations. This paper proposes the Analytic Hierarchy Process (AHP) based on Particle Swarm Optimization (PSO) to obtain the weights of each index for evaluating the blasting quality of shafts, then combine expert knowledge, field engineering experience and statistical data for a comprehensive analysis to determine the quantitative interval of blasting quality evaluation index levels and construct a blasting quality evaluation index system, which makes the evaluation indexes more accurate and more in line with reality. The PSO-AHP combined with fuzzy comprehensive evaluation technique has constructed a blasting quality evaluation matrix more in line with the engineering reality and established a shaft blasting quality evaluation model adapted to different geological conditions. Finally, the established blasting quality evaluation model is combined with computer programming and artificial intelligence technology to develop a visualized shaft blasting quality intelligent evaluation system, which meets the practical needs of front-line operators in the field to evaluate the blasting quality objectively and reasonably, and achieves the accuracy, objectivity and intelligence of shaft blasting quality evaluation.",10.1109/ACCESS.2022.3176373,2022,,INTELLIGENT QUALITY EVALUATION SYSTEM FOR VERTICAL SHAFT BLASTING AND ITS APPLICATION,
974,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In view of the influence of information's “incompleteness” and “asymmetry” to supply chain operation efficiency, we make big production enterprise as the object and apply blockchain to its supply chain endogenous risk management, to research the specific operation mechanism and application value. In the operation process of big production enterprise supply chain, because of the information's asymmetry, the fraud problem will produce among the business subjects; blockchain is a decentralized distributed accounting and data storage technology, and with blockchain technology, we can resolve the business subjects' fraud problem and can provide more accurate decision information basis for each business section, and realize group decision. This paper has described the system structure and intelligent contract operation mechanism under consensus authentication of blockchain applying in big production enterprise supply chain and analyzed by the case. In view of the limitation of classical blockchain technology applying in big production enterprise supply chain, we constructed the corresponding blockchain data storage mechanism and data access mechanism. Analyzed the economic value of this paper researching from the aspects of response speed, supply accuracy, cooperation integrity, business interaction economic cost, supply quality, and supply price. This paper research will provide ideas and model structure for developing supply chain area's blockchain system and will promote the application research development of blockchain in specific area.",10.1109/ACCESS.2019.2895327,2019,,BIG PRODUCTION ENTERPRISE SUPPLY CHAIN ENDOGENOUS RISK MANAGEMENT BASED ON BLOCKCHAIN,
975,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Traditional Chinese medicine (TCM) is based on a unique disease diagnosis and treatment system that has been developed over the last 2,300 years. In the TCM, “syndrome differentiation and treatment”(SDAT) is a core method for doctors to deal with diseases. This diagnostic and therapeutic technique that infer the occurrence and the development of diseases by observing symptoms as a whole, not only has its own uniqueness but also has been recognized by the public in oriented medical fields for its clinical efficacy. With recent developments in computer science, the Internet, big data, and artificial intelligence, a study based on the SDAT algorithm has aroused much attention. This paper encompasses three stages spanning 30 years to accomplish the following: 1) the TCM data and the modern SDAT system were collated and summarized based on 35,706 reference data on the TCM, starting from the syndrome differentiation of four aspects, such as the cause, location, characteristics, and conditions of the disease (CLCC), we constructed a quantitative model of the TCM SDAT regarding the CLCC of the disease, collected the symptom information on the diagnosed subject, and transferred them to the SDAT assistant algorithm for calculation and analysis, to determine the CLCC, Based on the therapy recommended by the differentiation results in the knowledge base and the prescription and traditional Chinese medicines recommended by the therapy, any stage of all diseases could determine a syndrome type by differentiating the CLCC, we constructed the basic SDAT algorithm integrating theory, method, prescription, and medicine and realized the calculability in the TCM diagnosis and treatment process; 2) based on the SDAT algorithm, we developed the TCM doctor's workstation software and introduced it to more than 80 TCM institutions in Sichuan province, China, we collated a large-scale trove of samples of the TCM data platform that was established with more than 2.9 million TCM electronic medical records (EMRs) and reference data, and had the compliance tested and algorithm verified on the 9,300 EMRs of the common diseases in the TCM; and 3) based on the dimension reduction and degree elevation optimization of the technology with a directed graph to the basic algorithm, the algorithm complexity was reduced and the accuracy of the algorithm was improved. It was demonstrated that the coincidence rate of the basic model was 80.47% and the basic coincidence rate was 96.19%. After optimizing the basic algorithm (for example, for gastric abscess), the coincidence rate increased by 7.04%. The test results demonstrated the efficacy of the model study. This model realized a computable SDAT to specify and assist in the differentiation diagnosis and in the treatment processes of the TCM and improve the service quality of the TCM diagnosis and treatment.",10.1109/ACCESS.2018.2881535,2018,,"SYNDROME DIFFERENTIATION AND TREATMENT ALGORITHM MODEL IN TRADITIONAL CHINESE MEDICINE BASED ON DISEASE CAUSE, LOCATION, CHARACTERISTICS AND CONDITIONS",
976,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Accuracies of most fingerprinting approaches for WiFi-based indoor localization applications are affected by the qualities of fingerprint databases, which are time-consuming and labor-intensive. Recently, many methods have been proposed to reduce the localization accuracy reliance on the qualities of the established fingerprint databases. However, studies on establishing fingerprint databases are relatively rare under the condition of sparse reference points. In this paper, we propose a novel data augmenter based on the adversarial networks to build fingerprint databases with sparse reference points. Additionally, two conditions of these networks are designed to generate data effectively and stably, which are 0-1 sketch and Gaussian sketch. Based on the networks, we design two augmenters with different cyclic training strategies to evaluate the augmenting effects comparatively. Meanwhile, five quantitative evaluation metrics of the augmenters are proposed from two perspectives of the artificial experiences and the data features, and some of them are also used as the gradient penalties for generators. Finally, experiments corresponding to these metrics and localization accuracies demonstrate that the data augmenter with the 0-1 sketch adversarial network is more efficient, effective and stable totally.",10.1109/ACCESS.2020.2971269,2020,,PROGRESSIVE RSS DATA AUGMENTER WITH CONDITIONAL ADVERSARIAL NETWORKS,
977,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The recent advances in cyber-physical domains, cloud, cloudlet, and edge platforms along with the evolving Artificial Intelligence (AI) techniques, big data analytics, and cutting-edge wireless communication technologies within the Industry 4.0 (4IR) are urging mechatronics designers, practitioners, and educators to further review the ways in which mechatronics systems are perceived, designed, manufactured, and advanced. Within this scope, we introduce the service-oriented cyber-physical advanced mechatronics systems (AMSs) along with current and future challenges. The objective in AMSs is to create remarkably intelligent autonomous products by 1) forging effective sensing, self-learning, Wisdom as a Service (WaaS), Information as a Service (InaaS), precise decision making, and actuation using effective location-independent monitoring, control and management techniques with products and 2) maintaining a competitive edge through better product performances via immediate and continuous learning, while the products are being used by customers and are being produced in factories within the cycle of Automation of Everything (AoE). With the advanced wireless communication techniques and improved battery technologies, the AMSs are capable of getting independent and working with other massive AMSs to construct robust, customizable, energy-efficient, autonomous, intelligent, and immersive platforms. In this regard, rather than providing technological details, this paper implements philosophical insights into 1) how mechatronics systems are being transformed into AMSs; 2) how robust AMSs can be developed by both exploiting the wisdom created within cyber-physical smart domains in the edge and cloud platforms and incorporating all the stakeholders with diverse objectives into all phases of the product life-cycle; and 3) what essential common features AMSs should acquire to increase the efficacy of products and prolong their product life. Against this background, an AMS development framework is proposed in order to contextualize all the necessary phases of AMS development and direct all stakeholders to rivet high-quality products and services within AoE.",10.1109/ACCESS.2019.2907809,2019,,TRANSFORMATION TO ADVANCED MECHATRONICS SYSTEMS WITHIN NEW INDUSTRIAL REVOLUTION: A NOVEL FRAMEWORK IN AUTOMATION OF EVERYTHING (AOE),
978,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The daily transaction of an organization generates a vast amount of unstructured data such as invoices and purchase orders. Managing and analyzing unstructured data is a costly affair for the organization. Unstructured data has a wealth of hidden valuable information. Extracting such insights automatically from unstructured documents can significantly increase the productivity of an organization. Thus, there is a huge demand to develop a tool that can automate the extraction of key fields from unstructured documents. Researchers have used different approaches for extracting key fields, but the lack of annotated and high-quality datasets is the biggest challenge. Existing work in this area has used standard and custom datasets for extracting key fields from unstructured documents. Still, the existing datasets face some serious challenges, such as poor-quality images, domain-related datasets, and a lack of data validation approaches to evaluate data quality. This work highlights the detailed process flow for end-to-end key fields extraction from unstructured documents. This work presents a high-quality, multi-layout unstructured invoice documents dataset assessed with a statistical data validation technique. The proposed multi-layout unstructured invoice documents dataset is highly diverse in invoice layouts to generalize key field extraction tasks for unstructured documents. The proposed multi-layout unstructured invoice documents dataset is evaluated with various feature extraction techniques such as Glove, Word2Vec, FastText, and AI approaches such as BiLSTM and BiLSTM-CRF. We also present the comparative analysis of feature extraction techniques and AI approaches on the proposed multi-layout unstructured invoice document dataset. We attained the best results with BiLSTM-CRF model.",10.1109/ACCESS.2021.3096739,2021,,MULTI-LAYOUT UNSTRUCTURED INVOICE DOCUMENTS DATASET: A DATASET FOR TEMPLATE-FREE INVOICE PROCESSING AND ITS EVALUATION USING AI APPROACHES,
979,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the popularization and development of the IoT(Internet of Things), more and more data needs to be transmitted over the Internet, which leads to the deterioration of network quality. The CDN (Content Distribution Network) technology is an important theoretical model to ensure network QoS (Quality of Service). To improve the QoS, we extend current CDN system to the hierarchical CDN system, that traditional CDN system is just a special case of hierarchical CDN system. In the traditional CDN system and the hierarchical CDN system, by analyzing the bandwidth between subsystems, we found the inter-system bandwidth is the bottleneck that impedes CDN system expansion. To address this problem, a new kind of distributed system architecture is proposed in this paper. This new architecture uses broadcast channels to distribute broadcast type data and still using bidirection uni-cast channels for other type of data, so we call the new architecture as CHCDN (Channel Heterogeneous CDN) in this paper. The new architecture is analyzed and compared with the traditional CDN system architecture and hierarchical CDN system architecture. Moreover, the experimental simulation result has shown that the CHCDN system features better in real-time cache updating and features with higher data transmission efficiency than the hierarchical CDN system, which indicating that the new architecture has great potential for being widely used in distributed computing.",10.1109/ACCESS.2020.3037164,2020,,AN EFFICIENT CONTENT DISTRIBUTION NETWORK ARCHITECTURE USING HETEROGENEOUS CHANNELS,
980,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In order to enhance the efficiency and safety of production and management of modern agriculture in China, problems, such as the quality and safety of agricultural products and the pollution of the environment from agricultural activities, should be unraveled. Based on the new generation of information technology (IT), an integrated framework system platform incorporating the Internet of Things (IoT), cloud computing, data mining, and other technologies is investigated and a new proposal for its application in the field of modern agriculture is offered. The experimental framework and simulation design suggest that the basic functions of the monitoring system of the IoT for agriculture can be realized. In addition, the innovation derived from integrating different technologies plays an important role in reducing the cost of system development and ensuring its reliability as well as security.",10.1109/ACCESS.2019.2903720,2019,,INTERNET OF THINGS MONITORING SYSTEM OF MODERN ECO-AGRICULTURE BASED ON CLOUD COMPUTING,
981,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Unmanned Ariel Vehicles (UAVs) are tasked to collect sensory data which are typically retrieved after the flight. The emergence of 5G and Device-to-Device (D2D) networks enables high speed network communication for UAVs to transfer data during a flight mission instead of post flight. UAVs are now subject to constraints of area coverage, battery capacity and network quality of service, making their path planning more challenging. In this paper, we formulate the issue as a combinatorial optimization problem which minimizes the flight cost of multiple UAVs covering the entire area. We show this problem is NP-hard, therefore we propose a Particle Swarm Optimization heuristic along with path encoding and local search techniques to solve the problem. Our numerical simulations demonstrate the effectiveness of the approach and how the size of the area and D2D link affect the number of UAVs needed and their flight time.",10.1109/ACCESS.2020.3010281,2020,,UAV PATH PLANNING WITH QOS CONSTRAINT IN DEVICE-TO-DEVICE 5G NETWORKS USING PARTICLE SWARM OPTIMIZATION,
982,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Microarray technology is a popular technique that has been extensively applied in cancer diagnosis. Many studies have used high-dimensional microarray data to identify informative features to classify the types of cancer, yet numerous irrelevant features that exist in microarray data may introduce the noise and decrease classification accuracy. Regularization techniques are common methods for feature selection, which can be used to reduce irrelevant features and avoid overfitting. In recent years, different regularization methods have been proposed. Theoretically, the Lq (0 <; q <; 1) type penalty function with the lower value of q would acquire better sparse solutions. In addition, the loss function in most regression models is based on least-squares minimization. However, the least-square method is sensitive to noise and has poor robustness, especially when the error has a heavy-tailed distribution. It is well known that the least absolute deviation regression is the most common method for the robust regression, which can overcome the big noise problem. In general, there is a high level of noise in microarray data, which deter the development of microarray technology. To solve the above-mentioned problems, we propose a robust logistic regression based on the Lq (0 <; q <; 1) regularization approach, which is a feasible and effective approach for feature selection in microarray classification. The Lq (0 <; q <; 1) regularization leads to a non-convex optimization problem that is difficult to be solved. In this paper, we utilize a genetic algorithm based on the global search strategy to obtain an optimal solution.",10.1109/ACCESS.2018.2880198,2018,,ROBUST SPARSE LOGISTIC REGRESSION WITH THE  $L_{Q}$  ( $0 < \TEXT{Q} < 1$ ) REGULARIZATION FOR FEATURE SELECTION USING GENE EXPRESSION DATA,
983,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Photoacoustic imaging is a new non-destructive biomedical imaging method. When limited independent data is available, the restoration of the initial pressure rise distribution is often an ill-posed problem. In this paper, based on the study of photoacoustic effects, the sparse prior information of photoacoustic images is integrated into the reconstruction process by using the compressed sensing (CS) theory and the L2 norm optimization technique, combining the augmented Langrange weighting of the alternating direction method of multipliers (ADMM) with the total variation (TV) minimization problem, and the reconstruction artifacts are effectively eliminated. The simulation data from the real numerical model show that compared with the common time reversal algorithm, interpolation algorithm and truncated back projection algorithm, the total variational regularization method based on ADMM can effectively improve the quality of reconstructed images under the condition of limited viewing angles and incomplete projection data.",10.1109/ACCESS.2021.3104154,2021,,RESEARCH ON ADMM RECONSTRUCTION ALGORITHM OF PHOTOACOUSTIC TOMOGRAPHY WITH LIMITED SAMPLING DATA,
984,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Health 4.0 establishes a new promising vision for the healthcare industry. It creatively integrates and employ innovative technologies such as the Internet of Health Things (IoHT), medical Cyber-Physical Systems (medical CPS), health cloud, health fog, big data analytics, machine learning, blockchain, and smart algorithms. The goal is to deliver improved, value-added and cost-effective healthcare services to patients and enhance the effectiveness and efficiency or the healthcare industry. Health 4.0 (adapted from the Industry 4.0 principles) changes the healthcare business model to enhance the interactions across the healthcare clients (the patients), stakeholders, infrastructure, and value chain. This effectively will improve the quality, flexibility, productivity, cost-effectiveness, and reliability of healthcare services in addition to increasing patients’ satisfaction. However, building and utilizing healthcare applications that follow the Health 4.0 concept is a non-trivial and complex endeavor. In addition, advanced potential applications based on Health 4.0 capabilities are not yet being investigated. In this paper we define the main objectives of Health 4.0 and discuss advanced potential Health 4.0 applications. To have a clear understanding of these applications, we categorize them in 4 groups based on the primary beneficiary of these applications. Thus we have patient targeted applications, applications supporting healthcare professionals, resource management applications and high-level healthcare systems management applications. In addition, as we studied the different applications, we realized that these is a certain collection of services that these most of them need regardless of their goals or business context. Services supporting data collection and transfer, security and privacy, reliable operations are some examples. As a result we propose creating a service-oriented middleware framework to offers the common services to the applications developers and facilitate the integration of different services to build applications under the Health 4.0 umbrella.",10.1109/ACCESS.2020.3038858,2020,,HEALTH 4.0: ON THE WAY TO REALIZING THE HEALTHCARE OF THE FUTURE,
985,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In order to achieve universal and personalized cloud service choices in a social network environment, we propose a cloud service selection method based on trust and user preference clustering. The method performs a comprehensive trust evaluation, which is used to evaluate and select cloud services. Meanwhile, we propose an improved condensed hierarchical clustering method based on user preference similarity to further improve the accuracy of recommendation trust. A cloud model-based approach is used to measure similarities between users, and then a hierarchical clustering method is used to divide users into different domains according to user similarity. The final recommendation trust will be obtained, which includes the intra-domain recommendation trust and the extra-domain recommendation trust. The comprehensive trust of cloud services, which consists of direct trust and recommended trust. Simulation experiments verify the accuracy and superiority of the clustering algorithm. Experimental results show that the cloud service selection method improves the transaction success rate and enables users to select more satisfactory cloud services.",10.1109/ACCESS.2019.2934153,2019,,A CLOUD SERVICE SELECTION METHOD BASED ON TRUST AND USER PREFERENCE CLUSTERING,
986,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"It has become a strategic consensus of the international community for accelerating the deployment of 5G network. This paper presents an approach for the deployment of 5G base stations under the considerations of both the cost and the signal coverage. We formulate an optimization problem for the site selection and location of 5G macro and micro base stations. An implementation procedure is proposed in the paper for the cooperative operation and deployment scheme of optimizing the location of 5G heterogeneous base stations, which aims to optimally reduce the setup cost and strengthen the signal coverage while deploying 5G base stations. A series of numerical examples are solved in the paper to demonstrate the proposed approach, and a cost-benefit analysis is also conducted to determine the optimal deployment plan for the number of macro and micro base stations. In the conclusion, a balanced executable solution is presented to make the signal strength of all demand points in the studied 5G network reach the strongest under the budget constraint.",10.1109/ACCESS.2020.3006733,2020,,A COVERAGE-BASED LOCATION APPROACH AND PERFORMANCE EVALUATION FOR THE DEPLOYMENT OF 5G BASE STATIONS,
987,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recent technology has modeled VANET (vehicular adhoc network) communication well in terms of privileges to derive vehicular communication technologically to save time, energy, and money. Due to the increase in powerful technology in modern times, VANETs play a vital role in uplifting daily concerns across vehicles and vehicular identities. Hence, to tune VANETs to become compatible with traditional technologies and increase demand, VANETs require upgrading. The severity and frequency of unwanted occurrences have become a considerable concern for our day-to-day lives relating to vehicular position. Thus, verily updated methodologies or working procedures are needed for the future VANET interplay to eradicate such problems occurring through vehicular identities. This article outlines in technology related to VANETS, future developments, and coping issues by deriving comprehensive frameworks, workflow patterns, upgrading procedures including big data, fog computing, SDN (software defined networking), and SIoT (social Internet of Things). This article provides a high-level overview of a complete VANET upgrade solution to address future problem management issues under a range of acceptable scientific themes, indicators, and combinations.",10.1109/ACCESS.2022.3183605,2022,,A REVIEW ON VANET RESEARCH: PERSPECTIVE OF RECENT EMERGING TECHNOLOGIES,
988,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Feedback from software users, such as bug reports, is vital in the management of software projects. In GitHub, the feedback is typically expressed as new issues. Through filing issue reports, users may help identify and fix bugs, document software code, and enhance software quality via feature requests. In this paper, we aim at investigating some characteristics of issues to facilitate issue management and software management. We investigate the important degrees of behaviors that are related to issues in popular projects to assess the importance of issues in GitHub and analyze the effectiveness of issue labeling for issue handling. Then, we explore the patterns of issue commits over time in popular projects based on visual analysis and obtain the following results: we find that the behaviors that are related to issues play important roles in the GitHub. We also find that the time distribution of issue commits follows a three-period development model, which approximately corresponds to the project life cycle. These results may provide a new knowledge about issues that can help managers manage and allocate project resources more effectively and even reduce software failures.",10.1109/ACCESS.2018.2810295,2018,,EXPLORING THE CHARACTERISTICS OF ISSUE-RELATED BEHAVIORS IN GITHUB USING VISUALIZATION TECHNIQUES,
989,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"CycleGAN can realize image translation and style transferring among unpaired images. However, it will easily generate inappropriate image results when the number and shapes of objects in the style offering image and the source image are greatly different. The paper proposed an improved network, named arCycleGAN, which introduced the mechanism of attribute registration into CycleGAN to solve the problem. The arCycleGAN can transfer the freshness styles from the style offering images to the unpaired input source images. The generated target images will have the freshness attributes of the style offering images, while maintaining the shapes and key features of the input source images. The realization of mechanism of attribute registration consists of three modules. The first module is attribute recognition module, which can identify and label the attributes of objects in images. The second module is image pre-screening module, which selects appropriate image subset as screened training set from raw image set according to the attributes of the input source images. The third module is similarity matching module, which matches the images in screened training set based on the similarity. The generator and discriminator in the new network are similar to that in the CycleGAN network. Experimental results demonstrate the effectiveness and better performance of the arCycleGAN. Compared with the CycleGAN, the new network can generate more convincing images. It can generate the target images of similar quality based on a smaller training set and less training time than the original CycleGAN. For generating images of similar quality, the number of images in the required training set can be reduced by 50%, while training time is reduced by 5.8%.",10.1109/ACCESS.2021.3068094,2021,,ARCYCLEGAN: IMPROVED CYCLEGAN FOR STYLE TRANSFERRING OF FRUIT IMAGES,
990,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In services-oriented computing networks, packets in the process of routing to a data center must wait for a sufficient amount of data before service aggregation to reduce the network transmission load. However, packets must be uploaded to the data center as soon as possible to reduce delay. With the exponential growth in the number of IoT connected devices, the wait time for packets is longer at routers due to massive amounts of data, which causes a large queuing delay. If this queuing time can be utilized for service aggregation in a service-oriented computing network, the network performance will be substantially improved. Therefore, a queuing delay utilization scheme for on-path service aggregation (SAQD) is proposed in this paper. This scheme has the following innovations: 1) SAQD fully utilizes the queuing delay of packets for service aggregation, which can effectively reduce the transmission volume and communication overhead. Based on the proposed service aggregation algorithm, packets are divided into forwarding packets and aggregating packets, and the service aggregation of aggregating packets is completed by utilizing the transmission time of forwarding packets to ensure that the transmission volume and communication overhead are effectively reduced without additional latency. 2) SAQD can effectively alleviate the traffic pressure of the data center and balance the workload of routers. By the service aggregation and intranet cache of routers, some requests for the data center can be handled by routers, which reduces the traffic pressure of the data center, especially in the peak period. Compared with conventional schemes, the experimental results demonstrate that SAQD reduces the workload of the data center by 55.8%-66.26% and provides users with a better quality of experience by reducing the request response delay by 31.33%~51.41%.",10.1109/ACCESS.2019.2899402,2019,,A QUEUING DELAY UTILIZATION SCHEME FOR ON-PATH SERVICE AGGREGATION IN SERVICES-ORIENTED COMPUTING NETWORKS,
991,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Searching and mining in large graphs is critical to a variety of applications, at the core of which is the pattern matching activity. The scalable processing of large graphs requires careful distribution of graphs across clusters. Graph partitioning is the technique that divides a big graph into several non-overlapped subgraphs and assigns each subgraph to a compute node. Traditional workload agnostic partitioners aim to minimize the number of inter-partition edges using only graph topology, which, however, may not obtain the best solution if the workload exhibits skew. Some workload-aware partitioners choose to mine information from a specific workload and use it to minimize the number of inter-partition traversals during execution; however, their methods are not suitable for pattern matching applications. In this work, we propose a query-sensitive graph partitioner that aims to improve existing partitioning for a given pattern matching workload. The partitioner takes any initial partitioning as a starting point and iteratively adjusts it by exchanging chosen clusters across partitions, heuristically reducing the probability of inter-partition traversals. We determine a few implementation-irrelative factors that may increase the traversal probability of an edge and quantify them into a calculable indicator with information from query patterns and graph topology. Then, we propose an efficient algorithm to calculate the indicator and implement a graph repartitioner by combining the indicator with a greedy cluster-exchanging mechanism. Finally, we generate a large heterogeneous labeled graph with real-world data crawled from the Netease Music website and evaluate the partitioning quality of our repartitioner with a few meaningful query patterns of common topologies including line, loop and branching. Compared with a hash-based partitioning, our system can reduce the inter-partition traversals by at least 70%. Compared with the state-of-the-art graph partitioner Metis, our repartitioner can reduce the inter-partition traversals by at least 50%.",10.1109/ACCESS.2019.2960868,2019,,QUERY-SENSITIVE GRAPH PARTITIONER FOR PATTERN MATCHING APPLICATIONS,
992,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"An appropriate management of the available resources within oceans and coastal regions is vital to guarantee their sustainable development and preservation, where water quality is a key element. Leveraging on a combination of cross-disciplinary technologies including Remote Sensing (RS), Internet of Things (IoT), Big Data, cloud computing, and Artificial Intelligence (AI) is essential to attain this aim. In this paper, we review methodologies and technologies for water quality assessment that contribute to a sustainable management of marine environments. Specifically, we focus on Deep Leaning (DL) strategies for water quality estimation and forecasting. The analyzed literature is classified depending on the type of task, scenario and architecture. Moreover, several applications including coastal management and aquaculture are surveyed. Finally, we discuss open issues still to be addressed and potential research lines where transfer learning, knowledge fusion, reinforcement learning, edge computing and decision-making policies are expected to be the main involved agents.",10.1109/ACCESS.2021.3109216,2021,,SUSTAINABLE MARINE ECOSYSTEMS: DEEP LEARNING FOR WATER QUALITY ASSESSMENT AND FORECASTING,
993,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Context: Mobile application developers are getting more concerned due to the importance of quality requirements or non-functional requirements (NFR) in software quality. Developers around the globe are actively asking a question(s) and sharing solutions to the problems related to software development on Stack Overflow (SO). The knowledge shared by developers on SO contains useful information related to software development such as feature requests (functional/non-functional), code snippets, reporting bugs or sentiments. Extracting the NFRs shared by iOS developers on programming Q&A website SO has become a challenge and a less researched area. Objective: To identify and understand the real problems, needs, trends, and the critical NFRs or quality requirements discussed on Stack Overflow related to iOS mobile application development. Method: We extracted and used only the iOS posts data of SO. We applied the well-known statistical topical model Latent Dirichlet Allocation (LDA) to identify the main topics in iOS posts on SO. Then, we labeled the extracted topics with quality requirements or NFRs by using the wordlists to assess the trend, evolution, hot and unresolved NFRs in all iOS discussions. Results: Our findings revealed that the highly frequent topics the iOS developers discussed are related to usability, reliability, and functionality followed by efficiency. Interestingly, the most problematic areas unresolved are also usability, reliability, and functionality though followed by portability. Besides, the evolution trend of each of the six different quality requirements or NFRs over time is depicted through comprehensive visualization. Conclusion: Our first empirical investigation on approximately 1.5 million iOS posts and comments of SO gives insight on comprehending the NFRs in iOS application development through the lens of real-world practitioners.",10.1109/ACCESS.2019.2914429,2019,,TOWARD EMPIRICALLY INVESTIGATING NON-FUNCTIONAL REQUIREMENTS OF IOS DEVELOPERS ON STACK OVERFLOW,
994,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Limited memory bandwidth is considered as the major bottleneck in multimedia cloud computing for more and more virtual machines (VMs) of multimedia processing requiring high memory bandwidth simultaneously. Moreover, contending memory bandwidth among parallel running VMs leads to poor quality of service (QoS) of the multimedia applications, missing the deadlines of these soft real-time multimedia applications. In this paper, we present an adaptive framework, Service Maximization Optimization (SMO), which is designed to improve the QoS of the soft real-time multimedia applications in multimedia cloud computing. The framework consists of an automatic detection mechanism and an adaptive memory bandwidth control mechanism. With the automatic detection mechanism, the critical section to the multimedia application performance in the VMs is detected. Then, our adaptive memory bandwidth control mechanism adjusts the memory access rates of all the parallel running VMs to protect the QoS of the soft real-time multimedia applications. From the case studies with real-world multimedia applications, our SMO significantly improves the QoS of the soft real-time multimedia applications with a negligible penalty on system throughput.",10.1109/ACCESS.2015.2496959,2015,,AN ADAPTIVE FRAMEWORK FOR IMPROVING QUALITY OF SERVICE IN INDUSTRIAL SYSTEMS,
995,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"One of the big factors affecting yarn quality is the cotton mix. There is always a considerable variation in the fiber characteristics from one bale to another, even within the same lot. This variation will result in the yarn quality difference, which leads to many fabric defects if the bales are mixed in an uncontrolled manner. The bale management system is based on the categorization of cotton bales according to their fiber quality characteristics. It includes the measurement of the fiber characteristics concerning each bale by using a High Volume Instrument (HVI). The separation of bales into categories for cotton lay-down to achieve balanced bale mixes must be based on a robust clustering algorithm. This paper discusses the utilization of the neutrosophic classifier, for the first time, to categorize the cotton in the warehouse. Although the traditional categorizing method using fuzzy logic came out with some satisfying results, it was missing the way of excluding the outlier’s data points (off-quality bales) which can affect the fabric quality. Neutrosophic classifier deals with cotton bale’s data type by excluding some bale data points that affect the fabric quality through falsity and indeterminacy membership functions to increase the accuracy of the bale management system. Our proposed method has been tested on mill cotton data. The results have been compared with the results of the traditional fuzzy logic algorithms and revealed higher accuracy.",10.1109/ACCESS.2021.3126790,2021,,COTTON WAREHOUSING IMPROVEMENT FOR BALE MANAGEMENT SYSTEM BASED ON NEUTROSOPHIC CLASSIFIER,
996,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the advent of the era of big data, the storage and retrieval of data have become a research hotspot. Hashing methods that transform high-dimensional data into compact binary codes have received increasing attention. Recently, with the successful application of convolutional neural networks in computer vision, deep hashing methods utilize an end-to-end framework to learn feature representations and hash codes mutually, which achieve better retrieval performance than conventional hashing methods. However, deep hashing methods still face some challenges in image retrieval. Firstly, most existing deep hashing methods preserve similarity between original data space and hash coding space using loss functions with high time complexity, which cannot get a win-win situation in time and accuracy. Secondly, few existing deep hashing methods are designed for fine-grained image retrieval, which is necessary in practice. In this study, we propose a novel semantics-preserving hashing method which solves the above problems. We add a hash layer before the classification layer as a feature switch layer to guide the classification. At the same time, we replace the complicated loss with the simple classification loss, combining with quantization loss and bit balance loss to generate high-quality hash codes. Besides, we incorporate feature extractor designed for fine-grained image classification into our network for better representation learning. The results on three widely-used fine-grained image datasets show that our method is superior to other state-of-the-art image retrieval methods.",10.1109/ACCESS.2020.2970223,2020,,A NOVEL SEMANTICS-PRESERVING HASHING FOR FINE-GRAINED IMAGE RETRIEVAL,
997,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"DevOps is an emerging paradigm that reduces the barriers between developers and operations teams to offer continuous fast delivery and enable quick responses to changing requirements within the software life cycle. A significant volume of activity has been carried out in recent years with the aim of coupling DevOps stages with tools and methods to improve the quality of the produced software and the underpinning delivery methodology. While the research community has produced a sustained effort by conducting numerous studies and innovative development tools to support quality analyses within DevOps, there is still a limited cohesion between the research themes in this domain and a shortage of surveys that holistically examine quality engineering work within DevOps. In this paper, we address the gap by comprehensively surveying existing efforts in this area, categorizing them according to the stage of the DevOps lifecycle to which they primarily contribute. The survey holistically spans across all the DevOps stages, identify research efforts to improve architectural design, modeling and infrastructure-as-code, continuous-integration/continuous-delivery (CI/CD), testing and verification, and runtime management. Our analysis also outlines possible directions for future work in quality-aware DevOps, looking in particular at AI for DevOps and DevOps for AI software.",10.1109/ACCESS.2021.3064867,2021,,QUALITY-AWARE DEVOPS RESEARCH: WHERE DO WE STAND?,
998,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Multi-version optimizer (MVO) inspired by the multi-verse theory is a new optimization algorithm for challenging multiple parameter optimization problems in the real world. In this paper, a novel parallel multi-verse optimizer (PMVO) with the communication strategy is proposed. The parallel mechanism is implemented to randomly divide the initial solutions into several groups, and share the information of different groups after each fixed iteration. This can significantly promote the cooperation individual of MVO algorithm, and reduce the deficiencies that the original MVO is premature convergence, search stagnation and easily trap into local optimal search space. To confirm the performance of the proposed scheme, the PMVO algorithm was compared with the other well-known optimization algorithms, such as gray wolf optimizer (GWO), particle swarm optimization (PSO), multi-version optimizer (MVO), and parallel particle swarm optimization (PPSO) under CEC2013 test suite. The experimental results prove that the PMVO is superior to the other compared algorithms. In addition, PMVO is also applied to solve complex multilevel image segmentation problems based on minimum cross entropy thresholding. The application results appear that the proposed PMVO algorithm can achieve higher quality image segmentation compared to other similar algorithms.",10.1109/ACCESS.2020.2973411,2020,,A PARALLEL MULTI-VERSE OPTIMIZER FOR APPLICATION IN MULTILEVEL IMAGE SEGMENTATION,
999,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Identifying overlapping communities is essential for analyzing network structures, exploring the interactions of groups, studying network functions, and obtaining insight into the dynamics of networks. Many algorithms have been proposed for detecting overlapping communities but identifying the intrinsic communities is still a non-trivial problem because of the difficulties with parameter tuning, user bias criteria, and the lack of ground truth information. In this paper, we propose a new model called OCDID (Overlapping Community Detection based on Information Dynamics) to uncover the overlapping communities, which treats the network as a dynamical system that allows an individual to communicate and share information with its neighbors. The information flow in the network is controlled by the underlying topology structure (e.g., the community structure), and the community structure is also reflected by the information dynamics. Overlapping nodes act as bridges between multiple communities and the information from multiple communities flows through these nodes. Thus, the overlapping nodes can be identified by analyzing the information flow among communities. In addition, we use the monotone convergence theorem to confirm the convergence of our model. Experiments based on synthetic and real-world networks demonstrate that in most cases, our proposed approach is superior to other representative algorithms in terms of the quality of overlapping community detection.",10.1109/ACCESS.2018.2879648,2018,,OVERLAPPING COMMUNITY DETECTION BASED ON INFORMATION DYNAMICS,
1000,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Designing a system to solve school bus routing problems (SBRP), especially in a large school district, is very complex and expensive. One of the challenges resides in designing routes for the school buses when they have mixed loads, where each bus transports students for one or more schools at the same time to save the total number of buses required. This article aims to explore whether the algorithm originally developed for pickup and delivery problem with time windows (PDPTW) can be employed for solving mixed load SBRP. We present a PDPTW-based algorithm to address the mixed load SBRP focusing on minimizing the number of buses required. Our algorithm combines a record-to-record travel framework with three neighborhood operators, single paired insertion, swapping pairs between routes, and within route insertion, to improve solution iteratively. Results from implementing this algorithm show that our PDPTW-based algorithm is feasible for mixed load SBRP. Moreover, we found that guided strategy is better than random for permuting nodes that would be selected to relocate positions in a route or among routes. In addition, the results also show that the spatiotemporal connectivity index used in our algorithm can reduce the computation time needed for searching for solutions without affecting the quality of the solutions.",10.1109/ACCESS.2020.3019806,2020,,A METAHEURISTIC ALGORITHM FOR ROUTING SCHOOL BUSES WITH MIXED LOAD,
1001,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Ultrasound computed tomography (USCT) is a promising technique for breast imaging. It provides three modalities: echo image, sound speed image (SSI), and attenuation image. The echo image reveals structural details of the breast with high resolution but is not quantitative. The SSI is quantitative, but its resolution is generally lower than that of the echo image. The SSI reconstruction is an ill-posed problem, thus the Tikhonov or total variation (TV) regularization methods are generally used. Tikhonov regularization is stable, but it tends to smooth the SSI and results in low resolution. TV regularization can preserve the sharp edges and provide higher resolution, but it may result in staircase artifacts. To combine the advantages of Tikhonov and TV regularizations, this article proposes a combined regularization method using prior structural information from the echo image. The proposed method mainly includes three steps. First, the echo image is reconstructed using the synthetic aperture (SA) technique and then segmented into breast and water regions. The segmentation result is used as prior structural information. Second, the USCT sound propagation forward model was built. Finally, with a penalty term according to the prior structural information, the combined regularization method is used to reconstruct the SSI. Both simulation and ex vivo experiments were conducted for evaluation. In the simulation, the proposed method has a low root-mean-square-error (13.78 m/s), a high correlation coefficient (0.812), a high structural similarity (0.755), and a low standard deviation of water sound speed (2.33 m/s). In the ex vivo experiment, the method has a low standard deviation of water sound speed (1.44 and 3.13 m/s for small and large objects, respectively), a low contrast to noise ratio (3.09 and 5.08), and a high Dice coefficient (0.92 and 0.97). Thus, the proposed combined regularization method using prior structural information can improve reconstruction quality.",10.1109/ACCESS.2020.3000062,2020,,A COMBINED REGULARIZATION METHOD USING PRIOR STRUCTURAL INFORMATION FOR SOUND-SPEED IMAGE RECONSTRUCTION OF ULTRASOUND COMPUTED TOMOGRAPHY,
1002,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, a new scheme of reversible watermarking is proposed using a complementary embedding strategy in the spatial domain. The proposed scheme consists of two stages: horizontal direction embedding and vertical direction embedding. A complementary embedding strategy is designed to increase the embedding capacity and decrease the distortion of the watermarked image in the vertical direction embedding. Specifically, in the horizontal direction, the proposed scheme embeds one secret data bit by increasing values of pixels in even rows and decreasing values of pixels in odd rows by one. In the vertical direction, it embeds another secret data bit by decreasing values of pixels in even rows and increasing values of pixels in odd rows by one. In addition, a histogram shrinkage technique is adopted to prevent overflow and underflow problems. Experimental results demonstrate that the proposed reversible watermarking scheme outperforms state-of-the-art methods in terms of both embedding capacity and watermarked image quality.",10.1109/ACCESS.2019.2942449,2019,,NOVEL SCHEME OF REVERSIBLE WATERMARKING WITH A COMPLEMENTARY EMBEDDING STRATEGY,
1003,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As one of the most important techniques in data mining, clustering has always been highly concerned. Most clustering algorithms have encountered challenges, such as the difficulty of cluster centers selection, the artificial determination of the number of clusters K, low accuracy of clustering, and uneven clustering efficiency of different data sets. Considering the difficulty of cluster centers chosen, a new algorithm of fast selecting the initial cluster centers is proposed in this paper. Generally, cluster centers are those data points with higher density, smaller radius threshold and far away from each other, this method uses MNN (M nearest neighbors), density and distance to determine the initial cluster centers. First, the neighborhood radius r of each point is measured by MNN based on distance, and the average value of all r is marked as r̅; second, the densities ρ of each point in the region within r̅ are calculated; and then, factor f is defined to describe the probability that points become cluster centers, based on which, the initial cluster centers are determined by the candidates with bigger f . In the end, the method proposed in this paper is tested by using 12 groups of typical benchmark data sets and applied in the stellar spectral data of LAMOST survey. The experiment results compared with the other six algorithms indicate that the initial cluster centers obtained by this method are of higher quality than that of the six algorithms. Meanwhile, the initial cluster centers of spectral data are of good agreement with the actual stellar classifications.",10.1109/ACCESS.2019.2921320,2019,,A NOVEL ALGORITHM FOR INITIAL CLUSTER CENTER SELECTION,
1004,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this modernistic age of innovative technologies like big data processing, cloud computing, and Internet of things, the utilization of multimedia information is growing daily. In contrast to other forms of multimedia, videos are extensively utilized and streamed over the Internet and communication networks in numerous Internet of Multimedia Things (IoMT) applications. Consequently, there is an immense necessity to achieve secure video transmission over modern communication networks due to the third-party exploitation and falsification of transmitted and stored digital multimedia data. The present methods for secure communication of multimedia content between clouds and mobile devices have constraints in terms of processing load, memory support, data size, and battery power. These methods are not the optimum solutions for large-sized multimedia content and are not appropriate for the restricted resources of mobile devices and clouds. The High-Efficiency Video Coding (HEVC) is the latest and modern video codec standard introduced for efficiently storing and streaming of high-resolution videos with suitable size and higher quality. In this paper, a novel hybrid cryptosystem combining DNA (Deoxyribonucleic Acid) sequences, Arnold chaotic map, and Mandelbrot sets is suggested for secure streaming of compressed HEVC streams. Firstly, the high-resolution videos are encoded using the H.265/HEVC codec to achieve efficient compression performance. Subsequently, the suggested Arnold chaotic map ciphering process is employed individually on three channels (Y, U, and V) of the compressed HEVC frame. Then, the DNA encoding sequences are established on the primary encrypted frames resulted from the previous chaotic ciphering process. After that, a modified Mandelbrot set-based conditional shift process is presented to effectively introduce confusion features on the Y, U, and V channels of the resulted ciphered frames. Massive simulation results and security analysis are performed to substantiate that the suggested HEVC cryptosystem reveals astonishing robustness and security accomplishment in contrast to the literature cryptosystems.",10.1109/ACCESS.2020.3008644,2020,,A NOVEL HYBRID CRYPTOSYSTEM FOR SECURE STREAMING OF HIGH EFFICIENCY H.265 COMPRESSED VIDEOS IN IOT MULTIMEDIA APPLICATIONS,
1005,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of global economy, the sustainable use of land resources has become a key research topic in the current social and economic development. To do a good job in the sustainable use of land resources can solve such problems as waste of land resources, quality degradation, environmental damage, ecological imbalance and so on. How to realize the sustainable utilization of resources, the first thing to be solved is the sustainable monitoring of land resources. At present, many researches have been done in this field at home and abroad, but in conclusion, there are some problems, that is, the basic theory is not deep and the practical application is less. Therefore, this paper will study the application of the monitoring system of the sustainable use of soil and land resources under the support of the Internet of things big data technology, and establish a practical monitoring system of the sustainable use of land resources. The monitoring system in this paper makes full use of modern science and technology. On the basis of intelligent technology, combined with the actual situation of land resources in China, according to the practical problems, the construction principles of evaluation index system and index construction are established. In the aspect of monitoring system construction, we have greatly optimized the traditional construction method, which makes the system in this paper have better adaptability, scalability and accuracy. In order to further verify the reliability of the system, this paper carries out the performance test, accuracy test, and monitoring test in extremely harsh environment. Finally, the data show that the system can be applied to most of the land environment to monitor the sustainability of land resources.",10.1109/ACCESS.2020.3016303,2020,,INTERNET OF THINGS TECHNOLOGY IN MONITORING SYSTEM OF SUSTAINABLE USE OF SOIL AND LAND RESOURCES,
1006,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Some recent researches have shown that the energy consumption problem caused by data collection in a wireless sensor network (WSN) based on a static data collector is a main threat to the network lifetime. However, with the progress of the mobile terminal technology, the implementation of mobile data collectors (MDCs) has become more popular in large-scale WSNs, but it remains a big problem to improve the Quality of Service (QoS) criteria and minimize the energy consumption at the same time. However, most existing systems based on MDCs do not successfully strike a balance between routing energy consumption and QoS. In addition, most WSN protocols fail to maintain their impact when the network topology changes. Thus, for a dynamic WSN, it is important to support an intelligent MDC to continue data propagation despite the inevitable changes in the WSN topology. Considering all the above challenges, we propose a new intelligent MDC based on the traveling salesman problem (TSP) to determine the optimal path traveled by the MDC for energy efficiency and latency. Specifically, our proposed Mobile Data Collectors-Traveling Salesman Problem-Low Energy Adaptive Clustering Hierarchy-K-Means (MDC-TSP-LEACH-K) protocol uses K-Means and Grid clustering algorithm to decrease energy consumption in the cluster head (CH) election phase. Additionally, MDC is utilized as an intermediate between CH and the sink to further enhance the QoS of WSNs, to reduce delays while collecting data, and improve the transmission phase of the LEACH protocol.",10.1109/ACCESS.2022.3178434,2022,,"ENHANCING QOS AND RESIDUAL ENERGY BY USING OF GRID-SIZE CLUSTERING, K-MEANS, AND TSP ALGORITHMS WITH MDC IN LEACH PROTOCOL",
1007,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"We propose a novel Web services clustering framework by considering the word distribution of WSDL documents and tags. Typically, tags are annotated to Web services by users for organization. In this paper, four strategies are proposed to integrate the tagging data and WSDL documents in the process of service clustering. Tagging data is inherently uncontrolled, ambiguous, and overly personalized. Two tag recommendation approaches are proposed to improve the tagging data quality and service clustering performance. Comprehensive experiments demonstrate the effectiveness of the proposed framework using a real-world dataset.",10.1109/ACCESS.2019.2950355,2019,,EXPLOITING USER TAGGING FOR WEB SERVICE CO-CLUSTERING,
1008,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,The biggest challenge in collaborative filtering recommendation system research is data sparsity; it mainly occurs as user rates very few items from widely available options. Data Imputation techniques address the data sparsity problem by filling the missing values and then predicting the likeliness of the user. Most of the existing imputation systems assign high ratings to the items or incorporate additional information to enhance the performance of collaborative filtering recommendations. This paper proposes an association rule-based imputation method (RUBLE) to improve the top-N prediction performance of the collaborative filtering recommendation. The proposed method identifies the unfavorable items of each user using the association rule mining technique and imputes them with low values. The proposed method not only addresses the sparsity problem but also provides a better quality of recommendation by eliminating the unfavorable items in top-N predictions. Existing collaborative methods can quickly adapt to the proposed method as it is method agnostic. The experimental results show that the proposed method enhances the accuracy of the traditional recommender methods by two times on average and significantly outperforms existing imputation based approaches.,10.1109/ACCESS.2020.3008514,2020,,RULE-BASED EFFECTIVE COLLABORATIVE RECOMMENDATION USING UNFAVORABLE PREFERENCE,
1009,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The Internet of Things (IoT) provides a new paradigm for the development of heterogeneous and distributed systems, and it has increasingly become a ubiquitous computing service platform. However, due to the lack of sufficient computing and storage resources dedicated to the processing and storage of huge volumes of the IoT data, it tends to adopt a cloud-based architecture to address the issues of resource constraints. Hence, a series of challenging security and trust concerns have arisen in the cloud-based IoT context. To this end, a novel trust assessment framework for the security and reputation of cloud services is proposed. This framework enables the trust evaluation of cloud services in order to ensure the security of the cloud-based IoT context via integrating security- and reputation-based trust assessment methods. The security-based trust assessment method employs the cloud-specific security metrics to evaluate the security of a cloud service. Furthermore, the feedback ratings on the quality of cloud service are exploited in the reputation-based trust assessment method in order to evaluate the reputation of a cloud service. The experiments conducted using a synthesized dataset of security metrics and a real-world web service dataset show that our proposed trust assessment framework can efficiently and effectively assess the trustworthiness of a cloud service while outperforming other trust assessment methods.",10.1109/ACCESS.2018.2890432,2019,,ENHANCING CLOUD-BASED IOT SECURITY THROUGH TRUSTWORTHY CLOUD SERVICE: AN INTEGRATION OF SECURITY AND REPUTATION APPROACH,
1010,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The widespread deployment of deep learning models in practice necessitates an assessment of their vulnerability, particularly in security-sensitive areas. As a result, transfer-based adversarial attacks have elicited increasing interest in assessing the security of deep learning models. However, adversarial samples usually exhibit poor transferability over different models because of overfitting of the particular architecture and feature representation of a source model. To address this problem, the Intermediate Layer Attack with Attention guidance (IAA) is proposed to alleviate overfitting and enhance the black-box transferability. The IAA works on an intermediate layer  $l$  of the source model. Guided by the model’s attention (i.e., gradients) to the features of layer  $l$ , the attack algorithm seeks and undermines the key features that are likely to be adopted by diverse architectures. Significantly, IAA focuses on improving existing white-box attacks without introducing significant visual perceptual quality degradation. Namely, IAA maintains the white-box attack performance of the original algorithm while significantly enhancing its black-box transferability. Extensive experiments on ImageNet classifiers confirmed the effectiveness of our method. The proposed IAA outperformed all state-of-the-art benchmarks in various white-box and black-box settings, i.e., improving the success rate of BIM by 29.65% against normally trained models and 27.16% against defense models.",10.1109/ACCESS.2022.3204696,2022,,INTERMEDIATE-LAYER TRANSFERABLE ADVERSARIAL ATTACK WITH DNN ATTENTION,
1011,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Many bugs and defects occur during software testing and maintenance. These bugs should be resolved as soon as possible, to improve software quality. However, bug triage aims to solve these bugs by assigning the reported bugs to an appropriate developer or list of developers. It is an arduous task for a human triager to assign an appropriate developer to a bug report, when there are several developers with different skills, and several automated and semi-automated triage systems have been proposed in the last decade. Some recent techniques have suggested possibilities for the development of an effective triage system. However, these techniques require improvement. In previous work, we proposed a heterogeneous graph representation for bug triage, using word&#x2013;word edges and word-bug document co-occurrences to build a heterogeneous graph of bug data. Cosine similarity is used to weight the word&#x2013;word edges. Then, a graph convolution network is used to learn a heterogeneous graph representation. This paper extends our previous work by adopting different similarity metrics and correlation metrics for weighting word&#x2013;word edges. The method was validated using different small and large datasets obtained from large-scale open-source projects. The top-k accuracy metric was used to evaluate the performance of the bug triage system. The experimental results showed that the point-wise mutual information of the proposed model was better than that of other word&#x2013;word weighting methods, and our method had better accuracy for large datasets than other recent state-of-the-art methods. The proposed method with point-wise mutual information showed 3&#x0025; to 6&#x0025; higher top-1 accuracy than state-of-the-art methods for large datasets.",10.1109/ACCESS.2022.3153075,2022,,A GRAPH CONVOLUTION NETWORK-BASED BUG TRIAGE SYSTEM TO LEARN HETEROGENEOUS GRAPH REPRESENTATION OF BUG REPORTS,
1012,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"General secret sharing schemes comprise a secret dealer and a number of participants. The dealer can randomly generate a secret and then distribute shares of the secret to the participants. Verifiable multi-secret sharing enables a dealer to share multiple secrets among a group of participants such that the deceptive behaviors of the dealer and the participants can be detected. However, in the absence of secure channels, few verifiable secret sharing schemes can simultaneously share multiple secrets at one time. In this paper, we present an information privacy protection and verifiable multi-secret sharing scheme with a simple structure and high security. Each participant can verify correctness of the share distribution process based on public information published by the dealer and guarantee validity of the received share to avoid offering fake information in the process of restoring the original secret. Our performance and security analysis indicate that the newly proposed scheme is more efficient and practical while maintaining the same level of security compared with similar protocols available.",10.1109/ACCESS.2020.2968728,2020,,"INFORMATION PRIVACY PROTECTION BASED ON VERIFIABLE (T, N)-THRESHOLD MULTI-SECRET SHARING SCHEME",
1013,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Along with the emergence of Web 2.0, User Generated Content (UGC) is becoming increasingly important for knowledge sharing. Wikipedia being the world’s largest-ever community-based collaborative encyclopedia, is also one of the biggest UGC databases in the world. Wikipedia is dealing with a significant problem of Information Quality (IQ) because of its open-source and collaborative nature. When carrying out attacks such as link spamming, malicious users take advantage of Wikipedia’s popularity on the World Wide Web (WWW). As a result, Wikipedia is generally not recommended for academic-related work. There are, however, some articles that are both rich in information and quality. Existing approaches for assessing Wikipedia’s IQ involve statistical models and machine learning algorithms; however, the existing models do not produce satisfactory results. In this study, a novel theoretical model based on Google’s E-A-T framework is introduced to assess Wikipedia’s IQ. The model comprises three IQ constructs Expertise, Authority and Trustworthiness. Based on the empirical findings and study results, a set of IQ dimensions that influence the above three IQ constructs, as well as 45 IQ attributes to measure the IQ dimensions, were identified. The IQ attributes were automatically and inexpensively extracted from the content and meta-data statistics of Wikipedia articles using a Selenium 3.14 web automation script. A sample of 2000 articles comprising 1000 Featured Articles (FA) and 1000 non-FA articles from six WikiProjects was used for the data analysis. The proposed model was compared with three previously published models in terms of classification and clustering accuracy. It received classification and clustering accuracies of 95% and 93% respectively, which is a drastic improvement over the existing models. Furthermore, an average inter-rater agreement of 84% was observed. Thus, the proposed model’s effectiveness is fairly validated by this extensive experiment. This study contributes to the related knowledge area by introducing a novel framework to assess Wikipedia articles’ IQ.",10.1109/ACCESS.2022.3172962,2022,,ASSESSING INFORMATION QUALITY OF WIKIPEDIA ARTICLES THROUGH GOOGLE’S E-A-T MODEL,
1014,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the rapid development of big data, cloud computing and other technologies, Cloud-based robotic has become one of the key research directions for service robot, such as used in hospitals. A framework and set of metrics for evaluating the quality of service (QOS) of a cloud robotic platform would be greatly facilitate research into and actual practice of service robots. In this paper, a QOS metrics framework of cloud robotic computing is summarized and the research of components and metrics of a cloud robotic platform is reviewed. QOS metrics are organized into software, network, and robotic services. By summarizing and analyzing the above three groups of metrics, a QOS framework or index system is proposed. Finally, future research towards open source and standardization of components of robotic cloud platform is discussed.",10.1109/ACCESS.2020.3030069,2020,,OVERVIEW AND FRAMEWORK OF QUALITY SERVICE METRICS FOR CLOUD-BASED ROBOTICS PLATFORMS,
1015,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recent technological advances encompassed by the smart factory concept have fundamentally changed industrial control systems in the way they are structured and how they operate. Majority of these changes affect Supervisory Control And Data Acquisition (SCADA) systems, shifting them to a higher level of interoperability, heterogeneous networks, big data and toward internet technologies and services in general. However, this transformation does not affect all SCADA systems equally. The immediate industrial environment and controlled processes have a significant impact as well. This paper presents a holistic approach to SCADA systems implemented in continuous flow production control within the steel industry production environment. We outline the multi-layer architecture of the SCADA control framework and the aspects of interoperability and interconnectivity within the architecture reference models, together with the research challenges and opportunities arising from the recent rapid increasement of the industrial control systems complexity and digital transformation under the Industry 4.0 paradigm, resulting in disrupting levels of the traditional automation pyramid based on Purdue model toward a higher level of integration and interoperability enabling cross-level data exchange empowered by the Industrial Internet of Things. Furthermore, the paper addresses the problem of proprietary SCADA systems and elaborates the causal correlation between SCADA quality requirements and adoption of new technologies in relation to the specific industrial environment of the steel manufacturing process.",10.1109/ACCESS.2022.3211288,2022,,"SCADA SYSTEMS WITH FOCUS ON CONTINUOUS MANUFACTURING AND STEEL INDUSTRY: A SURVEY ON ARCHITECTURES, STANDARDS, CHALLENGES AND INDUSTRY 5.0",
1016,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"e-Healthcare promises to be the next big wave in healthcare. It offers all the advantages and benefits imaginable by both the patient and the user. However, current e-Healthcare systems are not yet fully developed and mature, and thus lack the degree of confidentiality, integrity, privacy, and user trust necessary to be widely implemented. Two primary aspects of any operational healthcare enterprise are the quality of healthcare services and patient trust over the healthcare enterprise. Trust is intertwined with issues like confidentiality, integrity, accountability, authenticity, identity, and data management, to name a few. Privacy remains one of the biggest obstacles to ensuring the success of e-Healthcare solutions in winning patient trust as it indirectly covers most security concerns. Addressing privacy concerns requires addressing security issues like access control, authentication, non-repudiation, and accountability, without which end-to-end privacy cannot be ensured. Achieving privacy from the point of data collection in wireless sensor networks, to incorporating the Internet of Things, to communication links, and to data storage and access, is a huge undertaking and requires extensive work. Privacy requirements are further compounded by the fact that the data handled in an enterprise are of an extremely personal and private nature, and its mismanagement, either intentionally or unintentionally, could seriously hurt both the patient and future prospects of an e-Healthcare enterprise. Research carried out in order to address privacy concerns is not homogenous in nature. It focuses on the failure of certain parts of the e-Healthcare enterprise to fully address all aspects of privacy. In the middle of this ongoing research and implementation, a gradual shift has occurred, moving e-Healthcare enterprise controls away from an organizational level toward the level of patients. This is intended to give patients more control and authority over decision making regarding their protected health information/electronic health record. A lot of works and efforts are necessary in order to better assess the feasibility of this major shift in e-Healthcare enterprises. Existing research can be naturally divided on the basis of techniques used. These include data anonymization/pseudonymization and access control mechanisms primarily for stored data privacy. This, however, results in giving a back seat to certain privacy requirements (accountability, integrity, non-repudiation, and identity management). This paper reviews research carried out in this regard and explores whether this research offers any possible solutions to either patient privacy requirements for e-Healthcare or possibilities for addressing the (technical as well as psychological) privacy concerns of the users.",10.1109/ACCESS.2017.2767561,2018,,PRIVACY PRESERVATION IN E-HEALTHCARE ENVIRONMENTS: STATE OF THE ART AND FUTURE DIRECTIONS,
1017,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recently, Web service composition and optimization have received an increasing attention from both academia and industrial community. Most current methods have not paid enough attention to the user specific trust requirement for composite services. However, Trust is an important metric to judge whether a composite service can behave as user expected. In this work, firstly, a multifactor concept of trust of composite service is defined based on the trust of component services, interface compatibility and optimal binding schemes. Secondly, a trustworthy Web service composition and optimization framework called TWSCO is proposed to guarantee the trust of composite service and efficiency of Web service composition process. The interface-matching problem among component services and user preference are considered in TWSCO, which firstly uses component services filter to remove untrusted component services. Secondly, the concrete services, based on interface similarity, are organized as clusters. Thirdly, a composite template among component services is formed at the cluster level to guarantee the trust and efficiency of composite service. finally, the best binding scheme is discovered by an optimization method based on user specific trust metrics. In the end, experiments based on real Web services are presented to illustrate the proposed framework TWSCO can effectively guarantee the user preference trust of the composite service.",10.1109/ACCESS.2020.2984648,2020,,A FRAMEWORK FOR TRUSTWORTHY WEB SERVICE COMPOSITION AND OPTIMIZATION,
1018,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Caching popular contents at edge nodes such as base stations is a crucial solution for improving users' quality of services in next-generation networks. However, it is very challenging to correctly predict the future popularity of contents and decide which contents should be stored in the base station cache. Recently, with the advances in big data and high computing power, deep learning models have achieved high prediction accuracy. Hence, in this paper, deep learning is used to learn and predict the future popularity of contents to support cache decision. First, deep learning models are trained and utilized in the cloud data center to make an efficient cache decision. Then, the final cache decision is sent to each base station to store the popular contents proactively. The proposed caching scheme involves three distinct parts: 1) predicting the future class label of each content; 2) predicting the future popularity score of contents based on the predicted class label; and 3) caching the predicted contents with high popularity scores. The prediction models using the Keras and Tensorflow libraries are implemented in this paper. Finally, the performance of the caching schemes is tested with a Python-based simulator. In terms of a cache hit, simulation results show that the proposed scheme outperforms 38%, convolutional recurrent neural network-based scheme outperforms 33%, and convolutional neural network-based scheme outperforms 25% compared to the baseline scheme.",10.1109/ACCESS.2018.2884913,2018,,DEEPMEC: MOBILE EDGE CACHING USING DEEP LEARNING,
1019,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Multi-label classification aims to deal with the problem that an object may be associated with one or more labels, which is a more difficult task due to the complex nature of multi-label data. The crucial problem of multi-label classification is the more robust and higher-level feature representation learning, which can reduce non-helpful feature attributes from the input space prior to training. In recent years, deep learning methods based on autoencoders have achieved excellent performance in multi-label classification for the advantages of powerful representations learning ability and fast convergence speed. However, most existing autoencoder-based methods only rely on the single autoencoder model, which pose challenges for multi-label feature representations learning and fail to measure similarities between data spaces. To address this problem, in this paper, we propose a novel representation learning method with dual autoencoder for multi-label classification. Compared to the existing autoencoder-based methods, our proposed method can capture different characteristics and more abstract features from data by the serially connection of two different types of autoencoders. More specifically, firstly, the algorithm of Reconstruction Independent Component Analysis (RICA) in sparse autoencoder is trained on patches on all training and test dataset for robust global feature representations learning. Secondly, with the output of RICA, stacked autoencoder with manifold regularization (SAMR) is introduced to ameliorate the quality of multi-label features learning. Comprehensive experiments on several real-world data sets demonstrate the effectiveness of our proposed approach compared with several competing state-of-the-art methods.",10.1109/ACCESS.2021.3096194,2021,,REPRESENTATION LEARNING WITH DUAL AUTOENCODER FOR MULTI-LABEL CLASSIFICATION,
1020,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the significant increase in the volume, velocity, and variety of user data (e.g., user-generated data) in online social networks, there have been attempted to design new ways of collecting and analyzing such big data. For example, social bots have been used to perform automated analytical services and provide users with improved quality of service. However, malicious social bots have also been used to disseminate false information (e.g., fake news), and this can result in real-world consequences. Therefore, detecting and removing malicious social bots in online social networks is crucial. The most existing detection methods of malicious social bots analyze the quantitative features of their behavior. These features are easily imitated by social bots; thereby resulting in low accuracy of the analysis. A novel method of detecting malicious social bots, including both features selection based on the transition probability of clickstream sequences and semi-supervised clustering, is presented in this paper. This method not only analyzes transition probability of user behavior clickstreams but also considers the time feature of behavior. Findings from our experiments on real online social network platforms demonstrate that the detection accuracy for different types of malicious social bots by the detection method of malicious social bots based on transition probability of user behavior clickstreams increases by an average of 12.8%, in comparison to the detection method based on quantitative analysis of user behavior.",10.1109/ACCESS.2019.2901864,2019,,DETECTING MALICIOUS SOCIAL BOTS BASED ON CLICKSTREAM SEQUENCES,
1021,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The concentration of fine particulate matter (PM2.5), which represents inhalable particles with diameters of 2.5 micrometers and smaller, is a vital air quality index. Such particles can penetrate deep into the human lungs and severely affect human health. This paper studies accurate PM2.5 prediction, which can potentially contribute to reducing or avoiding the negative consequences. Our approach’s novelty is to utilize the genetic algorithm (GA) and an encoder-decoder (E-D) model for PM2.5 prediction. The GA benefits feature selection and remove outliers to enhance the prediction accuracy. The encoder-decoder model with long short-term memory (LSTM), which relaxes the restrictions between the input and output of the model, can be used to effectively predict the PM2.5 concentration. We evaluate the proposed model on air quality datasets from Hanoi and Taiwan. The evaluation results show that our model achieves excellent performance. By merely using the E-D model, we can obtain more accurate (up to 53.7%) predictions than those of previous works. Moreover, the GA in our model has the advantage of obtaining the optimal feature combination for predicting the PM2.5 concentration. By combining the GA-based feature selection algorithm and the E-D model, our proposed approach further improves the accuracy by at least 13.7%.",10.1109/ACCESS.2021.3072280,2021,,PM2.5 PREDICTION USING GENETIC ALGORITHM-BASED FEATURE SELECTION AND ENCODER-DECODER MODEL,
1022,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Octane number is the most important indicator of reflecting the combustion performance, and a great deal of research has been devoted to improving it. In this paper, a new analytical framework is proposed to predict octane number, kernel principal component analysis (KPCA) is used to reduce the dimension of the variables in the process of Fluid Catalytic Cracking (FCC), support vector regression (SVR) is used to construct the gasoline octane number prediction model and the particle swarm optimization algorithm (PSO) is used to select the optimal combination of parameters for the model. The experiments show that the octane number can be improved under a given production environment with a guaranteed desulfurization effect of gasoline products. Furthermore, several key attributes that have a significantly positive or negative correlation with the improvement of gasoline product quality are identified through computing the feature score. The findings can help engineers adjust operational variables to obtain a series of high-quality products.",10.1109/ACCESS.2021.3077028,2021,,PREDICTIVE ANALYTICS FOR OCTANE NUMBER: A NOVEL HYBRID APPROACH OF KPCA AND GS-PSO-SVR MODEL,
1023,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Anomaly detection is becoming widely used in Manufacturing Industry to enhance product quality. At the same time, it plays a great role in several other domains due to the fact that anomaly may reveal rare but represent an important phenomenon. The objective of this paper is to detect anomalies and identify the possible variables that caused these anomalies on historical assembly data for two series of products. Multiple anomaly detection techniques were performed; HBOS, IForest, KNN, CBLOF, OCSVM, LOF, and ABOD. Moreover, we used AUROC and Rank Power as performance metrics, followed by Boosting ensemble learning method to ensure the best anomaly detectors robustness. The techniques that gave the highest performance are KNN, ABOD for both product series datasets with 0.95 and 0.99 AUROC respectively. Finally, we applied a statistical root cause analysis on the detected anomalies with the use of Pareto chart to visualize the frequency of the possible causes and its cumulative occurrence. The results showed that there are seven rejection causes for both product series, whereas the first three causes are responsible for 85% of the rejection rates. Besides, assembly machines engineers reported a significant reduction in the rejection rates in both assembly machines after tuning the specification limits of the rejection causes identified by this research results.",10.1109/ACCESS.2020.3029826,2020,,ASSEMBLY LINE ANOMALY DETECTION AND ROOT CAUSE ANALYSIS USING MACHINE LEARNING,
1024,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Massive open online courses (MOOCs) have been experiencing increasing use and popularity in highly ranked universities in recent years. The opportunity of accessing high quality courseware content within such platforms, while eliminating the burden of educational, financial, and geographical obstacles has led to a rapid growth in participant numbers. The increasing number and diversity of participating learners has opened up new horizons to the research community for the investigation of effective learning environments. Learning Analytics has been used to investigate the impact of engagement on student performance. However, the extensive literature review indicates that there is little research on the impact of MOOCs, particularly in analyzing the link between behavioral engagement and motivation as predictors of learning outcomes. In this paper, we consider a dataset, which originates from online courses provided by Harvard University and the Massachusetts Institute of Technology, delivered through the edX platform. Two sets of empirical experiments are conducted using both statistical and machine learning techniques. Statistical methods are used to examine the association between engagement level and performance, including the consideration of learner educational backgrounds. The results indicate a significant gap between success and failure outcome learner groups, where successful learners are found to read and watch course material to a higher degree. Machine learning algorithms are used to automatically detect learners who are lacking in motivation at an early time in the course, thus providing instructors with insight in regards to student withdrawal.",10.1109/ACCESS.2018.2876755,2018,,ANALYZING LEARNERS BEHAVIOR IN MOOCS: AN EXAMINATION OF PERFORMANCE AND MOTIVATION USING A DATA-DRIVEN APPROACH,
1025,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Cloud systems and microservices are becoming powerful tools for businesses. The evidence of the advantages of offering infrastructure, hardware or software as a service (IaaS, PaaS, SaaS) is overwhelming. Microservices and decoupled applications are increasingly popular. These architectures, based on containers, have facilitated the efficient development of complex SaaS applications. A big challenge is to manage and design microservices with a massive range of different facilities, from processing and data storage to computing predictive and prescriptive analytics. Computing providers are mainly based on data centers formed of massive and heterogeneous virtualized systems, which are continuously growing and diversifying over time. Moreover, these systems require integrating into current systems while meeting the Quality of Service (QoS) constraints. The primary purpose of this work is to present an on-premise architecture based on Kubernetes and Docker containers aimed at improving QoS regarding resource usage and service level objectives (SLOs). The main contribution of this proposal is its dynamic autoscaling capabilities to adjust system resources to the current workload while improving QoS.",10.1109/ACCESS.2022.3158743,2022,,AUTOSCALING PODS ON AN ON-PREMISE KUBERNETES INFRASTRUCTURE QOS-AWARE,
1026,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Innovation is increasingly becoming the most crucial and effective way to tackle climate change and environmental pollution. Recently, innovation quality has received continuous attention from scholars, entrepreneurs and policymakers. It is necessary to measure innovation quality from the perspective of green development. Based on the statistics data of 30 provincial-level innovation systems in China, this study comprehensively evaluates regional innovation quality and identifies the configuration of factors which could lead to high regional innovation quality. Firstly, this study establishes an indicator system of measuring regional innovation quality which includes seven indicators from three aspects of technological, economic and ecological benefit of innovative activities, and entropy weight method is used to comprehensively evaluate regional innovation quality. The result reveals there are big differences between different regions in China in innovation quality. In terms of three economic regions in China, innovation quality in the eastern region is the highest, followed by the central region and the lowest in the western region. Then, fuzzy-set qualitative comparative analysis method is applied, which uncovers three configurations of factors that could lead to high regional innovation quality. Finally, the conclusion of this study provides policy pathways for improving regional innovation quality.",10.1109/ACCESS.2020.2973703,2020,,HOW TO IMPROVE REGIONAL INNOVATION QUALITY FROM THE PERSPECTIVE OF GREEN DEVELOPMENT? FINDINGS FROM ENTROPY WEIGHT METHOD AND FUZZY-SET QUALITATIVE COMPARATIVE ANALYSIS,
1027,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The use of deep learning (DL) for barcode recognition and analysis has achieved remarkable success and has attracted great attention in various domains. Unlike other barcode recognition methods, DL-based approaches can significantly improve the speed and accuracy of both barcode detection and decoding. However, after almost a decade of progress, the current status of DL-based barcode recognition has yet to be thoroughly explored. Specifically, summaries of key insights and gaps remain unavailable in the literature. Therefore, this study aims to comprehensively review recent applications of DL methods in barcode recognition. We mainly conducted a well-constructed systematic literature review (SLR) approach to collect relevant articles and evaluate and summarize the state of the art. This study’s contributions are threefold. First, the paper highlights new DL approaches’ applicability to barcode localization and decoding processes and their potential to either reduce the time required or provide higher quality. Second, another main finding of this study signifies an increasing demand for public and specific barcode datasets that allow DL methods to learn more efficiently in the big data era. Finally, we conclude with a discussion on the crucial challenges of DL with respect to barcode recognition, incorporating promising directions for future research development.",10.1109/ACCESS.2022.3143033,2022,,DEEP LEARNING IN BARCODE RECOGNITION: A SYSTEMATIC LITERATURE REVIEW,
1028,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Offloading the computationally intensive workloads to the edge and cloud not only improves the quality of computation, but also creates an extra degree of diversity by collecting information from devices in service. Nevertheless, significant concerns on privacy are raised as the aggregated information could be misused without the permission by the third party. Sparse coding, which has been successful in computer vision, is finding application in this new domain. In this paper, we develop a secured face recognition framework to orchestrate sparse coding in edge and cloud networks. Specifically, 1). To protect the privacy, a low-complexity encrypting algorithm is developed based on random unitary transform, where its influence on dictionary learning and sparse representation is analysed. Furthermore, it is proved that such influence will not affect the accuracy of face recognition. 2). To fully utilize the multi-device diversity and avoid big data transmission between edge and cloud, a distributed learning framework is established, which extracts deeper features in an intermediate space, expanded according to the dictionaries from each device. Classification is performed in this new feature space to combat the noise and modeling error. Finally, the efficiency and effectiveness of the proposed framework is demonstrated through simulation results.",10.1109/ACCESS.2020.3011112,2020,,A PRIVACY-PRESERVING LEARNING FRAMEWORK FOR FACE RECOGNITION IN EDGE AND CLOUD NETWORKS,
1029,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Large amounts of data will be generated due to the rapid development of the Internet of Things (IoT) technologies and 5th generation mobile networks (5G), the processing and analysis requirements of big data will challenge existing networks and processing platforms. As the most promising technology in 5G networks, edge computing will greatly ease the pressure on network and data processing analysis on the edge. In this paper, we considered the coordination between compute and cache resources between multi-level edge computing nodes (ENs), users under this system can offload computing tasks to ENs to improve quality of service (QoS). We aimed to maximize the long-term profit on the edge, while satisfying the low-latency computing of the users, and jointly optimize the edge-side node offloading strategy and resource allocation. However, it is challenging to obtain an optimal strategy in such a dynamic and complex system. To solve the complex resource allocation problem on the edge and make edge have certain adaptation and cooperation, we used double deep Q-learning (DDQN) to make decisions, ability to maximize long-term gains while making quick decisions. The simulation results prove the effectiveness of DDQN in maximizing revenue when allocation resources on the edge.",10.1109/ACCESS.2020.3007002,2020,,COLLABORATIVE EDGE COMPUTING AND CACHING WITH DEEP REINFORCEMENT LEARNING DECISION AGENTS,
1030,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Energy conservation is one of the most important challenges in wireless sensor networks (WSNs). Therefore, compared with the traditional networks, the WSNs not only need high-quality services with high throughput or low transmission delay, but also pay greater attention to energy utilization to extend network lifetime. The clustering routing algorithm is considered to be among the effective ways to collect and transmit data in WSNs. Cluster head (CH) plays a vital role in the cluster which is in charge of data aggregation and data transmission, so their energy consumption is higher than non-CH nodes. The traditional clustering algorithm tends to have the same size in each cluster. However, due to the randomness of the node distribution, the equal clustering mechanism obviously cannot reduce energy consumption. In order to solve this problem, this paper contributes a new unequal clustering algorithm, an energy-aware adaptive kernel density estimation algorithm (EAKDE), which aims to balance the energy dissipation among the CHs. EAKDE utilizes fuzzy logic to determine the priority of nodes competing for CH. In order to adapt the dynamic change of node conditions, adaptive kernel density estimation algorithm is utilized to assign the appropriate unequal cluster radius to sensor nodes. The simulation results demonstrate that, in different scenarios, EAKDE outperforms the other well-known algorithms in terms of network stability, network lifetime, and energy efficiency.",10.1109/ACCESS.2019.2902243,2019,,AN ENERGY AWARE ADAPTIVE KERNEL DENSITY ESTIMATION APPROACH TO UNEQUAL CLUSTERING IN WIRELESS SENSOR NETWORKS,
1031,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The traditional networks are facing difficulties in managing the services offered by cloud computing, big data, and the Internet of Things as the users have become more dependent on their services. Software-Defined Networking (SDN) has pulled enthusiasm in the integration process of technologies and function as per the user's requirements for both academia and industry, and it has begun to be embraced in actual framework usage. The emergence of SDN has given another idea to empower the focal programmability of the system. Because of the increasing demand and the scarcity of resources, the load balancing issue needs to be addressed efficiently to manage the incoming traffic and resources and to improve network performance. One of the most critical issues is the role of the controller in SDN to balance the load for having a better Quality of Service (QoS). Though there are few survey articles written on load balancing, there is no detail and systematic review conducted in load balancing in SDN. Hence, this paper extends and reviews the discussion with a taxonomy of current emerging load balancing techniques in SDN systematically by categorizing the techniques as conventional and artificial intelligence-based techniques to improve the service quality. The review also includes the study of metrics and parameters which have been used to measure the performance. This review would allow gaining more information on load balancing approaches in SDN and enables the researchers to fill the current research gaps.",10.1109/ACCESS.2020.2995849,2020,,A SYSTEMATIC REVIEW OF LOAD BALANCING TECHNIQUES IN SOFTWARE-DEFINED NETWORKING,
1032,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper proposes a double-objective optimization resource allocation algorithm for the multi-user multiple-input/multiple-output (MU-MIMO) system in the general wireless environment and demonstrates the maximum number of simultaneously supportable users and the achievable bit rates of users in the general wireless environment with full rank and rank-deficient channels. The double-objective joint optimization algorithm proposed in this paper simultaneously optimizes energy efficiency and system throughput by user selection and power allocation. On this basis, the proposed algorithm guarantees the different QoS requirements of various services, including rate requirements and delay requirements.",10.1109/ACCESS.2019.2915573,2019,,RESOURCE ALLOCATION ALGORITHM FOR MU-MIMO SYSTEMS WITH DOUBLE-OBJECTIVE OPTIMIZATION UNDER THE EXISTENCE OF THE RANK DEFICIENT CHANNEL MATRIX,
1033,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Crop disease diagnosis is an essential step in crop disease treatment and is a hot issue in agricultural research. However, in agricultural production, identifying only coarse-grained diseases of crops is insufficient because treatment methods are different in different grades of even the same disease. Inappropriate treatments are not only ineffective in treating diseases but also affect crop yield and food safety. We combine IoT technology with deep learning to build an IoT system for crop fine-grained disease identification. This system can automatically detect crop diseases and send diagnostic results to farmers. We propose a multidimensional feature compensation residual neural network (MDFC-ResNet) model for fine-grained disease identification in the system. MDFC-ResNet identifies from three dimensions, namely, species, coarse-grained disease, and fine-grained disease and sets up a compensation layer that uses a compensation algorithm to fuse multidimensional recognition results. Experiments show that the MDFC-ResNet neural network has better recognition effect and is more instructive in actual agricultural production activities than other popular deep learning models.",10.1109/ACCESS.2020.3001237,2020,,MDFC–RESNET: AN AGRICULTURAL IOT SYSTEM TO ACCURATELY RECOGNIZE CROP DISEASES,
1034,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Wireless cellular communications lead to huge demands for estimating and visualizing the data about Quality of Service (QoS) for mobile network operators in the 5th Generation (5G) networks. Constructing a coverage map is an important step to visualize global information about QoS. Inspired by the characteristic of the base station, we present an adaptive triangulation method to divide the region of interest into triangles. Then, we propose a novel area-wise Multi-criteria Triangulation-induced Interpolation (MTI) algorithm which utilizes the linear interpolation to estimate the key performance indicators of the QoS inside a triangle with the known values of its three vertexes, to construct the coverage maps and provide the closed-form solution of the covered region for the multi-criteria problems. We check the accuracy and the efficiency of the MTI algorithm both in 19-cells network scenario and in real big city scenario. The experiment results manifest that the MTI algorithm shows a good performance in constructing the coverage maps and it is significantly lower-cost and higher-efficiency than the traditional point-wise algorithms.",10.1109/ACCESS.2019.2923047,2019,,MULTI-CRITERIA COVERAGE MAP CONSTRUCTION BASED ON ADAPTIVE TRIANGULATION-INDUCED INTERPOLATION FOR CELLULAR NETWORKS,
1035,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Low-dose CT is an effective solution to alleviate radiation risk to patients, it also introduces additional noise and streak artifacts. In order to maintain a high image quality for low-dose scanned CT data, we propose a post-processing method based on deep learning and using 2-D and 3-D residual convolutional networks. Experimental results and comparisons with other competing methods show that the proposed approach can effectively reduce the low-dose noise and artifacts while preserving tissue details. It is also pointed out that the 3-D model can achieve better performance in both edge-preservation and noise-artifact suppression. Factors that may influence the model performance, such as model width, depth, and dropout, are also examined.",10.1109/ACCESS.2017.2766438,2017,,IMPROVING LOW-DOSE CT IMAGE USING RESIDUAL CONVOLUTIONAL NETWORK,
1036,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The magnetic resonance (MR) imaging technique is widely used in clinical diagnosis. Unfortunately, in practice, the MR images inevitably suffer from noise, which severely degrades image quality and accordingly impacts on the accuracy of clinical diagnosis. By exploiting both the nonlocal similarity over space and the inherent correlation across the slices of the 3D MR images, in this paper, we present a novel Rician noise reduction method for the 3D MR images. Specifically, the 3D nonlocal similar patches are first extracted from the input noisy 3D MR data and then grouped to form a noisy fourth-order tensor. Since 3D patches used to construct the fourth-order tensor share similar structures, a latent noise-free tensor can be approximated by a low-rank tensor. To this end, the higher-order singular value decomposition (HOSVD) is adopted to recover the latent noise-free tensor. Furthermore, the rank of each mode of the tensor is adaptively determined by an enhanced low-rank method. The experimental results on synthetic and real 3D MR images show that the proposed method outperforms several state-of-the-art denoising methods in terms of objective metrics and visual inspection.",10.1109/ACCESS.2019.2924907,2019,,DENOISING 3D MAGNETIC RESONANCE IMAGES BASED ON LOW-RANK TENSOR APPROXIMATION WITH ADAPTIVE MULTIRANK ESTIMATION,
1037,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data clustering is a challenging task to gain insights into data in various fields. In this paper, an Enhanced Quantum-Inspired Evolutionary Fuzzy C-Means (EQIE-FCM) algorithm is proposed for data clustering. In the EQIE-FCM, quantum computing concept is utilized in combination with the FCM algorithm to improve the clustering process by evolving the clustering parameters. The improvement in the clustering process leads to improvement in the quality of clustering results. To validate the quality of clustering results achieved by the proposed EQIE-FCM approach, its performance is compared with the other quantum-based fuzzy clustering approaches and also with other evolutionary clustering approaches. To evaluate the performance of these approaches, extensive experiments are being carried out on various benchmark datasets and on the protein database that comprises of four superfamilies. The results indicate that the proposed EQIE-FCM approach finds the optimal value of fitness function and the fuzzifier parameter for the reported datasets. In addition to this, the proposed EQIE-FCM approach also finds the optimal number of clusters and more accurate location of initial cluster centers for these benchmark datasets. Thus, it can be regarded as a more efficient approach for data clustering.",10.1109/ACCESS.2019.2891956,2019,,A GENERALIZED ENHANCED QUANTUM FUZZY APPROACH FOR EFFICIENT DATA CLUSTERING,
1038,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Sleep is an important part of the human daily routine. Restoring sleep is strongly related to a better physical, cognitive, and psychological well-being. By contrast, poor or disordered sleep leads to possible impairments of cognitive and psychological functioning and to a worsened general physical health. In this context, understanding changes in sleep quality becomes a research imperative that leads to the need for the definition of what restoring or quality sleep means. This understanding of what “sleep quality” means requires a cross-domain investigation. It arises the need for a comprehensive study that offers a complete taxonomy of sleep monitoring systems, with a focus on sleep quality, and that gives useful insights about which combination of metrics, signals, and sleep variables is the best in relation to different categories of users. The proposed study is focused on systematically categorizing the methods and approaches for sleep quality understanding, with an emphasis on technological approaches, including wearable, on-bed, and actigraphy devices. It offers a systematic review for researchers who are interested in sleep quality identification tasks, and highlights strengths and weaknesses of state-of-the-art metrics and solutions in order to suggest the best choice for new potential research challenges in the field. Another important outcome of the proposed work is the study of the impact on the identified signal metrics and solutions of the different target user populations with their specific user requirements.",10.1109/ACCESS.2019.2953835,2019,,THE MEANING OF SLEEP QUALITY: A SURVEY OF AVAILABLE TECHNOLOGIES,
1039,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Existing feature-based neural approaches for aspect-based sentiment analysis (ABSA) try to improve their performance with pre-trained word embeddings and by modeling the relations between the text sequence and the aspect (or category), thus heavily depending on the quality of word embeddings and task-specific architectures. Although the recently pre-trained language models, i.e., BERT and XLNet, have achieved state-of-the-art performance in a variety of natural language processing (NLP) tasks, they still subject to the aspect-specific, local feature-aware and task-agnostic challenges. To address these challenges, this paper proposes a XLNet and capsule network based model XLNetCN for ABSA. XLNetCN firstly constructs auxiliary sentence to model the sequence-aspect relation and generate global aspect-specific representations, which enables to enhance aspect-awareness and ensure the full pre-training of XLNet for improving task-agnostic capability. After that, XLNetCN also employs a capsule network with the dynamic routing algorithm to extract the local and spatial hierarchical relations of the text sequence, and yield its local feature representations, which are then merged with the global aspect-related representations for downstream classification via a softmax classifier. Experimental results show that XLNetCN outperforms significantly than the classical BERT, XLNet and traditional feature-based approaches on the two benchmark datasets of SemEval 2014, Laptop and Restaurant, and achieves new state-of-the-art results.",10.1109/ACCESS.2020.2997675,2020,,ENHANCING ASPECT-BASED SENTIMENT ANALYSIS WITH CAPSULE NETWORK,
1040,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet of Things (IoT), which is the inter-networking of a wide variety of physical devices, is widely used in our daily life. The exponential increase in the number of diverse devices has resulted in a significant increase in the volume, variety, velocity, and veracity of data (i.e., big data). These data present a large requirement on modern storage systems both for capacity and scale, and energy cost has become a critical problem. For storage clusters, much research effort has been invested in alleviating this problem by providing suitable resource capacity (i.e., on-demand providing). However, it is challenging to match the offered resource capacity with the real system workloads, thus resulting in a violation of service level agreement. By considering a storage cluster as a queueing system, this paper proposes a QoS-oriented capacity provisioning mechanism. Based on workload features, the mechanism models the pattern of current workloads as a suitable queueing model. In accordance with the model, our mechanism can well forecast the actual resource capacity demand without violating the service level agreement, and then offer the required resource capacity in terms of the real workloads. Experimental results demonstrate that the proposed mechanism significantly reduces the energy consumption of a typical storage cluster, while meeting the QoS requirements. It also significantly outperforms two classic and two state-of-the-art capacity provisioning mechanisms.",10.1109/ACCESS.2017.2767703,2017,,ON-DEMAND CAPACITY PROVISIONING IN STORAGE CLUSTERS THROUGH WORKLOAD PATTERN MODELING,
1041,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Highly immersive content in the form of extended reality (XR) is attracting attention as an alternative to conventional video services such as YouTube and Facebook. Many galleries and museums already offer online virtual reality (VR) tours where users are free to choose the spot they want to move to, beyond merely looking around. Although the ease of implementation, this key-spot hopping is still far from giving the real feeling of walking. Meanwhile, in recent volumetric or light-field-based studies, view rendering that supports free and continuous viewpoint movements has been attempted. With online services in mind, however, the high data volume and computational complexity are a big obstacle to practical applications. Path-walking VR, the target system of this paper, can be a good compromise, where the viewer can enjoy the virtual space while walking along the route. The interactive path-walking VR service is entry-level immersive video, but streaming over the network is still challenging. One of the main problems to be tackled is that the movement patterns of viewers need to be reflected in the streaming strategy to improve the quality of experience. Unlike unidirectional video, the movement of the viewer determines which images and how many images should be transmitted. This paper proposes schemes to reduce streaming delays by reflecting the viewer’s movement characteristics. It is differentiated from existing studies for omnidirectional video in that the proposed schemes control not only image quality but also view update rate. The first is a caching strategy which takes advantage of the geometrical locality of the virtual space that the viewer will soon reach a position close to the current position. This not only reduces the communication delay from the server, but also decreases the burden of server-side request handling. The second scheme uses the relationship between the viewer’s speed and the field of vision. The image quality is adjusted according to the viewer’s speed and head direction. Experimental results show that the proposed schemes achieve stable viewer’s experience by considering walking characteristics in virtual space. It is expected that the results of this paper will provide insight to those who design interactive streaming systems for immersive media applications.",10.1109/ACCESS.2022.3174351,2022,,LOW LATENCY STREAMING FOR PATH-WALKING VR SYSTEMS,
1042,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In a highly competitive and liberalized energy market, where the retail of electricity is open to many potential companies, it is essential to have tools that help make decisions and guide the design of marketing strategies. In this sense, it is essential for retailers to know the behavior of their customers to correctly define their commercial strategies. One of the most commonly used methods for this is the characterization of their consumption profiles. Fortunately, for regulatory reasons, in some countries, the monthly electricity demand of each customer is openly available to any competitor. This paper explores whether this information, especially the economic sector and geographic location of a client, is useful for determining the client’s demand profile. Specifically, data on electricity demand in Spain from more than 27 million users and for a period of 3 years are analyzed. For this purpose, the electricity consumption of every client is grouped by month and normalized. The resulting demand profiles are later clustered according to different criteria. The main finding of the research is that the combined information on economic activity and location definitely enables prediction of the demand profile. Additionally, profile quality metrics are defined and obtained for the entire dataset. The resulting profiles have a mean dispersion of 10% and a confidence interval of ±17%. To clarify the use of these metrics, several examples are detailed, showing how this profile information can be used to improve the marketing decision-making process for electricity retailers.",10.1109/ACCESS.2021.3089443,2021,,MONTHLY ELECTRICITY DEMAND PATTERNS AND THEIR RELATIONSHIP WITH THE ECONOMIC SECTOR AND GEOGRAPHIC LOCATION,
1043,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Enhanced with wireless power transfer capability, cloud radio access network (C-RAN) enables energy-restrained mobile devices to function uninterruptedly. Beamforming of C-RAN has potential to improve the efficiency of wireless power transfer, in addition to transmission data rates. In this paper, we design the beamforming jointly for data transmission and energy transfer, under finite fronthaul capacity of C-RAN. A non-convex problem is formulated to balance the fronthaul requirements of different remote radio heads (RRHs). Norm approximations and relaxations are carried out to convexify the problem to second-order cone programming (SOCP). To improve the scalability of the design to large networks, we further decentralize the SOCP problem using the alternating direction multiplier method (ADMM). A series of reformulations and transformations are conducted, such that the resultant problem conforms to the state-of-the-art ADMM solver and can be efficiently solved in real time. Simulation results show that the distributed algorithm can remarkably reduce the time complexity without compromising the fronthaul load balancing of its centralized counterpart. The proposed algorithms can also reduce the fronthaul bandwidth requirements by 25% to 50%, compared with the prior art.",10.1109/ACCESS.2017.2699198,2017,,FRONTHAUL LOAD BALANCING IN ENERGY HARVESTING POWERED CLOUD RADIO ACCESS NETWORKS,
1044,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Establishing accurate wireless propagation models is essential for high-quality communications. Aiming at the low accuracy and complexity of the traditional wireless propagation model, a novel accurate wireless propagation model is proposed based on the bi-directional long short-term memory (Bi-LSTM) algorithm of machine learning. The model uses machine learning technology driven by big data and can achieve high real-time performance with low complexity. Also, it can accurately predict the wireless signal coverage intensity in a new environment. To allow the model to accommodate the actual environment of target areas, the propagation model can be dynamically corrected by deep learning and training. The Bi-LSTM is used to describe the relationship between features themselves and the relationship between features and target values of reference signal receiving power (RSRP). The Bi-LSTM is also used to represent the relationship through a full-connection layer to obtain the results so that sufficient parameter space can be provided for the model. The propagation model parameters are searched and fitted through a full-connection optimization. After training and tuning, the model’s predicted value of poor coverage recognition rate (PCRR) can reach 0.2371, while the predicted value of root mean squared error (RMSE) can be 10.4855, which demonstrates the better accuracy of the proposed model.",10.1109/ACCESS.2022.3169174,2022,,A NOVEL WIRELESS PROPAGATION MODEL BASED ON BI-LSTM ALGORITHM,
1045,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Developing Question Answering systems (QA) is one of the main goals in Artificial Intelligence. With the advent of Deep Learning (DL) techniques, QA systems have witnessed significant advances. Although DL performs very well on QA, it requires a considerable amount of annotated data for training. Many annotated datasets have been built for the QA task; most of them are exclusively in English. In order to address the need for a high-quality QA dataset in the Persian language, we present PersianQuAD, the native QA dataset for the Persian language. We create PersianQuAD in four steps: 1) Wikipedia article selection, 2) question-answer collection, 3) three-candidates test set preparation, and 4) Data Quality Monitoring. PersianQuAD consists of approximately 20,000 questions and answers made by native annotators on a set of Persian Wikipedia articles. The answer to each question is a segment of the corresponding article text. To better understand PersianQuAD and ensure its representativeness, we analyze PersianQuAD and show it contains questions of varying types and difficulties. We also present three versions of a deep learning-based QA system trained with PersianQuAD. Our best system achieves an F1 score of 82.97% which is comparable to that of QA systems on English SQuAD, made by the Stanford University. This shows that PersianQuAD performs well for training deep-learning-based QA systems. Human performance on PersianQuAD is significantly better (96.49%), demonstrating that PersianQuAD is challenging enough and there is still plenty of room for future improvement. PersianQuAD and all QA models implemented in this paper are freely available.",10.1109/ACCESS.2022.3157289,2022,,PERSIANQUAD: THE NATIVE QUESTION ANSWERING DATASET FOR THE PERSIAN LANGUAGE,
1046,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The gradual prevalence of Internet of Things (IoT) and wireless communication technologies has enabled the wide adoption of various smart devices (e.g., smart watches) in provisioning the healthcare services to massive users. Besides monitoring the real-time health signals or conditions of users, smart devices can also record a series of sport-related user information such as user location information at a certain time point. The location sequence information is valuable to cluster the users who share the similar sport preferences or habits and therefore, is also playing a key role in providing wireless healthcare services to these users. However, the user location information is often sensitive to certain wireless users as they decline to reveal their daily sport behavior patterns to others. In this situation, a natural challenge is raised in securing the sensitive user location information while mining the users’ daily sport behavior patterns and provisioning better healthcare services to the users. Considering this challenge, we take advantage of the well-known SimHash technique to protect users’ location privacy while clustering the users who share similar sport preferences or habits for better healthcare services. At last, we validate the feasibility of the proposal through a set of simulated experiments conducted on a real-world dataset. Reported results demonstrate that our solution performs better than the other two competitive ones while securing user location information.",10.1109/ACCESS.2021.3051051,2021,,SPORT LOCATION-BASED USER CLUSTERING WITH PRIVACY-PRESERVATION IN WIRELESS IOT-DRIVEN HEALTHCARE,
1047,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Video surveillance system is the integration of computers, networks, communications, and video CODEC, etc. Because of its distributed architecture, parallel image processing and ease of installation and expansion, it is widely used in many fields such as education, transportation and industry. However, there are some challenges of video surveillance applications in smart cities such as large scale of video events, low quality and big delay of video data transmission, and the loss of video surveillance data integrity. In order to solve the above problems, this paper designs a series of optimization algorithms and scheduling strategies based on Unmanned Aerial Vehicle (UAV) cluster. Firstly, we construct a full device coverage network with UAV cluster in heterogeneous communication environment of smart cities. Secondly, we formulate the scheduling problem of UAV cluster as bi-objective fragile bin packing problem, and design an optimal scheduling algorithm with constant approximation performance ratio. The simulation experimental results fully demonstrate the effectiveness, feasibility and robustness of the proposed solution in terms of system life cycle, video decodable frame rate, the ratio of UAV flight time to system life cycle, throughput and delay.",10.1109/ACCESS.2020.2981647,2020,,UAV CLUSTER-BASED VIDEO SURVEILLANCE SYSTEM OPTIMIZATION IN HETEROGENEOUS COMMUNICATION OF SMART CITIES,
1048,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Delivering a reliable and high-quality software system to client is a big challenge in software development and evolution process. One of the software measures that confirm the quality of the system is the defect density. Practitioners usually need this measure during software development process or during a period of operation to indicate the reliability of software system. However, since predicting defect density before testing the modules is time consuming, managers need to build a prediction model that can help in detecting the defective modules. This process can reduce the testing cost and improve testing resources utilizations. The most intrinsic feature of software defect datasets is the data sparsity in the defect density which might bias the final prediction. Therefore, we use deep learning to build defect density prediction models and handle the inherit challenge of data sparsity in defect density. Deep learning has shown to be effective with sparse data. The constructed model has been evaluated against well-known machine learning methods over 28 public datasets. The obtained results confirmed that the deep learning model is generally more adequate than other machine models over the datasets with high and very high sparsity ratios, and competitive choice when the sparsity ratio is either medium or low.",10.1109/ACCESS.2022.3217480,2022,,SOFTWARE DEFECT DENSITY PREDICTION USING DEEP LEARNING,
1049,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Information and communication technologies have been widely used to achieve the objective of smart city development. A smart air quality sensing and forecasting system is an important part of a smart city. One of the major challenges in designing such a forecast system is ensuring high accuracy and an acceptable computation time. In this paper, we show that it is possible to accurately forecast fine particulate matter (PM2.5) concentrations with low computation time by using different clustering techniques. An Internet of Things framework comprising of Airbox devices for PM2.5 monitoring has been used to acquire the data. Our main focus is to achieve high forecasting accuracy with reduced computation time. We use a hybrid model to do the forecast and a grid based system to cluster the monitoring stations based on the geographical distance. The experiments and evaluation is done using Airbox devices data from 557 stations deployed all over Taiwan. We are able to demonstrate that a proper clustering based on geographical distance can reduce the forecasting error rate and also the computation time. Also, in order to further evaluate our system, we have applied wavelet-based clustering to group the monitoring stations. A final comparative analysis is done for different clustering schemes with respect to accuracy and computational time.",10.1109/ACCESS.2018.2820164,2018,,IMPROVING THE ACCURACY AND EFFICIENCY OF PM2.5 FORECAST SERVICE USING CLUSTER-BASED HYBRID NEURAL NETWORK MODEL,
1050,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Crop diseases have mainly affected crop production due to the lack of modern approaches for disease identification. For many years, farmers have identified various crop diseases and have local knowledge about disease management. However, the local knowledge of one agricultural region is not utilized in other regions due to the unavailability of knowledge sharing platforms. Agricultural research also suggests that crop production has mainly decreased due to diseases, methods of cultivation, irrigation, and lack of local agricultural knowledge. In this research, the experience of agricultural experts, farmers, and cultivators is gathered through a crowd-sourced platform. The data is then processed for various disease identification. Hence, timely identification of various crop diseases can benefit farmers to apply relevant management methods. In literature, researchers have proposed various methods for disease management, mostly based on the classification of crop diseases using Machine Learning (ML) algorithms. However, these algorithms are unable to give trustful results due to static data provisioning and the dynamic nature of various diseases in different agricultural regions. Further, the agricultural expert's experience is also not considered in verifying the classification results. To identify the dynamic nature of wheat diseases, we acquired high-quality images and symptoms-based text data from farmers, domain experts, and users using a crowd-sourced platform. Different augmentation techniques were also used to enhance the size of training data. In this paper, a modern generic approach has been proposed for the identification and classification of wheat diseases using Decision Trees (DT) and different deep learning models. Also, results of both algorithms were then verified by domain experts that improved the decision trees accuracy by 28.5%, CNN accuracy by 4.3% (leading to 97.2%), and resulted in decision rules for wheat diseases in a knowledge-based system.",10.1109/ACCESS.2021.3058582,2021,,A GENERIC APPROACH FOR WHEAT DISEASE CLASSIFICATION AND VERIFICATION USING EXPERT OPINION FOR KNOWLEDGE-BASED DECISIONS,
1051,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Image sentiment analysis is a hot research topic in the field of computer vision. However, two key issues need to be addressed. First, high-quality training samples are scarce. There are numerous ambiguous images in the original datasets owing to diverse subjective cognitions from different annotators. Second, the cross-modal sentimental semantics among heterogeneous image features has not been fully explored. To alleviate these problems, we propose a novel model called multidimensional extra evidence mining (ME2M) for image sentiment analysis, it involves sample-refinement and cross-modal sentimental semantics mining. A new soft voting-based sample-refinement strategy is designed to address the former problem, whereas the state-of-the-art discriminant correlation analysis (DCA) model is used to completely mine the cross-modal sentimental semantics among diverse image features. Image sentiment analysis is conducted based on the cross-modal sentimental semantics and a general classifier. The experimental results verify that the ME2M model is effective and robust and that it outperforms the most competitive baselines on two well-known datasets. Furthermore, it is versatile owing to its flexible structure.",10.1109/ACCESS.2020.2999128,2020,,MULTIDIMENSIONAL EXTRA EVIDENCE MINING FOR IMAGE SENTIMENT ANALYSIS,
1052,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Terahertz (THz) radiation ( $0.1\sim 10$  THz) shows great potential in agricultural products detection, biomedical, and security inspection in recent years. Machine learning methods are widely used to support the user demand of higher efficiency and high prediction accuracy. The technological and key challenges of machine learning methods are for THz spectroscopy and image data preprocessing, reconstruction algorithms, and qualitative and quantitative analysis. In this paper, an exhaustive review of recent related works of THz detection and imaging techniques and machine learning methods are presented. The application of machine learning methods combined with THz technology in quality inspection of agricultural products, biomedical, security inspection, and materials science are highlighted. Challenges of machine learning methods for these applications are addressed. The development trend and future perspectives of THz technology are also discussed.",10.1109/ACCESS.2022.3174595,2022,,MACHINE LEARNING AND APPLICATION IN TERAHERTZ TECHNOLOGY: A REVIEW ON ACHIEVEMENTS AND FUTURE CHALLENGES,
1053,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Edge-driven software applications often deployed as online services in the cloud-to-edge continuum lack significant protection for services and infrastructures against emerging cyberattacks. Very-Short Intermittent Distributed Denial of Service (VSI-DDoS) attack is one of the biggest factors for diminishing the Quality of Services (QoS) and Quality of Experiences (QoE) for users on edge. Unlike conventional DDoS attacks, these attacks live for a very short time (on the order of a few milliseconds) in the traffic to deceive users with a legitimate service experience. To provide protection, we propose a novel and efficient approach for detecting VSI-DDoS attacks using reinforced transformer learning that mitigates the tail latency and service availability problems in edge clouds. In the presence of attacks, the users’ demand for availing ultra-low latency and high throughput services deployed on the edge, can never be met. Moreover, these attacks send very-short intermittent requests towards the target services that enforce longer delays in users’ responses. The assimilation of transformer with deep reinforcement learning accelerates detection performance under adverse conditions by adapting the dynamic and the most discernible patterns of attacks (e.g., multiplicative temporal dependency, attack dynamism). The extensive experiments with testbed and benchmark datasets demonstrate that the proposed approach is suitable, effective, and efficient for detecting VSI-DDoS attacks in edge clouds. The results outperform state-of-the-art methods with  $0.9\%-3.2\%$  higher accuracy in both datasets.",10.1109/ACCESS.2022.3204812,2022,,REINFORCED TRANSFORMER LEARNING FOR VSI-DDOS DETECTION IN EDGE CLOUDS,
1054,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Motivated by complementing the ubiquitous sensor networks and cloud computing technique, a lot of attentions have been drawn to Sensor-Cloud (SC). The idea of SC thrives on the principle of virtualization of physical sensor nodes and has introduced the intermediate processing between physical sensor nodes and end users. This paper proposes an efficient interactive SC control scheme to provide on-demand sensing services for multiple applications. By adopting the game theory, we develop a new two-stage game model, which consists of a judicious mixture of selection and incentive algorithms. In our game model, a user can choose the most adaptable data center to execute its task, and each data center can give appropriate incentives to the participating sensors. The main merit possessed by our two-stage game approach is to shed light on the practical SC control problem while providing excellent adaptability and flexibility to satisfy the different application requirements. To the best of our knowledge, this is the first work to include a novel incentive algorithm in the SC system. Simulation results demonstrate that our approach can outperform existing schemes by about 5%~15% in terms of the normalized user profit, service delay, and SC system throughput. Finally, we discuss future directions for designing SC control frameworks including other issues.",10.1109/ACCESS.2018.2815578,2018,,AN EFFECTIVE SENSOR CLOUD CONTROL SCHEME BASED ON A TWO-STAGE GAME APPROACH,
1055,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Internet of Things (IoT) plays a big role in automating information generation and consumption in industrial monitoring applications. Blockchain can allow this information to be stored in a manner that is both accessible and reliable for the IoT devices to work with. Blockchain has the capability to collect data from IoT devices and store it in a distributed manner that prevents tampering with the data. This paper discusses the use of blockchain to calculate the Service Quality (SQ) in an Industrial IoT for monitoring application. The proposed framework looks at the blockchain as a finite number of fragmented pieces of data corresponding to a specific industrial process. The SQ is expressed as penalties which is the difference between the expected IoT sensor values and the actual sensor data in reported events from the IoT devices. It also moderates the penalty between similar industrial processes based on each other. The moderation allows better understanding of the system functions and identification of specific problems rather than simply recording the sensor data for a single process. Furthermore, this paper analyzes private blockchains for suitability in IIoT and summarizes some key challenges for IoT to be used with blockchain in context of the proposed framework. The paper uses supply chain as a use case scenario for describing the proposed framework and presents results on its technical feasibility.",10.1109/ACCESS.2019.2948269,2019,,ESTIMATING SERVICE QUALITY IN INDUSTRIAL INTERNET-OF-THINGS MONITORING APPLICATIONS WITH BLOCKCHAIN,
1056,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Nanopositioning systems are very popular and playing an increasingly vital role in micro and nano-scale positioning industry due to their unique ability to achieve high-precision and high-speed operation. However, hysteresis, commonly existing in piezoelectric actuators, degrades the precision seriously. Uncertain dynamics and sensor noises also greatly affect the accuracy. To address those challenges, a variable bandwidth active disturbance rejection control (VBADRC) is proposed and realized on a nanopositioning stage. All undesired issues are estimated by a time-varying extended state observer (TESO), and cancelled out by a variable bandwidth controller. Convergence of the TESO, advantages of a TESO over a linear extended state observer (LESO), and the closed-loop stability of the VBADRC are proven theoretically. Improvements of the VBADRC versus the linear active disturbance rejection control (LADRC) are validated by simulations and experiments. Both numerical and experimental results demonstrate that the VBADRC is not only able to provide the same disturbance estimation ability as the LADRC, but also more powerful in noise attenuation and reference tracking.",10.1109/ACCESS.2020.2987469,2020,,ON THE DISTURBANCE REJECTION OF A PIEZOELECTRIC DRIVEN NANOPOSITIONING SYSTEM,
1057,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Knowledge states modeling is a fundamental issue in online education. One of its tasks is to discover the potential knowledge capacity of students for predicting their performance (i.e., scores on exercises). Current studies either depend on cognitive diagnosis approaches or apply collaborative filtering. However, the prediction accuracy of traditional cognitive diagnosis is insufficient, and collaborative filtering has difficulty ensuring the interpretability of prediction. Actually, students usually read some auxiliary text learning materials that they are interested in, namely, preferred learning material, to consolidate what they have learned. Preference cognitive diagnosis means that the preferred learning materials can reflect the students’ knowledge states (i.e., proficiency for knowledge concepts) to some extent, which is beneficial for predicting students’ performance. Therefore, we propose a preference cognitive diagnosis method (PreferenceCD) to model students’ knowledge states. Specifically, we first design the Direct-Indirect method to acquire students’ preferred learning materials. This method mines important information from students’ reading content that can reflect their preference for learning materials to acquire those preferred learning materials directly. Moreover, it discovers preferred learning materials indirectly by analyzing the similarity of students’ learning behaviors during the reading process. Subsequently, we calculate students’ preference degree for knowledge concepts based on the acquired preferred learning materials and diagnose their proficiency for knowledge concepts by applying a cognitive diagnosis model. After that, we combine the above two aspects to model students’ knowledge states and further predict their scores on exercises. The experimental results on a real-world dataset demonstrate the effectiveness of PreferenceCD with both accuracy and interpretability. The accuracy, root mean square error (RMSE), and mean absolute error (MAE) of PreferenceCD are 0.7614, 0.4805, and 0.2386, respectively, which outperforms related works by about 2-12% in terms of these evaluation metrics.",10.1109/ACCESS.2020.3042775,2020,,PREFERENCE COGNITIVE DIAGNOSIS FOR STUDENT PERFORMANCE PREDICTION,
1058,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the prediction of zinc-binding sites in proteins, there are few real binding-site residues, whereas most residues are non-binding-site residues, resulting in a typical imbalanced classification problem. This paper proposes a novel method, SSWPNN (an ensemble of support vector machine and sample-weighted probabilistic neural network), based on downsampling and an ensemble of different classifiers, in view of the imbalance of zinc-binding sites in proteins. Multiple random downsampling techniques without replacement are performed on the whole set, and the support vector machine is trained as the base classifier on each subset to calculate the weights of samples, while the sample-weighted probabilistic neural network is constructed as a strong classifier for prediction. The experimental results showed that our method is superior to other methods not only in the overall prediction performance for the four types of residues but also in the prediction performance for any type of residue. The results of experimental testing on an independent test set collected by the authors in recent years showed that our method achieved better prediction performance than others not only for the four types of residues overall but also for any one type of residue. In addition, the importance of the features selected by the method is analyzed by reducing certain feature to calculate the scores of the performance index. The source code and datasets are available at http://net.jitsec.cn:88/UploadedImages/SSWPNN.rar.",10.1109/ACCESS.2019.2960374,2019,,A NOVEL PREDICTION METHOD FOR ZINC-BINDING SITES IN PROTEINS BY AN ENSEMBLE OF SVM AND SAMPLE-WEIGHTED PROBABILISTIC NEURAL NETWORK,
1059,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Superpixel is an essential tool for computer vision. In practice, classic superpixel algorithms do not exhibit good boundary adherence with fewer superpixels, which will greatly hamper further analysis. To remedy the defect, a superpixel boundary optimization framework is proposed in this paper. There are three steps in the framework. Firstly, based on the proposed information measure function, the under-segmented superpixels generated by classic superpixel algorithms are screened out. Secondly, with the two invariant centroids method, these under-segmented superpixels are re-segmented to improve the accuracy in boundary adherence. Finally, smaller superpixels are merged to maintain the same number with initial superpixels. Quantitative evaluations on the BSDS500 exhibit that the performance of the classic superpixel algorithms is improved by employing the framework, especially on the condition of fewer superpixels.",10.1109/ACCESS.2020.2984720,2020,,A SUPERPIXEL BOUNDARY OPTIMIZATION (SBO) FRAMEWORK BASED ON INFORMATION MEASURE FUNCTION,
1060,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As the mobile networks become even denser and the traffic demand is increasing drastically, it is becoming more heterogeneous. Recently, it is intensive to investigate the Cell-Free Massive multiple-input multiple-output Massive (MIMO) system, where a large number of access points (APs) simultaneously serve a much smaller number of users, and the APs and users are clustered to provide good service for all users. This paper designs a mobile base station (MBS)-assisted Cell-Free Massive MIMO system: Utilizing an MBS deployed on the unmanned aerial vehicle (UAV) to form an air-ground heterogeneous system with the Cell-Free Massive MIMO system and offload part of traffic to the MBS to further improve the system performance. To provide better service to all users, this paper design an MBS flight trajectory optimal method to improve the wireless coverage performance and user experience, and proposed a joint power allocation algorithm based on the consideration of the fairness of the service quality. The simulation results indicate that the performance of the system designed in this paper has a significant improvement compared with the normal Cell-Free Massive MIMO system.",10.1109/ACCESS.2021.3054652,2021,,TRAJECTORY OPTIMIZATION AND POWER ALLOCATION ALGORITHM IN MBS-ASSISTED CELL-FREE MASSIVE MIMO SYSTEMS,
1061,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Quantum key distribution (QKD) is regarded as an alternative to traditional cryptography methods for securing data communication by quantum mechanics rather than computational complexity. Towards the massive deployment of QKD, embedding it with the telecommunication system is crucially important. Homogenous optical multi-core fibers (MCFs) compatible with spatial division multiplexing (SDM) are essential components for the next-generation optical communication infrastructure, which provides a big potential for co-existence of optical telecommunication systems and QKD. However, the QKD channel is extremely vulnerable due to the fact that the quantum states can be annihilated by noise during signal propagation. Thus, investigation of telecom compatibility for QKD co-existing with high-speed classical communication in SDM transmission media is needed. In this paper, we present analytical models of the noise sources in QKD links over heterogeneous MCFs. Spontaneous Raman scattering and inter-core crosstalk are experimentally characterized over spans of MCFs with different refractive index profiles, emulating shared telecom traffic conditions. Lower bounds for the secret key rates and quantum bit error rate (QBER) due to different core/wavelength allocation are obtained to validate intra- and inter-core co-existence of QKD and classical telecommunication.",10.1109/ACCESS.2020.2990186,2020,,TELECOMMUNICATION COMPATIBILITY EVALUATION FOR CO-EXISTING QUANTUM KEY DISTRIBUTION IN HOMOGENOUS MULTICORE FIBER,
1062,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Software testing plays a crucial role in ensuring the quality of software systems. Mutation testing is designed to measure the adequacy of test suites by detecting artificially induced software faults. Despite their potential, the expensive cost and the scalability of mutation testing with large programs is a big obstacle in its practical use. The selective mutation has been widely investigated and considered to be an effective approach to reduce the cost of mutation testing. In the case of large programs where source code has hundreds of classes and more than 10 KLOC lines of code, the selective mutation can still generate thousands of mutants. Executing each mutant against the test suite is cost-intensive in terms of robustness, resource usage, and computational cost. In this paper, we introduce a new approach to extract features from mutant programs based on mutant killing conditions, i.e. reachability, necessity and sufficiency along with mutant significance and test suite metrics to extract features from mutant programs. A deep learning Keras model is proposed to predict killed and alive mutants from each program. First, the features are extracted using the Eclipse JDT library and program dependency analysis. Second, preprocessing techniques such as Principal Component Analysis and Synthetic Minority Oversampling are used to reduce the high dimensionality of data and to overcome the imbalanced class problem respectively. Lastly, the deep learning model is optimized using fine-tune parameters such as dropout and dense layers, activation function, error and loss rate respectively. The proposed work is analyzed on five opensource programs from GitHub repository consisting of thousands of classes and LOC. The experimental results are appreciable in terms of effectiveness and scalable mutation testing with a slight loss of accuracy.",10.1109/ACCESS.2019.2950171,2019,,SCALABLE MUTATION TESTING USING PREDICTIVE ANALYSIS OF DEEP LEARNING MODEL,
1063,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Quality of Service (QoS) value is usually unknown in service recommendation practice. There are some matrix factorization approaches for predicting the unknown value with a user-service model, which uses a single collaboration with the user's neighbor when looking for different services. However, the QoS value is highly related to the service provider and participants. The services are considered in various collaboration based on different users. By considering the context of services, this paper proposes a QoS prediction model using tensor decomposition based on service collaboration called Service-oriented Tensor (SOT). The prediction approach analyzes service collaboration from other similar services and relevant users by using a three-order tensor. Compared with the traditional model, the experiment results show that the proposed model achieves better prediction accuracy.",10.1109/ACCESS.2019.2912505,2019,,PERSONALIZED QOS PREDICTION FOR SERVICE RECOMMENDATION WITH A SERVICE-ORIENTED TENSOR MODEL,
1064,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, we consider the two key problems in the physical-layer security of nonorthogonal multiple access (NOMA) visible light communication (VLC) networks: investigating a closed-form achievable security rate and studying the optimal security beamforming design. Specifically, under the dimming control, practical power, and successive interference cancellation constraints, we derive both the outer and inner bounds of the security capacity region with closed-form expressions, which are evaluated via numerical results. Then, based on the proposed security-rate expression, we investigated the optimal security beamforming design to minimize the total LED power, and to maximize the minimum secrecy rate, respectively. Both the problems are nonconvex. We apply different relaxation techniques to efficiently solve them. The simulation results demonstrate the efficacy of the proposed security beamforming design schemes in the NOMA VLC networks.",10.1109/ACCESS.2019.2916548,2019,,SECURE TRANSMISSION FOR DOWNLINK NOMA VISIBLE LIGHT COMMUNICATION NETWORKS,
1065,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Extended Field of View Ultrasound Sonography (EFOV-US) uses the existing ultrasound images for image stitching, so as to display the shape and scope of organ occupation and the relationship with surrounding tissues comprehensively. However, there are still some problems in Extended Field of View Ultrasound Sonography, such as matching error and unstable quality of image stitching. In view of these problems, we propose Dual-enhanced EFOV-US method that overcomes the limitation and produces higher quality results. Firstly, the gray enhancement method is used to improve the image contrast and reduce the noise interference. Then the super-resolution method based on the generative adversarial network is used to improve the resolution of the ultrasonic image further and increase the number of feature point matching between stitching images. The high quality ultrasound wide-range image is gotten by stitching and fusing the double enhanced image. The experimental results show that the proposed method is effective and practical.",10.1109/ACCESS.2020.3008525,2020,,DUAL-ENHANCED REGISTRATION FOR FIELD OF VIEW ULTRASOUND SONOGRAPHY,
1066,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The performance of the salient object detection of strip surface defects has been promoted largely by deep learning based models. However, due to the complexity of strip surface defects, the existing models perform poorly in the challenging scenes such as noise disturbance, and low contrast between defect regions and background. Meanwhile, the detection results of existing models often suffer from coarse boundary details. Therefore, we propose a novel saliency model, namely an Edge-aware Multi-level Interactive Network, to detect the defects from the strip steel surface. Concretely, our model adopts the U-shape architecture where the two crucial points are the interactive feature integration and the edge-guided saliency fusion. Firstly, except the skip connection that combines the same stage of encoder and decoder, we deploy another connection, where the features from adjacent levels of encoder are transferred to the same stage of decoder. By this way, we are able to provide an effective fusion of multi-level deep features, yielding a well depiction for defects. Secondly, to give well-defined boundaries for prediction results, we add the edge extraction branch after each decoder block, where the progressive feature aggregation endows the edge with precise details and complete object cues. Meanwhile, together with the edge extraction branches, we deploy the saliency prediction branch at each decoder stage. After that, coupled with the fine edge information, we fuse all outputs of saliency prediction branches into the final saliency map, where the edge cue steers the saliency result to pay more attention to the boundary details. Following this way, we can provide a high-quality saliency map which can accurately locate and segment the defects. Extensive experiments are performed on the public dataset, and the results prove the effectiveness and robustness of our model which consistently outperforms the state-of-the-art models.",10.1109/ACCESS.2021.3124814,2021,,EDGE-AWARE MULTI-LEVEL INTERACTIVE NETWORK FOR SALIENT OBJECT DETECTION OF STRIP STEEL SURFACE DEFECTS,
1067,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In most of existing Internet of Things (IoT) applications, data compression, data encryption and error/erasure correction are implemented separately. To achieve reliable communication, in particular, in harsh wireless environment with strong interference, error/erasure correction codes with higher correction capability or Automatic repeat request (ARQ) scheme are desirable but at the cost of increasing complexity and energy consumption. Due to resource-constrained IoT device, it is often challenging to implement all of them. In this paper, we propose a novel lightweight efficient secure error-robust scheme, ENCRUST, which is able to achieve these three functions using simple matrix multiplication. ENCRUST is built on the new theoretical foundation of projection-based encoding presented in this paper, by leveraging the sparsity inherent in the signal. We perform theoretical analysis and experimental study of the proposed scheme in comparison with the conventional schemes. It shows that the proposed scheme can work in low SINR range and the reconstructed signal quality shows graceful degradation. Furthermore, we apply the proposed scheme on real-life electrocardiogram (ECG) dataset and images. The results demonstrate that ENCRUST achieves decent compression, information secrecy as well as strong error recovery in one go.",10.1109/ACCESS.2021.3064700,2021,,A NOVEL EFFICIENT SECURE AND ERROR-ROBUST SCHEME FOR INTERNET OF THINGS USING COMPRESSIVE SENSING,
1068,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recommender systems are being increasingly used to predict the preferences of users on online platforms and recommend relevant options that help them cope with information overload. In particular, modern model-based collaborative filtering algorithms, such as latent factor models, are considered state-of-the-art in recommendation systems. Unfortunately, these black box systems lack transparency, as they provide little information about the reasoning behind their predictions. White box systems, in contrast, can, by nature, easily generate explanations. However, their predictions are less accurate than sophisticated black box models. Recent research has demonstrated that explanations are an essential component in bringing the powerful predictions of big data and machine learning methods to a mass audience without compromising trust. Explanations can take a variety of formats, depending on the recommendation domain and the machine learning model used to make predictions. The objective of this work is to build a recommender system that can generate both accurate predictions and semantically rich explanations that justify the predictions. We propose a novel approach to build an explanation generation mechanism into a latent factor-based black box recommendation model. The designed model is trained to learn to make predictions that are accompanied by explanations that are automatically mined from the semantic web. Our evaluation experiments, which carefully study the trade-offs between the quality of predictions and explanations, show that our proposed approach succeeds in producing explainable predictions without a significant sacrifice in prediction accuracy.",10.1109/ACCESS.2019.2934633,2019,,MINING SEMANTIC KNOWLEDGE GRAPHS TO ADD EXPLAINABILITY TO BLACK BOX RECOMMENDER SYSTEMS,
1069,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The year 2020 opened with a dramatic epidemic caused by a new species of coronavirus that soon has been declared a pandemic by the WHO due to the high number of deaths and the critical mass of worldwide hospitalized patients, of order of millions. The COVID-19 pandemic has forced the governments of hundreds of countries to apply several heavy restrictions in the citizens’ socio-economic life. Italy was one of the most affected countries with long-term restrictions, impacting the socio-economic tissue. During this lockdown period, people got informed mostly on Online Social Media, where a heated debate followed all main ongoing events. In this scenario, the following study presents an in-depth analysis of the main emergent topics discussed during the lockdown phase within the Italian Twitter community. The analysis has been conducted through a general purpose methodological framework, grounded on a biological metaphor and on a chain of NLP and graph analysis techniques, in charge of detecting and tracking emerging topics in Online Social Media, e.g. streams of Twitter data. A term-frequency analysis in subsequent time slots is pipelined with nutrition and energy metrics for computing hot terms by also exploiting the tweets quality information, such as the social influence of the users. Finally, a co-occurrence analysis is adopted for building a topic graph where emerging topics are suitably selected. We demonstrate via a careful parameter setting the effectiveness of the topic tracking system, tailored to the current Twitter standard API restrictions, in capturing the main sociopolitical events that occurred during this dramatic phase.",10.1109/ACCESS.2020.3010033,2020,,AN INFOVEILLANCE SYSTEM FOR DETECTING AND TRACKING RELEVANT TOPICS FROM ITALIAN TWEETS DURING THE COVID-19 EVENT,
1070,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Generative Adversarial Networks (GANs) are a powerful subclass of generative models. Yet, how to effectively train them to reach Nash equilibrium is a challenge. A number of experiments have indicated that one possible solution is to bound the function space of the discriminator. In practice, when optimizing the standard loss function without limiting the discriminator's output, the discriminator may suffer from lack of convergence. To be able to reach the Nash equilibrium in a faster way during training and obtain better generative data, we propose constrained generative adversarial networks, GAN-C, where a constraint on the discriminator's output is introduced. We theoretically prove that our proposed loss function shares the same Nash equilibrium as the standard one, and our experiments on mixture of Gaussians, MNIST, CIFAR-10, STL-10, FFHQ, and CAT datasets show that our loss function can better stabilize training and yield even better high-quality images.",10.1109/ACCESS.2021.3054822,2021,,CONSTRAINED GENERATIVE ADVERSARIAL NETWORKS,
1071,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Progress in wearable techniques makes the long-term daily electrocardiogram (ECG) monitoring possible. However, the long-term wearable ECGs can be significantly contaminated by various noises, which affect the detection and diagnosis of cardiovascular diseases (CVDs). The situation becomes more serious for wearable ECG screening, where the data are huge, and doctors have no way to visually check the signal quality episode-by-episode. Therefore, automatic and accurate noise rejection for the wearable big-data ECGs is craving. This paper addressed this issue and proposed a noise rejection method for wearable ECGs based on the combination of modified frequency slice wavelet transform (MFSWT) and convolutional neural network (CNN). Wearable ECGs were recorded using the newly developed 12-lead Lenovo smart ECG vest with a sample rate of 500 Hz and a resolution of 16 bit. One thousand 10-s ECG segments were picked up and were manually labeled into three quality types: clinically useful segments with good signal quality (type A), clinically useful segments with poor signal quality (type B), and clinically useless segments (pure noises, type C). Each of the 1,000 10-s ECG segments were transformed into a 2-D time-frequency (T-F) image using the MFSWT, with a pixel size of 200×50. Then, the 2-D grayscale images from MFSWT were fed into a 13-layer CNN model for training the classification models. Results from the standard 5-folder cross-validation showed that the proposed combination method of MFSWT and CNN achieved a highest classification accuracy of 86.3%, which was higher than the comparable methods from continuous wavelet transform (CWT) and artificial neural networks (ANN). The combination of MFSWT and CNN also had a good calculation efficiency. This paper indicated that the combination of MFSWT and CNN is a potential method for automatic identification of noisy segments from wearable ECG recordings.",10.1109/ACCESS.2019.2900719,2019,,NOISE REJECTION FOR WEARABLE ECGS USING MODIFIED FREQUENCY SLICE WAVELET TRANSFORM AND CONVOLUTIONAL NEURAL NETWORKS,
1072,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Low-rate Denial of service (LDoS) attacks has become one of the biggest threats to the Internet, cloud computing platforms, and big data centers. As an evolutionary species of DDoS attack, LDoS attack is essentially different from the DDoS attack. DDoS attacks are the behavior of malicious blocking legitimate network traffic by destroying the targets and the infrastructure around it with huge network traffic. While, LDoS attacks are the behavior of intentional degrading the quality of TCP links by throttling TCP flows to a small fraction of its ideal rate with periodic small pulse sequence. Hence, LDoS attack has a very small flow (around 10%–20% of the background traffic), it is easy to eluding the detection of routers and counter-DoS mechanisms. We try to reveal the mechanism of the LDoS attack and attempt to figure out the generation principle of LDoS attack in this paper. We classify the LDoS attacks and existing defense methods according to time domain and frequency domain in which detection and defense are performed. Furthermore, we highlight the filter approach to defense against LDoS attack. The initial purpose of our work is to encourage researchers to study effective ways to detect and defend against LDoS attacks with innovation and aggressiveness.",10.1109/ACCESS.2020.2976609,2020,,"LOW-RATE DOS ATTACKS, DETECTION, DEFENSE, AND CHALLENGES: A SURVEY",
1073,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recent research on recommender systems has proved that by leveraging social network information, the quality of recommendations can be evidently improved. Traditional social recommendation models typically linearly combine social network information. For instance, matrix factorization based models linearly combine latent factors of relevant users and items. However, in practice, the multifaceted social relations are so complex that simple linear combination may not be able to reasonably organize such information for accurate social recommendation. On the other hand, existing deep learning based non-linear methods lack systematic modeling of user-item-friend relations. To handle these issues, we propose a novel, non-linear latent factor model for social recommendations leveraging Gaussian process. By introducing a social-aware covariance function, we organize individual users’ past feedback, as well as the associated social information (e.g., friends’ feedback to the same items) into a covariance matrix, which non-linearly and systematically learns the complex interactions among users, their interacted items and their friends’ opinions. A stochastic gradient descent based optimization algorithm is developed to fit the model. Extensive experiments conducted on three real-world datasets demonstrate that the proposed model outperforms the state-of-the-art social recommendation models and Gaussian process based models.",10.1109/ACCESS.2022.3141795,2022,,TOWARDS NON-LINEAR SOCIAL RECOMMENDATION USING GAUSSIAN PROCESS,
1074,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The detection of fabric defects is an important part of fabric quality control, and hence is thus a research hotspot in the textile industry. With the aim of effectively detecting fabric defects, this paper describes an improved fabric defect detection method based on the membership degree of each fabric region (TPA). By analyzing the regional features of fabric surface defects, the saliency of defect regions can be determined using the extreme point density map of the image and the features of the membership function region. A threshold iterative method and morphological processing are used to ensure the precise and accurate detection of fabric defects. Experimental results show that compared with two classical fabric defect detection methods, the proposed detection method can detect fabric defects more effectively while also suppressing the interference of noise and background textures. Additionally, numerical results demonstrate the validity and feasibility of the proposed method to satisfy the requirements of online detection.",10.1109/ACCESS.2020.2978900,2020,,FABRIC DEFECT DETECTION BASED ON MEMBERSHIP DEGREE OF REGIONS,
1075,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Real-time passenger flow prediction plays an important role in subway network design and management. Most of the existing prediction algorithms only consider the sequence of passenger flow volume, however, ignore the influence of other outer factors, for example, the weather conditions, air quality and temperature. In this paper, a systematic framework, MetroEye, is proposed for weather-aware prediction of real-time passenger flow. The framework contains an offline system and an online system. The offline system adopts a conditional random field (CRF) model to establish the relationship between passenger flow volume and weather factors. Experimental results show the superior prediction accuracy of the model, especially in large stations. The online system provides efficient methods to simulate the real-time passenger flow volume. Due to its high practicality, MetroEye has been adopted by Beijing Urban Rail Transit Control Center to monitor the passenger flow status of the Beijing subway system.",10.1109/ACCESS.2020.3007538,2020,,METROEYE: A WEATHER-AWARE SYSTEM FOR REAL-TIME METRO PASSENGER FLOW PREDICTION,
1076,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Considering operators of the urban rail transit systems are often faced with cost control, passengers required high service quality, which has inter-affection between each other in congestion issues for the peak period. A good cooperative timetable associated with time-based shift radios is proposed to achieve a mutually beneficial win-win situation for operators required low energy consumption (costs), and passengers required short waiting time in high peak level with different time-shift control schemes by shifting passengers' travel times. By seeking the optimal shift radios, we focus on generating a favorable train schedule by taking the optimal decisions in the presence of trade-offs between two conflicting objectives. Subsequently, an improved non-dominated sorting in genetic algorithms (INSGA-II) was presented to solve the multi-objective programming model. Finally, the computational results show that the optimized time-shift control scheme brings a significant effect on reducing congestion during the peak periods.",10.1109/ACCESS.2021.3078569,2021,,URBAN RAIL TRAIN SCHEDULING WITH SMOOTHING ENERGY CONSUMPTION PEAKS AND SYNCHRONIZATION TIME MINIMIZATION: USING NOVEL TIME-SHIFT CONTROL SCHEME,
1077,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Multi-objective sparse reconstruction methods have shown strong potential in sparse reconstruction. However, most methods are computationally expensive due to the requirement of excessive functional evaluations. Most of these methods adopt arbitrary regularization values for iterative thresholding-based local search, which hardly produces high-precision solutions stably. In this article, we propose a multi-objective sparse reconstruction scheme with novel techniques of transfer learning and localized regularization. Firstly, we design a knowledge transfer operator to reuse the search experience from previously solved homogeneous or heterogeneous sparse reconstruction problems, which can significantly accelerate the convergence and improve the reconstruction quality. Secondly, we develop a localized regularization strategy for iterative thresholding-based local search, which uses systematically designed independent regularization values according to decomposed subproblems. The strategy can lead to improved reconstruction accuracy. Therefore, our proposed scheme is more computationally efficient and accurate, compared to existing multi-objective sparse reconstruction methods. This is validated by extensive experiments on simulated signals and benchmark problems.",10.1109/ACCESS.2020.3029968,2020,,MULTI-OBJECTIVE SPARSE RECONSTRUCTION WITH TRANSFER LEARNING AND LOCALIZED REGULARIZATION,
1078,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The multiview low dynamic range images captured with sparse camera arrangement under ill-lighting conditions contain highlighted and shadow regions due to over-exposed and under-exposed regions. The processing of these images produces contrast distortion, and it is challenging to maintain relative brightness with color consistency. Moreover, the disparity map estimation faces the challenges of holes and artifacts due to a wide baseline and poor visibility, with a shared view of vision. In this article, we propose a multiview ghost-free image enhancement strategy for in-the-wild images with unknown exposure and geometry. We address the complex geometric alignment problem for a wide variational baseline among multiple sparsely arranged cameras. The features among multiple viewpoints are detected and matched for the image restoration. The restored image contains highlighted and shadow regions with a color imbalance problem. We synthesize virtual images following the intensity mapping function, which compensates for the relative brightness and color distortions. Finally, we fuse all the images to obtain high-quality images. The proposed method is more frequent and feasible for future multiview systems with varying baselines without relying on disparity maps. The experimental results demonstrate that the proposed method outperformed the state-of-the-art approaches.",10.1109/ACCESS.2021.3057167,2021,,MULTIVIEW GHOST-FREE IMAGE ENHANCEMENT FOR IN-THE-WILD IMAGES WITH UNKNOWN EXPOSURE AND GEOMETRY,
1079,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As serious public health problems require complex responses, health interventions often involve multiple components implemented by groups including policy experts, social workers, and health practitioners. The success or failure of an intervention depends on many different factors, ranging from available resources to characteristics of the targeted public health issue and community to the complex mechanics relating cause and effects of the actions performed. In this paper, we present a novel formal methodology to evaluate public health interventions, policies, and programs. Our method uses the theory of change (TOC) approach along with logic models that define the intervention under consideration to generate a causal diagram and an ontology-based inference model for causal description. The resulting causal diagram will then be compared to existing knowledge and data to determine whether the intervention is coherent, internally consistent and its goals are achievable in the allotted time with the resources provided. The contextual knowledge and semantics provided by the ontology will generate a more explainable, understandable, and trustworthy approach to compare and assess different interventions based on their shared goals. Depending upon the quality and quantity of data available we perform a mix of qualitative and quantitative evaluation of the interventions. This study uses smoking cessation interventions to showcase the proposed methodology in action.",10.1109/ACCESS.2020.2964802,2020,,HEALTH INTERVENTION EVALUATION USING SEMANTIC EXPLAINABILITY AND CAUSAL REASONING,
1080,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Wrapper methods are a type of feature selection method that finds a subset of variables to improve the performance of a classifier by removing redundant and irrelevant variables. The use of a wrapper implies that each time a candidate solution is explored, the classifier is evaluated on the quality measures selected (e.g. accuracy or precision). Though robust, this iteration across several candidate solutions can become computationally intensive and time-consuming. In this paper we propose a wrapper, that is based on binary Covering Arrays (CAs), and binary Incremental Covering Arrays (ICAs), that have been widely used for experimental design and fault detection in software and hardware testing. The new wrapper was evaluated with six classifiers on seven data sets. The results show that the CAs and ICAs with strength 6 significantly improve the performance and reduces the number of variables required by the classifier. A comparative analysis of the proposed method against wrappers based on other search approaches such as genetic algorithms (GA) and particle swarm optimization (PSO), shows that the proposed method yields results similar to GA, but not to PSO, with differences to PSO, in accuracy, which in the majority of cases is below 0.04. This lack of accuracy, by which the new wrapper fails to match PSO, is offset by the fact that the user does not need to fine tune algorithm parameters, such as velocity ranges, timing, cognitive coefficient, and social coefficient, while it is also much easier to program in parallel.",10.1109/ACCESS.2019.2944641,2019,,WRAPPER FOR BUILDING CLASSIFICATION MODELS USING COVERING ARRAYS,
1081,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, a 3D reconstruction based on structure from motion (SFM) has attracted much attention from the communities of computer vision and graphics. It is well known that the speed and quality of SFM systems largely depend on the technique of feature tracking. If a big volume of image data is inputted for SFM, the speed of this SFM system would become very slow. And, this problem becomes severer for large-scale scenes, which typically needs to capture several thousands of images to recover the point-cloud model of the scene. However, none of the existing methods fully addresses the problem of fast feature tracking. Brute force matching is capable of producing correspondences for small-scale scenes but often getting stuck in repeated features. Hashing matching can only deal with middle-scale scenes and is not capable of large-scale scenes. In this paper, we propose a new feature tacking method working in a parallel manner rather than in a single thread scheme. Our method consists of steps of keypoint detection, descriptor computing, descriptor matching by parallel k -nearest neighbor (Parallel-KNN) search, and outlier rejecting. This method is able to rapidly match a big volume of keypoints and avoids to consume high computation time, then yielding a set of correct correspondences. We demonstrate and evaluate the proposed method on several challenging benchmark datasets, including those with highly repeated features, and compare to the state-of-the-art methods. The experimental results indicate that our method outperforms the compared methods in both efficiency and effectiveness.",10.1109/ACCESS.2019.2912647,2019,,PARALLEL K NEAREST NEIGHBOR MATCHING FOR 3D RECONSTRUCTION,
1082,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, the Industrial world has been embracing new digital technology, including the internet of things (IoT) paradigm that promises revolutionizing-prospects in numerous industrial applications. However, many deployment challenges related to real-time big data analytics, service assurance, resource optimization, energy consumption, and security awareness are raised. In this work, we focus on service assurance and resource optimization, including energy consumption challenges over Industrial Internet of Things (IIoT)-based environments since the existing network routing algorithms cannot meet the strict heterogeneous quality of service (QoS) requirements of industrial communications while optimizing resources. We take advantage of the flexibility and programmability offered by the promising software-defined networking paradigm, and we propose a centralized route optimization and service assurance scheme, named ROSA, over a multi-layer programmable industrial architecture. The proposed solution supports a wide range of heterogeneous flows, such as ultra-reliable low-latency communications (URLLC) and bandwidth-sensitive services. The routing optimization problems are formulated as multi-constrained shortest path problems. The Lagrangian Relaxation approach is used to solve the . Hence, we deploy a pair of parallel routing algorithms run according to the flow type to ensure QoS requirements, efficiently allocate constrained resources, and enhance the overall network energy consumption. We conduct extensive simulations to validate the proposed ROSA scheme. The experimental results show promising performance in terms of reducing bandwidth utilization by up to 22%, end-to-end delay at least by 21%, packet loss by more than 19%, flow violation by about 16%, and energy consumption up to 14% as compared to well-known benchmarks in QoS provisioning and energy-aware routing problem.",10.1109/ACCESS.2021.3056931,2021,,PARALLEL ROUTE OPTIMIZATION AND SERVICE ASSURANCE IN ENERGY-EFFICIENT SOFTWARE-DEFINED INDUSTRIAL IOT NETWORKS,
1083,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Smart cities are expected to improve the quality of daily life, promote sustainable development, and improve the functionality of urban systems. Now that many smart systems have been implemented, security and privacy issues have become a major challenge that requires effective countermeasures. However, traditional cybersecurity protection strategies cannot be applied directly to these intelligent applications because of the heterogeneity, scalability, and dynamic characteristics of smart cities. Furthermore, it is necessary to be aware of security and privacy threats when designing and implementing new mechanisms or systems. Motivated by these factors, we survey the current situations of smart cities with respect to security and privacy to provide an overview of both the academic and industrial fields and to pave the way for further exploration. Specifically, this survey begins with an overview of smart cities to provide an integrated context for readers. Then, we discuss the privacy and security issues in current smart applications along with the corresponding requirements",10.1109/ACCESS.2018.2853985,2018,,SECURITY AND PRIVACY IN SMART CITIES: CHALLENGES AND OPPORTUNITIES,
1084,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In an age of struggling news media, automated generation of news via natural language generation (NLG) methods could be of great help, especially in areas where the amount of raw input data is big, and the structure of the data is known in advance. One such news automation system is the Valtteri NLG system, which generates news articles about the Finnish municipal elections of 2017. To evaluate the quality of Valtteri-produced articles and to identify aspects to improve, n = 152 users were asked to evaluate the output of Valtteri. Each evaluator rated six preselected computer-generated articles, four control articles written by journalists, and four computer-generated articles of their own choice. All the articles were evaluated along four dimensions: credibility, liking, quality, and representativeness. As expected, the texts written by Valtteri received lower ratings than those written by journalists, but overall the ratings were satisfactory (average 2.9 versus 4.0 for journalists on a five-point scale). Valtteri's best rating (3.6) was for credibility. The computer-written articles that the evaluators could freely select got slightly better ratings than the preselected computer-written articles. When looking at the results by demographic groups, males aged 55 or more liked the automatic articles best and females aged 34 or less liked them the least. Evaluators mistook 21% of the computer-written articles as written by humans and 10% of the human-written articles as computer-written. The share of users making these mistakes grew with the age. Overall, the male evaluators made less writer-identification mistakes than female evaluators did.",10.1109/ACCESS.2018.2861987,2018,,NO LANDSLIDE FOR THE HUMAN JOURNALIST - AN EMPIRICAL STUDY OF COMPUTER-GENERATED ELECTION NEWS IN FINLAND,
1085,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The growing interest and recent breakthroughs in artificial intelligence and machine learning (ML) have actively contributed to an increase in research and development of new methods to estimate the states of electrified vehicle batteries. Data-driven approaches, such as ML, are becoming more popular for estimating the state of charge (SOC) and state of health (SOH) due to greater availability of battery data and improved computing power capabilities. This paper provides a survey of battery state estimation methods based on ML approaches such as feedforward neural networks (FNNs), recurrent neural networks (RNNs), support vector machines (SVM), radial basis functions (RBF), and Hamming networks. Comparisons between methods are shown in terms of data quality, inputs and outputs, test conditions, battery types, and stated accuracy to give readers a bigger picture view of the ML landscape for SOC and SOH estimation. Additionally, to provide insight into how to best approach with the comparison of different neural network structures, an FNN and long short-term memory (LSTM) RNN are trained fifty times each for 3000 epochs. The error is somewhat different for each training repetition due to the random initial values of the trainable parameters, demonstrating that it is important to train networks multiple times to achieve the best result. Furthermore, it is recommended that when performing a comparison among estimation techniques such as those presented in this review paper, the compared networks should have a similar number of learnable parameters and be trained and tested with identical data. Otherwise, it is difficult to make a general conclusion regarding the quality of a given estimation technique.",10.1109/ACCESS.2020.2980961,2020,,MACHINE LEARNING APPLIED TO ELECTRIFIED VEHICLE BATTERY STATE OF CHARGE AND STATE OF HEALTH ESTIMATION: STATE-OF-THE-ART,
1086,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Traveling to a new region has become a very common thing for people, due to work or life requirement. With the development of recommendation engine and the popularity of social media network, people are more and more used to relying on personalized Points-of-Interest (POI) recommendations. However, traditional approaches can fail if users moves to a region where they had little or no active history or even social network friends information before. Under the requirement of smart city construction, the need to give high quality personalized POI recommendation when a user travels to a new region has arisen. Fortunately, with the widespread of wireless Internet, the booming of Internet-of-Things (IoT) and the common-usage of location sensors in mobile phones, the coupling degree between social media networks and location information is ever increasing, which could leads us to a new way to solve this problem in the ear of Big Data. In this research, we presented New Place Recommendation Algorithm (N-PRA) which is designed based on Latent Factor model. Many different types of social media contexts (time-related and location-related), such as a user's interest fluctuation, different types of POIs' popularity fluctuation, types of POIs, the influence of geographical neighborhood on POIs, and user's social network friendship are taken into consideration in this approach. The algorithm presented is verified on Yelp, an open-source real urban data-set, and compared against several other baseline POI recommendation algorithms. Experimental results show that the algorithm presented in this paper could achieve a better accuracy.",10.1109/ACCESS.2020.2980982,2020,,EXPLOITING LOCATION-BASED CONTEXT FOR POI RECOMMENDATION WHEN TRAVELING TO A NEW REGION,
1087,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In a cloud data center, there is usually a large waste of physical resources and link resources, which leads to increased energy consumption. This paper discusses reducing the loss of link resources from the perspective of connectivity between virtual machines. When the virtual machines of a single user request are concentrated to reduce energy consumption, there will be decreased request reliability. This paper considers a single point of failure to ensure the reliability of the requests. Finally, this paper proposes a multi-objective particle swarm optimization algorithm. It takes the physical resource utilization rate and the link loss rate as the optimization targets and uses service reliability and quality of the tenant as constraint conditions. The simulation results show that the method proposed in this paper reliably satisfies the tenant request, effectively controls the link loss in the data center, and significantly reduces the energy consumption of the data center.",10.1109/ACCESS.2018.2816983,2018,,RELIABLE VIRTUAL MACHINE PLACEMENT BASED ON MULTI-OBJECTIVE OPTIMIZATION WITH TRAFFIC-AWARE ALGORITHM IN INDUSTRIAL CLOUD,
1088,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Automatic recording and analysis of bird calls is becoming an important way to understand changes in bird populations and assess environmental health. An issue currently proving problematic with the automatic analysis of bird recordings is interference from noise that can mask vocalizations of interest. As such, noise reduction can greatly increase the accuracy of automatic analyses and reduce processing work for subsequent steps in bioacoustics analyses. However, only limited work has been done in the context of bird recordings. Most semiautomatic methods either manually apply sound enhancement methods available in audio processing systems such as SoX and Audacity or apply preliminary filters such as lowand highpass filters. These methods are insufficient both in terms of how generically they can be applied and their integration with automatic systems that need to process large amounts of data. Some other work applied more sophisticated denoising methods or combinations of different methods such as minimum mean square error short-time spectral amplitude estimator (MMSE STSA) and spectral subtraction for other species such as anurans. However, their effectiveness is not tested on bird recordings. In this paper, we analyze the applicability of the MMSE STSA algorithm to remove noise from environmental recordings containing bird sounds, particularly focusing on its quality and processing time. The experimental evaluation using real data clearly shows that MMSE STSA can reduce noise with similar effectiveness [using objective metrics such as predicted signal quality (SIG)] to a previously recommended wavelet-transform-based denoising technique while executing between approximately 5-300 times faster depending on the audio files tested.",10.1109/ACCESS.2017.2782778,2018,,AUTOMATIC AND EFFICIENT DENOISING OF BIOACOUSTICS RECORDINGS USING MMSE STSA,
1089,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Weakly-supervised object detection (WSOD) has attracted lots of attention in recent years. However, there is still a big gap between WSOD and generic object detection. The main barriers to the efficiency of WSOD are the ineffective data augmentations and inaccurate bounding box predictions. Given only image-level annotations, it is hard for WSOD to effectively utilize variant data augmentations and accurately regress the bounding boxes. Although a fully-supervised object detector can be trained using annotations generated from the weakly-supervised object detector, the performance is still severely limited due to the low quality of mined pseudo annotations. This paper proposes an efficient WSOD method with pseudo annotations (EWPA) to make better use of imperfect annotations. With the assistance of pseudo annotations, EWPA can effectively regress more accurate bounding boxes while the traditional WSOD can only locate the salient parts of an object. Furthermore, pseudo annotations can help design more complex data augmentations, driving the network to learn more discriminative feature representations. Extensive experiments are conducted on PASCAL VOC 2007 and 2012 datasets and validate the effectiveness of EWPA.",10.1109/ACCESS.2021.3099497,2021,,EFFICIENT WEAKLY-SUPERVISED OBJECT DETECTION WITH PSEUDO ANNOTATIONS,
1090,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Small to medium sized transportation and logistics companies are usually constrained by limited computing and IT professional resources on implementing an efficient parallel metaheuristic algorithm for planning or management solutions. In this paper we extend the standard meta-description for genetic algorithms (GA) with a simple non-trivial parallel implementation. Our parallel GA framework is chiefly concerned with the development of a straightforward way for engineers to modify existing genetic algorithm implementations for real transportation and logistics problems to make use of commonly available hardware resources without completely reworking complex, useful and usable codes. The framework presented at its parallel base is a modification of the primitive parallelization concept, but if implemented as described it may be gradually extended to fit the qualities of any underlying problem better (via the adaptation of the merging and communications functions).We present our framework and computational results for a classical transportation related combinatorial optimization problem - the traveling salesman problem with a standard sequential genetic algorithm implementation. Our empirical analysis shows that this simple extension can lead to considerable solution improvements. We also tested our assumptions that the framework is easily implemented by an engineer not initially familiar with genetic algorithms to implement the framework for another minimum multiprocessor scheduling problem. These case studies verify that our framework is better than primitive parallelization because it gives empirically better results under equitable conditions. It also outperforms fine grained parallelization as it is easier and faster to implement.",10.1109/ACCESS.2020.2997812,2020,,A PARALLEL GENETIC ALGORITHM FRAMEWORK FOR TRANSPORTATION PLANNING AND LOGISTICS MANAGEMENT,
1091,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Due to the rapid development of online retailers, there is a great demand for package express shipping services, which causes traffic congestion, resource consumption, and environmental pollution (e.g., carbon emission). However, there is still a large amount of under-utilized capacity in the public transportation systems during off-peak hours. In this paper, we investigate the same-day package distribution using crowdsourced public transportation systems (CPTSs). Specifically, given a number of packages and the timetable of available CPTSs trips, we optimize the schemes of delivering the packages using the under-utilized capacity of the CPTS trips, without impacting the quality of passenger experience. To estimate the amount of under-utilized capacity of each trip across any two adjacent stations, we propose the passenger transit model based on the history data. To assign the under-utilized capacity of each trip to the package deliveries, we develop the minimum limitation delivery (MLD) method, which only utilizes the minimum amount of under-utilized capacity of the whole trip to deliver packages. However, the available capacity is not fully utilized at most stations by MLD. Therefore, we further propose the adaptive limitation delivery (ALD) method, which loads as many packages as possible, until the volume of loaded packages reaches the available capacity in theory. The experimental results and theoretical analysis show that both MLD and ALD could distribute packages efficiently. Moreover, given a set of packages, scheduling of ALD only consumes about 67% time compared to the scheduling of MLD, with a little higher risk of impacting passengers.",10.1109/ACCESS.2018.2885081,2019,,PLANNING CITY-WIDE PACKAGE DISTRIBUTION SCHEMES USING CROWDSOURCED PUBLIC TRANSPORTATION SYSTEMS,
1092,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"A microarray can be easily used for quantitatively analyzing the expression levels of DNA genes. Yet, the noises introduced during the application will greatly affect the accuracy of DNA sequence detection. How to reduce the noise constitutes a challenging problem in microarray analysis. Especially, due to the weak fluorescence response, the image of microarray contains difficulties of the low peak-signal-to-noise ratio (PSNR) and luminance contrast. To solve the problem that the wavelet threshold denoising method has poor effective on low PSNR image, a wavelet denoising approach based on compression sensing (CS) optimized by the neural dynamics optimization algorithm (NDOA) is proposed, which preferably solves the denoising difficulties of noise pollution in the microarray image. Under the condition of Gaussian random observation matrix, the effectiveness of NDOA-optimized wavelet denoising based on CS gets better work than the orthogonal matching pursuit and its improved algorithms. The experimental results indicate that the expected wavelet coefficients of the noiseless image have been reconstructed with higher quality. When the compression sampling rate for microarray image is 0.875, the PSNR of the NDOA-optimized wavelet denoising algorithm based on CS is increased about 9 dB, and the root mean squared error is reduced obviously too, in comparison with the wavelet soft-threshold denoising method. It shows that the NDOA-optimized method improves the performance of the classical wavelet threshold denoising.",10.1109/ACCESS.2019.2891759,2019,,WAVELET DENOISING ALGORITHM BASED ON NDOA COMPRESSED SENSING FOR FLUORESCENCE IMAGE OF MICROARRAY,
1093,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Medical imaging techniques play a critical role in diagnosing diseases and patient healthcare. They help in treatment, diagnosis, and early detection. Image segmentation is one of the most important steps in processing medical images, and it has been widely used in many applications. Multi-level thresholding (MLT) is considered as one of the simplest and most effective image segmentation techniques. Traditional approaches apply histogram methods; however, these methods face some challenges. In recent years, swarm intelligence methods have been leveraged in MLT, which is considered an NP-hard problem. One of the main drawbacks of the SI methods is when searching for optimum solutions, and some may get stuck in local optima. This because during the run of SI methods, they create random sequences among different operators. In this study, we propose a hybrid SI based approach that combines the features of two SI methods, marine predators algorithm (MPA) and moth-?ame optimization (MFO). The proposed approach is called MPAMFO, in which, the MFO is utilized as a local search method for MPA to avoid trapping at local optima. The MPAMFO is proposed as an MLT approach for image segmentation, which showed excellent performance in all experiments. To test the performance of MPAMFO, two experiments were carried out. The first one is to segment ten natural gray-scale images. The second experiment tested the MPAMFO for a real-world application, such as CT images of COVID-19. Therefore, thirteen CT images were used to test the performance of MPAMFO. Furthermore, extensive comparisons with several SI methods have been implemented to examine the quality and the performance of the MPAMFO. Overall experimental results confirm that the MPAMFO is an efficient MLT approach that approved its superiority over other existing methods.",10.1109/ACCESS.2020.3007928,2020,,AN IMPROVED MARINE PREDATORS ALGORITHM WITH FUZZY ENTROPY FOR MULTI-LEVEL THRESHOLDING: REAL WORLD EXAMPLE OF COVID-19 CT IMAGE SEGMENTATION,
1094,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Content-centric networking (CCN) has emerged as a promising architecture for future Internet due to its in-network caching capability and the receiver-driven content retrieval paradigm. Recently, the growing energy consumption driven by explosive increase of network traffic has become a key issue in CCN and caused widespread academic concern. In this paper, we construct a model to analyze the energy consumption of content distribution in CCN, and propose an energy efficiency based in-network caching scheme. In this scheme, a judging condition is designed to reduce the total energy consumption of content dissemination, and then in combination with content popularity and node importance, a cache placement strategy is proposed to optimize the selection of caching nodes. Furthermore, a neighbor cooperation-based cache replacement strategy is also proposed, which uses the cache resource of neighbor nodes to increase the chances of content being cached and improve the quality of caching service and resource utilization. Simulation results demonstrate that our scheme can outperform the existing schemes in terms of the high cache hit rate, the low average response hops, and the low whole energy consumption.",10.1109/ACCESS.2018.2823722,2018,,AN IN-NETWORK CACHING SCHEME BASED ON ENERGY EFFICIENCY FOR CONTENT-CENTRIC NETWORKS,
1095,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Person re-identification has recently attracted increasing interest in the computer vision and safety-critical applications. In practice, due to poor quality of cameras or long distance away from person, the captured pedestrian videos usually suffer from low resolution, which will result in the loss of useful information contained in videos and make person re-identification between low-resolution (LR) and high-resolution (HR) videos (PRLHV) be a challenging task. However, the problem of PRLHV has not been well studied. In this paper, we propose a semi-coupled mapping based set-to-set distance learning (SMDL) approach for PRLHV. Specifically, by regarding each video as a set of features extracted from several walking cycles, we learn a discriminative set-to-set distance metric to enhance the separability between videos from different persons. To decrease the influence of low resolution on the distance learning, we design a clustering-based semi-coupled mapping term for our approach, which can reduce the variation between features of low-resolution and high-resolution videos by a semi-coupled mapping matrix. Since there exists no low-resolution video pedestrian re-identification dataset under real-world scenario up to now, we contribute a benchmark dataset for PRLHV, named high-resolution and low-resolution video person re-identification dataset (HLVID). Although this dataset is challenging and difficult for person re-identification, it is a useful attempt for further studies on low-resolution video-based pedestrian re-identification under the real-world scene. The extensive experiments on the newly collected video dataset demonstrate that our approach performs better than the state-of-the-art person re-identification methods in the PRLHV task.",10.1109/ACCESS.2019.2912302,2019,,HIGH-RESOLUTION AND LOW-RESOLUTION VIDEO PERSON RE-IDENTIFICATION: A BENCHMARK,
1096,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The vehicle rescue process for individuals in residential areas in disaster scenarios is a typical vehicle routing problem (VRP). However, most studies do not consider the factor of individual mobility. In residential areas, there are two types of individuals: individuals with high mobility and individuals with low mobility, such as the elderly. To improve the evacuation efficiency, besides ordinary vehicles, special vehicles equipped with wheelchairs and volunteers are also in great need. Thus, evacuation vehicles should consist of a heterogeneous fleet. Vehicles depart from parking lots, arrive at residential areas to pick up individuals, and then transport them to shelters. In other words, the origin and destination are different, but they are viewed as the same in classical VRP. Each residential area can be served directly by vehicles departing from parking lots or by vehicles that have already served others, which means demands can be split. All these make the VRP in emergency rescue more complicated than classical VRP. Therefore, we propose an integer liner program model – multi-parking lot and shelter heterogeneous vehicle routing problem with split pickup (MPSHVRPSP) model, which includes matching constraints of individuals and vehicles to satisfy the demands of different types of individuals, and considers the selectivity of parking lots and shelters too. We provide a Tabu Search (TS) algorithm with diversification strategy to solve the model and ensure the high quality of solution. A lot of experiments are carried out on various instances. Our results show that MPSHVRPSP can be applied to efficient evacuation of complicated scenarios that satisfies the demands of all individuals in residential areas. Besides, it is more reasonable compared with classical VRP, and TS can also obtain a satisfactory solution in less time. Furthermore, sensitivity analysis is conducted on factors that may affect the result of objective function.",10.1109/ACCESS.2022.3163715,2022,,MULTI-PARKING LOT AND SHELTER HETEROGENEOUS VEHICLE ROUTING PROBLEM WITH SPLIT PICKUP UNDER EMERGENCIES,
1097,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"For multimodal medical image fusion problems, most of the existing fusion approaches are based on pixel-level. However, the pixel-based fusion method tends to lose local and spatial information as the relationships between pixels are not considered appropriately, which has much influence on the quality of the fusion results. To address this issue, a region-based multimodal medical image fusion framework is proposed based on superpixel segmentation and a post-processing optimization method in this paper. In this framework, the average image of the source medical images is firstly obtained by a weighted averaging method. To effectively obtain homogeneous regions and preserve the complete information of image details, the fast linear spectral clustering(LSC) superpixel algorithm is carried out to segment the average image and get superpixel labels. For each region of the medical images, log-gabor filter(LGF) and sum modified laplacian(SML) are adopted to extract texture feature and contrast feature for the measurement of region importance. The most important regions are selected and the decision map is generated by comparison. Moreover, to get a more accurate decision map, a new post-processing optimized method based on genetic algorithm(GA) is given. A weighted strategy is applied to the extracted features and the weighting factor can be adaptively adjusted by GA. The effectiveness of the proposed fusion method is validated by conducting experiments on eight pairs of medical images from diverse modalities. In addition, seven other mainstream medical image fusion methods are adopted for comparing the performance of fusion. Experimental results in terms of qualitative and quantitative evaluation demonstrate that the proposed method can achieve state-of-the-art performance for multimodal medical image fusion problems.",10.1109/ACCESS.2021.3094972,2021,,A NOVEL GA-BASED OPTIMIZED APPROACH FOR REGIONAL MULTIMODAL MEDICAL IMAGE FUSION WITH SUPERPIXEL SEGMENTATION,
1098,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper proposes a new variational pansharpening model with joint spectral and spatial consistency priors, which aims to fuse a low resolution (LR) multispectral (MS) image and a high resolution (HR) panchromatic (Pan) image to produce a pan-sharpened HR MS image. Specifically, the proposed model combines three consistency terms into a unified variational framework, which are (1) Local spectral consistency fidelity term, which enforces the degradation relation-based local spectral consistency constraint between the HR MS and LR MS images; (2) Hessian feature-enforced spatial consistency prior term, which particularly models the Hessian feature consistency constraint between the HR MS and Pan images to enforce spatial consistency; and (3) Wavelet-based spectral-spatial consistency prior term, which models the consistency between the HR MS image and the constructed Wavelet-based matching image to enforce spectral-spatial consistency. Moreover, the proposed model is efficiently solved by designing an optimization algorithm under the forward-backward splitting framework. Finally, experiments on the QuickBird, Pleiades and GeoEye-1 satellite datasets systematically illustrate that the proposed method performs better spectral and spatial qualities than various compared methods.",10.1109/ACCESS.2019.2957214,2019,,JOINT SPECTRAL AND SPATIAL CONSISTENCY PRIORS FOR VARIATIONAL PANSHARPENING,
1099,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper analyzes the mechanism of the smart inceptor on the aircraft, as a means to mitigate human-vehicle system loss-of-control. We divide the smart inceptor cue into three modes: the smart cue on the human pilot, the smart cue on the flight control system and the smart cue on both of them. The control mechanism of these three modes is developed and analyzed in depth. To evaluate the effect of the three modes, we utilize an intelligent human pilot model to establish the human-vehicle system with the smart inceptor and a scalogram-based pilot induced oscillation metric to predict the handling qualities of the three modes. This paper presents details of the cueing modes and the results of the prediction focused on effectiveness of these modes in preventing the pilots from entering a loss-of-control event. The simulation results indicate that the smart cue on both of them was the most effective method to mitigate the impact of the pilot-aircraft system oscillations for the given failure scenarios. It embodies the function of pilot-aircraft cooperation.",10.1109/ACCESS.2020.2981047,2020,,MECHANISM ANALYSIS OF SMART CUE ON AIRCRAFT FOR LOSS OF CONTROL MITIGATION,
1100,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Multimedia content delivery, such as video transmission over wireless networks, imposes significant challenges include spectrum capacity and packet losses. The cognitive radio (CR) technology is developed to solve the spectrum issue, while multiple description coding (MDC) is one of the promising source coding techniques to alleviate packet loss problems and exploit the benefit of path diversity. The source information was split into several descriptions in MDC, then transmitted over a network with multiple paths. The quality of the received data increases with the number of descriptions received at the receiver. In this paper, the proposed system comprises of relay-assisted cognitive radio network using the MDC technique for video transmission. In the simulations, the outage performance of the MDC scheme over two networks, which were relay-assisted network and non-relay network, were compared. Then, the outage probability was used to estimate the video quality, peak signal to noise ratio (PSNR) of the received video. The results obtained show the benefits of the relay assisted networks by 9% improvement on average outage performance over the non-relay network. Furthermore, the video performance improved by an average of 9% in PSNR compared to the non-relay system.",10.1109/ACCESS.2022.3146396,2022,,MULTIPLE DESCRIPTION CODING FOR ENHANCING OUTAGE AND VIDEO PERFORMANCE OVER RELAY-ASSISTED COGNITIVE RADIO NETWORKS,
1101,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Packet transport network (PTN), as an efficient transmission network technology in mobile communications in the big data era, is used by more and more communication operators. The existing PTN resource utilization rate is low, the network security is poor, so the existing PTN needs to be optimized in all aspects. For the optimization of the PTN, it is necessary to consider the decision of both the operator user and the service product supplier. Therefore, this paper proposes a bilevel multi-objective gray wolf algorithm based on PTN optimization problem. The operator user is the upper-level decision maker, and the objective function is to pay the product supplier the lowest cost. The product supplier is the lower-level decision maker, it mainly includes two major objective functions. The first objective function is to maximize the Label switching path overlap rate(LSPOR) evaluation score to solve the abnormal Label Switching Path (LSP) problem in the network, and the second is to maximize the committed bandwidth with utilizing rate(CBWUR) evaluation score to solve the problem of excessive Committed Information Rate(CIR) bandwidth usage in the network. According to the three scale network situation in Hubei, China, the improved multi-objective gray wolf algorithm is used to solve the PTN bilevel programming problem. The experimental results show that compared with the initial network, the optimized network size dropped by 125314 hops on average, the LSPOR increased by 13.64%, and the CBWUR increased by 3.7%. This model not only improves the utilization of network resources, but also reduces the cost to be paid by superior decision makers.",10.1109/ACCESS.2021.3130280,2021,,BILEVEL MULTI-OBJECTIVE GRAY WOLF ALGORITHM BASED ON PACKET TRANSPORT NETWORK OPTIMIZATION,
1102,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Complex networks (CNs) have gained much attention in recent years due to their importance and popularity. The rapid growth in the size of CNs leads to more difficulties in the analysis of CNs tasks. Community Detection (CD) is an important multidisciplinary research area where many machine/deep learning-based methods have been applied to map CNs into a low-dimensional representation for extracting information similarity among members of CNs. Currently, Deep Learning (DL) is one of the promising methods to extract knowledge and learn information from high dimensional space and represent it in low dimensional space. However, designing an accurate and efficient DL-based CD method especially when dealing with large CNs is always an on-going research endeavor to pursue. Meta-Heuristic (MH) algorithms have shown their potentials in improving DL models in terms of solution quality and computational cost. In addition, parallel computing is a feasible solution for building efficient DL models. The algorithmic principle of MH is parallel in nature; however, its computation framework in DL training that is reported in the literature is not really implemented in a parallel computing setup. In this paper, we present a systematic review of CD in CNs from conventional machine learning to DL methods and point out the gap of applying DL-based CD methods in large CNs. In addition, the relevant studies on DL with parallel and MH approaches are reviewed and their implications on DL models are highlighted to prospect effective solutions to overcome the challenges of DL-based CD methods. We also point out research challenges in the field of CD and suggest possible future research directions.",10.1109/ACCESS.2021.3095335,2021,,A REVIEW ON COMMUNITY DETECTION IN LARGE COMPLEX NETWORKS FROM CONVENTIONAL TO DEEP LEARNING METHODS: A CALL FOR THE USE OF PARALLEL META-HEURISTIC ALGORITHMS,
1103,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The rapid proliferation of artificial intelligence has led to the development of sophisticated cutting-edge systems in natural language processing and computational linguistics domains. These systems heavily rely on high-quality dataset/corpora for the training of deep-learning algorithms to develop precise models. The preparation of a high-quality gold standard corpus for natural language processing on a large scale is a challenging task due to the need of huge computational resources, accurate language identification models, and precise content parsing tools. This task is further exacerbated in case of regional languages due to the scarcity of web content. In this article, we propose a generic framework of Corpus Analyzer - Corpulyzer - a novel framework for building low resource language corpora. Our framework consists of corpus generation and corpus analyzer module. We demonstrate the efficacy of our framework by creating a high-quality large scale corpus for the Urdu language as a case study. Leveraging dataset from Common Crawl Corpus (CCC), first, we prepare a list of seed URLs by filtering the Urdu language webpages. Next, we use Corpulyzer to crawl the World-Wide-Web (WWW) over a period of four years (2016-2020). We build Urdu web corpus “UrduWeb20” that consists of 8.0 million Urdu webpages crawled from 6,590 websites. In addition, we propose Low-Resource Language (LRL) website scoring algorithm and content-size filter for language-focused crawling to achieve optimal use of computational resources. Moreover, we analyze UrduWeb20 using variety of traditional metrics such as web-traffic-rank, URL depth, duplicate documents, and vocabulary distribution along with our newly defined content-richness metrics. Furthermore, we compare different characteristics of our corpus with three datasets of CCC. In general, we observe that contrary to CCC that focuses on crawling the limited number of webpages from highly ranked Urdu websites, Corpulyzer performs an in-depth crawling of Urdu content-rich websites. Finally, we made available Corpulyzer framework for the research community for corpus building.",10.1109/ACCESS.2021.3049793,2021,,CORPULYZER: A NOVEL FRAMEWORK FOR BUILDING LOW RESOURCE LANGUAGE CORPORA,
1104,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Over the last few years, interference has been a major hurdle for successfully implementing various end-user applications in the fifth-generation (5G) of wireless networks. During this era, several communication protocols and standards have been developed and used by the community. However, interference persists, keeping given quality of service (QoS) provision to end-users for different 5G applications. To mitigate the issues mentioned above, in this paper, we present an in-depth survey of state-of-the-art non-orthogonal multiple access (NOMA) variants having power and code domains as the backbone for interference mitigation, resource allocations, and QoS management in the 5G environment. These are future smart communication and supported by device-to-device (D2D), cooperative communication (CC), multiple-input and multiple-output (MIMO), and heterogeneous networks (HetNets). From the existing literature, it has been observed that NOMA can resolve most of the issues in the existing proposals to provide contention-based grant-free transmissions between different devices. The key differences between the orthogonal multiple access (OMA) and NOMA in 5G are also discussed in detail. Moreover, several open issues and research challenges of NOMA-based applications are analyzed. Finally, a comparative analysis of different existing proposals is also discussed to provide deep insights to the readers.",10.1109/ACCESS.2021.3081601,2021,,A SYSTEMATIC REVIEW ON NOMA VARIANTS FOR 5G AND BEYOND,
1105,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Mining slopes, electrical power generation dams and several big construction enterprises demands continuous inspections. The size and diversity of these structures demands high precision and portable approach. In such environments, 3D reconstruction methodologies are able to capture and analyze the real world in detail. However, the accuracy and precision can affect the ability to process and interpret the acquired data. For instance, laser scanning is a very accurate method and can deliver a higher quality result. Meanwhile, 3D photogrammetry using a single camera and Structure From Motion (SFM) have their performance correlated with the image quality. In a typical application, 3D data from reconstruction is pre-processed by a specialist. Then, it is stored for comparison and analyzed over time. The posterior analysis has several challenges associated with the reconstruction process characteristics. Several techniques have been developed to allow the comparison of point cloud captured at different epochs. Therefore, this research work presents a new methodology to perform alignment and comparison of point clouds, namely 3D-CP2, an acronym for 3D Correspondence and Point Projection. This method intends to analyze the point cloud motion to be applied in terrestrial 3D SFM reconstructions. Besides, the technique can also be used in many other related applications. The methodology developed in this work is applied in controlled experiments and real use cases to show its potential for point cloud displacements analysis. The results showed that the proposed method is efficient and can produce results more accurately than the referenced literature.",10.1109/ACCESS.2020.3027205,2020,,3D CORRESPONDENCE AND POINT PROJECTION METHOD FOR STRUCTURES DEFORMATION ANALYSIS,
1106,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The auditory selection framework with attention and memory (ASAM), which has an attention mechanism, embedding generator, generated embedding array, and life-long memory, is used to deal with mixed speech. When ASAM is applied to speech enhancement, the discrepancy between the voice and noise feature memories is huge and the separability of noise and voice is increased. However, ASAM cannot achieve desirable performance in terms of speech enhancement because it fails to utilize the time-frequency dependence of the embedding vectors to generate a corresponding mask unit. This work proposes a novel embedding encoder-decoder (EED), and a convolutional neural network (CNN) is used as decoder. The CNN structure is good at detecting local patterns, which can be exploited to extract correlation embedding data from the embedding array to generate the target spectrogram. This work evaluates a similar ASAM, EED with an LSTM encoder and a CNN decoder (RC-EED), RC-EED with an attention mechanism (RC-AEED), other similar EED structures and baseline models. Experiment results show that RC-EED and RC-AEED networks have good performance on speech enhancement task at low signal-to-noise ratio conditions. In addition, RC-AEED exhibits superior speech enhancement performance over ASAM and achieves better speech quality than do deep recurrent network and convolutional recurrent network.",10.1109/ACCESS.2020.2995346,2020,,EMBEDDING ENCODER-DECODER WITH ATTENTION MECHANISM FOR MONAURAL SPEECH ENHANCEMENT,
1107,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"At present, the rate control algorithm for multiview high-efficiency video coding (MV-HEVC) does not have the capability of efficient coding tree unit(CTU) layer bit allocation, and the video quality varies greatly for sequences with sudden scene changes or large motions. To overcome this limitation, this paper proposes a rate control algorithm for MV-HEVC based on scene detection. Firstly, we established ρ domain rate control model based on multi-objective optimization. Then, it uses image similarity to make reasonable bit allocation among viewpoints. If the video scene is switched, the image similarity is recalculated, and then the correlation between the weights of the interview point rates and the correlation between the viewpoints are analyzed. Finally, the frame layer rate control considers the layer B-frame and other factors in allocating the code rate, and the basic unit layer rate control adopts different quantization methods according to the content complexity of the CTU. Experimental results show that the proposed rate control algorithm can maintain good coding efficiency and decrease the average video quality variation by 25.29%.",10.1109/ACCESS.2020.2970063,2020,,CTU LAYER RATE CONTROL ALGORITHM IN SCENE CHANGE VIDEO FOR FREE-VIEWPOINT VIDEO,
1108,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"News publishers have decreased disseminating news through conventional newspapers and have migrated to the use of digital means like websites and purpose-built mobile applications. It is observed that news recommendation systems can automatically process lengthy articles and identify similar articles for readers considering predefined criteria. The objectives of the current work are to identify and classify the challenges in news recommendation domain, to identify state-of-the-art approaches and classify on the application domain, to identify datasets used for evaluation and their sources, the evaluation approaches used and to highlight the challenges explicitly addressed. The literature is thoroughly studied over the time span of 2001-2019 and shortlisted 81 related studies, broadly classified into six categories and discussed. The analysis showed that 60% of news recommendation system adopted a hybrid approach, 66% studies little talk about datasets, and addresses a few challenges from a long list of challenges in the news domain. This article is the first in the field to draw a comprehensive big picture of news recommendation and explore different dimensions covered in the studies. The last section presents the future research opportunities that lead to improving the recommendation of news articles in the news domain.",10.1109/ACCESS.2020.2967792,2020,,"NEWS RECOMMENDATION SYSTEMS - ACCOMPLISHMENTS, CHALLENGES & FUTURE DIRECTIONS",
1109,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Service discovery is vital to event handling in Internet of Things applications which are based on the event-driven service-oriented architecture. However, in service discovery, the problem of service matching that establishes relationships between services and events has been seldom investigated through a semantic way. In this paper, to facilitate the efficiency of service discovery triggered by events, we propose a novel method of semantic service matching based on word embeddings. In this method, two types of semantic services about events (i.e., event-recognition services and event-handing services) are specified and matched through semantic similarity assessment that is conducted with word embeddings. Besides, to obtain highquality word embeddings, we present a hybrid approach for learning word embedding which treats words in distinct means according to word frequency. Experiments demonstrated on different data sets show that our method of semantic service matching is an effective way to facilitate event-driven service discovery, and the proposed training approach for word embeddings outperforms existing works and is able to improve the accuracy of event-driven service discovery.",10.1109/ACCESS.2018.2876029,2018,,EVENT-DRIVEN SEMANTIC SERVICE DISCOVERY BASED ON WORD EMBEDDINGS,
1110,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The vision of Industry 4.0, otherwise known as the fourth industrial revolution, is the integration of massively deployed smart computing and network technologies in industrial production and manufacturing settings for the purposes of automation, reliability, and control, implicating the development of an Industrial Internet of Things (I-IoT). Specifically, I-IoT is devoted to adopting the IoT to enable the interconnection of anything, anywhere, and at any time in the manufacturing system context to improve the productivity, efficiency, safety, and intelligence. As an emerging technology, I-IoT has distinct properties and requirements that distinguish it from consumer IoT, including the unique types of smart devices incorporated, network technologies and quality-of-service requirements, and strict needs of command and control. To more clearly understand the complexities of I-IoT and its distinct needs and to present a unified assessment of the technology from a systems’ perspective, in this paper, we comprehensively survey the body of existing research on I-IoT. Particularly, we first present the I-IoT architecture, I-IoT applications (i.e., factory automation and process automation), and their characteristics. We then consider existing research efforts from the three key system aspects of control, networking, and computing. Regarding control, we first categorize industrial control systems and then present recent and relevant research efforts. Next, considering networking, we propose a three-dimensional framework to explore the existing research space and investigate the adoption of some representative networking technologies, including 5G, machine-to-machine communication, and software-defined networking. Similarly, concerning computing, we again propose a second three-dimensional framework that explores the problem space of computing in I-IoT and investigate the cloud, edge, and hybrid cloud and edge computing platforms. Finally, we outline particular challenges and future research needs in control, networking, and computing systems, as well as for the adoption of machine learning in an I-IoT context.",10.1109/ACCESS.2018.2884906,2018,,A SURVEY ON INDUSTRIAL INTERNET OF THINGS: A CYBER-PHYSICAL SYSTEMS PERSPECTIVE,
1111,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Distributed photovoltaic (PV) solar power plants are playing an increasing role as a power generation resource in the modern electricity grid. However, PVs pose significant challenges to grid planners, operators, owners, investors, aggregators, and other stakeholders. This is due to the high uncertainty of the PV output power, which is caused by its entire dependence on intermittent environmental factors. This has brought a serious problem to the power industry to integrate and manage power grids containing significant penetration of PVs. Thus, an enhanced PV power forecast is very important to operate these power grids efficiently and reliably. Most previous methodologies have focused on predicting the aggregate amount of potential solar power generation at the national or regional scale and ignored the distributed PVs that are installed primarily for local electric supply. Furthermore, a few research groups have carried out predictor selection before training predictive models. This paper proposes an adaptive hybrid predictor subset selection (PSS) strategy to obtain the most relevant and nonredundant predictors for enhanced short-term forecasting of the power output of distributed PVs. In the proposed strategy, the binary genetic algorithm (BGA) is applied for the feature selection process and support vector regression (SVR) is used for measuring the fitness score of the predictors. In order to validate the effectiveness of the proposed strategy, it is applied to actual distributed PVs located in the Otaniemi area of Espoo, Finland. The findings are compared with those achieved by other PSS techniques. The proposed strategy enhances the quality and efficiency of the predictor subset selection, with minimal chosen predictors to achieve enhanced prediction accuracy. It outperforms the other prediction selection methods. Besides, a configuration of an adaptive forecasting model is introduced and the performance tests are presented to further validate the impact of the PSS results for the PV power prediction accuracy enhancement.",10.1109/ACCESS.2019.2926826,2019,,ADAPTIVE PREDICTOR SUBSET SELECTION STRATEGY FOR ENHANCED FORECASTING OF DISTRIBUTED PV POWER GENERATION,
1112,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Major advances in information and communication technologies (ICTs) make citizens to be considered as sensors in motion. Carrying their mobile devices, moving in their connected vehicles or actively participating in social networks, citizens provide a wealth of information that, after properly processing, can support numerous applications for the benefit of the community. In the context of smart communities, the INRISCO [1] proposal intends for (i) the early detection of abnormal situations in cities (i.e., incidents), (ii) the analysis of whether, according to their impact, those incidents are really adverse for the community; and (iii) the automatic actuation by dissemination of appropriate information to citizens and authorities. Thus, INRISCO will identify and report on incidents in traffic (jam, accident) or public infrastructure (e.g., works, street cut), the occurrence of specific events that affect other citizens' life (e.g., demonstrations, concerts), or environmental problems (e.g., pollution, bad weather). It is of particular interest to this proposal the identification of incidents with a social and economic impact, which affects the quality of life of citizens.",10.1109/ACCESS.2020.2987483,2020,,INRISCO: INCIDENT MONITORING IN SMART COMMUNITIES,
1113,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the occurrence of Internet of Things (IoT) era, the proliferation of sensors coupled with the increasing usage of wireless spectrums especially the ISM band makes it difficult to deploy real-life IoT. Currently, the cognitive radio technology enables sensors transmit data packets over the licensed spectrum bands as well as the free ISM bands. The dynamic spectrum access technology enables secondary users (SUs) access wireless channel bands that are originally licensed to primary users. Due to the high dynamic of spectrum availability, it is challenging to design an efficient routing approach for SUs in cognitive sensor networks. We estimate the spectrum availability and spectrum quality from the view of both the global statistical spectrum usage and the local instant spectrum status, and then introduce novel routing metrics to consider the estimation. In our novel routing metrics, one retransmission is allowed to restrict the number of rerouting and then increase the routing performance. Then, the related two routing algorithms according to the proposed routing metrics are designed. Finally, our routing algorithms in extensive simulations are implemented to evaluate the routing performance, and we find that the proposed algorithms achieve a significant performance improvement compared with the reference algorithm.",10.1109/ACCESS.2017.2681743,2017,,SPECTRUM-AVAILABILITY BASED ROUTING FOR COGNITIVE SENSOR NETWORKS,
1114,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Recently, deep convolutional neural networks (CNNs) have been attracting considerable attention in single image super-resolution. Some CNN-based methods, such as VDSR verified that residual learning can speed up the training and significantly improve the performance of accuracy. However, with very deep networks, convergence speed is still a critical issue in training due to the cost of requiring enormous parameters. In order to deal with this issue, we redesign the residual networks based on dilated networks. In this paper, we propose symmetrical dilated residual convolution networks (FDSR) to tackle image super-resolution problems. Our network is on the basis of the dilated convolutions supported exponential expansion of the receptive field without loss of resolution and coverage. This means that FDSR can speed up the training and improve the performance of accuracy without increasing the model's depth or complexity. Meanwhile, we attempt to combine the image pre-processing approach of VGG-net with mean squared error (MSE) to enhance the performance. The experimental results demonstrate that the training time-consuming proposed model achieves nearly a half with even superior restoration quality. Further, we present a novel network with less layers and parameters can achieve real-time performance on a generic CPU and still maintain superior performance.",10.1109/ACCESS.2018.2865613,2019,,FAST SINGLE IMAGE SUPER-RESOLUTION VIA DILATED RESIDUAL NETWORKS,
1115,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Due to the impressive learning power, deep learning has achieved a remarkable performance in supervised hash function learning. In this paper, we propose a novel asymmetric supervised deep hashing method to preserve the semantic structure among different categories and generate the binary codes simultaneously. Specifically, two asymmetric deep networks are constructed to reveal the similarity between each pair of images according to their semantic labels. Furthermore, since the binary codes in the Hamming space also should keep the semantic affinity existing in the original space, another asymmetric pairwise loss is introduced to capture the similarity between the binary codes and real-value features. This asymmetric loss not only improves the retrieval performance, but also contributes to a quick convergence at the training phase. By taking advantage of the two-stream deep structures and two types of asymmetric pairwise functions, an alternative algorithm is designed to efficiently optimize the deep features and high-quality binary codes. Experimental results on three real-world datasets substantiate the effectiveness and superiority of our approach as compared with the state-of-the-art.",10.1109/ACCESS.2019.2927524,2019,,DUAL ASYMMETRIC DEEP HASHING LEARNING,
1116,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Image inpainting is a hot topic in computer vision research and has been successfully applied to both traditional and digital mediums, such as oil paintings or old photos mending, image or video denoising and super-resolution. With the introduction of artificial intelligence (AI), a series of algorithms, represented by semantic inpainting, have been developed and better results were achieved. Medical image inpainting, as one of the most demanding applications, needs to meet both the visual effects and strict content correctness. 3D reconstruction of microstructures, based on serial sections, could provide more spatial information and help us understand the physiology or pathophysiology mechanism in histology study, in which extremely high-quality continuous images without any defects are required. In this article, we proposed a novel Consecutive Context Perceive Generative Adversarial Networks (CCPGAN) for serial sections inpainting. Our method can learn semantic information from its neighboring image, and restore the damaged parts of serial sectioning images to maximum extent. Validated with 2 sets of serial sectioning images of mouse kidney, qualitative and quantitative results suggested that our method could robustly restore breakage of any size and location while achieving near realtime performance.",10.1109/ACCESS.2020.3031973,2020,,CONSECUTIVE CONTEXT PERCEIVE GENERATIVE ADVERSARIAL NETWORKS FOR SERIAL SECTIONS INPAINTING,
1117,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"IoT deployments for smart cities and smart buildings have been multiplying exponentially in recent years, benefiting from a steady rise in the number of new technologies that deal with the underlying networking and application challenges in indoor and outdoor spaces. Due to the overlap in their specifications, we are still trying to figure out which of these technologies fits better to certain application domains, such as building monitoring. In this work, we provide a comparative study between IEEE 802.15.4 and LoRa, based on our experiences from using both wireless networking technologies in the context of indoor deployments aimed at IoT-enabled school buildings in Europe. We provide an apples-to-apples comparison between the two technologies, comparing them in some cases in the same building and application context. Although these two technologies initially might not seem to be competing in the same application space, in practice we found out that both have strengths and weaknesses in the specific application domain we have been using them. Moreover, our LoRa-based networking implementation, on top of Arduino-based hardware, appears to be an option that allows for a robust, reliable and lower overall cost IoT deployment, especially in cases with multi-floor building installations and low bandwidth requirements. We also present a network-level dataset produced from our installations and upon which we based our findings and discussion. We provide data collected from 6 different school buildings, 8 networks and 49 devices, to compare the performance and cost-effectiveness of competing IoT technologies. In that effect, with LoRa we can achieve similar or better link quality to IEEE 802.15.4, with higher data rate and lower costs.",10.1109/ACCESS.2020.3020685,2020,,A COMPARATIVE STUDY OF LORA AND IEEE 802.15.4-BASED IOT DEPLOYMENTS INSIDE SCHOOL BUILDINGS,
1118,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The task of remaining useful life (RUL) uncertainty management is the major challenge in solving the failure of the complex mechanical system. Primary research methods use statistical models or stochastic processes to fit the distribution of historical degradation data. However, it is difficult to accurately capture the degradation information of monitoring big data through statistics in practice. In this paper, the prediction interval (PI) obtained by the proposed feature attention-log-norm bidirectional gated recurrent unit (FA-LBiGRU) model is adopted to quantify the prediction uncertainty of RUL. Initially, the critical feature vectors are extracted from multi-dimensional, nonlinear, and large-scale sensor signals using the feature attention mechanism. Additionally, the BiGRU network is used to model and learn the time-varying characteristics of the attention-weighted features from the forward and backward directions, and the network parameters are trained by the maximum log-likelihood loss function. Ultimately, the probability density function based on the lognormal distribution is calculated to measure the uncertainty of the equipment RUL. The effectiveness of the proposed method is verified through the well-known benchmark data set of the turbofan engines provided by NASA. The experimental results show that the proposed methods can obtain higher point prediction accuracy for the complex system compared with state-of-the-art approaches and high-quality PIs satisfying real-time requirements.",10.1109/ACCESS.2022.3212694,2022,,REMAINING USEFUL LIFE INTERVAL PREDICTION FOR COMPLEX SYSTEM BASED ON BIGRU OPTIMIZED BY LOG-NORM,
1119,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the global marketplace, supply chains are becoming increasingly linked. The risk posed by the ripple effect of uncertainty will damage the normal operation of the entire supply chain, so it is an important issue to enhance the resilience of enterprises that manufacture electronic to reduce the ripple effects of supply chains. Quality function deployment (QFD) has been applied in many areas to solve multi-criteria decision making (MCDM) problems successfully. However, there is still lack of study has addressed the improvement of supply chain resilience through Industry 4.0 to alleviate the ripple effect, and the application of QFD to integrate and analyze the relationship between Industry 4.0 and supply chain resilience, and between supply chain resilience and the ripple effect. Therefore, this study proposes an integrated QFD-MCDM model to identify the key Industry 4.0 enablers (I4Es) to strengthen supply chain resilience indicators (SCRIs) and mitigate the ripple effect risk factors (RERFs), thus providing an effective method for enterprises to develop a resilient supply chain that can quickly respond to changes and uncertainties. The case study considered China’s largest relay manufacturing enterprise as the object and obtained important management insights, as well as practical significance, from implementing the proposed research framework. The study found the following to be the most urgent I4Es required to strengthen SCRIs and reduce the key RERFs: IT information technology structure and level, enterprise strategic management and new technology coordination, supply chain digitization, analysis and management of big Data, IT Infrastructure and use digital technology for new product innovation, intelligent. When these measures are improved, the SCRIs can be improved, such as risk awareness, efficiency, agility, sustainability, coordination and cooperation, supply chain structure and safety assurance. Finally, RERFs, such as the ripple effect caused by economic collapse, epidemic conditions, natural disasters, political factors, supply chain operation capability caused, can be alleviated or eliminated. With limited resources, enterprises can devote their most important resources to the most critical Industry 4.0 improvement strategies. This framework provides an effective method for electronics manufacturers to formulate I4Es and strengthen SCRIs to mitigate the RERFs, and also provides a reference for enterprises in other fields of supply chain management.",10.1109/ACCESS.2022.3215620,2022,,DEPLOYING INDUSTRY 4.0 ENABLERS TO STRENGTHEN SUPPLY CHAIN RESILIENCE TO MITIGATE RIPPLE EFFECTS: AN EMPIRICAL STUDY OF TOP RELAY MANUFACTURER IN CHINA,
1120,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper describes an innovative approach to radio channel characterization in UMTS and LTE mobile networks. In place of traditional drive tests (DT), which employ a single test mobile, a massive collection of georeferenced radio measurements is made from a wide population of user equipment (UE). This is possible with new 3GPP features, called “minimization of DTs” (MDT), which are implemented in the last generation UEs and enable the reporting of additional periodical measurements, including GPS position and estimated UE distance (i.e. delay) over the radio path. This opens to new fields of investigation in the mobile radio channel, unreachable with the legacy DT approach, such as multipath and Doppler analysis. The UE MDT data of UMTS and LTE RAN of Telecom Italia Mobile, in the Italian midsized city of Bologna, have been statistically analyzed. The big data elaboration has been performed with the Nokia proprietary system “GeoSynthesis.” The results give a high-resolution geographical view of the above-mentioned channel phenomena affecting the quality and user experience. They are in good accordance with network performance indicators: the higher the multipath time, the worse the decoding performance of radio blocks (block error rate). The estimated Doppler shift also fits the known mobility patterns in the urban environment.",10.1109/ACCESS.2019.2892864,2019,,MULTIPATH AND DOPPLER CHARACTERIZATION OF AN ELECTROMAGNETIC ENVIRONMENT BY MASSIVE MDT MEASUREMENTS FROM 3G AND 4G MOBILE TERMINALS,
1121,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"One of the most important classification problems is selecting proper features, i.e. features that describe the classified object in the most straightforward way possible. Then, one of the biggest challenges of the feature selection is the evaluation of the feature’s quality. There is a plethora of feature evaluation methods in the literature. This paper presents the results of a comparison between nine selected feature evaluation methods, both existing in literature and newly defined. To make a comparison, features from ten various sets were evaluated by every method. Then, from every feature set, best subset (according to each method) was chosen. Those subsets then were used to train a set of classifiers (including decision trees and forests, linear discriminant analysis, naive Bayes, support vector machines, k nearest neighbors and an artificial neural network). The maximum accuracy of those classifiers, as well as the standard deviation between their accuracies, were used as a quality measures of each particular method. Furthermore, it was determined, which method is the most universal in terms of the data set, i.e. for which method, obtained accuracies were dependent on the feature set the least. Finally, computation time of each method was compared. Results indicated that for applications with limited computational power, method based on the average overlap between feature’s values seem best suited. It led to high accuracies and proved to be fast to compute. However, if the data set is known to be normally distributed, method based on two-sample  ${t}$ -test may be preferable.",10.1109/ACCESS.2021.3058428,2021,,EMPIRICAL COMPARISON OF THE FEATURE EVALUATION METHODS BASED ON STATISTICAL MEASURES,
1122,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the expansion of the network and increasing their users, as well as emerging new technologies, such as cloud computing and big data, managing traditional networks is difficult. Therefore, it is necessary to change the traditional network architecture. Lately, to address this issue, a notion named software-defined network (SDN) has been proposed, which makes network management more conformable. Due to limited network resources and to meet the requirements of quality of service, one of the points that must be considered is load balancing issue that serves to distribute data traffic among multiple resources in order to maximize the efficiency and reliability of network resources. Load balancing is established based on the local information of the network in the conventional network. Hence, it is not very precise. However, SDN controllers have a global view of the network and can produce more optimized load balances. Although load balancing mechanisms are important in the SDN, to the best of our knowledge, there exists no precise and systematic review or survey on investigating these issues. Hence, this paper reviews the load balancing mechanisms which have been used in the SDN systematically based on two categories, deterministic and non-deterministic. Also, this paper represents benefits and some weakness regarded of the selected load balancing algorithms and investigates the metrics of their algorithms. In addition, the important challenges of these algorithms have been reviewed, so better load balancing techniques can be applied by the researchers in the future.",10.1109/ACCESS.2018.2805842,2018,,LOAD BALANCING MECHANISMS IN THE SOFTWARE DEFINED NETWORKS: A SYSTEMATIC AND COMPREHENSIVE REVIEW OF THE LITERATURE,
1123,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Automated sewer defects detection has become an important trend for better management and maintenance of urban sewer systems. Deep learning technology has developed rapidly and offers an innovative solution for automated detection in engineering applications. However, insufficient data and unbalanced samples have proposed a big challenge to deep learning model training. This study adopts the state-of-the-art Style-based Generative Adversarial Networks (StyleGANs) model and compares the performances of its two variants in producing high-quality synthetic sewer defects images. Seven well-known CNN models are further fine-tuned and trained using the synthetic images for automated sewer defects detection to examine the effects of StyleGANs on augmenting the detection performance. Results show that both StyleGANs are efficient in producing high-quality images with various styles and high-level details for multiple types of sewer defects. Specifically, the StyleGAN2-Adaptive Discriminator Augmentation (StyleGAN2-ADA) with the aid of Freeze Discriminator (Freeze-D) yields the best model performance. Among the adopted CNN classifiers, Inception_v3 achieves the highest detection accuracy. The mean detection accuracy is 94% (with a specific accuracy of 99.7%, 97%, 95.3% and 84% for tree root, residential wall, disjoint and obstacle, respectively) and confirms the reliability of the StyleGANs' performance. The study shows that StyleGANs provide a promising method to alleviate the limited and uneven dataset problem and can improve the deep learning model performance.",10.1109/ACCESS.2021.3073915,2021,,AUTOMATED SEWER DEFECTS DETECTION USING STYLE-BASED GENERATIVE ADVERSARIAL NETWORKS AND FINE-TUNED WELL-KNOWN CNN CLASSIFIER,
1124,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The rapid urbanization process in the last century has deeply changed the way we live and interact with each other. As most people now live in urban areas, cities are experiencing growing demands for more efficient and sustainable public services that may improve the perceived quality of life, specially with the anticipated impacts of climatic changes. In this already complex scenario with increasingly overcrowded urban areas, different types of emergency situations may happen anywhere and anytime, with unpredictable costs in human lives and economic losses. In order to cope with unexpected and potentially dangerous emergencies, smart cities initiatives have been developed in different cities, addressing multiple aspects of emergencies detection, alerting, and mitigation. In this context, this article surveys recent smart city solutions for crisis management, proposing definitions for emergencies-oriented systems and classifying them according to the employed technologies and provided services. Additionally, recent developments in the domains of Internet of Things, Artificial Intelligence and Big Data are also highlighted when associated to the management of urban emergencies, potentially paving the way for new developments while classifying and organizing them according to different criteria. Finally, open research challenges will be identified, indicating promising trends and research directions for the coming years.",10.1109/ACCESS.2022.3180033,2022,,A SURVEY OF EMERGENCIES MANAGEMENT SYSTEMS IN SMART CITIES,
1125,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Over time, load balancing systems in cellular networks have been key to avoiding overload problems in the network and to maintaining a correct resource allocation and performance. However, the classical approaches were not designed for the dynamism generated by user behavior. The big crowds of users at certain social venues are one of the main concerns of mobile operators due to the load imbalance generated. Additionally, the mobility of users who attend social events (e.g., sports events, concerts, etc.) greatly impacts network performance due to its high correlation with network traffic. The availability to inform about events, particularly regarding venue location (e.g., stadiums, concert halls, convention centers) is exponentially growing thanks to its proliferation in social networks through geolocation databases and other functionalities. Therefore, the present work proposes a novel load balancing system integrating a fuzzy logic controller algorithm with social-awareness, which considers the relative position between cell sites and the social event venue in order to configure the network parameters. This approach is evaluated for different configurations of load balancing methods simulated on an urban macro scenario, mitigating the impact of the number of users per cell without degrading the signal quality. In this way, results show that social event data information plus soft or aggressive transmission power changes in cells can help to maintain the balance in the number of users per cell during mass events.",10.1109/ACCESS.2021.3100459,2021,,SOCIAL-AWARE LOAD BALANCING SYSTEM FOR CROWDS IN CELLULAR NETWORKS,
1126,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"A vast majority of the Internet of Things (IoT) devices will be connected in a topology where the edge-devices push data to a local gateway, which forwards the data to a cloud for further processing. In sizeable outdoor deployment regions, the edge-devices may experience poor connectivity due to their distant locations and limited transmission power. Repeaters or relays must be placed at a few locations to ensure reliable connectivity to either a gateway or another node in the network. A big challenge in achieving reliable connectivity and coverage is the outdoor propagation environment being heterogeneous. Engineers often deploy networks based on resource-intensive field visits, detailed surveys, measurements, initial test deployments, followed by fine-tuning. For scalability to large scale IoT deployments, automated network planning tools are essential. Such tools should predict connectivity based on the edge-device locations using available Geographical Information System (GIS) data, identify the need for relays/repeaters, and, if needed, suggest the number of relays needed with their locations. Furthermore, such tools should also be extended to suggest the minimum number and locations of base stations that maximise coverage. In this paper, we propose an automated network deployment framework using a black box received signal strength estimation oracle that provides signal strength estimates between candidate pairs of transceiver locations in a heterogeneous deployment region. Our proposed methodology uses either Ant Colony Optimisation (ACO) or Differential Evolution (DE) to identify the number and locations of relays for meeting specified quality of service constraints. We discuss adaptations of our techniques to handle scenarios with multiple gateways. Further, we show the effectiveness of these algorithms to find suitable candidate base station locations to provide coverage in a heterogeneous propagation environment that meets the specified quality of service constraints. We then demonstrate the effectiveness of our algorithms in two deployment regions.",10.1109/ACCESS.2022.3147488,2022,,RELAY PLACEMENT ALGORITHMS FOR IOT CONNECTIVITY AND COVERAGE IN AN OUTDOOR HETEROGENEOUS PROPAGATION ENVIRONMENT,
1127,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the exponential rise in the number of devices, the Internet of Things (IoT) is geared toward edge-centric computing to offer high bandwidth, low latency, and improved connectivity. In contrast, legacy cloud-centric platforms offer deteriorated bandwidth and connectivity that affect the quality of service. Edge-centric Internet of Things-based technologies, such as fog and mist computing, offer distributed and decentralized solutions to resolve the drawbacks of cloud-centric models. However, to foster distributed edge-centric models, a decentralized consensus system is necessary to incentivize all participants to share their edge resources. This paper is motivated by the shortage of comprehensive reviews on decentralized consensus systems for edge-centric Internet of Things that elucidates myriad of consensus facets, such as data structure, scalable consensus ledgers, and transaction models. Decentralized consensus systems adopt either blockchain or blockchainless directed acyclic graph technologies, which serve as immutable public ledgers for transactions. This paper scrutinizes the pros and cons of state-of-the-art decentralized consensus systems. With an extensive literature review and categorization based on existing decentralized consensus systems, we propose a thematic taxonomy. The pivotal features and characteristics associated with existing decentralized consensus systems are analyzed via a comprehensive qualitative investigation. The commonalities and variances among these systems are analyzed using key criteria derived from the presented literature. Finally, several open research issues on decentralized consensus for edge-centric IoT are presented, which should be highlighted regarding centralization risk and deficiencies in blockchain/blockchainless solutions.",10.1109/ACCESS.2017.2779263,2018,,"DECENTRALIZED CONSENSUS FOR EDGE-CENTRIC INTERNET OF THINGS: A REVIEW, TAXONOMY, AND RESEARCH ISSUES",
1128,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In this paper, a novel image compression–encryption hybrid algorithm is proposed. First, a Gauss random matrix and a random scrambling matrix are generated by using Chebyshev mapping and Logistic mapping, respectively. Then, based on the principle that a scrambling Gauss matrix is still a Gauss matrix, a compression scheme for ciphertext images is designed. It is dependent on the Gauss random matrix and the random scrambling matrix, which mainly consists of three parts: the permutation-based encryption using random scrambling matrix by Alice, the encoding with Gauss random matrix by Charlie, and the joint decryption and decoding by Bob. It has a special application scenario, that is, Alice requires semi integrity Charlie to transmit images to Bob through a channel. Experimental results show that the scheme has strong robustness against noise and chosen-plaintext attack, and further the peak signal-to-noise ratio (PSNR) and subjective visual quality of reconstructed images can be improved by comparing with the similar methods.",10.1109/ACCESS.2018.2874336,2018,,A NOVEL IMAGE COMPRESSION-ENCRYPTION SCHEME BASED ON CHAOS AND COMPRESSION SENSING,
1129,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Scene text detection is to detect the position of a text in the natural scene, the quality of which will directly affect the subsequent text recognition. It plays an important role in fields such as image retrieval and autopilot. How to perform multi-scale and multi-oriented text detection in the scene still remains as a problem. This paper proposes an effective scene text detection method that combines the convolutional neural network (CNN) and recurrent neural network (RNN). In order to better adapt to texts in different scales, feature pyramid networks (FPN) have been applied in the CNN part to extract multi-scale features of the image. We then utilize bidirectional long-short-term memory (Bi-LSTM) to encode these features to make full use of the text sequence characteristics with the outputs as a series of text proposals. The generated proposals are finally linked into a text line through a well-designed text connector, which can be flexibly adapted to any oriented texts. The proposed method is evaluated on three public datasets: ICDAR2013, ICDAR2015, and USTB-SV1K. For ICDAR2013 and USTB-1K, we have reached 92.5% and 62.6% F-measure, respectively. Our method has reached 72.8% F-measure on the more challenging ICDAR2015 which demonstrates the effectiveness of our method.",10.1109/ACCESS.2019.2908933,2019,,FTPN: SCENE TEXT DETECTION WITH FEATURE PYRAMID BASED TEXT PROPOSAL NETWORK,
1130,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Blur kernel (BK) estimation is the crucial technique to guarantee the success of blind image deblurring. In this paper, we propose a multi-regularization-constrained method to estimate an accurate BK from a single motion-blurred image. First, in order to generate sharp and reliable intermediate latent results, we propose a model which combines the spatial scale,  ${L} _{0}$  norm, and the dark channel prior. Second, in order to preserve the continuity and the sparsity, and to remove the flaw in the BK, a dual-constrained regularization model, which combines the  ${L} _{0}$ -regularized intensity prior and the  ${L} _{2}$ -regularized gradient prior, is proposed for accurate BK estimation. The proposed model can not only preserve the continuity and the sparsity of the BK very well but also can remove the flaw thoroughly. Finally, we propose an efficient optimization strategy which can solve the proposed model efficiently. Extensive experiments compared with the state-of-the-art methods demonstrate that our method estimates more accurate BKs and obtains higher quality deblurring images in terms of both subjective vision and quantitative metrics.",10.1109/ACCESS.2018.2889466,2019,,MULTI-REGULARIZATION-CONSTRAINED BLUR KERNEL ESTIMATION METHOD FOR BLIND MOTION DEBLURRING,
1131,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The pickup and delivery problem with time windows and last-in-first-out (LIFO) loading (PDPTWL) is a combinational optimization problem extended from the well-known vehicle routing problem (VRP), in which the type of customer point is no longer single and the loading order of the requests must meet the LIFO constraint. Due to its NP-hard nature, it is difficult for exact algorithms and heuristics with a linear structure to solve a large-scale problem in a reasonable time. In this paper, we propose a fast decomposition and reconstruction framework (D&R) to solve the PDPTWL with high quality in a relatively short time. An angle-based sweep method is used to decompose a complete solution into multiple sub-solutions, each of which is assigned to a tabu search for optimization. To speed up the whole process, the optimization procedure of sub-solutions is performed by different processors of multi-core CPU in parallel. Three neighborhood operators and three strategies to reduce the number of vehicles are designed to cope with the tabu search for further improvement. Moreover, the adaptive memory mechanism is added to provide a better start when the optimization procedure falls into the local optima. We compare our framework against the best known solutions on 119 instances with up to 300 requests, the results show that our framework is able to improve over 85% (107 out of 119) of the best known solutions. More specifically, the number of vehicles is optimized by about 60% (74 out of 119) and the driving distance by about 50% (59 out of 119). In addition on instances with the largest size of requests, the computational time of our framework can be 1/50 of the comparative results, confirming its efficiency.",10.1109/ACCESS.2019.2920444,2019,,A FAST DECOMPOSITION AND RECONSTRUCTION FRAMEWORK FOR THE PICKUP AND DELIVERY PROBLEM WITH TIME WINDOWS AND LIFO LOADING,
1132,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The minimum vertex cover problem is a well-known optimization problem; it has been used in a wide variety of applications. This paper focuses on rough set-based approach for the minimum vertex cover problem of the dynamic and static hypergraphs. First, we demonstrate the relationship between the attribute reduction of decision table and the minimum vertex cover of hypergraph, and the minimum vertex cover problem is converted to an attribute reduction problem based on this relationship. Then, we discuss the update mechanism of minimum vertex cover from the perspective of attribute reduction, and two types of incremental attribute reduction algorithms are proposed, one is the dynamic increase of single vertex and the other is the dynamic increase of multiple vertices. Our algorithms can quickly update the minimum vertex cover in a dynamic hypergraph and improve the rough sets-based method for the minimum vertex cover problem of a static hypergraph in terms of the computational time and the solution quality. The experimental results show the advantages and limitations of the proposed algorithms compared with the existing algorithms.",10.1109/ACCESS.2018.2868846,2018,,DIMENSION INCREMENTAL FEATURE SELECTION APPROACH FOR VERTEX COVER OF HYPERGRAPH USING ROUGH SETS,
1133,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The dynamics of a machine tool have an important influence on the quality and efficiency of the machining process. In this paper, the modal parameters identification method of machine tools under normal cutting excitation is proposed based on the fact that the random components in the cutting force can provide an effective excitation. However, the generated cutting force during machining contains strong periodic components and does not satisfy the white noise assumption. Directly applying the operational modal analysis (OMA) method will face serious harmonic interference. Therefore, it is difficult to ensure the accuracy of the identified parameters. The cepstrum editing method is proposed to eliminate the periodic component. And the modal parameters are extracted from the remaining signal by using the OMA method. The experimental results show that the proposed method works well under normal cutting conditions.",10.1109/ACCESS.2020.3006226,2020,,IDENTIFICATION METHOD OF MODAL PARAMETERS OF MACHINE TOOLS UNDER PERIODIC CUTTING EXCITATION,
1134,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Although iris recognition has achieved big successes on biometric identification in recent years, difficulties in the collection of iris images with high resolution and in the segmentation of valid regions prevent it from applying to large-scale practical applications. In this paper, we present an eye recognition framework based on deep learning, which relaxes the data collection procedure, improves the anti-fake quality, and promotes the performance of biometric identification. Specifically, we propose and train a mixed convolutional and residual network (MiCoRe-Net) for the eye recognition task. Such an architecture inserts a convolutional layer between every two residual layers and takes the advantages from both of convolutional networks and residual networks. Experiment results show that the proposed approach achieves accuracies of 99.08% and 96.12% on the CASIA-Iris-IntervalV4 and the UBIRIS.v2 datasets, respectively, which outperforms other classical classifiers and deep neural networks with other architectures.",10.1109/ACCESS.2018.2812208,2018,,EYE RECOGNITION WITH MIXED CONVOLUTIONAL AND RESIDUAL NETWORK (MICORE-NET),
1135,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The advances in underwater sensor communication has become imperative getting up-to-date information about underwater happenings, especially when world has already faced the calamity like Tsunami. The underwater environment possessed freak and unpredictable movements which becomes more harsh time to time. The sensor nodes deployed under such juncture are the main source of information which in fact, facing numerous challenges. These nodes are mainly energy-constrained and rely on limited battery source. Due to most intricated underwater routing architecture, the biggest detriment is the limited battery lifespan. Therefore, it is imperative to adopt the pragmatic and possible alternate to improve the life expectancy of these sensor nodes. The solution of such shortcomings and identifying the varieties of impingements impelled by forwarding node on battery lifespan during packet transmission course are meticulously explored by developing an Underwater Pragmatic Routing Approach through Packet Reverberation mechanism (UPRA-PR). It is a novel approach and never considered in past. Through Packet Reverberation technique, the use of energy has been confined and the desired outcomes are achieved in four phases. In the first phase, the eligibility criteria for both packet and nodes have been computed by setting the Node Depth Factor ( $\text{N}_{\mathrm {df}}$ ). Second phase formulates the forwarding relay node mechanism and rummage out the path failure by complying a Data Rate criterion  $D_{0}$ . The selection of the shrewd communication link is established in third phase by considering an Accepted Link Quality (ALQ) factor. The fourth phase where most prominent developments has been made regarding impingements effects on the battery lifespan left by the forwarding node after the packet transmission. The UPRA-PR performance metrics are assessed by staging extensive NS2 simulation with AquaSim 2.0 and compared to state-existing routing protocols i.e., DBR, H2DAB, GEDAR and FBR for Packet dissemination ratio, Path failure, Point-to-point delay estimation, System energy consumption, Network lifespan, Forwarding node impingement and Network throughput. The simulation results have ratified the UPRA-PR performance and justified the statements made in this respect.",10.1109/ACCESS.2020.3022565,2020,,UNDERWATER PRAGMATIC ROUTING APPROACH THROUGH PACKET REVERBERATION MECHANISM,
1136,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In healthcare, mobile-based interventions support the improvement of clinical process and result in a positive behavioral change and improve the patients' health condition. This study aims at reviewing mobile applications documented for pain management in the scientific databases, to identify the key factors that are vital for pain management. In this research, a systematic literature review was conducted on the selected studies collected from five scientific databases: Medline, PubMed, EMBASE, Web of Science and Scopus. After applying the inclusion and exclusion criteria and performing the quality assessment, twenty-five studies were finalized. It has been observed that the apps were not all-inclusive in features to provide an effective pain self-management solution. As found from the review, the general features of the pain management mobile applications are pain information, pain coping strategy, social support, sub-goals and achievements, self-reporting, feedback, and patient report. Some apps involved psychological interventions. A prominent technique found was cognitive behavior therapy. This study has contributed to the body of knowledge by proposing a conceptual model in guiding the development of pain management mobile applications. The conceptual model was evaluated by a panel of experts to evaluate comprehensiveness, accuracy, and dependencies among the elements of the model, and the appropriateness of the proposed model. Experts recognized the importance of pain management and provided positive feedback to the proposed model.",10.1109/ACCESS.2019.2940772,2019,,A SYSTEMATIC LITERATURE REVIEW OF THE PAIN MANAGEMENT MOBILE APPLICATIONS: TOWARD BUILDING A CONCEPTUAL MODEL,
1137,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Subnetwork identification plays a significant role in analyzing, managing, and comprehending the structure and functions in big networks. Numerous approaches have been proposed to solve the problem of subnetwork identification as well as community detection. Most of the methods focus on detecting communities by considering node attributes, edge information, or both. This study focuses on discovering subnetworks containing researchers with similar or related areas of interest or research topics. A topic-aware subnetwork identification is essential to discover potential researchers on particular research topics and provide quality work. Thus, we propose a topic-based optimal subnetwork identification approach (TOSNet). Based on some fundamental characteristics, this paper addresses the following problems: 1)How to discover topic-based subnetworks with a vigorous collaboration intensity? 2) How to rank the discovered subnetworks and single out one optimal subnetwork? We evaluate the performance of the proposed method against baseline methods by adopting the modularity measure, assess the accuracy based on the size of the identified subnetworks, and check the scalability for different sizes of benchmark networks. The experimental findings indicate that our approach shows excellent performance in identifying contextual subnetworks that maintain intensive collaboration amongst researchers for a particular research topic.",10.1109/ACCESS.2020.3034997,2020,,TOSNET: A TOPIC-BASED OPTIMAL SUBNETWORK IDENTIFICATION IN ACADEMIC NETWORKS,
1138,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Due to the computational complexity of multilevel image thresholding, Swarm Intelligence Optimization Algorithm (SIOA) has been widely applied to improve the calculation efficiency. Therefore, more and more attention has been paid to exploring the application of the latest SIOA in multilevel segmentation. This article takes Otsu and fuzzy entropy as the objective functions, using Coyote Optimization Algorithm (COA) for multilevel thresholds optimization selection, through fuzzy median aggregation of local neighborhood information and then forms the Fuzzy Coyote Optimization Algorithm (FCOA), so that the thresholding image segmentation can be achieved in the end. To prevent the COA algorithm from falling into the local optimum, this article follows the differential evolution strategy adopted by the standard COA, using the number of iterations to construct the differential scaling factor to form the Improved Coyote Optimization Algorithm (ICOA). The experimental results show that fuzzy Kapur entropy and fuzzy median value aggregation-based ICOA(FICOA) achieves better image segmentation quality. Compared with Grey Wolf Optimizer (GWO), Fuzzy Modified Quick Artificial Bee Colony and Aggregation Algorithm (FMQABCA) and Fuzzy Modified Discrete Grey Wolf Optimizer and Aggregation Algorithm (FMDGWOA), FCOA and FICOA have certain advantages in visual effects of image segmentation and PSNR, FSIM evaluation indices. Particularly compared with GWO (also a wolf evolutionary algorithm), FICOA shows significant advantages.",10.1109/ACCESS.2021.3060749,2021,,FUZZY MULTILEVEL IMAGE THRESHOLDING BASED ON IMPROVED COYOTE OPTIMIZATION ALGORITHM,
1139,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Buffer sizing for switching and routing devices is of significance for guaranteeing the Quality of Service (QoS) of critical services on the Internet of Things (IoT), continuously evolving scheduling mechanisms and complex traffic characteristics pose new challenges for the traditional method of static buffer sizing based on rule-of-thumb. In this paper, the scope of buffer sizing is extended from a basic scheduling system under homogeneous arrival traffic input to an integrated scheduling system under heterogeneous arrival traffic input which is more ubiquitous. In this context, Voices, videos and other heterogeneous data in the IoT are categorized into short-range-dependent (SRD) and long-range-dependent (LRD) traffic, and the integrated scheduling system is decomposed into single-server-single-queue (SSSQ) systems by not only decoupling the complex dependencies among heterogeneous traffic inputs but also taking the impact of SRD and LRD traffic burstiness on the buffer sizing into account. On this basis, expressions for the relation between the minimum buffer size and the maximum overflow probability are presented. The numerical analysis results and simulation analysis results reveal that the average arrival rate, traffic burst level and scheduling priority are positively correlated with the required buffer size, and once the overflow probability is set, the minimum buffer size can be determined correspondingly. The achievements of this paper will provide theoretical guidance for IoT manufacturers and technicians to set buffers more reasonably and use resources more efficiently.",10.1109/ACCESS.2021.3102423,2021,,BS-HTIS: BUFFER SIZING FOR HETEROGENEOUS TRAFFIC AND INTEGRATED SYSTEM,
1140,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Nowadays, big cities are facing many challenges with respect to traffic congestion, climate change, air and water pollution, among others. Thus, smart cities are intended to improve the life quality of the citizens, tackling such issues with the integration of information and communication technologies to reduce the impact and achieve a well-being state of citizens. In this work, a model to predict the traffic congestion applying a support vector machine method is proposed. In addition, a crowdsourcing approach based on mining the Twitter social networks collecting events associated with the traffic is also proposed. The main contribution of this research is focused on providing a methodology that characterizes the traffic congestion analyzing crowd-sensed data from a geospatial perspective. This approach was implemented over the Mexico City as a case study, in order to forecast possible future traffic events in the city, in which the citizens share their particular situation to discover alternatives routes for avoiding the traffic congestion. Future works are oriented towards designing mobile applications in order to introduce the proposed approach and integrate information from multiple platforms and navigation systems.",10.1109/ACCESS.2019.2942586,2019,,GEOSPATIAL MODELING OF ROAD TRAFFIC USING A SEMI-SUPERVISED REGRESSION ALGORITHM,
1141,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This research shows the methodology results for outdoor characterization by the I-V curves of the PV power generators at the biggest Brazilian rooftop PV power plant mounted at the Mineirão Football Stadium. The experimental results of the methodology were obtained by a measurement campaign using two capacitive loads. This work identified a significant difference when these measurements were extrapolated to standard test conditions (STC) and compared to the rated power data shown on the PV modules' label at strings: between 24.12% to 26.19% lower. Results showed a contribution of soiling in a power reduction of about 6.7% on average. Additionally, it was considered an uncertain method, and AC electrical parameters were monitored. The reference PV module's calibration was carried out with great attention - the measurements were made with the PV device under test (DUT), guaranteeing the same real operating conditions for the reference PV module and the PV string as DUT. This measurement method has allowed a better characterization of the uncertainty associated with the measurement process. Finally, this study demonstrates the importance of investigating the actual power of the installed PV generators and how these measurements are essential to guaranteeing energy production following the owner's expectations.",10.1109/ACCESS.2020.3044832,2020,,FIELD I-V CURVE MEASUREMENTS METHODOLOGY AT STRING LEVEL TO MONITOR FAILURES AND THE DEGRADATION PROCESS: A CASE STUDY OF A 1.42 MWP PV POWER PLANT,
1142,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the development of the Internet of Things (IoT) technology, its application in the medical field becomes more and more extensive. However, with a dramatic increase in medical data obtained from the IoT-based health service system, labeling a large number of medical data requires high cost and relevant domain knowledge. Therefore, how to use a small number of labeled medical data reasonably to build an efficient and high-quality clinical decision support model in the IoT-based platform has been an urgent research topic. In this paper, we propose a novel semi-supervised learning approach in association with generative adversarial networks (GANs) for supporting clinical decision making in the IoT-based health service system. In our approach, GAN is adopted to not only increase the number of labeled data but also to compensate the imbalanced labeled classes with additional artificial data in order to improve the semi-supervised learning performance. Extensive evaluations on a collection of benchmarks and real-world medical datasets show that the proposed technique outperforms the others and provides a potential solution for practical applications.",10.1109/ACCESS.2018.2888816,2019,,GAN-BASED SEMI-SUPERVISED LEARNING APPROACH FOR CLINICAL DECISION SUPPORT IN HEALTH-IOT PLATFORM,
1143,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"A promising way to improve the performance and guarantee the quality of service (QoS) of cognitive wireless cooperative relay networks is to jointly employ physical-layer network coding (PNC) and multi-antenna space-time block coding. This paper proposes a new multi-user transmission coding scheme, cooperative quadrature PNC (CQPNC), for cognitive wireless networks. In CQPNC scheme, two source nodes (users) first use quadrature carriers to transmit signals simultaneously, which are received and processed by a cooperative relay node using the PNC method. The processed signal is then transmitted to the destination node, which makes a combination of the signals from the direct path and relay path to obtain the information transmitted by the source node. Simulation results in difference cases of cognitive wireless networks show that the CQPNC scheme outperforms the traditional cooperation and cooperative network coding transmission schemes on the performance of anti-noise and throughput.",10.1109/ACCESS.2018.2854835,2018,,PHYSICAL-LAYER NETWORK CODING BASED MULTI-USER COOPERATIVE RELAY TRANSMISSION WITH MULTI-ANTENNAS IN COGNITIVE WIRELESS NETWORKS,
1144,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In order to overcome the lack of the multispectral image (MS) and adequately preserve the spatial information of panchromatic (PAN) image and the spectral information of MS image, this study proposes a method which adds the spectral information of the prior MS to the prior PAN during training, and only the posterior PAN is needed for predicting. Firstly, we introduce the autoencoder model based on image colorization and discuss its feasibility in the field of multi-band remote sensing image pan-sharpening. Then, the image quality evaluation functions including spatial and spectral indexes are formed as the loss function to control the image colorization model. Because the loss function contains spatial and spectral evaluation indexes, it could directly calculate the loss between the network output and the label considering characteristics of remote sensing images. Besides, the training data in our model is original PAN, this means that it is not necessary to make the simulated degraded MS and PAN data for training which is a big difference from most existing deep learning pan-sharpening methods. The new loss function including the spectral and spatial quality instead of the general MSE (mean square error), only the original PAN instead of the simulated degraded MS + PAN to be inputted, only the spectral feature instead of the direct fusion result to be learned, these three aspects change the current learning framework and optimization rule of deep learning pan-sharpening. Finally, thousands of remote sensing images from different scenes are adopted to make the training dataset to verify the effectiveness of the proposed method. In addition, we selected seven representative pan-sharpening algorithms and four widely recognized objective fusion metrics to evaluate and compare the performance on the WorldView-2 experimental data. The results show that the proposed method achieves optimal performance in terms of both the subjective visual effect and the object assessment.",10.1109/ACCESS.2021.3104321,2021,,PAN-SHARPENING BASED ON PANCHROMATIC COLORIZATION USING WORLDVIEW-2,
1145,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The novel coronavirus (COVID-19) pandemic has caused a considerable and long-lasting social and economic impact on the world. Along with other potential challenges across different domains, it has brought numerous cybersecurity challenges that must be tackled timely to protect victims and critical infrastructure. Social engineering–based cyber-attacks/threats are one of the major methods for creating turmoil, especially by targeting critical infrastructure, such as hospitals and healthcare services. Social engineering–based cyber-attacks are based on the use of psychological and systematic techniques to manipulate the target. The objective of this research study is to explore the state-of-the-art and state-of-the-practice social engineering–based techniques, attack methods, and platforms used for conducting such cybersecurity attacks and threats. We undertake a systematically directed Multivocal Literature Review (MLR) related to the recent upsurge in social engineering–based cyber-attacks/threats since the emergence of the COVID-19 pandemic. A total of 52 primary studies were selected from both formal and grey literature based on the established quality assessment criteria. As an outcome of this research study; we discovered that the major social engineering–based techniques used during the COVID-19 pandemic are phishing, scamming, spamming, smishing, and vishing, in combination with the most used socio-technical method: fake emails, websites, and mobile apps used as weapon platforms for conducting successful cyber-attacks. Three types of malicious software were frequently used for system and resource exploitation are; ransomware, trojans, and bots. We also emphasized the economic impact of cyber-attacks performed on different organizations and critical infrastructure in which hospitals and healthcare were on the top targeted infrastructures during the COVID-19 pandemic. Lastly, we identified the open challenges, general recommendations, and prospective solutions for future work from the researcher and practitioner communities by using the latest technology, such as artificial intelligence, blockchain, and big data analytics.",10.1109/ACCESS.2020.3048839,2021,,A MULTIVOCAL LITERATURE REVIEW ON GROWING SOCIAL ENGINEERING BASED CYBER-ATTACKS/THREATS DURING THE COVID-19 PANDEMIC: CHALLENGES AND PROSPECTIVE SOLUTIONS,
1146,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"It is expected that peer to peer energy trading will constitute a significant share of research in upcoming generation power systems due to the rising demand of energy in smart microgrids. However, the on-demand use of energy is considered a big challenge to achieve the optimal cost for households. This paper proposes a blockchain-based predictive energy trading platform to provide real-time support, day-ahead controlling, and generation scheduling of distributed energy resources. The proposed blockchain-based platform consists of two modules; blockchain-based energy trading and smart contract enabled predictive analytics modules. The blockchain module allows peers with real-time energy consumption monitoring, easy energy trading control, reward model, and unchangeable energy trading transaction logs. The smart contract enabled predictive analytics module aims to build a prediction model based on historical energy consumption data to predict short-term energy consumption. This paper uses real energy consumption data acquired from the Jeju province energy department, the Republic of Korea. This study aims to achieve optimal power flow and energy crowdsourcing, supporting energy trading among the consumer and prosumer. Energy trading is based on day-ahead, real-time control, and scheduling of distributed energy resources to meet the smart grid’s load demand. Moreover, we use data mining techniques to perform time-series analysis to extract and analyze underlying patterns from the historical energy consumption data. The time-series analysis supports energy management to devise better future decisions to plan and manage energy resources effectively. To evaluate the proposed predictive model’s performance, we have used several statistical measures, such as mean square error and root mean square error on various machine learning models, namely recurrent neural networks and alike. Moreover, we also evaluate the blockchain platform’s effectiveness through hyperledger calliper in terms of latency, throughput, and resource utilization. Based on the experimental results, the proposed model is effectively used for energy crowdsourcing between the prosumer and consumer to attain service quality.",10.1109/ACCESS.2021.3060457,2021,,PEER-TO-PEER ENERGY TRADING MECHANISM BASED ON BLOCKCHAIN AND MACHINE LEARNING FOR SUSTAINABLE ELECTRICAL POWER SUPPLY IN SMART GRID,
1147,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The high uncertainty of the recovery time, quantity and quality of waste machine tools has led to dynamic changes in the recycling logistics network and is difficult to plan. Considering factors such as recycling efficiency, cost, and carbon emissions, an optimized model for the recycling network of waste machine tool recycling with the goal of minimizing total operating costs and total carbon tax penalties was proposed. The optimization of the combination of recycling efficiency, cost and carbon emissions of waste machine tools has been achieved. For model solving, an optimization model solving algorithm based on the multi-object gray wolf algorithm was proposed. Problems that are difficult to apply due to too slow convergence speed and too many solving parameters were solved. Finally, the recycling process of waste machine tools of a machine tool remanufacturing enterprise was taken as an example, and the proposed model and algorithm were used to optimize the logistics network of waste machine tools recycling. The results show that the optimal scheme of the optimization model of the recycling network of waste machine tools can be obtained from the proposed model. The gray wolf algorithm is superior to the multi-objective non-dominated sorting genetic algorithm in both the convergence speed and the total cost of recovered logistics. Therefore, the validity and feasibility of the model and algorithm in this paper have been verified.",10.1109/ACCESS.2020.3011509,2020,,DESIGN OF REVERSE LOGISTICS NETWORK FOR REMANUFACTURING WASTE MACHINE TOOLS BASED ON MULTI-OBJECTIVE GRAY WOLF OPTIMIZATION ALGORITHM,
1148,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Three-dimensional (3D) point clouds are important for many applications, including object tracking and 3D scene reconstruction. Point clouds are usually obtained from laser scanners, but their high cost impedes the widespread adoption of this technology. We propose a method to generate the 3D point cloud corresponding to a single red–green–blue (RGB) image. The method retrieves high-quality 3D data from two-dimensional (2D) images captured by conventional cameras, which are generally less expensive. The proposed method comprises two stages. First, a generative adversarial network generates a depth image estimation from a single RGB image. Then, the 3D point cloud is calculated from the depth image. The estimation relies on the parameters of the depth camera employed to generate the training data. The experimental results verify that the proposed method provides high-quality 3D point clouds from single 2D images. Moreover, the method does not require a PC with outstanding computational resources, further reducing implementation costs, as only a moderate-capacity graphics processing unit can efficiently handle the calculations.",10.1109/ACCESS.2018.2886213,2019,,GENERATIVE ADVERSARIAL NETWORK-BASED METHOD FOR TRANSFORMING SINGLE RGB IMAGE INTO 3D POINT CLOUD,
1149,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"This paper discusses the use of a nonlinear sensing technology based on radio frequency (RF) intermodulation response to track both the vital signs and location of human subjects. Smart health sensing was realized through the use of a wearable nonlinear tag and an intermodulation-based nonlinear sensor operating in both Doppler and frequency shift keying (FSK) modes. The Doppler mode was used to detect the heartbeat and breathing of the target subject while human subject localization was achieved in the FSK mode. One of the key advantages of this nonlinear smart sensor system was clutter rejection. This system identified the signal reflected from the wearable nonlinear tag and suppressed undesired signals and interferences that were reflected from other objects. The wearable tags used for the experiments were passive, hence they did not require any battery or power supply for their operation. Since the respiration signal is typically stronger than the heartbeat signal, the nonlinear detection setup was designed such that the respiratory signal receives less gain to avoid its sidelobes and harmonics from interfering heartbeat signal detection. This enhanced the heartbeat signal quality so that the cardiac activity could be easily tracked. Four types of experiments were performed on multiple subjects to demonstrate the advantages of this intermodulation-based nonlinear smart health sensing system. Previously, 2nd order harmonics were utilized for target localization and vital sign monitoring. However, these 2nd order harmonics suffer from high path loss and licensing issues. In this paper, target localization and smart health sensing were realized using 3rd order intermodulation with less path loss and no licensing issues compared with its harmonic counterparts. The experiment performed in nonlinear FSK mode was able to detect and locate the source of motion with high accuracy. Similarly, vital signs were recorded in the nonlinear Doppler mode. The design effectively made the amplitude of the heartbeat signal component more prominent, so that the sidelobes and harmonics of respiration do not suppress heartbeat signal.",10.1109/ACCESS.2019.2950347,2019,,INTERMODULATION-BASED NONLINEAR SMART HEALTH SENSING OF HUMAN VITAL SIGNS AND LOCATION,
1150,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In recent years, with the improvement of national income levels, people&#x0027;s consumption concept has begun to transition from enjoyment to quality, and people pay more and more attention to food safety and health. The research of intelligent brand image recognition technology is the most important to prevent the spread of counterfeit and shoddy products and brand cultivation. This article mainly studies the cultivation method of consumer marketing brand based on image recognition technology. This article is based on image recognition technology. Consumers can obtain relevant information and brand culture through the mobile phone camera function anytime, anywhere, establish a bridge between consumers and company brands, broaden the company&#x0027;s channels for obtaining consumer information big data, and deeply tap consumer potential. Demand, further enrich the brand cultivation methods, and achieve a new terminal service experience of &#x0022;efficient, convenient and satisfactory&#x0022; for consumers. In the experiment of this paper, the shape of the product packaging is relatively irregular, so there are fewer feature points generated in this part, which leads to the inaccurate extraction and distribution of visual words, which reduces the accuracy of single product extraction slightly, but the overall result is good. The maximum number of iterations in this experiment is 40, which can meet the requirements of most pictures. From the perspective of consumer perception, this paper explores and proposes a new path for consumer marketing brand cultivation of image recognition technology, promotes the deep integration of new artificial intelligence technology and brand industry, and fills the gaps in industry-related technologies and applications.",10.1109/ACCESS.2020.3018112,2020,,CONSUMER MARKETING BRAND CULTIVATION PATH BASED ON IMAGE RECOGNITION TECHNOLOGY,
1151,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Precision medicine (PM) is an innovative medical approach that considers differences in the individuals’ omics, medical histories, lifestyles, and environmental information in treating diseases. To fully achieve the envisaged gains of PM, various contemporary and future technologies have to be employed, among which are nanotechnology, sensor network, big data, and artificial intelligence. These technologies and other applications require a communication network that will enable them to work in tandem for the benefit of PM. Hence, communication technology serves as the nervous system of PM, without which the entire system collapses. Therefore, it is essential to explore and determine the candidate communication technology requirements that can guarantee the envisioned gains of PM. To the best of our knowledge, no work exploring how communication technology directly impacts the development and deployment of PM solutions exists. This survey paper is designed to stimulate discussions on PM from the communication engineering perspective. We introduce the fundamentals of PM and the demands in terms of quality of service that each of the enabling technologies of PM places on the communication network. We explore the information in the literature to suggest the ideal metric values of the key performance indicators for the implementation of the different components of PM. The comparative analysis of the suitability of the contemporary and future communication technologies for PM implementation is discussed. Finally, some open research challenges for the candidate communication technologies that will enable the full implementation of PM solutions are highlighted.",10.1109/ACCESS.2022.3175573,2022,,ENABLING PRECISION MEDICINE VIA CONTEMPORARY AND FUTURE COMMUNICATION TECHNOLOGIES: A SURVEY,
1152,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The emergence of many new computing applications, such as Internet of Vehicles (IoV) and smart homes, has been made possible by the large pool of cloud resources and services. However, the cloud computing paradigm is unable to meet the requirements of delay-sensitive business applications, such as low latency, mobility support, and location awareness. In this context, Mobile Edge Computing (MEC) is introduced to improve the quality of experience (QoE) by bringing cloud resources and services closer to the user by leveraging available resources in the edge networks. However, the performance of MEC is dynamic in nature due to its location awareness, mobility and proximity. As a result, an effective mechanism is needed for providing efficient dynamic service maintenance for edge services. In this paper, we propose applying the Skyline Graph Model and employing the Directed Acyclic Graph theory to store and update mobile edge services. Specifically, the Skyline Graph (SG) algorithm is designed to solve the insertion, deletion, updating and searching of mobile edge services to achieve efficient maintenance for edge services. Comprehensive experiments are conducted on both real-world web services and simulated datasets to evaluate the effectiveness and efficiency of our approaches. The results show that our algorithms can achieve significantly better performance and robustness than the baseline algorithm.",10.1109/ACCESS.2018.2806391,2018,,EFFICIENT DYNAMIC SERVICE MAINTENANCE FOR EDGE SERVICES,
1153,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Machine Learning brings intelligence services to IoT systems, with Edge Computing contributing for edge nodes to be part of these services, allowing data to be processed directly in the nodes in real time. This paper introduces a new way of creating a self-configurable IoT node, in terms of communications, supported by machine learning and edge computing, in order to achieve a better efficiency in terms of power consumption, as well as a comparison between regression models and between deploying them in edge or cloud fashions, with a real case implementation. The correct choice of protocol and configuration parameters can make the difference between a device battery lasting 100 times more. The proposed method predicts the energy consumption and quality of signal using regressions based on node location, distance and obstacles and the transmission power used. With an accuracy of 99.88% and a margin of error of 1.504 mA for energy consumption and 98.68% and a margin of error of 1.9558 dBm for link quality, allowing the node to use the best transmission power values for reliability and energy efficiency. With this it is possible to achieve a network that can reduce up to 68% the energy consumption of nodes while only compromising in 7% the quality of the network. Besides that, edge computing proves to be a better solution when energy efficient nodes are needed, as less messages are exchanged, and the reduced latency allows nodes to be configured in less time.",10.1109/ACCESS.2021.3081794,2021,,AUTONOMOUS CONFIGURATION OF COMMUNICATION SYSTEMS FOR IOT SMART NODES SUPPORTED BY MACHINE LEARNING,
1154,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Conceptual design plays an important role in a product development process. Significant development of technologies in the cyber-physical system (CPS) provides innovative approaches for product conceptual design. This paper proposes an architecture of CPS for conceptual design that realizes the acquisition of real-time physiological data from the physical world and the feedback of psychological states from the cyber world. As understanding and meeting the needs of customers have been recognized as significant aspects for conceptual design, an intelligent psycho-physiological approach that incorporates electroencephalogram (EEG) into the Kano model is adopted in this CPS for real-time customer needs analysis. The sample entropy (SampEn) extracted from EEG data is an endogenous neural indicator for customers' psychological states. A support vector machine using this SampEn as input is trained for classifying different categories of quality attributes defined in the Kano model. A case study is conducted to testify the feasibility of the approach proposed in this paper.",10.1109/ACCESS.2017.2686986,2017,,A CYBER-PHYSICAL SYSTEM FOR PRODUCT CONCEPTUAL DESIGN BASED ON AN INTELLIGENT PSYCHO-PHYSIOLOGICAL APPROACH,
1155,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Vehicular network aims at providing intelligent transportation and ubiquitous network access. Edge computing is able to reduce the consumption of core network bandwidth and serving latency by processing the generated data at the network edge, and social network is able to provide precise services by analyzing user’s personal behaviors. In this paper, we propose a new network system referred to as vehicular social edge computing (VSEC) that inherits the advantages of both edge computing and social network. VSEC is capable of improving the drivers’ quality of experience while enhancing the service providers’ quality of service. In order to further improve the performance of VSEC, the network utility is modeled and maximized by optimally managing the available network resources via two steps. First, the total processing time is minimized to achieve the optimal payment of the user to each edge device for each kind of the required resource. Second, a utility model is proposed, and the available resources are optimally allocated based on the results from the first step. The two optimization problems are solved by the Lagrangian theory, and the closed-form expressions are obtained. Numerical simulations show different capacities in different scenarios, which may provide some useful insights for VSEC design.",10.1109/ACCESS.2018.2878879,2018,,A NOVEL UTILITY BASED RESOURCE MANAGEMENT SCHEME IN VEHICULAR SOCIAL EDGE COMPUTING,
1156,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"As one of the most successful recommendation techniques, collaborative filtering provides a useful recommendation by associating an active user with a crowd of users who share the same interests. Although some achievements have been achieved both in theory and practice, the efficiency of recommender systems has been negatively affected by the problems of cold start and data sparsity recently. To solve the above problems, the trust relationship among users is employed into recommender systems to build a learning model to further promote the prediction quality and users' satisfaction. However, most of the existing social networks-based recommendation algorithms fail to take into account the fact that users with different levels of trust and backgrounds, that is, user's social status and homophily have different degrees of influence on their friends. In this paper, a novel social matrix factorization-based recommendation method is proposed to improve the recommendation quality by fusing user's social status and homophily. User's social status and homophily play important roles in improving the performance of recommender systems. We first build a user's trust relationship network based on user social relationships and the rating information. Then, the degree of trust is calculated through the trust propagation method and the PageRank algorithm. Finally, the trust relationship is integrated into the matrix factorization model to accurately predict unknown ratings. The proposed method is evaluated using real-life datasets including the Epinions and Douban datasets. The experimental results and comparisons demonstrate that the proposed approach is superior to the existing social networks-based recommendation algorithms.",10.1109/ACCESS.2019.2893024,2019,,A NOVEL SOCIAL RECOMMENDATION METHOD FUSING USER’S SOCIAL STATUS AND HOMOPHILY BASED ON MATRIX FACTORIZATION TECHNIQUES,
1157,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"A rise in the population has immensely increased the pressure on the agriculture sector. With the advent of technology, this decade is witnessing a shift from conventional approaches to the most advanced ones. The Internet of Things (IoT) has transformed both the quality and quantity of the agriculture sector. Hybridization of species along with the real-time monitoring of the farms paved a way for resource optimization. Scientists, research institutions, academicians, and most nations across the globe are moving towards the practice and execution of collaborative projects to explore the horizon of this field for serving mankind. The tech industry is racing to provide more optimal solutions. Inclusion of IoT, along with cloud computing, big data analytics, and wireless sensor networks can provide sufficient scope to predict, process, and analyze the situations and improve the activities in the real-time scenario. The concept of heterogeneity and interoperability of the devices by providing flexible, scalable, and durable methods, models are also opening new domains in this field. Therefore, this paper contributes towards the recent IoT technologies in the agriculture sector, along with the development of hardware and software systems. The public and private sector projects and startup's started all over the globe to provide smart and sustainable solutions in precision agriculture are also discussed. The current scenario, applications, research potential, limitations, and future aspects are briefly discussed. Based on the concepts of IoT a precision farming framework is also proposed in this article.",10.1109/ACCESS.2020.3009298,2020,,RECENT DEVELOPMENTS OF THE INTERNET OF THINGS IN AGRICULTURE: A SURVEY,
1158,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Several causes make brain cancer identification a challenging task for neurosurgeons during the surgical procedure. The surgeons' naked eye sometimes is not enough to accurately delineate the brain tumor location and extension due to its diffuse nature that infiltrates in the surrounding healthy tissue. For this reason, a support system that provides accurate cancer delimitation is essential in order to improve the surgery outcomes and hence the patient's quality of life. The brain cancer detection system developed as part of the “HypErspectraL Imaging Cancer Detection” (HELICoiD) European project meets this requirement exploiting a non-invasive technique suitable for medical diagnosis: the hyperspectral imaging (HSI). A crucial constraint that this system has to satisfy is providing a real-time response in order to not prolong the surgery. The large amount of data that characterizes the hyperspectral images, and the complex elaborations performed by the classification system make the High Performance Computing (HPC) systems essential to provide real-time processing. The most efficient implementation developed in this work, which exploits the Graphic Processing Unit (GPU) technology, is able to classify the biggest image of the database (worst case) in less than three seconds, largely satisfying the real-time constraint set to 1 minute for surgical procedures, becoming a potential solution to implement hyperspectral video processing in the near future.",10.1109/ACCESS.2020.2963939,2020,,TOWARDS REAL-TIME COMPUTING OF INTRAOPERATIVE HYPERSPECTRAL IMAGING FOR BRAIN CANCER DETECTION USING MULTI-GPU PLATFORMS,
1159,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball’s accurate motion control, which depends on various factors such as the incoming ball’s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball’s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball’s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable “target landing location” and the “over-net height” which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70%.",10.1109/ACCESS.2021.3093340,2021,,BALL MOTION CONTROL IN THE TABLE TENNIS ROBOT SYSTEM USING TIME-SERIES DEEP REINFORCEMENT LEARNING,
1160,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Insomnia is a common sleep disorder in which patients cannot sleep properly. Accurate detection of insomnia disorder is a crucial step for mental disease analysis in the early stages. The disruption in getting quality sleep is one of the big sources of cardiovascular syndromes such as blood pressure and stroke. The traditional insomnia detection methods are time-consuming, cumbersome, and more expensive because they demand a long time from a trained neurophysiologist, and they are prone to human error, hence, the accuracy of diagnosis gets compromised. Therefore, the automatic insomnia diagnosis from the electrocardiogram (ECG) records is vital for timely detection and cure. In this paper, a novel hybrid artificial intelligence (AI) approach is proposed based on the power spectral density (PSD) of the heart rate variability (HRV) to detect insomnia in three classification scenarios: (1) subject-based classification scenario (normal Vs. insomnia), (2) sleep stage-based classification (REM Vs. W. stage), and (3) the combined classification scenario using both subject-based and sleep stage-based deep features. The ensemble learning of random forest (RF) and decision tree (DT) classifiers are used to perform the first and second classification scenarios, while the linear discriminant analysis (LDA) classifier is used to perform the third combined scenario. The proposed framework includes data collection, investigation of the ECG signals, extraction of the signal HRV, estimation of the PSD, and AI-based classification via hybrid machine learning classifiers. The proposed framework is fine-tuned and evaluated using the free public PhysioNet dataset over fivefold trails cross-validation. For the subject-based classification scenario, the detection performance in terms of sensitivity, specificity, and accuracy is recorded to be 96.0%, 94.0%, and 96.0%, respectively. For the sleep stage-based classification scenario, the detection evaluation results are recorded equally with 96.0% for ceiling level accuracy, sensitivity, and specificity. For the combined classification scenario, the LDA classifier has achieved the best insomnia detection accuracy with 99.0%. In the future, the proposed hybrid AI approach could be applicable for mobile observation schemes to automatically detect insomnia disorders.",10.1109/ACCESS.2022.3212120,2022,,ENSEMBLE COMPUTATIONAL INTELLIGENT FOR INSOMNIA SLEEP STAGE DETECTION VIA THE SLEEP ECG SIGNAL,
1161,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.",10.1109/ACCESS.2015.2508940,2015,,A MULTI-OBJECTIVE OPTIMIZATION SCHEDULING METHOD BASED ON THE ANT COLONY ALGORITHM IN CLOUD COMPUTING,
1162,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Nowadays, there is an increasing demand for images with high definition and fine textures, but images captured in natural scenes usually suffer from complicated blurry artifacts, caused mostly by object motion or camera shaking. Since these annoying artifacts greatly decrease image visual quality, deblurring algorithms have been proposed from various aspects. However, most energy-optimization-based algorithms rely heavily on blur kernel priors, and some learning-based methods either adopt pixel-wise loss function or ignore global structural information. Therefore, we propose an image deblurring algorithm based on a recurrent conditional generative adversarial network (RCGAN), in which the scale-recurrent generator extracts sequence spatio–temporal features and reconstructs sharp images in a coarse-to-fine scheme. To thoroughly evaluate the global and local generator performance, we further propose a receptive field recurrent discriminator. Besides, the discriminator takes blurry images as conditions, which helps to differentiate reconstructed images from real sharp ones. Last but not least, since the gradients are vanishing when training the generator with the output of the discriminator, a progressive loss function is proposed to enhance the gradients in back propagation and to take full advantage of discriminative features. Extensive experiments prove the superiority of RCGAN over state-of-the-art algorithms both qualitatively and quantitatively.",10.1109/ACCESS.2018.2888885,2019,,RECURRENT CONDITIONAL GENERATIVE ADVERSARIAL NETWORK FOR IMAGE DEBLURRING,
1163,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The maximum edge weighted clique problem (MEWCP), an extension of the classical maximum clique problem, is an important NP-hard combinatorial optimization problem. The problem has been widely used in various areas. The objective of this paper is to design an efficient local search algorithm to solve the MEWCP. First, the proposed scoring strategy is used to evaluate the benefit of adding and swapping operators. Second, the vertex weighting strategy is used to increase the diversity of solutions and the configuration checking strategy is used to avoid the cycling problem. By combining these three strategies, we propose multiple rules to select the added vertex or the swapped vertex pair. Based on the multiple rules, an efficient local search algorithm, namely, local search based on multiple rules (LSMR), is proposed. LSMR is compared with several representative algorithms on massive graph instances. The experimental results indicate that LSMR is superior to competitors in terms of solution quality and computational efficiency in most instances.",10.1109/ACCESS.2018.2799953,2018,,AN EFFICIENT LOCAL SEARCH FOR THE MAXIMUM EDGE WEIGHTED CLIQUE PROBLEM,
1164,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Identifying shoe-print impressions in the scene of crime (SoC) from database images is a challenging problem in forensic science due to the complicated impressing surface, the partial absence of on-site impressions, and the huge domain gap between the query and the gallery images. The existing approaches pay much attention to feature extraction while ignoring its distinctive characteristics. In this paper, we propose a novel multi-part weighted convolutional neural network (MP-CNN) for shoe-print image retrieval. Specifically, the proposed CNN model processes images in three steps: 1) dividing the input images vertically into two parts and extracting sub-features by a parameter-shared network individually; 2) calculating the importance weight matrix of the sub-features based on the informative pixels they contained and concatenating them as the final feature, and; 3) using the triplet loss function to measure the similarity between the query and the gallery images. In addition to the proposed network, we adopt an effective strategy to enhance the quality of the images and to reduce the domain gap using the U-Net structure. The experimental evaluations demonstrate that our proposed method significantly outperforms other fine-grained cross-domain methods on SPID dataset and obtains comparative results with the state-of-the-art shoe-print retrieval methods on FID300 dataset.",10.1109/ACCESS.2019.2914455,2019,,SHOE-PRINT IMAGE RETRIEVAL WITH MULTI-PART WEIGHTED CNN,
1165,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Aiming at the shortages of basic flower pollination algorithm (FPA) with slow convergence speed, low search precision, and easy to fall into local optimum, a new adaptive FPA based on opposition-based learning and t-distribution (OTAFPA) was proposed and be applied to the social networks. First, the opposition-based learning strategy is utilized to increase the diversity and quality of the initial population. Then, the adaptive dynamic switching probability is introduced, which can effectively balance the global and local search according to the current number of iterations. Finally, the t-distribution variation is used to increase the population diversity and to help the algorithm jump out of the local optimum. The simulation experiments on eight classical test functions show that OTAFPA has better global optimization ability, which improves the convergence speed and the solution accuracy of the algorithm. The OTAFPA also shows superior performance in practical applications of user identification across social networks.",10.1109/ACCESS.2018.2889801,2019,,IMPROVED FLOWER POLLINATION ALGORITHM AND ITS APPLICATION IN USER IDENTIFICATION ACROSS SOCIAL NETWORKS,
1166,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The influential factors of green logistics development have been an important research topic for academics. However, little attention has been devoted to studying the issue of the prioritization and the hierarchical structure of these factors. The purpose of this study is to identify the key factors influencing the development of green logistics, and to explore the prioritization and the hierarchical structure of the influential factors. An indicator system for influential factors of green logistics development is first developed based on the theory of triple bottom line, including sixteen indicators or factors. The comprehensive influences and the prioritization of these sixteen factors are then analyzed using the DEMATEL method and the multi-level hierarchical structure of these factors is constructed by applying the ISM method. The results indicate that government policies, public supports, laws and regulations, green education, green technology innovations, consumer green demands, quantity and quality of green logistics talents are more influential than the other factors. Social factors including laws and regulations and government policies, public supports and green education are the underlying factors affecting the development of green logistics. Economic factors are at the middle levels and environmental factors are at the surface-level of the hierarchical structure. Recommendations are finally given to governmental agencies and business firms. These findings will be beneficial to promoting the sustainable development of green logistics.",10.1109/ACCESS.2020.3008443,2020,,GREEN LOGISTICS DEVELOPMENT DECISION-MAKING: FACTOR IDENTIFICATION AND HIERARCHICAL FRAMEWORK CONSTRUCTION,
1167,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In actual distribution process, the traffic flow varies with time, and each consumer has multiple fuzzy windows. To minimize the total distribution cost and mean consumer dissatisfaction, this paper sets up a vehicle routing problem (VRP) model with multiple fuzzy time windows, based on time-varying traffic flow. In addition, the Ito algorithm was improved based on time-varying traffic flow. The model and algorithm were verified through example simulation, in comparison with ant colony optimization (ACO). During the simulation, the improved Ito algorithm effectively reduced the distribution cost and consumer dissatisfaction, and outperformed the ACO in solving efficiency and solution quality. The results fully demonstrate the feasibility and effectiveness of the proposed algorithm. The research findings provide a desirable solution to VRPs with multiple fuzzy windows and time-varying traffic flow in the real world.",10.1109/ACCESS.2020.2974774,2020,,A VEHICLE ROUTING PROBLEM MODEL WITH MULTIPLE FUZZY WINDOWS BASED ON TIME-VARYING TRAFFIC FLOW,
1168,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In order to support the process of scheduling a hybrid cyclic timetable, this paper is devoted to inserting additional non-cyclic train paths into existing cyclic timetable. The adding train paths problem is an integration of timetable scheduling and rescheduling problem. The train dispatcher can not only modify the given timetable to manage the interruptions in existing operations, but also establish schedules for additional trains. A multi-objective model minimizing both the travel time of additional trains and the variation of existing trains is proposed in this paper. In addition, we consider both general constraints and some additional practical constraints, such as the overtaking priority constraint, reasonable adjustment of initial schedules and the scheduled connections. This problem is very difficult and must be solved in practice. A heuristic algorithm is introduced to find high-quality solutions for large-scale cases within reasonable computing time. Based on high-speed railway line in China, the case studies illustrate the methodology and compare the performance of trains. Numerical experiments indicate that the proposed solution approach to the adding train paths problem is promising.",10.1109/ACCESS.2020.2997777,2020,,SCHEDULING EXTRA TRAIN PATHS INTO CYCLIC TIMETABLE BASED ON THE GENETIC ALGORITHM,
1169,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"In the above-named article, the funding information was incorrect. In addition, there was an error in the author affiliation that is corrected here.",10.1109/ACCESS.2020.2980179,2020,,CORRECTION TO “FREQUENCY SEPARATION NETWORK FOR IMAGE SUPER-RESOLUTION”,
1170,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Data mining has actively contributed to solving many real-world problems with a variety of techniques. Traditional approaches in this field are classification, clustering and regression. During the last few years a number of chal-lenges have emerged, such as imbalanced data, multi-label and multi-instance problems, low quality and/or noisy data or semi-supervised learning, among others [item 1) in the Appendix]. When these non-standard scenarios are encountered in the realm of big data, it remains an uncharted research territory, although a growing effort has been made to break the limits. The current trend is to address the classical and newly emerging data mining problems in big data and knowledge processing. Granular computing provides a powerful tool for multiple granularity and multiple-view data analysis at differ-ent granularity levels, which has demonstrated strong capabil-ities and advantages in intelligent data analysis, pattern recog-nition, machine learning and uncertain reasoning [item 2) inthe Appendix]. Big data often contains a significant amount of unstructured, uncertain and imprecise data. There are new challenges regarding the scalability of granular computing when addressing very big data sets [item 3) in the Appendix]. Big data mining relies on distributed computational strate-gies; it is often impossible to store and process data on one single computing node. The exploration of data mining and granular computing in big data and knowledge processing is an emerging field which crosses multiple research disciplines and industry domains, including transportation, communications, social network, medical health, and so on.",10.1109/ACCESS.2019.2908776,2019,,IEEE ACCESS SPECIAL SECTION EDITORIAL: DATA MINING AND GRANULAR COMPUTING IN BIG DATA AND KNOWLEDGE PROCESSING,
1171,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the explosion of big data technology, healthcare data is continuously and rapidly growing, with abundant and various values. There are wide varieties of data and heterogeneous healthcare data (images, text, video, raw sensor data, etc.) that are generated and required to be effectively stored, processed, queried, indexed and analyzed. These datasets differ widely in their volume, variety, velocity and value, including patient-oriented data such as electronic medical records (EMR), public-oriented data such as public health data, and knowledge-oriented data such as drug-to-drug, drug-to-disease, and disease-to-disease interaction registries. Big data in healthcare brings great challenges but plays an important role in healthcare transformation. The traditional techniques do not compromise end-users’ Quality of Service (QoS) in terms of data availability, data response delay, etc. It is urgent to develop software tools and techniques that support rapid query processing and speed-up data analytics, which provide awareness and knowledge in real-time.",10.1109/ACCESS.2018.2870417,2018,,IEEE ACCESS SPECIAL SECTION EDITORIAL: HEALTHCARE BIG DATA,
1172,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With growing attention from both academia and industry, Industrial Internet of Things (IIoT), comprised of a multitude of connected devices, is supposed to monitor, collect, exchange, analyze, and instantly act on information to intelligently change the industrial device’s behavior or the industrial environment (e.g., autonomous reaction to unexpected changes in production by effectively detecting failures and triggering maintenance processes). Toward this goal, the convergence of sensor networks, cloud computing, and big data in IIoT is recently identified as an essential component. Specifically, to capture various data in IIoT, sensor networks are deployed. Meanwhile, to store and process data powerfully in IIoT, cloud computing platforms are developed. Moreover, to glean valuable findings from the massive data in IIoT, big data analytics tools are utilized. However, to integrate sensor networks, cloud computing, and big data in IIoT in a robust way, there are a lot of tough issues to be solved with respect to various aspects (e.g., framework, greenness, security, quality of service, etc.).",10.1109/ACCESS.2020.3037614,2020,,"IEEE ACCESS SPECIAL SECTION EDITORIAL: CONVERGENCE OF SENSOR NETWORKS, CLOUD COMPUTING, AND BIG DATA IN INDUSTRIAL INTERNET OF THINGS",
1173,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Social networks have become one of the most popular platforms for people to communicate and interact with their friends and share personal information and experiences (e.g., Facebook owns over 1.23 billion monthly active users). The increasing popularity of social networks has generated extremely large-scale user data (e.g., Twitter generates 500 million tweets per day and around 200 billion tweets per year). These data can help improve people’s quality of life as well as benefit various interest groups such as advertisers, application developers, and so on. However, privacy may be compromised if learning algorithms are used to infer unpublished privacy information from published data. Hence, user data privacy preservation has become one of the most urgent research issues in social networks.",10.1109/ACCESS.2020.3036101,2022,,IEEE ACCESS SPECIAL SECTION: PRIVACY PRESERVATION FOR LARGE-SCALE USER DATA IN SOCIAL NETWORKS,
1174,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"The proliferation of the Internet of Things (IoT) has paved the way for the future of smart cities. The large volume of data over the IoT can enable decision-making for various applications such as smart transportation, smart parking, and smart lighting. The key to the success of smart cities is data collection and aggregation over the IoT. Recently, crowdsensing has become a new data collection paradigm over the IoT, which can realize large-scale and fine-grained data collection with low cost for various applications. For example, we can leverage the power of the crowd to build a real-time noise map with microphones on smartphones. Despite the advantages of crowdsensing and the IoT, there are many challenges to utilize crowdsensing over the IoT for smart cities, such as how to allocate tasks to appropriate users to provide high-quality sensing data, how to incentivize users to participate in crowdsourcing, how to detect the reliability of the crowdsourced data, and how to protect the privacy of users.",10.1109/ACCESS.2021.3106756,2021,,IEEE ACCESS SPECIAL SECTION EDITORIAL: TOWARD SMART CITIES WITH IOT BASED ON CROWDSENSING,
1175,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"We live in a world with growing disparity in the quality of life available to people in the developed and developing countries. Healthcare in the developing world is fraught with numerous problems such as the lack of health infrastructure, and human resources, which results in very limited health coverage. The field of health informatics has made great strides in recent years towards improving public health systems in the developing world by augmenting them with state-of-the-art information and communication technologies (ICT). Through real-world deployment of these technologies, there is real hope that the health industry in the developing world will progress from its current, largely dysfunctional state to one that is more effective, personalized, and cost effective. Health informatics can usher a new era of personalized health analytics, with the potential to transform healthcare in the developing world. In conjunction with mHealth and eHealth, many other important health informatics trends—such as artificial intelligence (AI), machine learning (ML), big data, crowdsourcing, cloud computing—are also emerging. Exponentially growing heterogeneous data, with the help of big data analytics, has the potential to provide descriptive, predictive, and prescriptive health insights as well as enable new applications such as telemedicine and remote diagnostics and surgery. Such systems could enhance the overall process of monitoring, diagnosis, and prognosis of diseases.",10.1109/ACCESS.2017.2783118,2017,,IEEE ACCESS SPECIAL SECTION EDITORIAL: HEALTH INFORMATICS FOR THE DEVELOPING WORLD,
1176,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"With the advances of technologies in Micro-electro-mechanics (MEMS) and wireless communications, it has become feasible to deploy a large-scale wireless sensor network (WSN) with thousands of tiny and inexpensive sensor nodes scattered over a vast field so that information of interest can be obtained, processed, transmitted, and fused automatically via node collaboration and sensing. With the help of cloud computing, Internet of Things (IoTs), device to device (D2D) communications, and big data, cooperative and intelligent sensing will bridge the gap of ubiquitous sensing, intelligent computing, cooperative communication, and mass data management technologies to create novel solutions that improve the urban environment, human life quality, and smart city systems.",10.1109/ACCESS.2017.2783139,2017,,A SPECIAL SECTION IN IEEE ACCESS: COOPERATIVE AND INTELLIGENT SENSING,
1177,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Urban computing utilizes unobtrusive and ubiquitous sensing technologies, advanced data management and analytics models, and novel visualization methods to create win-win-win solutions which intelligently improve people’s lives, urban environments, and city operation systems. With the help of cloud computing, the Internet of Things, device-to-device (D2D) communication, artificial intelligence (AI), big data, and urban computing and intelligence will bridge the gap of ubiquitous sensing, intelligent computing, cooperative communication, and mass data management technologies, to create novel solutions that improve urban environments, human life quality, and smart city systems. Thus, urban computing and intelligence has recently attracted significant attention from industry and academia for building smart cities.",10.1109/ACCESS.2021.3111669,2021,,IEEE ACCESS SPECIAL SECTION EDITORIAL: URBAN COMPUTING AND INTELLIGENCE,
1178,21100374601,IEEE ACCESS,journal,21693536,"0,587",Q1,127,18036,24267,771081,116691,24200,"4,48","42,75",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2013-2020,Computer Science (miscellaneous) (Q1); Engineering (miscellaneous) (Q1); Materials Science (miscellaneous) (Q2),"105,968",3.367,0.15396,"Industry 4.0, also known as the fourth industrial revolution, is an area that many scientists and manufacturers are pursuing. Industry 4.0 consists of many topics such as the Internet of things (IoT), big data, cloud computing, smart manufacturing, and so on. Smart manufacturing is a crucial and valuable topic which aims at developing advanced techniques to improve the quality and costs of manufacturing. Through sensors, networks, and high-performance computers, powerful algorithms for smart manufacturing can be developed and implemented. Thanks to an innovative variety of sensors, reliable, and high-resolution information can be collected and utilized. Networks allow signals to be exchanged quickly between sensors, machines, and computers. Artificial intelligence (AI) requires huge computation power. Modern computers provide graphic cards with parallel computing, breaking this restriction. Algorithms related to smart manufacturing will be more complicated than before. As a result, this Special Section aims to speed up the development of smart manufacturing, attract the attention of communities, and disseminate novel research.",10.1109/ACCESS.2021.3106717,2021,,IEEE ACCESS SPECIAL SECTION EDITORIAL: ADVANCED ARTIFICIAL INTELLIGENCE TECHNOLOGIES FOR SMART MANUFACTURING,
1179,12370,JOURNAL OF COMPUTER AND SYSTEM SCIENCES,journal,00220000,"0,573",Q2,99,46,252,1626,568,245,"1,87","35,35",United States,Northern America,Academic Press Inc.,1967-2021,Applied Mathematics (Q2); Computational Theory and Mathematics (Q2); Computer Networks and Communications (Q2); Theoretical Computer Science (Q2),"4,516",1.023,0.00268,"It is well known that processing big graph data can be costly on Cloud. Processing big graph data introduces complex and multiple iterations that raise challenges such as parallel memory bottlenecks, deadlocks, and inefficiency. To tackle the challenges, we propose a novel technique for effectively processing big graph data on Cloud. Specifically, the big data will be compressed with its spatiotemporal features on Cloud. By exploring spatial data correlation, we partition a graph data set into clusters. In a cluster, the workload can be shared by the inference based on time series similarity. By exploiting temporal correlation, in each time series or a single graph edge, temporal data compression is conducted. A novel data driven scheduling is also developed for data processing optimisation. The experiment results demonstrate that the spatiotemporal compression and scheduling achieve significant performance gains in terms of data size and data fidelity loss.",https://doi.org/10.1016/j.jcss.2014.04.022,2014,Chi Yang and Xuyun Zhang and Changmin Zhong and Chang Liu and Jian Pei and Kotagiri Ramamohanarao and Jinjun Chen,A SPATIOTEMPORAL COMPRESSION BASED APPROACH FOR EFFICIENT BIG DATA PROCESSING ON CLOUD,article
1180,12370,JOURNAL OF COMPUTER AND SYSTEM SCIENCES,journal,00220000,"0,573",Q2,99,46,252,1626,568,245,"1,87","35,35",United States,Northern America,Academic Press Inc.,1967-2021,Applied Mathematics (Q2); Computational Theory and Mathematics (Q2); Computer Networks and Communications (Q2); Theoretical Computer Science (Q2),"4,516",1.023,0.00268,"Big data streaming has become an important paradigm for real-time processing of massive continuous data flows in large scale sensing networks. While dealing with big sensing data streams, a Data Stream Manager (DSM) must always verify the security (i.e. authenticity, integrity, and confidentiality) to ensure end-to-end security and maintain data quality. Existing technologies are not suitable, because real time introduces delay in data stream. In this paper, we propose a Dynamic Prime Number Based Security Verification (DPBSV) scheme for big data streams. Our scheme is based on a common shared key that updated dynamically by generating synchronized prime numbers. The common shared key updates at both ends, i.e., source sensing devices and DSM, without further communication after handshaking. Theoretical analyses and experimental results of our DPBSV scheme show that it can significantly improve the efficiency of verification process by reducing the time and utilizing a smaller buffer size in DSM.",https://doi.org/10.1016/j.jcss.2016.02.005,2017,Deepak Puthal and Surya Nepal and Rajiv Ranjan and Jinjun Chen,A DYNAMIC PRIME NUMBER BASED EFFICIENT SECURITY MECHANISM FOR BIG SENSING DATA STREAMS,article
1181,5100154502,JOURNAL OF FORENSIC AND LEGAL MEDICINE,journal,1752928X,"0,569",Q1,47,134,428,3921,668,407,"1,57","29,26",United Kingdom,Western Europe,Churchill Livingstone,2007-2020,Law (Q1); Medicine (miscellaneous) (Q2); Pathology and Forensic Medicine (Q2),"2,328",1.614,0.00305,"The study of cause-specific mortality data is one of the main sources of information for public health monitoring. In most industrialized countries, when a death occurs, it is a legal requirement that a medical certificate based on the international form recommended by World Health Organization's (WHO) is filled in by a physician. The physician reports the causes of death that directly led or contributed to the death on the death certificate. The death certificate is then forwarded to a coding office, where each cause is coded, and one underlying cause is defined, using the rules of the International Classification of Diseases and Related Health Problems, now in its 10th Revision (ICD-10). Recently, a growing number of countries have adopted, or have decided to adopt, the coding software Iris, developed and maintained by an international consortium1. This whole standardized production process results in a high and constantly increasing international comparability of cause-specific mortality data. While these data could be used for international comparisons and benchmarking of global burden of diseases, quality of care and prevention policies, there are also many other ways and methods to explore their richness, especially when they are linked with other data sources. Some of these methods are potentially referring to the so-called “big data” field. These methods could be applied both to the production of the data, to the statistical processing of the data, and even more to process these data linked to other databases. In the present note, we depict the main domains in which this new field of methods could be applied. We focus specifically on the context of France, a 65 million inhabitants country with a centralized health data system. Finally we will insist on the importance of data quality, and the specific problematics related to death certification in the forensic medicine domain.",https://doi.org/10.1016/j.jflm.2016.12.004,2018,Grégoire Rey and Karim Bounebache and Claire Rondet,"CAUSES OF DEATHS DATA, LINKAGES AND BIG DATA PERSPECTIVES",article
1182,5100154502,JOURNAL OF FORENSIC AND LEGAL MEDICINE,journal,1752928X,"0,569",Q1,47,134,428,3921,668,407,"1,57","29,26",United Kingdom,Western Europe,Churchill Livingstone,2007-2020,Law (Q1); Medicine (miscellaneous) (Q2); Pathology and Forensic Medicine (Q2),"2,328",1.614,0.00305,"In less than a decade, big data in medicine has become quite a phenomenon and many biomedical disciplines got their own tribune on the topic. Perspectives and debates are flourishing while there is a lack for a consensual definition for big data. The 3Vs paradigm is frequently evoked to define the big data principles and stands for Volume, Variety and Velocity. Even according to this paradigm, genuine big data studies are still scarce in medicine and may not meet all expectations. On one hand, techniques usually presented as specific to the big data such as machine learning techniques are supposed to support the ambition of personalized, predictive and preventive medicines. These techniques are mostly far from been new and are more than 50 years old for the most ancient. On the other hand, several issues closely related to the properties of big data and inherited from other scientific fields such as artificial intelligence are often underestimated if not ignored. Besides, a few papers temper the almost unanimous big data enthusiasm and are worth attention since they delineate what is at stakes. In this context, forensic science is still awaiting for its position papers as well as for a comprehensive outline of what kind of contribution big data could bring to the field. The present situation calls for definitions and actions to rationally guide research and practice in big data. It is an opportunity for grounding a true interdisciplinary approach in forensic science and medicine that is mainly based on evidence.",https://doi.org/10.1016/j.jflm.2017.08.001,2018,Thomas Lefèvre,BIG DATA IN FORENSIC SCIENCE AND MEDICINE,article
1183,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"This paper presents the approach to Big Data Analytics (BDA) developed in the SIBDA (Sistema Innovativo Big Data Analytics) Project. The project aim is to study and develop innovative solutions in the field of BDA for three companies cooperating in a temporary association of enterprises. We discuss elements of Big Data tackled in the project, namely document processing, mass e-mail applications and Internet of Things sensor networks, to be integrated into a shared platform of common assets and services for the three cooperating companies. We comment about the “Big Data Journey” status in Italy reported by Osservatorio Politecnico di Milano. Then, the paper presents the SIBDA project approach and requirements, outlines the adopted architecture and provides implementation hints, along with some experiments and considerations on the use of the proposed architecture for Smart Cities and Smart Enterprises and Communities.",https://doi.org/10.1016/j.bdr.2021.100192,2021,Mariagrazia Fugini and Jacopo Finocchi and Paolo Locatelli,A BIG DATA ANALYTICS ARCHITECTURE FOR SMART CITIES AND SMART COMPANIES,article
1184,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"Research in Big Data and analytics offers tremendous opportunities to utilize evidence in making decisions in many application domains. To what extent can the paradigms of Big Data and analytics be used in the domain of transport? This article reports on an outcome of a systematic review of published articles in the last five years that discuss Big Data concepts and applications in the transportation domain. The goal is to explore and understand the current research, opportunities, and challenges relating to the utilization of Big Data and analytics in transportation. The review shows the potential of Big Data and analytics to garner insights and improve transportation systems through the analysis of various forms of data obtained from traffic monitoring systems, connected vehicles, crowdsourcing, and social media. We discuss some platforms and software architecture for the transport domain, along with a wide array of storage, processing, and analytical techniques, and describe challenges associated with the implementation of Big Data and analytics. This review contributes broadly to the various ways in which cities can utilize Big Data in transportation to guide the creation of sustainable and safer traffic systems. Since research in Big Data and transportation is, by and large, at infancy, this article does not prescribe recommendations to the various challenges identified, which also constitutes the limitation of the article.",https://doi.org/10.1016/j.bdr.2019.03.001,2019,Alex Neilson and  Indratmo and Ben Daniel and Stevanus Tjandra,SYSTEMATIC REVIEW OF THE LITERATURE ON BIG DATA IN THE TRANSPORTATION DOMAIN: CONCEPTS AND APPLICATIONS,article
1185,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"The management of the exponential growth of data that Next Generation Sequencing techniques produce has become a challenge for researchers that are forced to delve into an ocean of complex data in order to extract new insights to unravel the secrets of human diseases. Initially, this can be faced as a Big Data-related problem, but the genomic data have particular and relevant challenges that make them different from other Big Data working domains. Genomic data are much more heterogeneous; they are spread in hundreds of repositories, represented in multiple formats, and have different levels of quality. In addition, getting meaningful conclusions from genomic data requires considering all of the relevant surrounding knowledge that is under continuous evolution. In this scenario, the precise identification of what makes Genome Data Management so different is essential in order to provide effective Big Data-based solutions. Genomic projects require dealing with the technological problems associated with data management, nomenclature standards, and quality issues that only robust Information Systems that use Big Data techniques can provide. The main contribution of this paper is to present a Big Data-driven approach for managing genomic data, that is adapted to the particularities of the domain and to show its applicability to improve genetic diagnoses, which is the core of the development of accurate Precision Medicine.",https://doi.org/10.1016/j.bdr.2021.100253,2021,Ana León and Óscar Pastor,ENHANCING PRECISION MEDICINE: A BIG DATA-DRIVEN APPROACH FOR THE MANAGEMENT OF GENOMIC DATA,article
1186,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"With the boom in Internet techniques and computer science, a variety of big data have been introduced into forecasting research, bringing new knowledge and improving prediction models. This paper is the first attempt to conduct a literature review on full-scale big data in forecasting research. By source, big data in forecasting research fell into user-generated content data (from the users on social media in texts, photos, etc.), device-monitored data (by meteorological monitors, smart meters, GPS, etc.) and activity log data (for web searching/visiting, online/offline marketing, clinical treatments, laboratory experiments, etc.). Different data types, bearing distinctive information and characteristics, dominated different forecasting tasks, required different analysis technologies and improved different forecasting models. This survey provides an overall review of big data-based forecasting research, details what (regarding data types and sources), where (forecasting hotspots) and how (analysis and forecasting methods used) big data improved prediction, and offers insights into future prospects.",https://doi.org/10.1016/j.bdr.2021.100289,2022,Ling Tang and Jieyi Li and Hongchuan Du and Ling Li and Jun Wu and Shouyang Wang,BIG DATA IN FORECASTING RESEARCH: A LITERATURE REVIEW,article
1187,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"Renal failure is a fatal disease raising global concerns. Previous risk models for renal failure mostly rely on the diagnosis of chronic kidney disease, which lacks obvious clinical symptoms and thus is mostly undiagnosed, causing significant omission of high-risk patients. In this paper, we proposed a framework to predict the risk of renal failure directly from a big data repository of chronic disease population without prerequisite diagnosis of chronic kidney disease. The electronic health records of 42,256 patients with hypertension or diabetes in Shenzhen Health Information Big Data Platform were collected, with 398 suffered from renal failure during a 3-year follow-up. Five state-of-the-art machine learning methods are utilized to build risk prediction models of renal failure for chronic disease population. Extensive experimental results show that the proposed framework achieves quite well performance. Particularly, the XGBoost obtains the best performance with an area under receiving-operating-characteristics curve (AUC) of 0.9139. By analyzing the effect of risk factors, we identified that serum creatine, age, urine acid, systolic blood pressure, and blood urea nitrogen are the top five factors associated with renal failure risk. Compared with existing models, our model can be deployed into routine chronic disease management procedures and enable more preemptive, widely-covered screening of renal risks, which would in turn reduce the damage caused by the disease through timely intervention.",https://doi.org/10.1016/j.bdr.2021.100234,2021,Yujie Yang and Ye Li and Runge Chen and Jing Zheng and Yunpeng Cai and Giancarlo Fortino,RISK PREDICTION OF RENAL FAILURE FOR CHRONIC DISEASE POPULATION BASED ON ELECTRONIC HEALTH RECORD BIG DATA,article
1188,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"Production lines in pharmaceutical manufacturing generate numerous heterogeneous data sets from various embedded systems which control the multiple processes of medicine production. Such data sets should arguably ensure end-to-end traceability and data integrity in order to release a medicine batch, which is uniquely identified and tracked by its batch number/code. Consequently, auditable computerised systems are crucial on pharmaceutical production lines, since the industry is becoming increasingly regulated for product quality and patient health purposes. This paper describes the EU-funded SPuMoNI project, which aims to ensure the quality of large amounts of data produced by computerised production systems in representative pharmaceutical environments. Our initial results include significant progress in: (i) end-to-end verification taking advantage of blockchain properties and smart contracts to ensure data authenticity, transparency, and immutability; (ii) data quality assessment models to identify data behavioural patterns that can violate industry practices and/or international regulations; and (iii) intelligent agents to collect and manipulate data as well as perform smart decisions. By analysing multiple sensors in medicine production lines, manufacturing work centres, and quality control laboratories, our approach has been initially evaluated using representative industry-grade pharmaceutical manufacturing data sets generated at an IT environment with regulated processes inspected by regulatory and government agencies.",https://doi.org/10.1016/j.bdr.2020.100172,2021,Fátima Leal and Adriana E. Chis and Simon Caton and Horacio González–Vélez and Juan M. García–Gómez and Marta Durá and Angel Sánchez–García and Carlos Sáez and Anthony Karageorgos and Vassilis C. Gerogiannis and Apostolos Xenakis and Efthymios Lallas and Theodoros Ntounas and Eleni Vasileiou and Georgios Mountzouris and Barbara Otti and Penelope Pucci and Rossano Papini and David Cerrai and Mariola Mier,SMART PHARMACEUTICAL MANUFACTURING: ENSURING END-TO-END TRACEABILITY AND DATA INTEGRITY IN MEDICINE PRODUCTION,article
1189,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"We are living in a world where everything computes, everyone and everything is connected and sharing data. Going beyond just capturing and managing data, enterprises are tapping into IoT and Artificial Intelligence (AI) to create insights and intelligence in a revolutionary way that was not possible before. For instance, by analyzing unstructured data (such as text), call centers can extract entities, concepts, themes which can enable them to get faster insights that only few years back was not feasible. Public safety and law enforcement are only few of the examples that benefit from text analytics used to strengthen crime investigation. Sentiment Analysis, Content Classification, Language Detection and Intent Detection are just some of the Text Classification applications. The overall process model of such applications considering the complexity of the unstructured data, can be definitely challenging. In response to the chaotic emerging science of unstructured data analysis, the main goal of this paper is to first contribute to the gap of no existing methodology approach for Text Analytics projects, by introducing a methodology approach based on one of the most widely accepted and used methodology approach of CRISP-DM.",https://doi.org/10.1016/j.bdr.2021.100274,2022,Christina G. Skarpathiotaki and Konstantinos E. Psannis,CROSS-INDUSTRY PROCESS STANDARDIZATION FOR TEXT ANALYTICS,article
1190,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"In a fast growing big data era, volume and varieties of data processed in Internet applications drastically increase. Real-world search engines commonly use text classifiers with thousands of classes to improve relevance or data quality. These large scale classification problems lead to severe runtime performance challenges, so practitioners often resort to fast approximation techniques. However, the increase in classification speed comes at a cost, as approximations are lossy, mis-assigning classes relative to the original reference classification algorithm. To address this problem, we introduce a Lossless Pruned Naive Bayes (LPNB) classification algorithm tailored to real-world, big data applications with thousands of classes. LPNB achieves significant speed-ups by drawing on Information Retrieval (IR) techniques for efficient posting list traversal and pruning. We show empirically that LPNB can classify text up to eleven times faster than standard Naive Bayes on a real-world data set with 7205 classes, with larger gains extrapolated for larger taxonomies. In practice, the achieved acceleration is significant as it can greatly cut required computation time. In addition, it is lossless: the output is identical to standard Naive Bayes, in contrast to extant techniques such as hierarchical classification. The acceleration does not rely on the taxonomy structure, and it can be used for both hierarchical and flat taxonomies.",https://doi.org/10.1016/j.bdr.2018.05.007,2018,Nanfei Sun and Bingjun Sun and Jian (Denny) Lin and Michael Yu-Chi Wu,LOSSLESS PRUNED NAIVE BAYES FOR BIG DATA CLASSIFICATIONS,article
1191,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,,https://doi.org/10.1016/j.bdr.2019.100123,2019,Nikos Bikakis and George Papastefanatos and Olga Papaemmanouil,"BIG DATA EXPLORATION, VISUALIZATION AND ANALYTICS",article
1192,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"This paper presents a system that employs information visualization techniques to analyze urban traffic data and the impact of traffic emissions on urban air quality. Effective visualizations allow citizens and public authorities to identify trends, detect congested road sections at specific times, and perform monitoring and maintenance of traffic sensors. Since road transport is a major source of air pollution, also the impact of traffic on air quality has emerged as a new issue that traffic visualizations should address. Trafair Traffic Dashboard exploits traffic sensor data and traffic flow simulations to create an interactive layout focused on investigating the evolution of traffic in the urban area over time and space. The dashboard is the last step of a complex data framework that starts from the ingestion of traffic sensor observations, anomaly detection, traffic modeling, and also air quality impact analysis. We present the results of applying our proposed framework on two cities (Modena, in Italy, and Santiago de Compostela, in Spain) demonstrating the potential of the dashboard in identifying trends, seasonal events, abnormal behaviors, and understanding how urban vehicle fleet affects air quality. We believe that the framework provides a powerful environment that may guide the public decision-makers through effective analysis of traffic trends devoted to reducing traffic issues and mitigating the polluting effect of transportation.",https://doi.org/10.1016/j.bdr.2021.100292,2022,Chiara Bachechi and Laura Po and Federica Rollo,BIG DATA ANALYTICS AND VISUALIZATION IN TRAFFIC MONITORING,article
1193,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"In recent years, the rapid development of Internet, Internet of Things, and Cloud Computing have led to the explosive growth of data in almost every industry and business area. Big data has rapidly developed into a hot topic that attracts extensive attention from academia, industry, and governments around the world. In this position paper, we first briefly introduce the concept of big data, including its definition, features, and value. We then identify from different perspectives the significance and opportunities that big data brings to us. Next, we present representative big data initiatives all over the world. We describe the grand challenges (namely, data complexity, computational complexity, and system complexity), as well as possible solutions to address these challenges. Finally, we conclude the paper by presenting several suggestions on carrying out big data projects.",https://doi.org/10.1016/j.bdr.2015.01.006,2015,Xiaolong Jin and Benjamin W. Wah and Xueqi Cheng and Yuanzhuo Wang,SIGNIFICANCE AND CHALLENGES OF BIG DATA RESEARCH,article
1194,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,,https://doi.org/10.1016/j.bdr.2021.100244,2021,Lars Lundberg and Håkan Grahn and Valeria Cardellini and Andreas Polze and Sogand Shirinbab,EDITORIAL TO THE SPECIAL ISSUE ON BIG DATA IN INDUSTRIAL AND COMMERCIAL APPLICATIONS,article
1195,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"The increasing presence of geo-distributed sensor networks implies the generation of huge volumes of data from multiple geographical locations at an increasing rate. This raises important issues which become more challenging when the final goal is that of the analysis of the data for forecasting purposes or, more generally, for predictive tasks. This paper proposes a framework which supports predictive modeling tasks from streaming data coming from multiple geo-referenced sensors. In particular, we propose a distance-based anomaly detection strategy which considers objects described by embedding features learned via a stacked auto-encoder. We then devise a repair strategy which repairs the data detected as anomalous exploiting non-anomalous data measured by sensors in nearby spatial locations. Subsequently, we adopt Gradient Boosted Trees (GBTs) to predict/forecast values assumed by a target variable of interest for the repaired newly arriving (unlabeled) data, using the original feature representation or the embedding feature representation learned via the stacked auto-encoder. The workflow is implemented with distributed Apache Spark programming primitives and tested on a cluster environment. We perform experiments to assess the performance of each module, separately and in a combined manner, considering the predictive modeling of one-day-ahead energy production, for multiple renewable energy sites. Accuracy results show that the proposed framework allows reducing the error up to 13.56%. Moreover, scalability results demonstrate the efficiency of the proposed framework in terms of speedup, scaleup and execution time under a stress test.",https://doi.org/10.1016/j.bdr.2019.04.001,2019,Roberto Corizzo and Michelangelo Ceci and Nathalie Japkowicz,ANOMALY DETECTION AND REPAIR FOR ACCURATE PREDICTIONS IN GEO-DISTRIBUTED BIG DATA,article
1196,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"The emergence of new technologies such as Internet/Web/Network-of-Things and large scale wireless sensor systems enables the collection of data from an increasing volume and variety of networked sensors for analysis. In this review article, we summarize the latest developments of big sensor data systems (a term to conceptualize the application of the big data model towards networked sensor systems) in various representative studies for urban environments, including for air pollution monitoring, assistive living, disaster management systems, and intelligent transportation. An important focus is the inclusion of how value is extracted from the big data system. We also discuss some recent techniques for big data acquisition, cleaning, aggregation, modeling, and interpretation in large scale sensor-based systems. We conclude the paper with a discussion on future perspectives and challenges of sensor-based data systems in the big data era.",https://doi.org/10.1016/j.bdr.2015.12.003,2016,Li-Minn Ang and Kah Phooi Seng,BIG SENSOR DATA APPLICATIONS IN URBAN ENVIRONMENTS,article
1197,21100356018,BIG DATA RESEARCH,journal,22145796,"0,565",Q2,25,11,76,547,324,69,"4,06","49,73",United States,Northern America,Elsevier Inc.,2014-2020,Computer Science Applications (Q2); Information Systems (Q2); Information Systems and Management (Q2); Management Information Systems (Q2),586,3.578,0.00126,"Data science has employed great research efforts in developing advanced analytics, improving data models and cultivating new algorithms. However, not many authors have come across the organizational and socio-technical challenges that arise when executing a data science project: lack of vision and clear objectives, a biased emphasis on technical issues, a low level of maturity for ad-hoc projects and the ambiguity of roles in data science are among these challenges. Few methodologies have been proposed on the literature that tackle these type of challenges, some of them date back to the mid-1990, and consequently they are not updated to the current paradigm and the latest developments in big data and machine learning technologies. In addition, fewer methodologies offer a complete guideline across team, project and data & information management. In this article we would like to explore the necessity of developing a more holistic approach for carrying out data science projects. We first review methodologies that have been presented on the literature to work on data science projects and classify them according to the their focus: project, team, data and information management. Finally, we propose a conceptual framework containing general characteristics that a methodology for managing data science projects with a holistic point of view should have. This framework can be used by other researchers as a roadmap for the design of new data science methodologies or the updating of existing ones.",https://doi.org/10.1016/j.bdr.2020.100183,2021,Iñigo Martinez and Elisabeth Viles and Igor {G. Olaizola},DATA SCIENCE METHODOLOGIES: CURRENT CHALLENGES AND FUTURE APPROACHES,article
1198,26602,EVALUATION AND PROGRAM PLANNING,journal,01497189,"0,555",Q2,62,107,353,5140,753,350,"1,93","48,04",United Kingdom,Western Europe,Elsevier Ltd.,1978-2020,"Business and International Management (Q2); Geography, Planning and Development (Q2); Public Health, Environmental and Occupational Health (Q2); Social Psychology (Q2); Strategy and Management (Q2)","3,211",1.849,0.0031,"Data to inform and improve health care systems in low- and middle-income countries (LMICs) has been facilitated by the development of monitoring and evaluation (M&E) systems. The drivers of change in M&E systems over the last 50 years have included a series of health concerns that have animated global donors (e.g., family planning, vaccination campaigns, and HIV/AIDS); the data requirements of donors; improved national economies enabling LMICs to invest more in M&E systems; and rapid advances in digital technologies. Progress has included the training and expansion of an M&E workforce, the creation of systems for data collection and use, and processes for assessing and ensuring data quality. Controversies have included the development of disease-specific systems that do not coordinate with each other, and a growing burden on health care deliverers to collect data for a proliferating number of health and process indicators. Digital technologies offer the promise of real time data and quick adaptation but also raise ethical and privacy concerns. The desire for speed can cast large-scale evaluations, considered by some to be the gold standard, in an unfavorable light as slow and expensive. Accordingly, there is a growing demand for speedy evaluations that rely on routine health information systems and privately collected “big data” from electronic health records and social media.",https://doi.org/10.1016/j.evalprogplan.2021.101994,2021,James C. Thomas and Kathy Doherty and Stephanie Watson-Grant and Manish Kumar,ADVANCES IN MONITORING AND EVALUATION IN LOW- AND MIDDLE-INCOME COUNTRIES,article
1199,12189,SIMULATION MODELLING PRACTICE AND THEORY,journal,1569190X,"0,554",Q2,69,132,316,5805,1227,312,"4,02","43,98",Netherlands,Western Europe,Elsevier,2002-2021,Hardware and Architecture (Q2); Modeling and Simulation (Q2); Software (Q2),"3,547",3.272,0.00315,"Simulation stands out as an appropriate method for the Supply Chain Management (SCM) field. Nevertheless, to produce accurate simulations of Supply Chains (SCs), several business processes must be considered. Thus, when using real data in these simulation models, Big Data concepts and technologies become necessary, as the involved data sources generate data at increasing volume, velocity and variety, in what is known as a Big Data context. While developing such solution, several data issues were found, with simulation proving to be more efficient than traditional data profiling techniques in identifying them. Thus, this paper proposes the use of simulation as a semantic validator of the data, proposed a classification for such issues and quantified their impact in the volume of data used in the final achieved solution. This paper concluded that, while SC simulations using Big Data concepts and technologies are within the grasp of organizations, their data models still require considerable improvements, in order to produce perfect mimics of their SCs. In fact, it was also found that simulation can help in identifying and bypassing some of these issues.",https://doi.org/10.1016/j.simpat.2019.101985,2020,António AC Vieira and Luís MS Dias and Maribel Y Santos and Guilherme AB Pereira and José A Oliveira,ON THE USE OF SIMULATION AS A BIG DATA SEMANTIC VALIDATOR FOR SUPPLY CHAIN MANAGEMENT,article
1200,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"Nowadays, social network data of ever increasing size is gathered, stored and analyzed by researchers from a range of disciplines. This data is often automatically gathered from API’s, websites or existing databases. As a result, the quality of this data is typically not manually validated, and the resulting social networks may be based on false, biased or incomplete data. In this paper, we investigate the effect of data quality issues on the analysis of large networks. We focus on the global board interlock network, in which nodes represent firms across the globe, and edges model social ties between firms – shared board members holding a position at both firms. First, we demonstrate how we can automatically assess the completeness of a large dataset of 160 million firms, in which data is missing not at random. Second, we present a novel method to increase the accuracy of the entries in our data. By comparing the expected and empirical characteristics of the resulting network topology, we develop a technique that automatically prunes and merges duplicate nodes and edges. Third, we use a case study of the board interlock network of Sweden to show how poor quality data results in distorted network topologies, incorrect community division, biased centrality values and abnormal influence spread under a well-known diffusion model. Finally, we demonstrate how the proposed data quality assessment methods help restore the network structure, ultimately allowing us to derive meaningful and correct results from the analysis of the network.",https://doi.org/10.1016/j.is.2017.10.005,2018,Javier Garcia-Bernardo and Frank W. Takes,THE EFFECTS OF DATA QUALITY ON THE ANALYSIS OF CORPORATE BOARD INTERLOCK NETWORKS,article
1201,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"In the recent years the problems of using generic storage (i.e., relational) techniques for very specific applications have been detected and outlined and, as a consequence, some alternatives to Relational DBMSs (e.g., HBase) have bloomed. Most of these alternatives sit on the cloud and benefit from cloud computing, which is nowadays a reality that helps us to save money by eliminating the hardware as well as software fixed costs and just pay per use. On top of this, specific querying frameworks to exploit the brute force in the cloud (e.g., MapReduce) have also been devised. The question arising next tries to clear out if this (rather naive) exploitation of the cloud is an alternative to tuning DBMSs or it still makes sense to consider other options when retrieving data from these settings. In this paper, we study the feasibility of solving OLAP queries with Hadoop (the Apache project implementing MapReduce) while benefiting from secondary indexes and partitioning in HBase. Our main contribution is the comparison of different access plans and the definition of criteria (i.e., cost estimation) to choose among them in terms of consumed resources (namely CPU, bandwidth and I/O).",https://doi.org/10.1016/j.is.2014.09.005,2015,Oscar Romero and Victor Herrero and Alberto Abelló and Jaume Ferrarons,TUNING SMALL ANALYTICS ON BIG DATA: DATA PARTITIONING AND SECONDARY INDEXES IN THE HADOOP ECOSYSTEM,article
1202,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"Our work is motivated by the fact that there is an increasing need to perform complex analytics jobs over streaming data as close to the edge devices as possible and, in parallel, it is important that data quality is considered as an optimization objective along with performance metrics. In this work, we develop a solution that trades latency for an increased fraction of incoming data, for which data quality-related measurements and operations are performed, in jobs running over geo-distributed heterogeneous and constrained resources. Our solution is hybrid: on the one hand, we perform search heuristics over locally optimal partial solutions to yield an enhanced global solution regarding task allocations; on the other hand, we employ a spring relaxation algorithm to avoid unnecessarily increased degree of partitioned parallelism. Through thorough experiments, we show that we can improve upon state-of-the-art solutions in terms of our objective function that combines latency and extent of quality checks by up to 2.56X. Moreover, we implement our solution within Apache Storm, and we perform experiments in an emulated setting. The results show that we can reduce the latency in 86.9% of the cases examined, while latency is up to 8 times lower compared to the built-in Storm scheduler, with the average latency reduction being 52.5%.",https://doi.org/10.1016/j.is.2021.101953,2022,Anna-Valentini Michailidou and Anastasios Gounaris and Moysis Symeonides and Demetris Trihinas,EQUALITY: QUALITY-AWARE INTENSIVE ANALYTICS ON THE EDGE,article
1203,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"The efficiency and effectiveness of business processes are usually evaluated by Process Performance Indicators (PPIs), which are computed using process event logs. PPIs can be insightful only when they are measurable, i.e., reliable. This paper proposes to define PPI measurability on the basis of the quality of the data in the process logs. Then, based on this definition, a framework for PPI measurability assessment and improvement is presented. For the assessment, we propose novel definitions of PPI accuracy, completeness, consistency, timeliness and volume that contextualise the traditional definitions in the data quality literature to the case of process logs. For the improvement, we define a set of guidelines for improving the measurability of a PPI. These guidelines may concern improving existing event logs, for instance through data imputation, implementation or enhancement of the process monitoring systems, or updating the PPI definitions. A case study in a large-sized institution is discussed to show the feasibility and the practical value of the proposed framework.",https://doi.org/10.1016/j.is.2021.101874,2022,Cinzia Cappiello and Marco Comuzzi and Pierluigi Plebani and Matheus Fim,ASSESSING AND IMPROVING MEASURABILITY OF PROCESS PERFORMANCE INDICATORS BASED ON QUALITY OF LOGS,article
1204,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"Cyber-physical systems (CPSs) are integrated systems engineered to combine computational control algorithms and physical components such as sensors and actuators, effectively using an embedded communication core. Smart cities can be viewed as large-scale, heterogeneous CPSs that utilise technologies like the Internet of Things (IoT), surveillance, social media, and others to make informed decisions and drive the innovations of automation in urban areas. Such systems incorporate multiple layers and complex structure of hardware, software, analytical algorithms, business knowledge and communication networks, and operate under noisy and dynamic conditions. Thus, large-scale CPSs are vulnerable to enormous technical and operational challenges that may compromise the quality of data of their applications and accordingly reduce the quality of their services. This paper presents a systematic literature review to investigate data quality challenges in smart-cities large-scale CPSs and to identify the most common techniques used to address these challenges. This systematic literature review showed that significant work had been conducted to address data quality management challenges in smart cities, large-scale CPS applications. However, still, more is required to provide a practical, comprehensive data quality management solution to detect errors in sensor nodes’ measurements associated with the main data quality dimensions of accuracy, timeliness, completeness, and consistency. No systematic or generic approach was demonstrated for detecting sensor nodes and sensor node networks failures in large-scale CPS applications. Moreover, further research is required to address the challenges of ensuring the quality of the spatial and temporal contextual attributes of sensor nodes’ observations.",https://doi.org/10.1016/j.is.2021.101951,2022,Ahmed Abdulhasan Alwan and Mihaela Anca Ciupala and Allan J. Brimicombe and Seyed Ali Ghorashi and Andres Baravalle and Paolo Falcarin,DATA QUALITY CHALLENGES IN LARGE-SCALE CYBER-PHYSICAL SYSTEMS: A SYSTEMATIC REVIEW,article
1205,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"Cloud computing is a powerful technology to perform massive-scale and complex computing. It eliminates the need to maintain expensive computing hardware, dedicated space, and software. Massive growth in the scale of data or big data generated through cloud computing has been observed. Addressing big data is a challenging and time-demanding task that requires a large computational infrastructure to ensure successful data processing and analysis. The rise of big data in cloud computing is reviewed in this study. The definition, characteristics, and classification of big data along with some discussions on cloud computing are introduced. The relationship between big data and cloud computing, big data storage systems, and Hadoop technology are also discussed. Furthermore, research challenges are investigated, with focus on scalability, availability, data integrity, data transformation, data quality, data heterogeneity, privacy, legal and regulatory issues, and governance. Lastly, open research issues that require substantial research efforts are summarized.",https://doi.org/10.1016/j.is.2014.07.006,2015,Ibrahim Abaker Targio Hashem and Ibrar Yaqoob and Nor Badrul Anuar and Salimah Mokhtar and Abdullah Gani and Samee {Ullah Khan},THE RISE OF “BIG DATA” ON CLOUD COMPUTING: REVIEW AND OPEN RESEARCH ISSUES,article
1206,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"Data quality evaluation is built upon data quality measurement results. “Data quality evaluation” uses the “data quality rules” representing the risk appetite of the organization to decide on the usability of the data; “data quality measurement” uses the business rules describing the “data requirements” or “data specifications” to determine the validity of the data. Consequently, to conduct meaningful and useful data quality evaluations, business rules must be first completely identified and captured at the beginning of the evaluation to perform sound measurements. We propose that the evaluation leads to better and more interpretable and useful results when the potential contribution of these business rules to the measurement of the data quality characteristics is first evaluated, avoiding the inclusion in the evaluation of those not having potential contribution and the resulting waste of resources. Considering this, we feel that for a better management of business rules for data quality evaluation, it makes sense to group all business rules having an important contribution to the evaluation of data quality characteristics, something that other business rules management methodologies have not covered yet. Through our experiences in conducting industrial projects of data quality evaluations we identified six problems when collecting and grouping the business rules. These problems make data quality evaluation processes less efficient and more costly. The main contribution of this paper is a methodology to systematically collect, group and validate the business rules to avoid or to alleviate these problems. For the sake of generalization, comparability, and reusability, we propose to do the grouping for data quality characteristics and properties defined in ISO/IEC 25012 and ISO/IEC 25024, respectively. Lastly, we validate the methodology in three case studies of real projects. From this validation, it is possible to raise the conclusion that the methodology is useful, applicable in the real world, and valid to capture and group the business rules used as a basis for data quality evaluation.",https://doi.org/10.1016/j.is.2022.102058,2022,Ismael Caballero and Fernando Gualo and Moisés Rodríguez and Mario Piattini,BR4DQ: A METHODOLOGY FOR GROUPING BUSINESS RULES FOR DATA QUALITY EVALUATION,article
1207,12305,INFORMATION SYSTEMS,journal,03064379,"0,547",Q2,85,100,271,4739,1027,255,"3,39","47,39",United Kingdom,Western Europe,Elsevier Ltd.,1975-2021,Hardware and Architecture (Q2); Information Systems (Q2); Software (Q2),"2,604",2.309,0.00331,"The production of analytic datasets is a significant big data trend and has gone well beyond the scope of traditional IT-governed dataset development. Analytic datasets are now created by data scientists and data analysts using big data frameworks and agile data preparation tools. However, despite the profusion of available datasets, it remains quite difficult for a data analyst to start from a dataset at hand and customize it with additional attributes coming from other existing datasets. This article describes a model and algorithms that exploit automatically extracted and user-defined semantic relationships for extending analytic datasets with new atomic or aggregated attribute values. Our framework is implemented as a REST service in SAP HANA and includes a careful theoretical analysis and practical solutions for several complex data quality issues.",https://doi.org/10.1016/j.is.2020.101495,2020,Rutian Liu and Eric Simon and Bernd Amann and Stéphane Gançarski,DISCOVERING AND MERGING RELATED ANALYTIC DATASETS,article
1208,17368,IEEE TRANSACTIONS ON NUCLEAR SCIENCE,journal,15581578,"0,537",Q2,122,336,1094,8725,2065,1074,"1,92","25,97",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q2); Nuclear and High Energy Physics (Q2); Nuclear Energy and Engineering (Q2),"13,802",1.679,0.00711,New approaches to statistical modeling in radiation hardness assurance are discussed. These approaches yield quantitative bounds on flight-part radiation performance even in the absence of conventional data sources. This allows the analyst to bound radiation risk at all stages and for all decisions in the RHA process. It also allows optimization of RHA procedures for the project's risk tolerance.,10.1109/TNS.2015.2462754,2015,,STATISTICAL MODELING FOR RADIATION HARDNESS ASSURANCE: TOWARD BIGGER DATA,
1209,17368,IEEE TRANSACTIONS ON NUCLEAR SCIENCE,journal,15581578,"0,537",Q2,122,336,1094,8725,2065,1074,"1,92","25,97",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1963-2020,Electrical and Electronic Engineering (Q2); Nuclear and High Energy Physics (Q2); Nuclear Energy and Engineering (Q2),"13,802",1.679,0.00711,"Proton therapy is a precise forms of radiation therapy that makes use of high energy proton compared to the conventional, more commonly used and less precise x-ray and electron beams. On the other hand, to fully exploit the proton therapy advantages, very accurate quality controls of the treatments are required. These are mainly related to the dose calculations and treatment planning. Actually dose calculations are routinely performed on the basis of X-ray computed tomography while a big improvement could be obtained with the direct use of protons as the imaging system. In this work we report the results of Monte Carlo simulations for the study of an imaging system based on the use of high energy protons: the proton computed tomography (pCT). The main limitation of the pCT and the current adopted technical solutions, based on the use of the most likely path (MLP) approximation are illustrated. Simulation results are compared with experimental data obtained with a first prototype of pCT system tested with 200 MeV proton beams available at the Loma Linda University Medical Center (LLUMC) (CA).",10.1109/TNS.2007.906988,2007,,MONTE CARLO STUDIES OF A PROTON COMPUTED TOMOGRAPHY SYSTEM,
1210,28436,JOURNAL OF ATMOSPHERIC AND SOLAR-TERRESTRIAL PHYSICS,journal,13646826,"0,515",Q2,89,180,628,8954,1256,620,"1,89","49,74",United Kingdom,Western Europe,Elsevier Ltd.,1997-2020,Geophysics (Q2); Atmospheric Science (Q3); Space and Planetary Science (Q3),"7,321",1.735,0.00523,"Starting from a set of 6190 meteorological stations we are choosing 6130 of them and only for Northern Hemisphere we are computing average values for absolute annual Mean, Minimum, Q1, Median, Q3, Maximum temperature plus their standard deviations for years 1800–2013, while we use 4887 stations and 389467 rows of complete yearly data. The data quality and the seasonal bias indices are defined and used in order to evaluate our dataset. After the year 1969 the data quality is monotonically decreasing while the seasonal bias is positive in most of the cases. An Extreme Value Distribution estimation is performed for minimum and maximum values, giving some upper bounds for both of them and indicating a big magnitude for temperature changes. Finally suggestions for improving the quality of meteorological data are presented.",https://doi.org/10.1016/j.jastp.2015.03.009,2015,Demetris T. Christopoulos,EXTRACTION OF THE GLOBAL ABSOLUTE TEMPERATURE FOR NORTHERN HEMISPHERE USING A SET OF 6190 METEOROLOGICAL STATIONS FROM 1800 TO 2013,article
1211,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"The explosive growth of data volume in mobile networks makes fast online diagnose a pressing search problem. In this paper, an object-oriented detection framework with a two-step clustering, named as Hourglass Clustering, is given. Where three object parameters are chosen as Synthetical Quality of Experience (SQoE) Key Quality Indicators (KQIs) to reflect accessibility, integrality, and maintainability of networks. Then, we choose represented Key Performance Indicators (rKPIs) as cause parameters with correlation analysis. For these two kinds of parameters, a hybrid algorithm combining the self-organizing map (SOM) and k-medoids is used for clustering them into different types. We apply this framework to online anomaly detection in Cellular Networks, named SQoE-driven Anomaly Detection and Cause Location System (SQoE-ADCL). Our experiments with real 4G data show that besides fast online detection, SQoE-ADCL makes a better soft decision instead of a traditional hard decision. Furthermore, it is also a general way of being applied to other similar applications in big data.",10.1109/CC.2018.8485466,2018,,SQOE KQIS ANOMALY DETECTION IN CELLULAR NETWORKS: FAST ONLINE DETECTION FRAMEWORK WITH HOURGLASS CLUSTERING,
1212,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"Mobile operators face the challenge of how to best design a service-centric network that can effectively process the rapidly increasing number of bandwidth-intensive user requests while providing a higher quality of experience (QoE). Existing content distribution networks (CDN) and mobile content distribution networks (mCDN) have both latency and throughput limitations due to being multiple network hops away from end-users. Here, we first propose a new Personalized Edge Caching System (PECS) architecture that employs big data analytics and mobile edge caching to provide personalized service access at the edge of the mobile network. Based on the proposed system architecture, the edge caching strategy based on user behavior and trajectory is analyzed. Employing our proposed PECS strategies, we use data mining algorithms to analyze the personalized trajectory and service usage patterns. Our findings provide guidance on how key technologies of PECS can be employed for current and future networks. Finally, we highlight the challenges associated with realizing such a system in 5G and beyond.",10.23919/JCC.2019.08.009,2019,,PECS: TOWARDS PERSONALIZED EDGE CACHING FOR FUTURE SERVICE-CENTRIC NETWORKS,
1213,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"Recent emergence of diverse services have led to explosive traffic growth in cellular data networks. Understanding the service dynamics in large cellular networks is important for network design, trouble shooting, quality of service (QoE) support, and resource allocation. In this paper, we present our study to reveal the distributions and temporal patterns of different services in cellular data network from two different perspectives, namely service request times and service duration. Our study is based on big traffic data, which is parsed to readable records by our Hadoop-based packet parsing platform, captured over a week-long period from a tier-1 mobile operator's network in China. We propose a Zipf's ranked model to characterize the distributions of traffic volume, packet, request times and duration of cellular services. Two-stage method (Self-Organizing Map combined with kmeans) is first used to cluster time series of service into four request patterns and three duration patterns. These seven patterns are combined together to better understand the fine-grained temporal patterns of service in cellular network. Results of our distribution models and temporal patterns present cellular network operators with a better understanding of the request and duration characteristics of service, which of great importance in network design, service generation and resource allocation.",10.1109/CC.2015.7275255,2015,,MODELING AND MINING THE TEMPORAL PATTERNS OF SERVICE IN CELLULAR NETWORK,
1214,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"To support dramatically increased traffic loads, communication networks become ultra-dense. Traditional cell association (CA) schemes are time-consuming, forcing researchers to seek fast schemes. This paper proposes a deep Q-learning based scheme, whose main idea is to train a deep neural network (DNN) to calculate the Q values of all the state-action pairs and the cell holding the maximum Q value is associated. In the training stage, the intelligent agent continuously generates samples through the trial-and-error method to train the DNN until convergence. In the application stage, state vectors of all the users are inputted to the trained DNN to quickly obtain a satisfied CA result of a scenario with the same BS locations and user distribution. Simulations demonstrate that the proposed scheme provides satisfied CA results in a computational time several orders of magnitudes shorter than traditional schemes. Meanwhile, performance metrics, such as capacity and fairness, can be guaranteed.",10.23919/JCC.2021.02.018,2021,,INTELLIGENT FAST CELL ASSOCIATION SCHEME BASED ON DEEP Q-LEARNING IN ULTRA-DENSE CELLULAR NETWORKS,
1215,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"Nowadays, the fifth-generation (5G) mobile communication system has obtained prosperous development and deployment, reshaping our daily lives. However, anomalies of cell outages and congestion in 5G critically influence the quality of experience and significantly increase operational expenditures. Although several big data and artificial intelligence-based anomaly detection methods have been proposed for wireless cellular systems, they change distributions of the data and ignore the relevance among user activities, causing anomaly detection ineffective for some cells. In this paper, we propose a highly effective and accurate anomaly detection framework by utilizing generative adversarial networks (GAN) and long short-term memory (LSTM) neural networks. The framework expands the original dataset while simultaneously keeping the distribution of data unchanged, and explores the relevance among user activities to further improve the system performance. The results demonstrate that our framework can achieve 97.16% accuracy and 2.30% false positive rate by utilizing the correlation of user activities and data expansion.",10.23919/JCC.2022.08.013,2022,,AN EFFICIENT CORRELATION-AWARE ANOMALY DETECTION FRAMEWORK IN CELLULAR NETWORK,
1216,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,Clustering is one of the recently challenging tasks since there is an ever-growing amount of data in scientific research and commercial applications. High quality and fast document clustering algorithms are in great demand to deal with large volume of data. The computational requirements for bringing such growing amount data to a central site for clustering are complex. The proposed algorithm uses optimal centroids for K-Means clustering based on Particle Swarm Optimization(PSO). PSO is used to take advantage of its global search ability to provide optimal centroids which aids in generating more compact clusters with improved accuracy. This proposed methodology utilizes Hadoop and MapReduce framework which provides distributed storage and analysis to support data intensive distributed applications. Experiments were performed on Reuter's and RCV1 document dataset which shows an improvement in accuracy with reduced execution time.,10.1109/CC.2017.7868161,2017,,DISTRIBUTED DOCUMENT CLUSTERING ANALYSIS BASED ON A HYBRID METHOD,
1217,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"How to explore and exploit the full potential of artificial intelligence (AI) technologies in future wireless communications such as beyond 5G (B5G) and 6G is an extremely hot inter-disciplinary research topic around the world. On the one hand, AI empowers intelligent resource management for wireless communications through powerful learning and automatic adaptation capabilities. On the other hand, embracing AI in wireless communication resource management calls for new network architecture and system models as well as standardized interfaces/protocols/data formats to facilitate the large-scale deployment of AI in future B5G/6G networks. This paper reviews the state-of-art AI-empowered resource management from the framework perspective down to the methodology perspective, not only considering the radio resource (e.g., spectrum) management but also other types of resources such as computing and caching. We also discuss the challenges and opportunities for AI-based resource management to widely deploy AI in future wireless communication networks.",10.23919/JCC.2020.03.006,2020,,ARTIFICIAL INTELLIGENCE-EMPOWERED RESOURCE MANAGEMENT FOR FUTURE WIRELESS COMMUNICATIONS: A SURVEY,
1218,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"The space-air-ground integrated network (SAGIN) is regarded as the key approach to realize global coverage in future network and it reaches broad access for various services. Being the new paradigm of service, immersive media (IM) has attracted users' attention for its virtualization, but it poses challenges to network performance, e.g. bandwidth, rate, latency. However, the SAGIN has limitations in supporting IM services, such as 4K/8K video, virtual reality, and interactive games. In this paper, a novel service customized SAGIN architecture for IM applications (SAG-IM) is proposed, which achieves content interactive and real-time communication among terminal users. State-of-the-art research is investigated in detail to facilitate the combination of SAGIN and service customized technology, which provides end-to-end differentiated services for users. Besides, the functional components of SAG-IM contain the infrastructure layer, perception layer, intelligence layer, and application layer, reaching the capabilities of intelligent management of the network. Moreover, to provide IM content with ultra-high-definition and high frame rate for the optimal user experience, the promising key technologies on intelligent routing and delivery are discussed. The performance evaluation shows the superiority of SAG-IM in supporting IM service. Finally, the prospects in practical application are highlighted.",10.23919/JCC.2022.01.001,2022,,"SERVICE CUSTOMIZED SPACE-AIR-GROUND INTEGRATED NETWORK FOR IMMERSIVE MEDIA: ARCHITECTURE, KEY TECHNOLOGIES, AND PROSPECTS",
1219,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"Reasonable allocation of storage and computing resources is the basis of building big data system. With the development of IoT (Internet of Things), more data will be brought. A three-layer architecture includes smart devices layer, edge cloud layer and blockchain-based distributed cloud layer. Blockchain is used in IoT for building a distributed decentralize P2P architecture to deal with the secure issue while edge computing deals with increasing volume of data. Edge caching is one of the important application scenarios. In order to allocate edge cache resources reasonably, to improve the quality of service and to reduce the waste of bandwidth resources, this paper proposes a content selection algorithm of edge cache nodes. The algorithm adopts markov chain model, improves the utilization of cache space and reduces the content transmission delay. The hierarchical caching strategy is adopted and the secondary cache stores slides of contents to expand the coverage of cached content and to reduce user waiting time. Regional node cooperation is adopted to expand the cache space and to support the regional preference of cache content. Compared with the classical substitution algorithm, simulation results show that the algorithm in this paper has higher cache hit ratio and higher space utilization.",10.23919/JCC.2020.09.006,2020,,AN ALGORITHM BASED ON MARKOV CHAIN TO IMPROVE EDGE CACHE HIT RATIO FOR BLOCKCHAIN-ENABLED IOT,
1220,19700177325,CHINA COMMUNICATIONS,journal,16735447,"0,508",Q2,42,227,629,6632,2012,607,"3,53","29,22",China,Asiatic Region,China Institute of Communication,2008-2020,Computer Networks and Communications (Q2); Electrical and Electronic Engineering (Q2),"2,891",2.688,0.00373,"Mobile edge computing has emerged as a new paradigm to enhance computing capabilities by offloading complicated tasks to nearby cloud server. To conserve energy as well as maintain quality of service, low time complexity algorithm is proposed to complete task offloading and server allocation. In this paper, a multi-user with multiple tasks and single server scenario is considered for small network, taking full account of factors including data size, bandwidth, channel state information. Furthermore, we consider a multi-server scenario for bigger network, where the influence of task priority is taken into consideration. To jointly minimize delay and energy cost, we propose a distributed unsupervised learning-based offloading framework for task offloading and server allocation. We exploit a memory pool to store input data and corresponding decisions as key-value pairs for model to learn to solve optimization problems. To further reduce time cost and achieve near-optimal performance, we use convolutional neural networks to process mass data based on fully connected networks. Numerical results show that the proposed algorithm performs better than other offloading schemes, which can generate near-optimal offloading decision timely.",10.23919/JCC.2022.07.018,2022,,EFFICIENT MULTI-USER FOR TASK OFFLOADING AND SERVER ALLOCATION IN MOBILE EDGE COMPUTING SYSTEMS,
1221,12300,IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS,journal,15579999,"0,506",Q2,105,257,887,8001,2867,878,"3,15","31,13",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1993-2020,Electrical and Electronic Engineering (Q2); Hardware and Architecture (Q2); Software (Q2),"6,270",2.312,0.00889,"To increase the quality of wireless transmission, wireless communication systems employ advanced forward error correction codes such as turbo codes and low-density parity-check (LDPC) codes. To achieve smooth transition between turbo and LDPC decoding in different communication standards, we propose a VLSI design of a multimode radix-4 soft-input soft-output (SISO) kernel in this paper. The proposed radix-4 SISO kernel composed of three recursive processing elements alternatively employs a radix-4 forward-backward algorithm for LDPC decoding and a radix-4 single-binary/double-binary enhanced max-log-maximum a posteriori probability algorithm for turbo decoding by efficiently sharing computational units. The proposed radix-4 SISO kernel achieves an area reduction of 21.8% when compared with the uncombined SISO kernels for alternatively decoding the turbo and LDPC codes. The proposed radix-4 SISO kernel is verified by implementing it in an application-specific integrated circuit of 0.45 mm2 core area by using a 90-nm CMOS process with a maximum area efficiency of 10.65 bits/mm2. In addition, the throughput rates of the long-term evolution and worldwide interoperability for microwave access schemes for both LDPC and turbo decoding can be achieved using eight proposed radix-4 SISO kernels.",10.1109/TVLSI.2014.2363777,2015,,MULTIMODE RADIX-4 SISO KERNEL DESIGN FOR TURBO/LDPC DECODING,
1222,12300,IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS,journal,15579999,"0,506",Q2,105,257,887,8001,2867,878,"3,15","31,13",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1993-2020,Electrical and Electronic Engineering (Q2); Hardware and Architecture (Q2); Software (Q2),"6,270",2.312,0.00889,"The impending Internet of Things (IoT) wave is promising to affect every aspect of our daily lives, ranging from smart things to smart buildings, smart cities, and smart environments. A lot of attention has been devoted to the tsunami of data produced by IoT, and the related means of extracting useful actionable information from it, spawning efforts in Big Data processing and machine learning. Yet, all of this does little to address the need for IoT to capture, interpret, and act on this wall of (noisy) information at the right time, at the right place, and in the right form. Conventional computing systems are a poor match to the needs of this emerging massively distributed real-time system. Hence, alternative computing techniques present an attractive alternative, trading off computational resolution for significant gains in quality-of-service energy efficiency and robustness. This observation is based on the conjecture that most applications related to IoT have an inherent error resilience and are evolutionary (that is, learning-based). Alternative computing strategies may be conceived at every level of the design hierarchy, starting from the device level with novel 3-D nonvolatile memory/logic combinations, or at the architectural level by shifting away from the traditional von Neumann architecture to different computing paradigms such as neuromorphic and/or stochastic computation all the way up to the algorithmic and data representation levels.",10.1109/TVLSI.2017.2742098,2017,,GUEST EDITORIAL: ALTERNATIVE COMPUTING AND MACHINE LEARNING FOR INTERNET OF THINGS,
1223,15099,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,journal,00188646,"0,470",Q2,95,55,145,1371,464,130,"2,99","24,93",United States,Northern America,IBM Corporation,1969-2020,Computer Science (miscellaneous) (Q2),"3,412",1.889,0.00101,"As data-intensive decision making is being increasingly adopted by businesses, governments, and other agencies around the world, most organizations encountering a very large amount and variety of data are still contemplating and assessing their readiness to embrace “Big Data.” While these organizations devise various ways to deal with the challenges such data brings, the impact and importance of Big Data to information quality and governance programs should not be underestimated. Drawing upon implementation experiences of early adopters of Big Data technologies across multiple industries, this paper explores the issues and challenges involved in the management of Big Data, highlighting the principles and best practices for effective Big Data governance.",10.1147/JRD.2013.2241359,2013,,GOVERNING BIG DATA: PRINCIPLES AND PRACTICES,
1224,15099,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,journal,00188646,"0,470",Q2,95,55,145,1371,464,130,"2,99","24,93",United States,Northern America,IBM Corporation,1969-2020,Computer Science (miscellaneous) (Q2),"3,412",1.889,0.00101,"The mobile Internet brought tremendous opportunities for businesses to capitalize on the vast amount of SoLoMo (social-location-mobile) data for delivering high-quality and personalized customer services. In this paper, we describe algorithms and technologies for discovering actionable customer insights using the combined power of social network, location pattern mining, and mobile usage analysis. We illustrate our implementation using Big Data platforms including IBM InfoSphere® BigInsights, IBM InfoSphere Streams, and IBM Netezza® Data Warehouse, while addressing various Big Data-related challenges, such as context generation of unstructured data and high-performance analytics for both data at rest and data in motion. The presented system combines location, social interactions, and user behavior data to find like-minded communities. The system leverages Big Data capabilities to attempt to scale to support the subscriber base of large telecoms in an efficient manner.",10.1147/JRD.2014.2336177,2014,,SOLOMO ANALYTICS FOR TELCO BIG DATA MONETIZATION,
1225,15099,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,journal,00188646,"0,470",Q2,95,55,145,1371,464,130,"2,99","24,93",United States,Northern America,IBM Corporation,1969-2020,Computer Science (miscellaneous) (Q2),"3,412",1.889,0.00101,"Massive-scale Big Data analytics is representative of a new class of workloads that justifies a rethinking of how computing systems should be optimized. This paper addresses the need for a set of benchmarks that system designers can use to measure the quality of their designs and that customers can use to evaluate competing systems offerings with respect to commonly performed text-oriented workflows in Hadoop™. Additions are needed to existing benchmarks such as HiBench in terms of both scale and relevance. We describe a methodology for creating a petascale data-size text-oriented benchmark that includes representative Big Data workflows and can be used to test total system performance, with demands balanced across storage, network, and computation. Creating such a benchmark requires meeting unique challenges associated with the data size and its often unstructured nature. To be useful, the benchmark also needs to be sufficiently generic to be accepted by the community at large. Here, we focus on a text-oriented Hadoop workflow that consists of three common tasks: categorizing text documents, identifying significant documents within each category, and analyzing significant documents for new topic creation.",10.1147/JRD.2013.2240732,2013,,BIG DATA TEXT-ORIENTED BENCHMARK CREATION FOR HADOOP,
1226,15099,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,journal,00188646,"0,470",Q2,95,55,145,1371,464,130,"2,99","24,93",United States,Northern America,IBM Corporation,1969-2020,Computer Science (miscellaneous) (Q2),"3,412",1.889,0.00101,"In this analysis of the risk and return of stocks in the United States and global markets, we apply several portfolio construction and optimization techniques to U.S. and global stock universes. We find that (1) mean-variance techniques continue to produce portfolios capable of generating excess returns above transaction costs and statistically significant asset selection, (2) optimization techniques minimizing expected tail loss are statistically significant in portfolio construction, and (3) global markets offer the potential for greater returns relative to risk than domestic markets. In this experiment, mean-variance, enhanced-index-tracking techniques, and mean-expected tail-loss methodologies are examined. Global equity data and the vast quantity (and quality) of the data relative to U.S. equity modeling have been discussed in the literature. We estimate expected return models in the U.S. and global equity markets using a given stock-selection model and generate statistically significant active returns from various portfolio construction techniques.",10.1147/JRD.2013.2272483,2013,,EFFICIENT GLOBAL PORTFOLIOS: BIG DATA AND INVESTMENT UNIVERSES,
1227,15099,IBM JOURNAL OF RESEARCH AND DEVELOPMENT,journal,00188646,"0,470",Q2,95,55,145,1371,464,130,"2,99","24,93",United States,Northern America,IBM Corporation,1969-2020,Computer Science (miscellaneous) (Q2),"3,412",1.889,0.00101,"Computational creativity is an emerging branch of artificial intelligence that places computers in the center of the creative process. Broadly, creativity involves a generative step to produce many ideas and a selective step to determine the ones that are the best. Many previous attempts at computational creativity, however, have not been able to achieve a valid selective step. This paper shows how bringing data sources from the creative domain and from hedonic psychophysics together with machine learning and data analytics techniques can overcome this shortcoming to yield a system that can produce novel and high-quality creative artifacts. To demonstrate our data-driven approach, we developed and deployed a computational creativity system for culinary recipes and menus, Chef Watson, which can operate either autonomously or semiautonomously with human interaction. We present the basic system architecture, data engineering, and algorithms that are involved. Experimental results demonstrate the system passes the test for creativity based on the consensual assessment technique, producing a novel and flavorful recipe. Large-scale deployments are also discussed.",10.1147/JRD.2019.2893905,2019,,A BIG DATA APPROACH TO COMPUTATIONAL CREATIVITY: THE CURIOUS CASE OF CHEF WATSON,
1228,28031,IEEE TRANSACTIONS ON PLASMA SCIENCE,journal,19399375,"0,460",Q2,106,574,1758,14496,2567,1731,"1,37","25,25",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,1973-2020,Condensed Matter Physics (Q2); Nuclear and High Energy Physics (Q3),"11,311",1.222,0.00884,"A redesign of the Thomson scattering data acquisition system located on the DIII-D tokamak is undergoing its trial phase. The redesign was made necessary by several factors, including the desire to improve the quality of the acquired data. In addition, the previous generation system was based on CAMAC technology, which has become difficult to maintain and is no longer supported. A big part of this improved redesign comes from the use of faster electronics allowing for greatly improved background light subtraction, the main source of noise. The past system utilized LeCroy FERA CAMAC gated integrator modules for integration and digitization. The redesigned system takes a much more distributed approach. The new system consists of a number of subsystems, including photodetectors, digitizers, distribution panels, and timing circuits. The most significant upgrade was performed on the photodetector electronic assembly. A key feature was to make the units much more self-contained in regard to the preamplifier, background subtraction, integration, and bias circuits. The redesigned photodetectors and preliminary test results of the trial phase will be presented.",10.1109/TPS.2010.2049587,2010,,"THE DESIGN, IMPLEMENTATION, AND PRELIMINARY RESULTS OF A NEW PHOTODETECTOR FOR THE DIII–D THOMSON SCATTERING DIAGNOSTIC",
1229,17833,MEDICAL HYPOTHESES,journal,03069877,"0,441",Q3,87,816,979,28666,1452,883,"1,40","35,13",United States,Northern America,Churchill Livingstone,1975-2020,Medicine (miscellaneous) (Q3),"9,727",1.538,0.005,"For the first time in history, it is possible to study human behavior on great scale and in fine detail simultaneously. Online services and ubiquitous computational devices, such as smartphones and modern cars, record our everyday activity. The resulting Big Data offers unprecedented opportunities for tracking and analyzing behavior. This paper hypothesizes the applicability and impact of Big Data technologies in the context of psychometrics both for research and clinical applications. It first outlines the state of the art, including the severe shortcomings with respect to quality and quantity of the resulting data. It then presents a technological vision, comprised of (i) numerous data sources such as mobile devices and sensors, (ii) a central data store, and (iii) an analytical platform, employing techniques from data mining and machine learning. To further illustrate the dramatic benefits of the proposed methodologies, the paper then outlines two current projects, logging and analyzing smartphone usage. One such study attempts to thereby quantify severity of major depression dynamically; the other investigates (mobile) Internet Addiction. Finally, the paper addresses some of the ethical issues inherent to Big Data technologies. In summary, the proposed approach is about to induce the single biggest methodological shift since the beginning of psychology or psychiatry. The resulting range of applications will dramatically shape the daily routines of researches and medical practitioners alike. Indeed, transferring techniques from computer science to psychiatry and psychology is about to establish Psycho-Informatics, an entire research direction of its own.",https://doi.org/10.1016/j.mehy.2013.11.030,2014,Alexander Markowetz and Konrad Błaszkiewicz and Christian Montag and Christina Switala and Thomas E. Schlaepfer,PSYCHO-INFORMATICS: BIG DATA SHAPING MODERN PSYCHOMETRICS,article
1230,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"Data quality is an important aspect in data application and management, and currency is one of the major dimensions influencing its quality. In real applications, datasets timestamps are often incomplete and unavailable, or even absent. With the increasing requirements to update real-time data, existing methods can fail to adequately determine the currency of entities. In consideration of the velocity of big data, we propose a series of efficient algorithms for determining the currency of dynamic datasets, which we divide into two steps. In the preprocessing step, to better determine data currency and accelerate dataset updating, we propose the use of a topological graph of the processing order of the entity attributes. Then, we construct an Entity Query B-Tree (EQB-Tree) structure and an Entity Storage Dynamic Linked List (ES-DLL) to improve the querying and updating processes of both the data currency graph and currency scores. In the currency determination step, we propose definitions of the currency score and currency information for tuples referring to the same entity and use examples to discuss methods and algorithms for their computation. Based on our experimental results with both real and synthetic data, we verify that our methods can efficiently update data in the correct order of currency.",10.23919/TST.2017.7914196,2017,,EFFICIENT CURRENCY DETERMINATION ALGORITHMS FOR DYNAMIC DATA,
1231,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"Big Personal Data is growing explosively. Consequently, an increasing number of internet users are drowning in a sea of data. Big Personal Data has enormous commercial value; it is a new kind of data asset. An urgent problem has thus arisen in the data market: How to price Big Personal Data fairly and reasonably. This paper proposes a pricing model for Big Personal Data based on tuple granularity, with the help of comparative analysis of existing data pricing models and strategies. This model is put forward to implement positive rating and reverse pricing for Big Personal Data by investigating data attributes that affect data value, and analyzing how the value of data tuples varies with information entropy, weight value, data reference index, cost, and other factors. The model can be adjusted dynamically according to these parameters. With increases in data scale, reductions in its cost, and improvements in its quality, Big Personal Data users can thereby obtain greater benefits.",10.1109/TST.2016.7590317,2016,,A PRICING MODEL FOR BIG PERSONAL DATA,
1232,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"A large volume of Remote Sensing (RS) data has been generated with the deployment of satellite technologies. The data facilitate research in ecological monitoring, land management and desertification, etc. The characteristics of RS data (e.g., enormous volume, large single-file size, and demanding requirement of fault tolerance) make the Hadoop Distributed File System (HDFS) an ideal choice for RS data storage as it is efficient, scalable, and equipped with a data replication mechanism for failure resilience. To use RS data, one of the most important techniques is geospatial indexing. However, the large data volume makes it time-consuming to efficiently construct and leverage. Considering that most modern geospatial data centres are equipped with HDFS-based big data processing infrastructures, deploying multiple geospatial indices becomes natural to optimise the efficacy. Moreover, because of the reliability introduced by high-quality hardware and the infrequently modified property of the RS data, the use of multi-indexing will not cause large overhead. Therefore, we design a framework called Multi-IndeXing-RS (MIX-RS) that unifies the multi-indexing mechanism on top of the HDFS with data replication enabled for both fault tolerance and geospatial indexing efficiency. Given the fault tolerance provided by the HDFS, RS data are structurally stored inside for faster geospatial indexing. Additionally, multi-indexing enhances efficiency. The proposed technique naturally sits on top of the HDFS to form a holistic framework without incurring severe overhead or sophisticated system implementation efforts. The MIX-RS framework is implemented and evaluated using real remote sensing data provided by the Chinese Academy of Sciences, demonstrating excellent geospatial indexing performance.",10.26599/TST.2021.9010082,2022,,MIX-RS: A MULTI-INDEXING SYSTEM BASED ON HDFS FOR REMOTE SENSING DATA STORAGE,
1233,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"The Internet of Things (IoT) implies a worldwide network of interconnected objects uniquely addressable, via standard communication protocols. The prevalence of IoT is bound to generate large amounts of multisource, heterogeneous, dynamic, and sparse data. However, IoT offers inconsequential practical benefits without the ability to integrate, fuse, and glean useful information from such massive amounts of data. Accordingly, preparing us for the imminent invasion of things, a tool called data fusion can be used to manipulate and manage such data in order to improve process efficiency and provide advanced intelligence. In order to determine an acceptable quality of intelligence, diverse and voluminous data have to be combined and fused. Therefore, it is imperative to improve the computational efficiency for fusing and mining multidimensional data. In this paper, we propose an efficient multidimensional fusion algorithm for IoT data based on partitioning. The basic concept involves the partitioning of dimensions (attributes), i.e., a big data set with higher dimensions can be transformed into certain number of relatively smaller data subsets that can be easily processed. Then, based on the partitioning of dimensions, the discernible matrixes of all data subsets in rough set theory are computed to obtain their core attribute sets. Furthermore, a global core attribute set can be determined. Finally, the attribute reduction and rule extraction methods are used to obtain the fusion results. By means of proving a few theorems and simulation, the correctness and effectiveness of this algorithm is illustrated.",10.1109/TST.2013.6574675,2013,,AN EFFICIENT MULTIDIMENSIONAL FUSION ALGORITHM FOR IOT DATA BASED ON PARTITIONING,
1234,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"Collaborative filtering solves information overload problem by presenting personalized content to individual users based on their interests, which has been extensively applied in real-world recommender systems. As a class of simple but efficient collaborative filtering method, similarity based approaches make predictions by finding users with similar taste or items that have been similarly chosen. However, as the number of users or items grows rapidly, the traditional approach is suffering from the data sparsity problem. Inaccurate similarities derived from the sparse user-item associations would generate the inaccurate neighborhood for each user or item. Consequently, its poor recommendation drives us to propose a Threshold based Similarity Transitivity (TST) method in this paper. TST firstly filters out those inaccurate similarities by setting an intersection threshold and then replaces them with the transitivity similarity. Besides, the TST method is designed to be scalable with MapReduce framework based on cloud computing platform. We evaluate our algorithm on the public data set MovieLens and a real-world data set from AppChina (an Android application market) with several well-known metrics including precision, recall, coverage, and popularity. The experimental results demonstrate that TST copes well with the tradeoff between quality and quantity of similarity by setting an appropriate threshold. Moreover, we can experimentally find the optimal threshold which will be smaller as the data set becomes sparser. The experimental results also show that TST significantly outperforms the traditional approach even when the data becomes sparser.",10.1109/TST.2013.6522590,2013,,TST: THRESHOLD BASED SIMILARITY TRANSITIVITY METHOD IN COLLABORATIVE FILTERING WITH CLOUD COMPUTING,
1235,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"Discovering regularities between entities in temporal graphs is vital for many real-world applications (e.g., social recommendation, emergency event detection, and cyberattack event detection). This paper proposes temporal graph association rules (TGARs) that extend traditional graph-pattern association rules in a static graph by incorporating the unique temporal information and constraints. We introduce quality measures (e.g., support, confidence, and diversification) to characterize meaningful TGARs that are useful and diversified. In addition, the proposed support metric is an upper bound for alternative metrics, allowing us to guarantee a superset of patterns. We extend conventional confidence measures in terms of maximal occurrences of TGARs. The diversification score strikes a balance between interestingness and diversity. Although the problem is NP-hard, we develop an effective discovery algorithm for TGARs that integrates TGARs generation and TGARs selection and shows that mining TGARs is feasible over a temporal graph. We propose pruning strategies to filter TGARs that have low support or cannot make top-$k$ as early as possible. Moreover, we design an auxiliary data structure to prune the TGARs that do not meet the constraints during the TGARs generation process to avoid conducting repeated subgraph matching for each extension in the search space. We experimentally verify the effectiveness, efficiency, and scalability of our algorithms in discovering diversified top-$k$ TGARs from temporal graphs in real-life applications.",10.26599/TST.2021.9010090,2023,,DISCOVERING ASSOCIATION RULES WITH GRAPH PATTERNS IN TEMPORAL NETWORKS,
1236,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"Internet of Things (IoT) is a new paradigm that the ubiquitous smart objects, such as devices, vehicles, buildings, etc., interact and exchange data through emerging wireless technology with the intention of improving people's quality of lives in variety areas, such as transportation, manufacturing industry, health care industry, etc. Besides benefits, this envisioned paradigm also poses unprecedented challenges in many respects, including identification of things, privacy and security issues, integration and management of big sensory data, sensing and delivering information from dynamic environments, utilization of knowledge-based decision systems, connectivity issues, etc.",10.23919/TST.2017.7986937,2017,,GUEST EDITORIAL: SPECIAL ISSUE ON INTERNET OF THINGS,
1237,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"In the era of big data, data intensive applications have posed new challenges to the field of service composition. How to select the optimal composited service from thousands of functionally equivalent services but different Quality of Service (QoS ) attributes has become a hot research in service computing. As a consequence, in this paper, we propose a novel algorithm MR-IDPSO (MapReduce based on Improved Discrete Particle Swarm Optimization), which makes use of the improved discrete Particle Swarm Optimization (PSO) with the MapReduce to solve large-scale dynamic service composition. Experiments show that our algorithm outperforms the parallel genetic algorithm in terms of solution quality and is efficient for large-scale dynamic service composition. In addition, the experimental results also demonstrate that the performance of MR-IDPSO becomes more better with increasing number of candidate services.",10.1109/TST.2015.7349932,2015,,MR-IDPSO: A NOVEL ALGORITHM FOR LARGE-SCALE DYNAMIC SERVICE COMPOSITION,
1238,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"This special issue on Cloud Computing and Big Data of Tsinghua Science and Technology is devoted to gather and present new research that address the challenges in the broad areas of Cloud Computing and Big Data. Despite being popular topics in both industry and academia, Cloud Computing and Big Data are having more unsolved problems, not fewer. Challenging problems include key enabling technologies like virtualization and software defined network, powerful data process like deep learning and No-SQL, energy efficiency, privacy and policy, new ecosystem and many more. This Special Issue therefore aims to publish high quality, original, unpublished research papers in the broad area of Cloud Computing and Big Data, and thus presents a platform for scientists and scholars to share their observations and research results in the field.",10.1109/TST.2013.6574681,2013,,CALL FOR PAPERS SPECIAL ISSUE OF TSINGHUA SCIENCE AND TECHNOLOGY ON CLOUD COMPUTING AND BIG DATA,
1239,25522,TSINGHUA SCIENCE AND TECHNOLOGY,journal,10070214,"0,428",Q1,43,69,200,2169,564,199,"2,79","31,43",China,Asiatic Region,Tsing Hua University,2003-2021,Multidisciplinary (Q1),"1,474",2.016,0.00116,"This special section on Smart Grid of Tsinghua Science and Technology is devoted to gather and present new research that addresses the challenges in the broad area of Smart Grid. Smart Grid uses information and communications technology, such as Big Data, Internet of Thing (IoT), and new network technology, to transform electrical grid to be more intelligent and active to gather information about the behaviors of suppliers and consumers, in an automated fashion to improve the efficiency, reliability, and sustainability of the generation and distribution of electricity energy. This special section therefore aims to publish high quality, original, unpublished research papers in the broad area of Smart Grid, and thus presents a platform for scientists and scholars to share their observations and research results in the field.",10.1109/TST.2013.6616528,2013,,CALL FOR PAPERS SPECIAL SECTION OF TSINGHUA SCIENCE AND TECHNOLOGY ON SMART GRID,
1240,21100201770,HEALTH POLICY AND TECHNOLOGY,journal,22118837,"0,393",Q3,21,86,168,3120,325,151,"1,84","36,28",Netherlands,Western Europe,,2012-2020,Biomedical Engineering (Q3); Health Policy (Q3),630,1.931,0.0009,"Background
Big data analytics are becoming more prevalent due to the recent availability of health data. Yet in spite of evidence supporting the potential contribution of big data analytics to health policy makers and care providers, these tools are still too complex to be routinely used. Further, access to comprehensive datasets required for more accurate results is complex and costly. Consequently, big data analytics are mostly used by researchers and experts who are far removed from actual clinical practice. Hence, policy makers should allocate resources to encourage studies that clarify and simplify big data analytics so it can be used by non-experts (e.g., clinicians, practitioners and decision-makers who may not have advanced computer skills). It is also important to fund data collection and integration from various health IT, a pre-condition for any big data analytics project.
Objectives
To methodologically clarify the rationale and logic behind several analytics algorithms to help non-expert users employ big data analytics by understanding how to implement relatively easy to use platforms as Azure ML.
Methods
We demonstrate the predictive power of four known algorithms and compare their accuracy in predicting early mortality of Congestive Heart Failure (CHF) patients.
Results
The results of our models outperform those reported in the literature, attesting to the strength of some of the models, and the utility of comprehensive data.
Conclusions
The results support our call to policy makers to allocate resources to establishing comprehensive, integrated health IT systems, and to projects aimed at simplifying ML analytics.",https://doi.org/10.1016/j.hlpt.2018.12.003,2019,Ofir Ben-Assuli and Tsipi Heart and Nir Shlomo and Robert Klempfner,BRINGING BIG DATA ANALYTICS CLOSER TO PRACTICE: A METHODOLOGICAL EXPLANATION AND DEMONSTRATION OF CLASSIFICATION ALGORITHMS,article
1241,28580,RADIO SCIENCE,journal,1944799X,"0,371",Q2,84,102,334,3695,565,327,"1,68","36,23",United States,Northern America,Wiley-Blackwell,1966-2020,Earth and Planetary Sciences (miscellaneous) (Q2); Electrical and Electronic Engineering (Q2); Condensed Matter Physics (Q3),"5,181",1.431,0.00275,"Newly acquired multi-receiver capability of Advanced Indian MST radar has been utilized to implement the spaced antenna (SA) technique for profiling of winds and turbulence. Two experiments were conducted. In Experiment 1, in addition to the traditional Full Correlation Analysis (FCA), SA analysis is also performed on off-vertical beam measurements (hereafter Oblique Spaced Antenna [OSA]) and the products are evaluated against those retrieved with Doppler Beam Swinging (DBS) and collocated GPS radiosonde. In Experiment 2, the dependence of height coverage on antenna aperture is examined. The synchronization and phase matching of receiving channels are found to be well within the designed values. The consensus averaged zonal and meridional wind velocities obtained by FCA and OSA compare very well with DBS and radiosonde measurements with correlation coefficients >0.85 and root mean square error (RMSE) < 2 ms−1. The mean value of antenna parameter, ah, extracted from correlation of different antenna pairs compare well with the theoretical estimate. The efficacy of ah in quality controlling the SA derived winds has been examined. Imposing ah condition has certainly removed several outliers and reduced the RMSE (relative to reference) considerably, but it also reduced useful data by 50%. The consensus averaging of winds is found to be more effective in removing outliers and reducing the RMSE. The wind variances estimated by DBS (after accounting the non-turbulent contributions) and SA agree quite well with a correlation coefficient of 0.95. Utilization of a bigger array increased the height coverage from 10–12 to 20 km.",10.1029/2021RS007263,2021,,MULTI-RECEIVER AUGMENTATION TO ADVANCED INDIAN MST RADAR (AIR)—IMPLEMENTATION OF SPACED ANTENNA TECHNIQUE,
1242,26437,SOCIAL SCIENCE JOURNAL,journal,03623319,"0,349",Q2,39,138,198,8250,340,194,"1,61","59,78",United States,Northern America,Elsevier Inc.,"1978, 1980, 1982-2020",Sociology and Political Science (Q2); Social Psychology (Q3),"1,817",2.376,0.00167,"This review discusses practical benefits and limitations of novel data-driven research for social scientists in general and criminologists in particular by providing a comprehensive examination of the matter. Specifically, this study is an attempt to critically evaluate ‘big data’, data-driven perspectives, and their epistemological value for both scholars and practitioners, particularly those working on crime. It serves as guidance for those who are interested in data-driven research by pointing out new research avenues. In addition to the benefits, the drawbacks associated with data-driven approaches are also discussed. Finally, critical problems that are emerging in this era, such as privacy and ethical concerns are highlighted.",https://doi.org/10.1016/j.soscij.2018.10.010,2019,Turgut Ozkan,CRIMINOLOGY IN THE AGE OF DATA EXPLOSION: NEW DIRECTIONS,article
1243,18370,MEDICINA INTENSIVA,journal,02105691,"0,336",Q3,28,237,401,4303,416,346,"0,98","18,16",Spain,Western Europe,"Ediciones Doyma, S.L.",1988-2020,Critical Care and Intensive Care Medicine (Q3),"1,177",2.491,0.00147,"The introduction of clinical information systems (CIS) in Intensive Care Units (ICUs) offers the possibility of storing a huge amount of machine-ready clinical data that can be used to improve patient outcomes and the allocation of resources, as well as suggest topics for randomized clinical trials. Clinicians, however, usually lack the necessary training for the analysis of large databases. In addition, there are issues referred to patient privacy and consent, and data quality. Multidisciplinary collaboration among clinicians, data engineers, machine-learning experts, statisticians, epidemiologists and other information scientists may overcome these problems. A multidisciplinary event (Critical Care Datathon) was held in Madrid (Spain) from 1 to 3 December 2017. Under the auspices of the Spanish Critical Care Society (SEMICYUC), the event was organized by the Massachusetts Institute of Technology (MIT) Critical Data Group (Cambridge, MA, USA), the Innovation Unit and Critical Care Department of San Carlos Clinic Hospital, and the Life Supporting Technologies group of Madrid Polytechnic University. After presentations referred to big data in the critical care environment, clinicians, data scientists and other health data science enthusiasts and lawyers worked in collaboration using an anonymized database (MIMIC III). Eight groups were formed to answer different clinical research questions elaborated prior to the meeting. The event produced analyses for the questions posed and outlined several future clinical research opportunities. Foundations were laid to enable future use of ICU databases in Spain, and a timeline was established for future meetings, as an example of how big data analysis tools have tremendous potential in our field.
Resumen
La aparición de los sistemas de información clínica (SIC) en el entorno de los cuidados intensivos brinda la posibilidad de almacenar una ingente cantidad de datos clínicos en formato electrónico durante el ingreso de los pacientes. Estos datos pueden ser empleados posteriormente para obtener respuestas a preguntas clínicas, para su uso en la gestión de recursos o para sugerir líneas de investigación que luego pueden ser explotadas mediante ensayos clínicos aleatorizados. Sin embargo, los médicos clínicos carecen de la formación necesaria para la explotación de grandes bases de datos, lo que supone un obstáculo para aprovechar esta oportunidad. Además, existen cuestiones de índole legal (seguridad, privacidad, consentimiento de los pacientes) que deben ser abordadas para poder utilizar esta potente herramienta. El trabajo multidisciplinar con otros profesionales (analistas de datos, estadísticos, epidemiólogos, especialistas en derecho aplicado a grandes bases de datos), puede resolver estas cuestiones y permitir utilizar esta herramienta para investigación clínica o análisis de resultados (benchmarking). Se describe la reunión multidisciplinar (Critical Care Datathon) realizada en Madrid los días 1, 2 y 3 de diciembre de 2017. Esta reunión, celebrada bajo los auspicios de la Sociedad Española de Medicina Intensiva, Crítica y Unidades Coronarias (SEMICYUC) entre otros, fue organizada por el Massachusetts Institute of Technology (MIT), la Unidad de Innovación y el Servicio de Medicina Intensiva del Hospital Clínico San Carlos, así como el grupo de investigación «Life Supporting Technologies» de la Universidad Politécnica de Madrid. Tras unas ponencias de formación sobre big data, seguridad y calidad de los datos, y su aplicación al entorno de la medicina intensiva, un grupo de clínicos, analistas de datos, estadísticos, expertos en seguridad informática de datos realizaron sesiones de trabajo colaborativo en grupos utilizando una base de datos reales anonimizada (MIMIC III), para analizar varias preguntas clínicas establecidas previamente a la reunión. El trabajo colaborativo permitió establecer resultados relevantes con respecto a las preguntas planteadas y esbozar varias líneas de investigación clínica a desarrollar en el futuro. Además, se sentaron las bases para poder utilizar las bases de datos de las UCI con las que contamos en España, y se estableció un calendario de trabajo para planificar futuras reuniones contando con los datos de nuestras unidades. El empleo de herramientas de big data y el trabajo colaborativo con otros profesionales puede permitir ampliar los horizontes en aspectos como el control de calidad de nuestra labor cotidiana, la comparación de resultados entre unidades o la elaboración de nuevas líneas de investigación clínica.",https://doi.org/10.1016/j.medin.2018.06.002,2019,Antonio {Núñez Reiz} and Fernando {Martínez Sagasti} and Manuel {Álvarez González} and Antonio {Blesa Malpica} and Juan Carlos {Martín Benítez} and Mercedes {Nieto Cabrera} and Ángela {del Pino Ramírez} and José Miguel {Gil Perdomo} and Jesús {Prada Alonso} and Leo Anthony Celi and Miguel Ángel {Armengol de la Hoz} and Rodrigo Deliberato and Kenneth Paik and Tom Pollard and Jesse Raffa and Felipe Torres and Julio Mayol and Joan Chafer and Arturo {González Ferrer} and Ángel Rey and Henar {González Luengo} and Giuseppe Fico and Ivana Lombroni and Liss Hernandez and Laura López and Beatriz Merino and María Fernanda Cabrera and María Teresa Arredondo and María Bodí and Josep Gómez and Alejandro Rodríguez and Miguel {Sánchez García},BIG DATA AND MACHINE LEARNING IN CRITICAL CARE: OPPORTUNITIES FOR COLLABORATIVE RESEARCH,article
1244,25547,INTERACTING WITH COMPUTERS,journal,18737951,"0,328",Q3,82,31,112,1881,237,112,"2,12","60,68",United Kingdom,Western Europe,Oxford University Press,1989-2020,Human-Computer Interaction (Q3); Software (Q3),"1,685",1.174,0.00082,"Speech recognition technology continues to improve, but users still experience significant difficulty using the software to create and edit documents. The reported composition speed using speech software is only between 8 and 15 words per minute [Proc CHI 99 (1999) 568; Universal Access Inform Soc 1 (2001) 4], much lower than people’s normal speaking speed of 125–150 words per minute. What causes the huge gap between natural speaking and composing using speech recognition? Is it possible to narrow the gap and make speech recognition more promising to users? In this paper we discuss users’ learning processes and the difficulties they experience as related to continuous dictation tasks using state of the art Automatic Speech Recognition (ASR) software. Detailed data was collected for the first time on various aspects of the three activities involved in document composition tasks: dictation, navigation, and correction. The results indicate that navigation and error correction accounted for big chunk of the dictation task during the early stages of interaction. As users gained more experience, they became more efficient at dictation, navigation and error correction. However, the major improvements in productivity were due to dictation quality and the usage of navigation commands. These results provide insights regarding the factors that cause the gap between user expectation with speech recognition software and the reality of use, and how those factors changed with experience. Specific advice is given to researchers as to the most critical issues that must be addressed.",10.1016/j.intcom.2004.06.013,2005,,HOW PRODUCTIVITY IMPROVES IN HANDS-FREE CONTINUOUS DICTATION TASKS: LESSONS LEARNED FROM A LONGITUDINAL STUDY,
1245,15552,MICROPROCESSORS AND MICROSYSTEMS,journal,01419331,"0,323",Q3,38,462,428,12804,962,423,"2,34","27,71",Netherlands,Western Europe,Elsevier,1978-2020,Artificial Intelligence (Q3); Computer Networks and Communications (Q3); Hardware and Architecture (Q3); Software (Q3),"1,490",1.525,0.00207,"Cross-Language Information Retrieval (CLIR) the purpose of another language (target language), a collection of documents written question from one language (source language).CLIR employees publish documents based on user queries, dictionary translation, machine translation methods, and promotion problems. Through various detection methods and translation, this word applies to single words, translation, transliteration of names, including transcription and translation and disambiguation. CLIR Recovery in Question Semantics Technology is the most appropriate) Translation to retrieve documents (dictionary related method) based on English Question Concentrations and Question translation. To the proposed model of translating Arabic to English, and provides the high accuracy Optical Character Recognition (OCR) errors in handling orthography, expanding outside and transliteration dubbed gives higher accuracy in resolving ambiguities. Thus, the single question expands with additional meanings and related words that improve significantly with semantic input. However, the documents related to the questions recover those cross language boundaries. The development of large data systems is completely different from the actual goal of small (traditional, structured) data system development. When the in-depth learning technology is developed, face some space and environmental barriers in different laboratory environments. To describe the requirements when running embedded applications on computers for deep learning.",https://doi.org/10.1016/j.micpro.2021.103928,2021,Zhihong Li,SEARCH QUERY OF ENGLISH TRANSLATION TEXT BASED ON EMBEDDED SYSTEM AND BIG DATA,article
1246,15552,MICROPROCESSORS AND MICROSYSTEMS,journal,01419331,"0,323",Q3,38,462,428,12804,962,423,"2,34","27,71",Netherlands,Western Europe,Elsevier,1978-2020,Artificial Intelligence (Q3); Computer Networks and Communications (Q3); Hardware and Architecture (Q3); Software (Q3),"1,490",1.525,0.00207,"Data mining and big data computing are the emerging domains in the current era of predictions for societal applications. Millions of people are interested in sharing their views through tweets. Healthcare predictions are one of the attractive researches in big data social mining. Healthcare predictions are derived by implementing topic models by the ailments data. An ailment refers to either illness or sign of a particular health problem. Millions of tweets are collected based on conditions and assessed with ailment topic aspect models. The existing topic model, Latent Dirichlet Allocation (LDA), Latent Semantic Indexing, Probabilistic LSI (PLSI), limits the healthcare results assessment concerning any one of the ailments aspects. Recent ailments topic aspect model (ATAM) overcome the problems of these topic models and delivers the healthcare assessment results concerning the fundamental aspects of ailments data except side-effects analysis of treatments. The scalability performance of ATAM is degraded in showing healthcare results over the massive amounts of health data. A high-performance computing model of ATAM has been developed in the distributed environment to address scalability. Its intelligent model is designed in the cloud and multi-node Hadoop environment to deliver high-performance social computing results for healthcare. Experiments are conducted on many comparative studies is demonstrated between the existing and proposed high-performance models using the massive amount of health-related tweets concerning the ailments aspects.",https://doi.org/10.1016/j.micpro.2022.104690,2022,K Narasimhulu and K.T. {Meena Abarna},HIGH PERFORMANCE SOCIAL DATA COMPUTING WITH DEVELOPMENT OF INTELLIGENT TOPIC MODELS FOR HEALTHCARE,article
1247,27632,CRITICAL CARE NURSING CLINICS OF NORTH AMERICA,journal,08995885,"0,320",Q3,29,51,164,1964,188,140,"1,04","38,51",United Kingdom,Western Europe,W.B. Saunders Ltd,1989-2020,Critical Care Nursing (Q3),592,1.326,0.00061,,https://doi.org/10.1016/j.cnc.2018.07.005,2018,Lynn E. Bayne,"BIG DATA IN NEONATAL HEALTH CARE: BIG REACH, BIG REWARD?",article
1248,23792,COMPUTER JOURNAL,journal,14602067,"0,319",Q2,64,121,347,4405,580,346,"1,78","36,40",United Kingdom,Western Europe,Oxford University Press,1967-2020,Computer Science (miscellaneous) (Q2),"4,057",1.494,0.00224,"Regular expressions have been widely studied due to their expressiveness and flexibility for various applications. A common yet challenging way to ensure the quality of regular expressions is regular expression testing. In this work, we study coverage criteria-based string generation for testing regular expressions. First, we propose a notion of pairwise coverage criterion for regular expressions and analyze the subsumption relationships with existing coverage criteria for both regular grammars and finite automata. Second, we design an algorithm that given as an input a regular expression, outputs a small set of strings that satisfies the pairwise coverage criterion. Third, we extend the coverage criterion and the generation algorithm to further deal with regular operators counting and interleaving. Fourth, we experimentally demonstrate the effectiveness and efficiency of our algorithms by testing element-type definitions of real-world XML schemas. Finally, we identify more applications of pairwise coverage and its corresponding generation algorithm and show that they can be used to generate characteristic samples for certain regular expression learning algorithms that follow Gold's learning paradigm of learning (identification) in the limit. These results are not only theoretically meaningful but also useful for practical applications involved with regular expressions.",10.1093/comjnl/bxy137,2020,,STRING GENERATION FOR TESTING REGULAR EXPRESSIONS,
1249,21100904890,JOURNAL OF COMPUTER LANGUAGES,journal,25901184,"0,254",Q3,6,36,49,1889,104,47,"2,12","52,47",United Kingdom,Western Europe,Elsevier Ltd.,2019-2020,Computer Networks and Communications (Q3); Human-Computer Interaction (Q3); Software (Q3),78,1.271,0.0001,"We present BiDaML 2.0, an integrated suite of visual languages and supporting tool to help multidisciplinary teams with the design of big data analytics solutions. BiDaML tool support provides a platform for efficiently producing BiDaML diagrams and facilitating their design, creation, report and code generation. We evaluated BiDaML using two types of evaluations, a theoretical analysis using the “physics of notations”, and an empirical study with 1) a group of 12 target end-users and 2) five individual end-users. Participants mostly agreed that BiDaML was straightforward to understand/learn, and prefer BiDaML for supporting complex data analytics solution modeling than other modeling languages.",https://doi.org/10.1016/j.cola.2020.100964,2020,Hourieh Khalajzadeh and Andrew J. Simmons and Mohamed Abdelrazek and John Grundy and John Hosking and Qiang He,AN END-TO-END MODEL-BASED APPROACH TO SUPPORT BIG DATA ANALYTICS DEVELOPMENT,article
1250,19700181218,IEEE LATIN AMERICA TRANSACTIONS,journal,15480992,"0,251",Q3,26,176,964,5055,975,959,"0,92","28,72",United States,Northern America,IEEE Computer Society,2003-2020,Computer Science (miscellaneous) (Q3); Electrical and Electronic Engineering (Q3),"1,792",0.729,0.00215,"The Electrical Load data are stored in each time interval generating big databases with high dimensional data. Each data stored contains significant information that can assist the planning and operation of electrical system. In the data analysis step, many aspects must be considered such as the data consistency and the identification and treatment of outliers. This is a critical step because data quality is directly reflected in the results of the planning and operation of electrical system. This paper proposes two models for the identification and treatment of outliers in electrical load data. The first model was built using the ensemble technique through a combination of individual models. The second model was created from an expert system that uses a rules database to detect outliers. The processing of the outliers detected is conducted through a combination of non-outliers load in the same time interval. To evaluate the performance, the models were applied in a historical load database measured in the Northeast of Brazil during year of 2006. The results showed that the proposed models showed satisfactory results in terms of detection as well in the treatment of outliers.",10.1109/TLA.2016.7786306,2016,,INTELLIGENT MODELS TO IDENTIFICATION AND TREATMENT OF OUTLIERS IN ELECTRICAL LOAD DATA,
1251,27052,AORN JOURNAL,journal,00012092,"0,222",Q2,43,288,682,2461,276,475,"0,25","8,55",United States,Northern America,John Wiley &amp; Sons Inc.,1963-2020,Medical and Surgical Nursing (Q2),"1,553",0.676,0.0013,"Big data are large volumes of digital data that can be collected from disparate sources and are challenging to analyze. These data are often described with the five “Vs”: volume, velocity, variety, veracity, and value. Perioperative nurses contribute to big data through documentation in the electronic health record during routine surgical care, and these data have implications for clinical decision making, administrative decisions, quality improvement, and big data science. This article explores methods to improve the quality of perioperative nursing data and provides examples of how these data can be combined with broader nursing data for quality improvement. We also discuss a national action plan for nursing knowledge and big data science and how perioperative nurses can engage in collaborative actions to transform health care. Standardized perioperative nursing data has the potential to affect care far beyond the original patient.",https://doi.org/10.1016/j.aorn.2016.07.009,2016,Bonnie L. Westra and Jessica J. Peterson,BIG DATA AND PERIOPERATIVE NURSING,article
1252,20786,BELL LABS TECHNICAL JOURNAL,journal,10897089,"0,120",Q4,42,1,3,57,2,3,"0,50","57,00",United States,Northern America,John Wiley and Sons Inc.,"1985-2015, 2017, 2019",Electrical and Electronic Engineering (Q4),416,0.333,0.00011,"In an environment where communications service providers (CSPs) increasingly have the same service offers and devices, offering a superior customer experience is a priority to compete. Solutions that have the ability to highlight what really matters in driving customer satisfaction and deliver actionable insights from their wide-reaching customer, network, and service data are key differentiators for CSPs. This paper explores ways of integrating big data insights with automated and assisted processes related to key customer touchpoints to ultimately improve the customer experience. We show how innovation from Alcatel-Lucent and Bell Labs helps CSPs improve their business performance, using unique methodology designed to select the right key quality indicators, build accurate key business objective “formula,” predict customer behavior, and ultimately understand which factors are influencing the most. This can be used for example to improve the Net Promoter Score (NPS). The net result is a happier customer and a higher customer value.",10.1002/bltj.21642,2014,,USING BIG DATA TO IMPROVE CUSTOMER EXPERIENCE AND BUSINESS PERFORMANCE,
1253,21101017898,CSEE JOURNAL OF POWER AND ENERGY SYSTEMS,journal,20960042,"0,118",Q4,4,43,148,1634,27,148,"0,18","38,00",United States,Northern America,Institute of Electrical and Electronics Engineers Inc.,2020,"Electrical and Electronic Engineering (Q4); Electronic, Optical and Magnetic Materials (Q4); Energy (miscellaneous) (Q4)","1,205",3.938,0.0027,"In order to improve the data quality, the big data cleaning method of distribution network was studied in this paper. First, the Local Outlier Factor (LOF) algorithm based on DBSCAN clustering was used to detect outliers. However, due to the difficulty in determining the LOF threshold, a method of dynamically calculating the threshold based on the transformer districts and time was proposed. Besides, the LOF algorithm combines the statistical distribution method to reduce the ""misjudgment rate"". Aiming at the diversity and complexity of data missing forms in power big data, this paper improved the Random Forest imputation algorithm, which can be applied to various forms of missing data, especially the blocked missing data and even some horizontal or vertical data completely missing. The data in this paper were from real data of 44 transformer districts of a certain 10kV line in distribution network. Experimental results showed that outlier detection was accurate and suitable for any shape and multidimensional power big data. The improved Random Forest imputation algorithm was suitable for all missing forms, with higher imputation accuracy and better model stability. By comparing the network loss prediction between the data using this data cleaning method and the data removing outliers and missing values, it was found that the accuracy of network loss prediction had been improved by nearly 4 percentage points using the data cleaning method mentioned in this paper. Additionally, as the proportion of bad data increased, the difference between the prediction accuracy of cleaned data and that of uncleaned data was greater.",10.17775/CSEEJPES.2020.04080,2020,,A BIG DATA CLEANING METHOD BASED ON IMPROVED CLOF AND RANDOM FOREST FOR DISTRIBUTION NETWORK,
